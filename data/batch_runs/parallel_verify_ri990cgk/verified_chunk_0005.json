[
  {
    "id": "04171",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cirros-vm\n  annotations:\n    kubernetes.io/target-runtime: virtlet.cloud\nspec:\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: extraRuntime\n            operator: In\n            values:\n            - virtlet\n  containers:\n  - name: cirros-vm\n    imagePullPolicy: IfNotPresent\n    image: virtlet.cloud/cirros:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  volumes:\n  - name: raw\n    flexVolume:\n      driver: virtlet/flexvolume_driver\n      options:\n        type: raw\n        path: /dev/loop0\n",
    "errors": []
  },
  {
    "id": "04172",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cirros-vm\n  annotations:\n    kubernetes.io/target-runtime: virtlet.cloud\nspec:\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: extraRuntime\n            operator: In\n            values:\n            - virtlet\n  containers:\n  - name: cirros-vm\n    imagePullPolicy: IfNotPresent\n    image: virtlet.cloud/cirros:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  volumes:\n  - name: raw\n    flexVolume:\n      driver: virtlet/flexvolume_driver\n      options:\n        type: raw\n        path: /dev/loop0\n",
    "errors": []
  },
  {
    "id": "04173",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: test-rc\n  labels:\n    name: test-rc\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: test-rc\n    spec:\n      containers:\n      - name: test-rc\n        image: nginx:stable\n        args:\n        - -random_flag=%s@domain.com\n        ports:\n        - containerPort: 80\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04174",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: test-rc\n  labels:\n    name: test-rc\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: test-rc\n    spec:\n      containers:\n      - name: test-rc\n        image: nginx:stable\n        args:\n        - -random_flag=%s@domain.com\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04175",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: test-rc\n  labels:\n    name: test-rc\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: test-rc\n    spec:\n      containers:\n      - name: test-rc\n        image: nginx:stable\n        args:\n        - -random_flag=%s@domain.com\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04176",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: test-rc\n  labels:\n    name: test-rc\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: test-rc\n    spec:\n      containers:\n      - name: test-rc\n        image: nginx:stable\n        args:\n        - -random_flag=%s@domain.com\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04177",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: test-rc\n  labels:\n    name: test-rc\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: test-rc\n    spec:\n      containers:\n      - name: test-rc\n        image: nginx:stable\n        args:\n        - -random_flag=%s@domain.com\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04178",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: yolo-controller\n  namespace: knative-serving\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: yolo-controller\n  template:\n    metadata:\n      labels:\n        app: yolo-controller\n    spec:\n      serviceAccountName: controller\n      containers:\n      - name: yolo\n        image: github.com/josephburnett/kubecon-seattle-2018/yolo:stable\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04179",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: yolo-controller\n  namespace: knative-serving\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: yolo-controller\n  template:\n    metadata:\n      labels:\n        app: yolo-controller\n    spec:\n      serviceAccountName: controller\n      containers:\n      - name: yolo\n        image: github.com/josephburnett/kubecon-seattle-2018/yolo:stable\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04180",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: yolo-controller\n  namespace: knative-serving\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: yolo-controller\n  template:\n    metadata:\n      labels:\n        app: yolo-controller\n    spec:\n      serviceAccountName: controller\n      containers:\n      - name: yolo\n        image: github.com/josephburnett/kubecon-seattle-2018/yolo:stable\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04181",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: yolo-controller\n  namespace: knative-serving\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: yolo-controller\n  template:\n    metadata:\n      labels:\n        app: yolo-controller\n    spec:\n      serviceAccountName: controller\n      containers:\n      - name: yolo\n        image: github.com/josephburnett/kubecon-seattle-2018/yolo:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04182",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error validating \"STDIN\": error validating data: failed to download openapi: Get \"https://127.0.0.1:55768/openapi/v2?timeout=32s\": net/http: TLS handshake timeout; if you choose to ignore these errors, turn validation off with --validate=false"
    ]
  },
  {
    "id": "04183",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cyborg-seeker-qualifiers-nrfin00009-pov1\n  labels:\n    type: cyborg-seeker\nspec:\n  volumes:\n  - name: cyborg-results\n    persistentVolumeClaim:\n      claimName: cyborg-results\n  containers:\n  - name: cyborg-seeker-qualifiers-nrfin00009-pov1\n    image: zardus/research:cyborg-generator\n    command:\n    - /bin/bash\n    - -c\n    - python /home/angr/cyborg-generator/kubernetes_seeker.py qualifiers NRFIN_00009\n      pov_1 3600\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: cyborg-results\n      mountPath: /results\n    resources:\n      limits:\n        cpu: 500m\n        memory: 10Gi\n      requests:\n        cpu: 100m\n        memory: 10Gi\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04184",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: Error from server (Timeout): error when creating \"STDIN\": Timeout: request did not complete within requested timeout - context deadline exceeded"
    ]
  },
  {
    "id": "04185",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: rmt.example.com:5000/nginx:1.12.0\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04186",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when creating \"STDIN\": Post \"https://127.0.0.1:55768/apis/apps/v1/namespaces/default/deployments?dryRun=All&fieldManager=kubectl-client-side-apply&fieldValidation=Strict\": http2: client connection lost"
    ]
  },
  {
    "id": "04187",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error validating \"STDIN\": error validating data: failed to download openapi: Get \"https://127.0.0.1:55768/openapi/v2?timeout=32s\": net/http: TLS handshake timeout; if you choose to ignore these errors, turn validation off with --validate=false"
    ]
  },
  {
    "id": "04188",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when creating \"STDIN\": Post \"https://127.0.0.1:55768/apis/apps/v1/namespaces/default/deployments?dryRun=All&fieldManager=kubectl-client-side-apply&fieldValidation=Strict\": EOF"
    ]
  },
  {
    "id": "04189",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error validating \"STDIN\": error validating data: failed to download openapi: unknown; if you choose to ignore these errors, turn validation off with --validate=false"
    ]
  },
  {
    "id": "04190",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sleep-1\nspec:\n  selector:\n    matchLabels:\n      app: sleep-1\n  template:\n    metadata:\n      labels:\n        app: sleep-1\n    spec:\n      containers:\n      - name: sleeping-container\n        image: sergiofgonzalez/sleeping-container:stable\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04191",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sleep-1\nspec:\n  selector:\n    matchLabels:\n      app: sleep-1\n  template:\n    metadata:\n      labels:\n        app: sleep-1\n    spec:\n      containers:\n      - name: sleeping-container\n        image: sergiofgonzalez/sleeping-container:stable\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04192",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sleep-1\nspec:\n  selector:\n    matchLabels:\n      app: sleep-1\n  template:\n    metadata:\n      labels:\n        app: sleep-1\n    spec:\n      containers:\n      - name: sleeping-container\n        image: sergiofgonzalez/sleeping-container:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04193",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sleep-1\nspec:\n  selector:\n    matchLabels:\n      app: sleep-1\n  template:\n    metadata:\n      labels:\n        app: sleep-1\n    spec:\n      containers:\n      - name: sleeping-container\n        image: sergiofgonzalez/sleeping-container:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04194",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20220217-362d6ac4a0\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/credentials/service-account.json\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        - --kubernetes-blob-storage-workers=1\n        - --pubsub-workers=5\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        - --gcs-credentials-file=/etc/credentials/service-account.json\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        - name: gcs-service-account\n          mountPath: /etc/credentials\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: workload-clusters-kubeconfig\n      - name: gcs-service-account\n        secret:\n          secretName: sa-crier\n",
    "errors": []
  },
  {
    "id": "04195",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20220217-362d6ac4a0\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/credentials/service-account.json\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        - --kubernetes-blob-storage-workers=1\n        - --pubsub-workers=5\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        - --gcs-credentials-file=/etc/credentials/service-account.json\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        - name: gcs-service-account\n          mountPath: /etc/credentials\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: workload-clusters-kubeconfig\n      - name: gcs-service-account\n        secret:\n          secretName: sa-crier\n",
    "errors": []
  },
  {
    "id": "04196",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20220217-362d6ac4a0\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/credentials/service-account.json\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        - --kubernetes-blob-storage-workers=1\n        - --pubsub-workers=5\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        - --gcs-credentials-file=/etc/credentials/service-account.json\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        - name: gcs-service-account\n          mountPath: /etc/credentials\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: workload-clusters-kubeconfig\n      - name: gcs-service-account\n        secret:\n          secretName: sa-crier\n",
    "errors": []
  },
  {
    "id": "04197",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20220217-362d6ac4a0\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /etc/credentials/service-account.json\n        args:\n        - --blob-storage-workers=1\n        - --config-path=/etc/config/config.yaml\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --github-workers=5\n        - --job-config-path=/etc/job-config\n        - --kubeconfig=/etc/kubeconfig/config\n        - --kubernetes-blob-storage-workers=1\n        - --pubsub-workers=5\n        - --slack-token-file=/etc/slack/token\n        - --slack-workers=1\n        - --gcs-credentials-file=/etc/credentials/service-account.json\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        - name: gcs-service-account\n          mountPath: /etc/credentials\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: workload-clusters-kubeconfig\n      - name: gcs-service-account\n        secret:\n          secretName: sa-crier\n",
    "errors": []
  },
  {
    "id": "04198",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7229\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04199",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7229\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04200",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7229\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04201",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7229\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04202",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-7229\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04203",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ibm-vpc-block-csi-node\" is invalid: spec.template.spec.containers[1].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04204",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ibm-vpc-block-csi-node\" is invalid: spec.template.spec.containers[1].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04205",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ibm-vpc-block-csi-node\" is invalid: spec.template.spec.containers[1].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04206",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ibm-vpc-block-csi-node\" is invalid: spec.template.spec.containers[1].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04207",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ibm-vpc-block-csi-node\" is invalid: spec.template.spec.containers[1].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04208",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ibm-vpc-block-csi-node\" is invalid: spec.template.spec.containers[1].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04209",
    "policy_id": "drop_capabilities",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ibm-vpc-block-csi-node\" is invalid: spec.template.spec.containers[1].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04210",
    "policy_id": "no_privileged",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ibm-vpc-block-csi-node\" is invalid: spec.template.spec.containers[1].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04211",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ibm-vpc-block-csi-node\" is invalid: spec.template.spec.containers[1].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04212",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ibm-vpc-block-csi-node\" is invalid: spec.template.spec.containers[1].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04213",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ibm-vpc-block-csi-node\" is invalid: spec.template.spec.containers[1].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04214",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx7\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: bitnami/nginx:stable\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04215",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx7\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: bitnami/nginx:stable\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04216",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx7\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: bitnami/nginx:stable\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04217",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx7\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: bitnami/nginx:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04218",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx7\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: bitnami/nginx:stable\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04219",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"web\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"www\""
    ]
  },
  {
    "id": "04220",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"web\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"www\""
    ]
  },
  {
    "id": "04221",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"web\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"www\""
    ]
  },
  {
    "id": "04222",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"web\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"www\""
    ]
  },
  {
    "id": "04223",
    "policy_id": "env_var_secret",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": false,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "environment variable STANDARD_AUTHSERVICE_CERT_SECRET_NAME must use secretKeyRef",
      "environment variable WILDCARD_ENDPOINT_CERT_SECRET must use secretKeyRef"
    ]
  },
  {
    "id": "04224",
    "policy_id": "env_var_secret",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": false,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "environment variable STANDARD_AUTHSERVICE_CERT_SECRET_NAME must use secretKeyRef",
      "environment variable WILDCARD_ENDPOINT_CERT_SECRET must use secretKeyRef"
    ]
  },
  {
    "id": "04225",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: enmasse\n    name: address-space-controller\n  name: address-space-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: enmasse\n      name: address-space-controller\n  template:\n    metadata:\n      labels:\n        app: enmasse\n        name: address-space-controller\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 1\n            preference:\n              matchExpressions:\n              - key: node-role.enmasse.io/operator-infra\n                operator: In\n                values:\n                - 'true'\n      containers:\n      - env:\n        - name: JAVA_OPTS\n          value: -verbose:gc\n        - name: ENABLE_EVENT_LOGGER\n          value: 'true'\n        - name: EXPOSE_ENDPOINTS_BY_DEFAULT\n          valueFrom:\n            configMapKeyRef:\n              key: exposeEndpointsByDefault\n              name: address-space-controller-config\n              optional: true\n        - name: ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              key: environment\n              name: address-space-controller-config\n              optional: true\n        - name: TEMPLATE_DIR\n          value: /opt/templates\n        - name: RESOURCES_DIR\n          value: /opt\n        - name: STANDARD_AUTHSERVICE_CONFIG_NAME\n          value: keycloak-config\n        - name: STANDARD_AUTHSERVICE_CREDENTIALS_SECRET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: standard-authservice-credentials-secret-name-secret\n              key: standard_authservice_credentials_secret_name\n        - name: STANDARD_AUTHSERVICE_CERT_SECRET_NAME\n          value: standard-authservice-cert\n        - name: WILDCARD_ENDPOINT_CERT_SECRET\n          valueFrom:\n            configMapKeyRef:\n              key: wildcardEndpointCertSecret\n              name: address-space-controller-config\n              optional: true\n        - name: RESYNC_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: resyncInterval\n              name: address-space-controller-config\n              optional: true\n        - name: RECHECK_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: recheckInterval\n              name: address-space-controller-config\n              optional: true\n        - name: IMAGE_PULL_POLICY\n          value: Always\n        - name: ROUTER_IMAGE\n          value: registry.redhat.io/amq7/amq-interconnect:1.4\n        - name: STANDARD_CONTROLLER_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-standard-controller:dev\n        - name: AGENT_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-agent:dev\n        - name: BROKER_IMAGE\n          value: registry.redhat.io/amq-broker-7/amq-broker-73-openshift:latest\n        - name: BROKER_PLUGIN_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-broker-plugin:dev\n        - name: TOPIC_FORWARDER_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-topic-forwarder:dev\n        - name: MQTT_GATEWAY_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-mqtt-gateway:dev\n        - name: MQTT_LWT_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-mqtt-lwt:dev\n        image: registry.redhat.io/amq7/amq-online-1-address-space-controller:dev\n        imagePullPolicy: Always\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n            scheme: HTTP\n        name: address-space-controller\n        ports:\n        - containerPort: 8080\n          name: http\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n            scheme: HTTP\n        resources:\n          limits:\n            memory: 512Mi\n            cpu: 500m\n          requests:\n            memory: 256Mi\n            cpu: 100m\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      serviceAccountName: address-space-controller\n",
    "errors": []
  },
  {
    "id": "04226",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: enmasse\n    name: address-space-controller\n  name: address-space-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: enmasse\n      name: address-space-controller\n  template:\n    metadata:\n      labels:\n        app: enmasse\n        name: address-space-controller\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 1\n            preference:\n              matchExpressions:\n              - key: node-role.enmasse.io/operator-infra\n                operator: In\n                values:\n                - 'true'\n      containers:\n      - env:\n        - name: JAVA_OPTS\n          value: -verbose:gc\n        - name: ENABLE_EVENT_LOGGER\n          value: 'true'\n        - name: EXPOSE_ENDPOINTS_BY_DEFAULT\n          valueFrom:\n            configMapKeyRef:\n              key: exposeEndpointsByDefault\n              name: address-space-controller-config\n              optional: true\n        - name: ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              key: environment\n              name: address-space-controller-config\n              optional: true\n        - name: TEMPLATE_DIR\n          value: /opt/templates\n        - name: RESOURCES_DIR\n          value: /opt\n        - name: STANDARD_AUTHSERVICE_CONFIG_NAME\n          value: keycloak-config\n        - name: STANDARD_AUTHSERVICE_CREDENTIALS_SECRET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: standard-authservice-credentials-secret-name-secret\n              key: standard_authservice_credentials_secret_name\n        - name: STANDARD_AUTHSERVICE_CERT_SECRET_NAME\n          value: standard-authservice-cert\n        - name: WILDCARD_ENDPOINT_CERT_SECRET\n          valueFrom:\n            configMapKeyRef:\n              key: wildcardEndpointCertSecret\n              name: address-space-controller-config\n              optional: true\n        - name: RESYNC_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: resyncInterval\n              name: address-space-controller-config\n              optional: true\n        - name: RECHECK_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: recheckInterval\n              name: address-space-controller-config\n              optional: true\n        - name: IMAGE_PULL_POLICY\n          value: Always\n        - name: ROUTER_IMAGE\n          value: registry.redhat.io/amq7/amq-interconnect:1.4\n        - name: STANDARD_CONTROLLER_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-standard-controller:dev\n        - name: AGENT_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-agent:dev\n        - name: BROKER_IMAGE\n          value: registry.redhat.io/amq-broker-7/amq-broker-73-openshift:latest\n        - name: BROKER_PLUGIN_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-broker-plugin:dev\n        - name: TOPIC_FORWARDER_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-topic-forwarder:dev\n        - name: MQTT_GATEWAY_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-mqtt-gateway:dev\n        - name: MQTT_LWT_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-mqtt-lwt:dev\n        image: registry.redhat.io/amq7/amq-online-1-address-space-controller:dev\n        imagePullPolicy: Always\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n            scheme: HTTP\n        name: address-space-controller\n        ports:\n        - containerPort: 8080\n          name: http\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n            scheme: HTTP\n        resources:\n          limits:\n            memory: 512Mi\n            cpu: 500m\n          requests:\n            memory: 256Mi\n            cpu: 100m\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      serviceAccountName: address-space-controller\n",
    "errors": []
  },
  {
    "id": "04227",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: enmasse\n    name: address-space-controller\n  name: address-space-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: enmasse\n      name: address-space-controller\n  template:\n    metadata:\n      labels:\n        app: enmasse\n        name: address-space-controller\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 1\n            preference:\n              matchExpressions:\n              - key: node-role.enmasse.io/operator-infra\n                operator: In\n                values:\n                - 'true'\n      containers:\n      - env:\n        - name: JAVA_OPTS\n          value: -verbose:gc\n        - name: ENABLE_EVENT_LOGGER\n          value: 'true'\n        - name: EXPOSE_ENDPOINTS_BY_DEFAULT\n          valueFrom:\n            configMapKeyRef:\n              key: exposeEndpointsByDefault\n              name: address-space-controller-config\n              optional: true\n        - name: ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              key: environment\n              name: address-space-controller-config\n              optional: true\n        - name: TEMPLATE_DIR\n          value: /opt/templates\n        - name: RESOURCES_DIR\n          value: /opt\n        - name: STANDARD_AUTHSERVICE_CONFIG_NAME\n          value: keycloak-config\n        - name: STANDARD_AUTHSERVICE_CREDENTIALS_SECRET_NAME\n          valueFrom:\n            secretKeyRef:\n              name: standard-authservice-credentials-secret-name-secret\n              key: standard_authservice_credentials_secret_name\n        - name: STANDARD_AUTHSERVICE_CERT_SECRET_NAME\n          value: standard-authservice-cert\n        - name: WILDCARD_ENDPOINT_CERT_SECRET\n          valueFrom:\n            configMapKeyRef:\n              key: wildcardEndpointCertSecret\n              name: address-space-controller-config\n              optional: true\n        - name: RESYNC_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: resyncInterval\n              name: address-space-controller-config\n              optional: true\n        - name: RECHECK_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: recheckInterval\n              name: address-space-controller-config\n              optional: true\n        - name: IMAGE_PULL_POLICY\n          value: Always\n        - name: ROUTER_IMAGE\n          value: registry.redhat.io/amq7/amq-interconnect:1.4\n        - name: STANDARD_CONTROLLER_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-standard-controller:dev\n        - name: AGENT_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-agent:dev\n        - name: BROKER_IMAGE\n          value: registry.redhat.io/amq-broker-7/amq-broker-73-openshift:latest\n        - name: BROKER_PLUGIN_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-broker-plugin:dev\n        - name: TOPIC_FORWARDER_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-topic-forwarder:dev\n        - name: MQTT_GATEWAY_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-mqtt-gateway:dev\n        - name: MQTT_LWT_IMAGE\n          value: registry.redhat.io/amq7/amq-online-1-mqtt-lwt:dev\n        image: registry.redhat.io/amq7/amq-online-1-address-space-controller:dev\n        imagePullPolicy: Always\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n            scheme: HTTP\n        name: address-space-controller\n        ports:\n        - containerPort: 8080\n          name: http\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n            scheme: HTTP\n        resources:\n          limits:\n            memory: 512Mi\n            cpu: 500m\n          requests:\n            memory: 256Mi\n            cpu: 100m\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      serviceAccountName: address-space-controller\n",
    "errors": []
  },
  {
    "id": "04228",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dc-api\n  labels:\n    app: dc-api\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: dc-api\n  template:\n    metadata:\n      labels:\n        app: dc-api\n    spec:\n      containers:\n      - name: dc-api\n        image: gcr.io/neural-pattern-278618/dc-api:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n        envFrom:\n        - configMapRef:\n            name: dc-api\n        - secretRef:\n            name: dc-api\n        - secretRef:\n            name: postgres\n        resources:\n          limits:\n            cpu: '0.3'\n            memory: 256Mi\n          requests:\n            cpu: '0.3'\n            memory: 128Mi\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 3\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          periodSeconds: 5\n          initialDelaySeconds: 200\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04229",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dc-api\n  labels:\n    app: dc-api\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: dc-api\n  template:\n    metadata:\n      labels:\n        app: dc-api\n    spec:\n      containers:\n      - name: dc-api\n        image: gcr.io/neural-pattern-278618/dc-api:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n        envFrom:\n        - configMapRef:\n            name: dc-api\n        - secretRef:\n            name: dc-api\n        - secretRef:\n            name: postgres\n        resources:\n          limits:\n            cpu: '0.3'\n            memory: 256Mi\n          requests:\n            cpu: '0.3'\n            memory: 128Mi\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 3\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          periodSeconds: 5\n          initialDelaySeconds: 200\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04230",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dc-api\n  labels:\n    app: dc-api\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: dc-api\n  template:\n    metadata:\n      labels:\n        app: dc-api\n    spec:\n      containers:\n      - name: dc-api\n        image: gcr.io/neural-pattern-278618/dc-api:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n        envFrom:\n        - configMapRef:\n            name: dc-api\n        - secretRef:\n            name: dc-api\n        - secretRef:\n            name: postgres\n        resources:\n          limits:\n            cpu: '0.3'\n            memory: 256Mi\n          requests:\n            cpu: '0.3'\n            memory: 128Mi\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 3\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          periodSeconds: 5\n          initialDelaySeconds: 200\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04231",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dc-api\n  labels:\n    app: dc-api\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: dc-api\n  template:\n    metadata:\n      labels:\n        app: dc-api\n    spec:\n      containers:\n      - name: dc-api\n        image: gcr.io/neural-pattern-278618/dc-api:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n        envFrom:\n        - configMapRef:\n            name: dc-api\n        - secretRef:\n            name: dc-api\n        - secretRef:\n            name: postgres\n        resources:\n          limits:\n            cpu: '0.3'\n            memory: 256Mi\n          requests:\n            cpu: '0.3'\n            memory: 128Mi\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 3\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          periodSeconds: 5\n          initialDelaySeconds: 200\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04232",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: foo\n  name: foo\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: foo\n  template:\n    metadata:\n      labels:\n        app: foo\n    spec:\n      containers:\n      - image: dgkanatsios/simpleapp:stable\n        name: simpleapp\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04233",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: foo\n  name: foo\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: foo\n  template:\n    metadata:\n      labels:\n        app: foo\n    spec:\n      containers:\n      - image: dgkanatsios/simpleapp:stable\n        name: simpleapp\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04234",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: foo\n  name: foo\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: foo\n  template:\n    metadata:\n      labels:\n        app: foo\n    spec:\n      containers:\n      - image: dgkanatsios/simpleapp:stable\n        name: simpleapp\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04235",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: foo\n  name: foo\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: foo\n  template:\n    metadata:\n      labels:\n        app: foo\n    spec:\n      containers:\n      - image: dgkanatsios/simpleapp:stable\n        name: simpleapp\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04236",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: foo\n  name: foo\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: foo\n  template:\n    metadata:\n      labels:\n        app: foo\n    spec:\n      containers:\n      - image: dgkanatsios/simpleapp:stable\n        name: simpleapp\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04237",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: banias-frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: banias-frontend\n  template:\n    metadata:\n      labels:\n        app: banias-frontend\n        k8s-app: banias-frontend\n    spec:\n      initContainers:\n      - name: init-sysctl\n        image: busybox:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sysctl -w net.ipv4.ip_forward=0\n\n          sysctl -w net.ipv4.conf.default.rp_filter=1\n\n          sysctl -w net.ipv4.conf.default.accept_source_route=0\n\n          sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1\n\n          sysctl -w net.ipv4.icmp_ignore_bogus_error_responses=1\n\n          sysctl -w kernel.msgmnb=65536\n\n          sysctl -w kernel.msgmax=65536\n\n          sysctl -w kernel.shmmax=68719476736\n\n          sysctl -w kernel.shmall=4294967296\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w fs.file-max=100000\n\n          sysctl -w net.ipv4.tcp_syncookies=1\n\n          sysctl -w net.ipv4.conf.all.log_martians=0\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w net.ipv4.tcp_max_syn_backlog=30000\n\n          sysctl -w net.ipv4.conf.all.send_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_source_route=0\n\n          sysctl -w net.ipv6.conf.all.forwarding=0\n\n          sysctl -w net.ipv4.tcp_slow_start_after_idle=0\n\n          sysctl -w net.ipv4.tcp_window_scaling=1\n\n          sysctl -w net.ipv4.tcp_timestamp=1\n\n          sysctl -w net.ipv4.tcp_sack=1\n\n          sysctl -w net.ipv4.tcp_congestion_control=htcp\n\n          sysctl -w net.ipv4.tcp_keepalive_time=60\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=10\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_established=300\n\n          sysctl -w net.netfilter.nf_conntrack_generic_timeout=300\n\n          sysctl -w net.ipv4.tcp_max_tw_buckets=2000000\n\n          sysctl -w net.ipv4.tcp_fin_timeout=10\n\n          sysctl -w net.ipv4.tcp_tw_reuse=1\n\n          sysctl -w net.ipv4.tcp_keepalive_intvl=15\n\n          sysctl -w net.ipv4.tcp_keepalive_probes=5\n\n          '\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: banias-frontend\n        image: gcr.io/my-project/banias-frontend:test\n        resources:\n          limits:\n            cpu: '3'\n            memory: 12G\n          requests:\n            cpu: 500m\n            memory: 200Mi\n        volumeMounts:\n        - name: google-cloud-key\n          mountPath: /var/secrets/google\n        ports:\n        - name: http\n          containerPort: 8081\n        - name: prom-metrics\n          containerPort: 8080\n        env:\n        - name: BANIAS_PROJECTID\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PROJECTID\n              name: banias-frontend-config\n        - name: BANIAS_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_DEBUG\n              name: banias-frontend-config\n        - name: BANIAS_TOPIC\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_TOPIC\n              name: banias-frontend-config\n        - name: BANIAS_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PORT\n              name: banias-frontend-config\n        - name: BANIAS_METRICSPORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_METRICSPORT\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXBATCH\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXBATCH\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBAGGRIGATORS\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBAGGRIGATORS\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXPUBLISHDELAY\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXPUBLISHDELAY\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n              name: banias-frontend-config\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/secrets/google/key.json\n        imagePullPolicy: Always\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: google-cloud-key\n        secret:\n          secretName: pubsub-key\n",
    "errors": []
  },
  {
    "id": "04238",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: banias-frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: banias-frontend\n  template:\n    metadata:\n      labels:\n        app: banias-frontend\n        k8s-app: banias-frontend\n    spec:\n      initContainers:\n      - name: init-sysctl\n        image: busybox:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sysctl -w net.ipv4.ip_forward=0\n\n          sysctl -w net.ipv4.conf.default.rp_filter=1\n\n          sysctl -w net.ipv4.conf.default.accept_source_route=0\n\n          sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1\n\n          sysctl -w net.ipv4.icmp_ignore_bogus_error_responses=1\n\n          sysctl -w kernel.msgmnb=65536\n\n          sysctl -w kernel.msgmax=65536\n\n          sysctl -w kernel.shmmax=68719476736\n\n          sysctl -w kernel.shmall=4294967296\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w fs.file-max=100000\n\n          sysctl -w net.ipv4.tcp_syncookies=1\n\n          sysctl -w net.ipv4.conf.all.log_martians=0\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w net.ipv4.tcp_max_syn_backlog=30000\n\n          sysctl -w net.ipv4.conf.all.send_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_source_route=0\n\n          sysctl -w net.ipv6.conf.all.forwarding=0\n\n          sysctl -w net.ipv4.tcp_slow_start_after_idle=0\n\n          sysctl -w net.ipv4.tcp_window_scaling=1\n\n          sysctl -w net.ipv4.tcp_timestamp=1\n\n          sysctl -w net.ipv4.tcp_sack=1\n\n          sysctl -w net.ipv4.tcp_congestion_control=htcp\n\n          sysctl -w net.ipv4.tcp_keepalive_time=60\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=10\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_established=300\n\n          sysctl -w net.netfilter.nf_conntrack_generic_timeout=300\n\n          sysctl -w net.ipv4.tcp_max_tw_buckets=2000000\n\n          sysctl -w net.ipv4.tcp_fin_timeout=10\n\n          sysctl -w net.ipv4.tcp_tw_reuse=1\n\n          sysctl -w net.ipv4.tcp_keepalive_intvl=15\n\n          sysctl -w net.ipv4.tcp_keepalive_probes=5\n\n          '\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: banias-frontend\n        image: gcr.io/my-project/banias-frontend:test\n        resources:\n          limits:\n            cpu: '3'\n            memory: 12G\n          requests:\n            cpu: 500m\n            memory: 200Mi\n        volumeMounts:\n        - name: google-cloud-key\n          mountPath: /var/secrets/google\n        ports:\n        - name: http\n          containerPort: 8081\n        - name: prom-metrics\n          containerPort: 8080\n        env:\n        - name: BANIAS_PROJECTID\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PROJECTID\n              name: banias-frontend-config\n        - name: BANIAS_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_DEBUG\n              name: banias-frontend-config\n        - name: BANIAS_TOPIC\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_TOPIC\n              name: banias-frontend-config\n        - name: BANIAS_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PORT\n              name: banias-frontend-config\n        - name: BANIAS_METRICSPORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_METRICSPORT\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXBATCH\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXBATCH\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBAGGRIGATORS\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBAGGRIGATORS\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXPUBLISHDELAY\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXPUBLISHDELAY\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n              name: banias-frontend-config\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/secrets/google/key.json\n        imagePullPolicy: Always\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: google-cloud-key\n        secret:\n          secretName: pubsub-key\n",
    "errors": []
  },
  {
    "id": "04239",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: banias-frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: banias-frontend\n  template:\n    metadata:\n      labels:\n        app: banias-frontend\n        k8s-app: banias-frontend\n    spec:\n      initContainers:\n      - name: init-sysctl\n        image: busybox:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sysctl -w net.ipv4.ip_forward=0\n\n          sysctl -w net.ipv4.conf.default.rp_filter=1\n\n          sysctl -w net.ipv4.conf.default.accept_source_route=0\n\n          sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1\n\n          sysctl -w net.ipv4.icmp_ignore_bogus_error_responses=1\n\n          sysctl -w kernel.msgmnb=65536\n\n          sysctl -w kernel.msgmax=65536\n\n          sysctl -w kernel.shmmax=68719476736\n\n          sysctl -w kernel.shmall=4294967296\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w fs.file-max=100000\n\n          sysctl -w net.ipv4.tcp_syncookies=1\n\n          sysctl -w net.ipv4.conf.all.log_martians=0\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w net.ipv4.tcp_max_syn_backlog=30000\n\n          sysctl -w net.ipv4.conf.all.send_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_source_route=0\n\n          sysctl -w net.ipv6.conf.all.forwarding=0\n\n          sysctl -w net.ipv4.tcp_slow_start_after_idle=0\n\n          sysctl -w net.ipv4.tcp_window_scaling=1\n\n          sysctl -w net.ipv4.tcp_timestamp=1\n\n          sysctl -w net.ipv4.tcp_sack=1\n\n          sysctl -w net.ipv4.tcp_congestion_control=htcp\n\n          sysctl -w net.ipv4.tcp_keepalive_time=60\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=10\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_established=300\n\n          sysctl -w net.netfilter.nf_conntrack_generic_timeout=300\n\n          sysctl -w net.ipv4.tcp_max_tw_buckets=2000000\n\n          sysctl -w net.ipv4.tcp_fin_timeout=10\n\n          sysctl -w net.ipv4.tcp_tw_reuse=1\n\n          sysctl -w net.ipv4.tcp_keepalive_intvl=15\n\n          sysctl -w net.ipv4.tcp_keepalive_probes=5\n\n          '\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: banias-frontend\n        image: gcr.io/my-project/banias-frontend:test\n        resources:\n          limits:\n            cpu: '3'\n            memory: 12G\n          requests:\n            cpu: 500m\n            memory: 200Mi\n        volumeMounts:\n        - name: google-cloud-key\n          mountPath: /var/secrets/google\n        ports:\n        - name: http\n          containerPort: 8081\n        - name: prom-metrics\n          containerPort: 8080\n        env:\n        - name: BANIAS_PROJECTID\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PROJECTID\n              name: banias-frontend-config\n        - name: BANIAS_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_DEBUG\n              name: banias-frontend-config\n        - name: BANIAS_TOPIC\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_TOPIC\n              name: banias-frontend-config\n        - name: BANIAS_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PORT\n              name: banias-frontend-config\n        - name: BANIAS_METRICSPORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_METRICSPORT\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXBATCH\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXBATCH\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBAGGRIGATORS\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBAGGRIGATORS\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXPUBLISHDELAY\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXPUBLISHDELAY\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n              name: banias-frontend-config\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/secrets/google/key.json\n        imagePullPolicy: Always\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: google-cloud-key\n        secret:\n          secretName: pubsub-key\n",
    "errors": []
  },
  {
    "id": "04240",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: banias-frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: banias-frontend\n  template:\n    metadata:\n      labels:\n        app: banias-frontend\n        k8s-app: banias-frontend\n    spec:\n      initContainers:\n      - name: init-sysctl\n        image: busybox:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sysctl -w net.ipv4.ip_forward=0\n\n          sysctl -w net.ipv4.conf.default.rp_filter=1\n\n          sysctl -w net.ipv4.conf.default.accept_source_route=0\n\n          sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1\n\n          sysctl -w net.ipv4.icmp_ignore_bogus_error_responses=1\n\n          sysctl -w kernel.msgmnb=65536\n\n          sysctl -w kernel.msgmax=65536\n\n          sysctl -w kernel.shmmax=68719476736\n\n          sysctl -w kernel.shmall=4294967296\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w fs.file-max=100000\n\n          sysctl -w net.ipv4.tcp_syncookies=1\n\n          sysctl -w net.ipv4.conf.all.log_martians=0\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w net.ipv4.tcp_max_syn_backlog=30000\n\n          sysctl -w net.ipv4.conf.all.send_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_source_route=0\n\n          sysctl -w net.ipv6.conf.all.forwarding=0\n\n          sysctl -w net.ipv4.tcp_slow_start_after_idle=0\n\n          sysctl -w net.ipv4.tcp_window_scaling=1\n\n          sysctl -w net.ipv4.tcp_timestamp=1\n\n          sysctl -w net.ipv4.tcp_sack=1\n\n          sysctl -w net.ipv4.tcp_congestion_control=htcp\n\n          sysctl -w net.ipv4.tcp_keepalive_time=60\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=10\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_established=300\n\n          sysctl -w net.netfilter.nf_conntrack_generic_timeout=300\n\n          sysctl -w net.ipv4.tcp_max_tw_buckets=2000000\n\n          sysctl -w net.ipv4.tcp_fin_timeout=10\n\n          sysctl -w net.ipv4.tcp_tw_reuse=1\n\n          sysctl -w net.ipv4.tcp_keepalive_intvl=15\n\n          sysctl -w net.ipv4.tcp_keepalive_probes=5\n\n          '\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: banias-frontend\n        image: gcr.io/my-project/banias-frontend:test\n        resources:\n          limits:\n            cpu: '3'\n            memory: 12G\n          requests:\n            cpu: 500m\n            memory: 200Mi\n        volumeMounts:\n        - name: google-cloud-key\n          mountPath: /var/secrets/google\n        ports:\n        - name: http\n          containerPort: 8081\n        - name: prom-metrics\n          containerPort: 8080\n        env:\n        - name: BANIAS_PROJECTID\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PROJECTID\n              name: banias-frontend-config\n        - name: BANIAS_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_DEBUG\n              name: banias-frontend-config\n        - name: BANIAS_TOPIC\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_TOPIC\n              name: banias-frontend-config\n        - name: BANIAS_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PORT\n              name: banias-frontend-config\n        - name: BANIAS_METRICSPORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_METRICSPORT\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXBATCH\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXBATCH\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBAGGRIGATORS\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBAGGRIGATORS\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXPUBLISHDELAY\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXPUBLISHDELAY\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n              name: banias-frontend-config\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/secrets/google/key.json\n        imagePullPolicy: Always\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: google-cloud-key\n        secret:\n          secretName: pubsub-key\n",
    "errors": []
  },
  {
    "id": "04241",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: banias-frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: banias-frontend\n  template:\n    metadata:\n      labels:\n        app: banias-frontend\n        k8s-app: banias-frontend\n    spec:\n      initContainers:\n      - name: init-sysctl\n        image: busybox:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sysctl -w net.ipv4.ip_forward=0\n\n          sysctl -w net.ipv4.conf.default.rp_filter=1\n\n          sysctl -w net.ipv4.conf.default.accept_source_route=0\n\n          sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1\n\n          sysctl -w net.ipv4.icmp_ignore_bogus_error_responses=1\n\n          sysctl -w kernel.msgmnb=65536\n\n          sysctl -w kernel.msgmax=65536\n\n          sysctl -w kernel.shmmax=68719476736\n\n          sysctl -w kernel.shmall=4294967296\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w fs.file-max=100000\n\n          sysctl -w net.ipv4.tcp_syncookies=1\n\n          sysctl -w net.ipv4.conf.all.log_martians=0\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w net.ipv4.tcp_max_syn_backlog=30000\n\n          sysctl -w net.ipv4.conf.all.send_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_source_route=0\n\n          sysctl -w net.ipv6.conf.all.forwarding=0\n\n          sysctl -w net.ipv4.tcp_slow_start_after_idle=0\n\n          sysctl -w net.ipv4.tcp_window_scaling=1\n\n          sysctl -w net.ipv4.tcp_timestamp=1\n\n          sysctl -w net.ipv4.tcp_sack=1\n\n          sysctl -w net.ipv4.tcp_congestion_control=htcp\n\n          sysctl -w net.ipv4.tcp_keepalive_time=60\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=10\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_established=300\n\n          sysctl -w net.netfilter.nf_conntrack_generic_timeout=300\n\n          sysctl -w net.ipv4.tcp_max_tw_buckets=2000000\n\n          sysctl -w net.ipv4.tcp_fin_timeout=10\n\n          sysctl -w net.ipv4.tcp_tw_reuse=1\n\n          sysctl -w net.ipv4.tcp_keepalive_intvl=15\n\n          sysctl -w net.ipv4.tcp_keepalive_probes=5\n\n          '\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: banias-frontend\n        image: gcr.io/my-project/banias-frontend:test\n        resources:\n          limits:\n            cpu: '3'\n            memory: 12G\n          requests:\n            cpu: 500m\n            memory: 200Mi\n        volumeMounts:\n        - name: google-cloud-key\n          mountPath: /var/secrets/google\n        ports:\n        - name: http\n          containerPort: 8081\n        - name: prom-metrics\n          containerPort: 8080\n        env:\n        - name: BANIAS_PROJECTID\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PROJECTID\n              name: banias-frontend-config\n        - name: BANIAS_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_DEBUG\n              name: banias-frontend-config\n        - name: BANIAS_TOPIC\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_TOPIC\n              name: banias-frontend-config\n        - name: BANIAS_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PORT\n              name: banias-frontend-config\n        - name: BANIAS_METRICSPORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_METRICSPORT\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXBATCH\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXBATCH\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBAGGRIGATORS\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBAGGRIGATORS\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXPUBLISHDELAY\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXPUBLISHDELAY\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n              name: banias-frontend-config\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/secrets/google/key.json\n        imagePullPolicy: Always\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: google-cloud-key\n        secret:\n          secretName: pubsub-key\n",
    "errors": []
  },
  {
    "id": "04242",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: banias-frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: banias-frontend\n  template:\n    metadata:\n      labels:\n        app: banias-frontend\n        k8s-app: banias-frontend\n    spec:\n      initContainers:\n      - name: init-sysctl\n        image: busybox:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sysctl -w net.ipv4.ip_forward=0\n\n          sysctl -w net.ipv4.conf.default.rp_filter=1\n\n          sysctl -w net.ipv4.conf.default.accept_source_route=0\n\n          sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1\n\n          sysctl -w net.ipv4.icmp_ignore_bogus_error_responses=1\n\n          sysctl -w kernel.msgmnb=65536\n\n          sysctl -w kernel.msgmax=65536\n\n          sysctl -w kernel.shmmax=68719476736\n\n          sysctl -w kernel.shmall=4294967296\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w fs.file-max=100000\n\n          sysctl -w net.ipv4.tcp_syncookies=1\n\n          sysctl -w net.ipv4.conf.all.log_martians=0\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w net.ipv4.tcp_max_syn_backlog=30000\n\n          sysctl -w net.ipv4.conf.all.send_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_source_route=0\n\n          sysctl -w net.ipv6.conf.all.forwarding=0\n\n          sysctl -w net.ipv4.tcp_slow_start_after_idle=0\n\n          sysctl -w net.ipv4.tcp_window_scaling=1\n\n          sysctl -w net.ipv4.tcp_timestamp=1\n\n          sysctl -w net.ipv4.tcp_sack=1\n\n          sysctl -w net.ipv4.tcp_congestion_control=htcp\n\n          sysctl -w net.ipv4.tcp_keepalive_time=60\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=10\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_established=300\n\n          sysctl -w net.netfilter.nf_conntrack_generic_timeout=300\n\n          sysctl -w net.ipv4.tcp_max_tw_buckets=2000000\n\n          sysctl -w net.ipv4.tcp_fin_timeout=10\n\n          sysctl -w net.ipv4.tcp_tw_reuse=1\n\n          sysctl -w net.ipv4.tcp_keepalive_intvl=15\n\n          sysctl -w net.ipv4.tcp_keepalive_probes=5\n\n          '\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: banias-frontend\n        image: gcr.io/my-project/banias-frontend:test\n        resources:\n          limits:\n            cpu: '3'\n            memory: 12G\n          requests:\n            cpu: 500m\n            memory: 200Mi\n        volumeMounts:\n        - name: google-cloud-key\n          mountPath: /var/secrets/google\n        ports:\n        - name: http\n          containerPort: 8081\n        - name: prom-metrics\n          containerPort: 8080\n        env:\n        - name: BANIAS_PROJECTID\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PROJECTID\n              name: banias-frontend-config\n        - name: BANIAS_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_DEBUG\n              name: banias-frontend-config\n        - name: BANIAS_TOPIC\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_TOPIC\n              name: banias-frontend-config\n        - name: BANIAS_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PORT\n              name: banias-frontend-config\n        - name: BANIAS_METRICSPORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_METRICSPORT\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXBATCH\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXBATCH\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBAGGRIGATORS\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBAGGRIGATORS\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXPUBLISHDELAY\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXPUBLISHDELAY\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n              name: banias-frontend-config\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/secrets/google/key.json\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: google-cloud-key\n        secret:\n          secretName: pubsub-key\n",
    "errors": []
  },
  {
    "id": "04243",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: banias-frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: banias-frontend\n  template:\n    metadata:\n      labels:\n        app: banias-frontend\n        k8s-app: banias-frontend\n    spec:\n      initContainers:\n      - name: init-sysctl\n        image: busybox:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sysctl -w net.ipv4.ip_forward=0\n\n          sysctl -w net.ipv4.conf.default.rp_filter=1\n\n          sysctl -w net.ipv4.conf.default.accept_source_route=0\n\n          sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1\n\n          sysctl -w net.ipv4.icmp_ignore_bogus_error_responses=1\n\n          sysctl -w kernel.msgmnb=65536\n\n          sysctl -w kernel.msgmax=65536\n\n          sysctl -w kernel.shmmax=68719476736\n\n          sysctl -w kernel.shmall=4294967296\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w fs.file-max=100000\n\n          sysctl -w net.ipv4.tcp_syncookies=1\n\n          sysctl -w net.ipv4.conf.all.log_martians=0\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w net.ipv4.tcp_max_syn_backlog=30000\n\n          sysctl -w net.ipv4.conf.all.send_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_source_route=0\n\n          sysctl -w net.ipv6.conf.all.forwarding=0\n\n          sysctl -w net.ipv4.tcp_slow_start_after_idle=0\n\n          sysctl -w net.ipv4.tcp_window_scaling=1\n\n          sysctl -w net.ipv4.tcp_timestamp=1\n\n          sysctl -w net.ipv4.tcp_sack=1\n\n          sysctl -w net.ipv4.tcp_congestion_control=htcp\n\n          sysctl -w net.ipv4.tcp_keepalive_time=60\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=10\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_established=300\n\n          sysctl -w net.netfilter.nf_conntrack_generic_timeout=300\n\n          sysctl -w net.ipv4.tcp_max_tw_buckets=2000000\n\n          sysctl -w net.ipv4.tcp_fin_timeout=10\n\n          sysctl -w net.ipv4.tcp_tw_reuse=1\n\n          sysctl -w net.ipv4.tcp_keepalive_intvl=15\n\n          sysctl -w net.ipv4.tcp_keepalive_probes=5\n\n          '\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: banias-frontend\n        image: gcr.io/my-project/banias-frontend:test\n        resources:\n          limits:\n            cpu: '3'\n            memory: 12G\n          requests:\n            cpu: 500m\n            memory: 200Mi\n        volumeMounts:\n        - name: google-cloud-key\n          mountPath: /var/secrets/google\n        ports:\n        - name: http\n          containerPort: 8081\n        - name: prom-metrics\n          containerPort: 8080\n        env:\n        - name: BANIAS_PROJECTID\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PROJECTID\n              name: banias-frontend-config\n        - name: BANIAS_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_DEBUG\n              name: banias-frontend-config\n        - name: BANIAS_TOPIC\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_TOPIC\n              name: banias-frontend-config\n        - name: BANIAS_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PORT\n              name: banias-frontend-config\n        - name: BANIAS_METRICSPORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_METRICSPORT\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXBATCH\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXBATCH\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBAGGRIGATORS\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBAGGRIGATORS\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXPUBLISHDELAY\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXPUBLISHDELAY\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n              name: banias-frontend-config\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/secrets/google/key.json\n        imagePullPolicy: Always\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: google-cloud-key\n        secret:\n          secretName: pubsub-key\n",
    "errors": []
  },
  {
    "id": "04244",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: banias-frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: banias-frontend\n  template:\n    metadata:\n      labels:\n        app: banias-frontend\n        k8s-app: banias-frontend\n    spec:\n      initContainers:\n      - name: init-sysctl\n        image: busybox:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sysctl -w net.ipv4.ip_forward=0\n\n          sysctl -w net.ipv4.conf.default.rp_filter=1\n\n          sysctl -w net.ipv4.conf.default.accept_source_route=0\n\n          sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1\n\n          sysctl -w net.ipv4.icmp_ignore_bogus_error_responses=1\n\n          sysctl -w kernel.msgmnb=65536\n\n          sysctl -w kernel.msgmax=65536\n\n          sysctl -w kernel.shmmax=68719476736\n\n          sysctl -w kernel.shmall=4294967296\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w fs.file-max=100000\n\n          sysctl -w net.ipv4.tcp_syncookies=1\n\n          sysctl -w net.ipv4.conf.all.log_martians=0\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w net.ipv4.tcp_max_syn_backlog=30000\n\n          sysctl -w net.ipv4.conf.all.send_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_source_route=0\n\n          sysctl -w net.ipv6.conf.all.forwarding=0\n\n          sysctl -w net.ipv4.tcp_slow_start_after_idle=0\n\n          sysctl -w net.ipv4.tcp_window_scaling=1\n\n          sysctl -w net.ipv4.tcp_timestamp=1\n\n          sysctl -w net.ipv4.tcp_sack=1\n\n          sysctl -w net.ipv4.tcp_congestion_control=htcp\n\n          sysctl -w net.ipv4.tcp_keepalive_time=60\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=10\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_established=300\n\n          sysctl -w net.netfilter.nf_conntrack_generic_timeout=300\n\n          sysctl -w net.ipv4.tcp_max_tw_buckets=2000000\n\n          sysctl -w net.ipv4.tcp_fin_timeout=10\n\n          sysctl -w net.ipv4.tcp_tw_reuse=1\n\n          sysctl -w net.ipv4.tcp_keepalive_intvl=15\n\n          sysctl -w net.ipv4.tcp_keepalive_probes=5\n\n          '\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: banias-frontend\n        image: gcr.io/my-project/banias-frontend:test\n        resources:\n          limits:\n            cpu: '3'\n            memory: 12G\n          requests:\n            cpu: 500m\n            memory: 200Mi\n        volumeMounts:\n        - name: google-cloud-key\n          mountPath: /var/secrets/google\n        ports:\n        - name: http\n          containerPort: 8081\n        - name: prom-metrics\n          containerPort: 8080\n        env:\n        - name: BANIAS_PROJECTID\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PROJECTID\n              name: banias-frontend-config\n        - name: BANIAS_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_DEBUG\n              name: banias-frontend-config\n        - name: BANIAS_TOPIC\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_TOPIC\n              name: banias-frontend-config\n        - name: BANIAS_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PORT\n              name: banias-frontend-config\n        - name: BANIAS_METRICSPORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_METRICSPORT\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXBATCH\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXBATCH\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBAGGRIGATORS\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBAGGRIGATORS\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXPUBLISHDELAY\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXPUBLISHDELAY\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n              name: banias-frontend-config\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/secrets/google/key.json\n        imagePullPolicy: Always\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: google-cloud-key\n        secret:\n          secretName: pubsub-key\n",
    "errors": []
  },
  {
    "id": "04245",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: banias-frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: banias-frontend\n  template:\n    metadata:\n      labels:\n        app: banias-frontend\n        k8s-app: banias-frontend\n    spec:\n      initContainers:\n      - name: init-sysctl\n        image: busybox:stable\n        command:\n        - /bin/sh\n        - -c\n        - 'sysctl -w net.ipv4.ip_forward=0\n\n          sysctl -w net.ipv4.conf.default.rp_filter=1\n\n          sysctl -w net.ipv4.conf.default.accept_source_route=0\n\n          sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1\n\n          sysctl -w net.ipv4.icmp_ignore_bogus_error_responses=1\n\n          sysctl -w kernel.msgmnb=65536\n\n          sysctl -w kernel.msgmax=65536\n\n          sysctl -w kernel.shmmax=68719476736\n\n          sysctl -w kernel.shmall=4294967296\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w fs.file-max=100000\n\n          sysctl -w net.ipv4.tcp_syncookies=1\n\n          sysctl -w net.ipv4.conf.all.log_martians=0\n\n          sysctl -w net.core.somaxconn=50000\n\n          sysctl -w net.ipv4.tcp_max_syn_backlog=30000\n\n          sysctl -w net.ipv4.conf.all.send_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_redirects=0\n\n          sysctl -w net.ipv4.conf.all.accept_source_route=0\n\n          sysctl -w net.ipv6.conf.all.forwarding=0\n\n          sysctl -w net.ipv4.tcp_slow_start_after_idle=0\n\n          sysctl -w net.ipv4.tcp_window_scaling=1\n\n          sysctl -w net.ipv4.tcp_timestamp=1\n\n          sysctl -w net.ipv4.tcp_sack=1\n\n          sysctl -w net.ipv4.tcp_congestion_control=htcp\n\n          sysctl -w net.ipv4.tcp_keepalive_time=60\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_time_wait=10\n\n          sysctl -w net.netfilter.nf_conntrack_tcp_timeout_established=300\n\n          sysctl -w net.netfilter.nf_conntrack_generic_timeout=300\n\n          sysctl -w net.ipv4.tcp_max_tw_buckets=2000000\n\n          sysctl -w net.ipv4.tcp_fin_timeout=10\n\n          sysctl -w net.ipv4.tcp_tw_reuse=1\n\n          sysctl -w net.ipv4.tcp_keepalive_intvl=15\n\n          sysctl -w net.ipv4.tcp_keepalive_probes=5\n\n          '\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: banias-frontend\n        image: gcr.io/my-project/banias-frontend:test\n        resources:\n          limits:\n            cpu: '3'\n            memory: 12G\n          requests:\n            cpu: 500m\n            memory: 200Mi\n        volumeMounts:\n        - name: google-cloud-key\n          mountPath: /var/secrets/google\n        ports:\n        - name: http\n          containerPort: 8081\n        - name: prom-metrics\n          containerPort: 8080\n        env:\n        - name: BANIAS_PROJECTID\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PROJECTID\n              name: banias-frontend-config\n        - name: BANIAS_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_DEBUG\n              name: banias-frontend-config\n        - name: BANIAS_TOPIC\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_TOPIC\n              name: banias-frontend-config\n        - name: BANIAS_PORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PORT\n              name: banias-frontend-config\n        - name: BANIAS_METRICSPORT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_METRICSPORT\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXBATCH\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXBATCH\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBAGGRIGATORS\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBAGGRIGATORS\n              name: banias-frontend-config\n        - name: BANIAS_PUBSUBMAXPUBLISHDELAY\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_PUBSUBMAXPUBLISHDELAY\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINESAMOUNT\n              name: banias-frontend-config\n        - name: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n          valueFrom:\n            configMapKeyRef:\n              key: BANIAS_MAXPUBSUBGOROUTINEIDLEDURATION\n              name: banias-frontend-config\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/secrets/google/key.json\n        imagePullPolicy: Always\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: google-cloud-key\n        secret:\n          secretName: pubsub-key\n",
    "errors": []
  },
  {
    "id": "04246",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6857\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04247",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6857\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04248",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6857\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04249",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6857\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04250",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-6857\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04251",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210305-350f3b2f2e\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --kubeconfig=/etc/kubeconfig/config\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04252",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210305-350f3b2f2e\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --kubeconfig=/etc/kubeconfig/config\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04253",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210305-350f3b2f2e\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --kubeconfig=/etc/kubeconfig/config\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04254",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: deck\n  labels:\n    app: deck\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: deck\n  template:\n    metadata:\n      labels:\n        app: deck\n    spec:\n      serviceAccountName: deck\n      containers:\n      - name: deck\n        image: gcr.io/k8s-prow/deck:v20210305-350f3b2f2e\n        imagePullPolicy: Always\n        ports:\n        - name: http\n          containerPort: 8080\n        args:\n        - --kubeconfig=/etc/kubeconfig/config\n        - --tide-url=http://tide/\n        - --hook-url=http://hook:8888/plugin-help\n        - --redirect-http-to=prow.k8s.io\n        - --oauth-url=/github-login\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --spyglass=true\n        - --rerun-creates-job\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-oauth-config-file=/etc/githuboauth/secret\n        - --cookie-secret=/etc/cookie/secret\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth-config\n          mountPath: /etc/githuboauth\n          readOnly: true\n        - name: cookie-secret\n          mountPath: /etc/cookie\n          readOnly: true\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth-token\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 3\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz/ready\n            port: 8081\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          timeoutSeconds: 600\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: oauth-config\n        secret:\n          secretName: github-oauth-config\n      - name: oauth-token\n        secret:\n          secretName: oauth-token\n      - name: cookie-secret\n        secret:\n          secretName: cookie\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04255",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: v1.9.5\n  name: kube-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: v1.9.5\n    spec:\n      containers:\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        - --metric-blacklist=kube_secret_labels\n        image: quay.io/coreos/kube-state-metrics:v1.9.5\n        name: kube-state-metrics\n        resources:\n          requests:\n            cpu: 2m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /tmp\n          name: volume-directive-shadow\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      securityContext: {}\n      serviceAccountName: kube-state-metrics\n      volumes:\n      - emptyDir: {}\n        name: volume-directive-shadow\n      - name: kube-state-metrics-tls\n        secret:\n          secretName: kube-state-metrics-tls\n",
    "errors": []
  },
  {
    "id": "04256",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: v1.9.5\n  name: kube-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: v1.9.5\n    spec:\n      containers:\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        - --metric-blacklist=kube_secret_labels\n        image: quay.io/coreos/kube-state-metrics:v1.9.5\n        name: kube-state-metrics\n        resources:\n          requests:\n            cpu: 2m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /tmp\n          name: volume-directive-shadow\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      securityContext: {}\n      serviceAccountName: kube-state-metrics\n      volumes:\n      - emptyDir: {}\n        name: volume-directive-shadow\n      - name: kube-state-metrics-tls\n        secret:\n          secretName: kube-state-metrics-tls\n",
    "errors": []
  },
  {
    "id": "04257",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: v1.9.5\n  name: kube-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: v1.9.5\n    spec:\n      containers:\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        - --metric-blacklist=kube_secret_labels\n        image: quay.io/coreos/kube-state-metrics:v1.9.5\n        name: kube-state-metrics\n        resources:\n          requests:\n            cpu: 2m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /tmp\n          name: volume-directive-shadow\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      securityContext: {}\n      serviceAccountName: kube-state-metrics\n      volumes:\n      - emptyDir: {}\n        name: volume-directive-shadow\n      - name: kube-state-metrics-tls\n        secret:\n          secretName: kube-state-metrics-tls\n",
    "errors": []
  },
  {
    "id": "04258",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: v1.9.5\n  name: kube-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: v1.9.5\n    spec:\n      containers:\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        - --metric-blacklist=kube_secret_labels\n        image: quay.io/coreos/kube-state-metrics:v1.9.5\n        name: kube-state-metrics\n        resources:\n          requests:\n            cpu: 2m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /tmp\n          name: volume-directive-shadow\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      securityContext: {}\n      serviceAccountName: kube-state-metrics\n      volumes:\n      - emptyDir: {}\n        name: volume-directive-shadow\n      - name: kube-state-metrics-tls\n        secret:\n          secretName: kube-state-metrics-tls\n",
    "errors": []
  },
  {
    "id": "04259",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: v1.9.5\n  name: kube-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: v1.9.5\n    spec:\n      containers:\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        - --metric-blacklist=kube_secret_labels\n        image: quay.io/coreos/kube-state-metrics:v1.9.5\n        name: kube-state-metrics\n        resources:\n          requests:\n            cpu: 2m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /tmp\n          name: volume-directive-shadow\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      securityContext: {}\n      serviceAccountName: kube-state-metrics\n      volumes:\n      - emptyDir: {}\n        name: volume-directive-shadow\n      - name: kube-state-metrics-tls\n        secret:\n          secretName: kube-state-metrics-tls\n",
    "errors": []
  },
  {
    "id": "04260",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: v1.9.5\n  name: kube-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: v1.9.5\n    spec:\n      containers:\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        - --metric-blacklist=kube_secret_labels\n        image: quay.io/coreos/kube-state-metrics:v1.9.5\n        name: kube-state-metrics\n        resources:\n          requests:\n            cpu: 2m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /tmp\n          name: volume-directive-shadow\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      securityContext: {}\n      serviceAccountName: kube-state-metrics\n      volumes:\n      - emptyDir: {}\n        name: volume-directive-shadow\n      - name: kube-state-metrics-tls\n        secret:\n          secretName: kube-state-metrics-tls\n",
    "errors": []
  },
  {
    "id": "04261",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: v1.9.5\n  name: kube-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: v1.9.5\n    spec:\n      containers:\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        - --metric-blacklist=kube_secret_labels\n        image: quay.io/coreos/kube-state-metrics:v1.9.5\n        name: kube-state-metrics\n        resources:\n          requests:\n            cpu: 2m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /tmp\n          name: volume-directive-shadow\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      securityContext: {}\n      serviceAccountName: kube-state-metrics\n      volumes:\n      - emptyDir: {}\n        name: volume-directive-shadow\n      - name: kube-state-metrics-tls\n        secret:\n          secretName: kube-state-metrics-tls\n",
    "errors": []
  },
  {
    "id": "04262",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: v1.9.5\n  name: kube-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: v1.9.5\n    spec:\n      containers:\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        - --metric-blacklist=kube_secret_labels\n        image: quay.io/coreos/kube-state-metrics:v1.9.5\n        name: kube-state-metrics\n        resources:\n          requests:\n            cpu: 2m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /tmp\n          name: volume-directive-shadow\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      securityContext: {}\n      serviceAccountName: kube-state-metrics\n      volumes:\n      - emptyDir: {}\n        name: volume-directive-shadow\n      - name: kube-state-metrics-tls\n        secret:\n          secretName: kube-state-metrics-tls\n",
    "errors": []
  },
  {
    "id": "04263",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: v1.9.5\n  name: kube-state-metrics\n  namespace: openshift-monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: kube-state-metrics\n        app.kubernetes.io/version: v1.9.5\n    spec:\n      containers:\n      - args:\n        - --host=127.0.0.1\n        - --port=8081\n        - --telemetry-host=127.0.0.1\n        - --telemetry-port=8082\n        - --metric-blacklist=kube_secret_labels\n        image: quay.io/coreos/kube-state-metrics:v1.9.5\n        name: kube-state-metrics\n        resources:\n          requests:\n            cpu: 2m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /tmp\n          name: volume-directive-shadow\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:8443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8081/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-main\n        ports:\n        - containerPort: 8443\n          name: https-main\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      - args:\n        - --logtostderr\n        - --secure-listen-address=:9443\n        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\n        - --upstream=http://127.0.0.1:8082/\n        - --tls-cert-file=/etc/tls/private/tls.crt\n        - --tls-private-key-file=/etc/tls/private/tls.key\n        image: quay.io/coreos/kube-rbac-proxy:v0.4.1\n        name: kube-rbac-proxy-self\n        ports:\n        - containerPort: 9443\n          name: https-self\n        resources:\n          requests:\n            cpu: 1m\n            memory: 40Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /etc/tls/private\n          name: kube-state-metrics-tls\n          readOnly: false\n      securityContext: {}\n      serviceAccountName: kube-state-metrics\n      volumes:\n      - emptyDir: {}\n        name: volume-directive-shadow\n      - name: kube-state-metrics-tls\n        secret:\n          secretName: kube-state-metrics-tls\n",
    "errors": []
  },
  {
    "id": "04264",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.4.0-classifier-efficientnet-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04265",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.4.0-classifier-efficientnet-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04266",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.4.0-classifier-efficientnet-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04267",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.4.0-classifier-efficientnet-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04268",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.4.0-classifier-efficientnet-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04269",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.4.0-classifier-efficientnet-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04270",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.4.0-classifier-efficientnet-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04271",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.4.0-classifier-efficientnet-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04272",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.4.0-classifier-efficientnet-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04273",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.4.0-classifier-efficientnet-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04274",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.4.0-classifier-efficientnet-func-v2-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04275",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: results-app\n  labels:\n    app: my-voting-app\n    tier: results\nspec:\n  containers:\n  - image: dockersamples/examplevotingapp_result:stable\n    name: results-app\n    ports:\n    - containerPort: 80\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04276",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: results-app\n  labels:\n    app: my-voting-app\n    tier: results\nspec:\n  containers:\n  - image: dockersamples/examplevotingapp_result:stable\n    name: results-app\n    ports:\n    - containerPort: 80\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04277",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: results-app\n  labels:\n    app: my-voting-app\n    tier: results\nspec:\n  containers:\n  - image: dockersamples/examplevotingapp_result:stable\n    name: results-app\n    ports:\n    - containerPort: 80\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04278",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: results-app\n  labels:\n    app: my-voting-app\n    tier: results\nspec:\n  containers:\n  - image: dockersamples/examplevotingapp_result:stable\n    name: results-app\n    ports:\n    - containerPort: 80\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04279",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: results-app\n  labels:\n    app: my-voting-app\n    tier: results\nspec:\n  containers:\n  - image: dockersamples/examplevotingapp_result:stable\n    name: results-app\n    ports:\n    - containerPort: 80\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04280",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"label-sync\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04281",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"label-sync\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04282",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"label-sync\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04283",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"label-sync\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04284",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"kube-janitor\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04285",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"kube-janitor\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04286",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: signalfx-agent\n  labels:\n    app: signalfx-agent\n    version: 5.1.4\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: signalfx-agent\n  template:\n    metadata:\n      labels:\n        app: signalfx-agent\n        version: 5.1.4\n      annotations: {}\n    spec:\n      serviceAccountName: signalfx-agent\n      containers:\n      - name: signalfx-agent\n        image: quay.io/signalfx/signalfx-agent:5.1.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/signalfx-agent\n        volumeMounts:\n        - mountPath: /etc/signalfx\n          name: config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: SFX_ACCESS_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: signalfx-agent\n              key: access-token\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: MY_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: MY_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: config\n        configMap:\n          name: signalfx-agent-v5\n",
    "errors": []
  },
  {
    "id": "04287",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: signalfx-agent\n  labels:\n    app: signalfx-agent\n    version: 5.1.4\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: signalfx-agent\n  template:\n    metadata:\n      labels:\n        app: signalfx-agent\n        version: 5.1.4\n      annotations: {}\n    spec:\n      serviceAccountName: signalfx-agent\n      containers:\n      - name: signalfx-agent\n        image: quay.io/signalfx/signalfx-agent:5.1.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/signalfx-agent\n        volumeMounts:\n        - mountPath: /etc/signalfx\n          name: config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: SFX_ACCESS_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: signalfx-agent\n              key: access-token\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: MY_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: MY_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: signalfx-agent-v5\n",
    "errors": []
  },
  {
    "id": "04288",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: signalfx-agent\n  labels:\n    app: signalfx-agent\n    version: 5.1.4\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: signalfx-agent\n  template:\n    metadata:\n      labels:\n        app: signalfx-agent\n        version: 5.1.4\n      annotations: {}\n    spec:\n      serviceAccountName: signalfx-agent\n      containers:\n      - name: signalfx-agent\n        image: quay.io/signalfx/signalfx-agent:5.1.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/signalfx-agent\n        volumeMounts:\n        - mountPath: /etc/signalfx\n          name: config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: SFX_ACCESS_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: signalfx-agent\n              key: access-token\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: MY_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: MY_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: signalfx-agent-v5\n",
    "errors": []
  },
  {
    "id": "04289",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: signalfx-agent\n  labels:\n    app: signalfx-agent\n    version: 5.1.4\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: signalfx-agent\n  template:\n    metadata:\n      labels:\n        app: signalfx-agent\n        version: 5.1.4\n      annotations: {}\n    spec:\n      serviceAccountName: signalfx-agent\n      containers:\n      - name: signalfx-agent\n        image: quay.io/signalfx/signalfx-agent:5.1.4\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/signalfx-agent\n        volumeMounts:\n        - mountPath: /etc/signalfx\n          name: config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: SFX_ACCESS_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: signalfx-agent\n              key: access-token\n        - name: MY_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: MY_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: MY_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: signalfx-agent-v5\n",
    "errors": []
  },
  {
    "id": "04290",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vppagent-client\nspec:\n  selector:\n    matchLabels:\n      networkservicemesh.io/app: vppagent-client\n  replicas: 4\n  template:\n    metadata:\n      labels:\n        networkservicemesh.io/app: vppagent-client\n    spec:\n      containers:\n      - name: vppagent-client\n        image: networkservicemesh/vpp-icmp-vppagent-client:stable\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: OUTGOING_NSC_NAME\n          value: icmp-responder\n        - name: OUTGOING_NSC_LABELS\n          value: app=vppagent-endpoint\n        resources:\n          limits:\n            networkservicemesh.io/socket: 1\n            cpu: 500m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04291",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vppagent-client\nspec:\n  selector:\n    matchLabels:\n      networkservicemesh.io/app: vppagent-client\n  replicas: 4\n  template:\n    metadata:\n      labels:\n        networkservicemesh.io/app: vppagent-client\n    spec:\n      containers:\n      - name: vppagent-client\n        image: networkservicemesh/vpp-icmp-vppagent-client:stable\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: OUTGOING_NSC_NAME\n          value: icmp-responder\n        - name: OUTGOING_NSC_LABELS\n          value: app=vppagent-endpoint\n        resources:\n          limits:\n            networkservicemesh.io/socket: 1\n            cpu: 500m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04292",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vppagent-client\nspec:\n  selector:\n    matchLabels:\n      networkservicemesh.io/app: vppagent-client\n  replicas: 4\n  template:\n    metadata:\n      labels:\n        networkservicemesh.io/app: vppagent-client\n    spec:\n      containers:\n      - name: vppagent-client\n        image: networkservicemesh/vpp-icmp-vppagent-client:stable\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: OUTGOING_NSC_NAME\n          value: icmp-responder\n        - name: OUTGOING_NSC_LABELS\n          value: app=vppagent-endpoint\n        resources:\n          limits:\n            networkservicemesh.io/socket: 1\n            cpu: 500m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04293",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vppagent-client\nspec:\n  selector:\n    matchLabels:\n      networkservicemesh.io/app: vppagent-client\n  replicas: 4\n  template:\n    metadata:\n      labels:\n        networkservicemesh.io/app: vppagent-client\n    spec:\n      containers:\n      - name: vppagent-client\n        image: networkservicemesh/vpp-icmp-vppagent-client:stable\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: OUTGOING_NSC_NAME\n          value: icmp-responder\n        - name: OUTGOING_NSC_LABELS\n          value: app=vppagent-endpoint\n        resources:\n          limits:\n            networkservicemesh.io/socket: 1\n            cpu: 500m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04294",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vppagent-client\nspec:\n  selector:\n    matchLabels:\n      networkservicemesh.io/app: vppagent-client\n  replicas: 4\n  template:\n    metadata:\n      labels:\n        networkservicemesh.io/app: vppagent-client\n    spec:\n      containers:\n      - name: vppagent-client\n        image: networkservicemesh/vpp-icmp-vppagent-client:stable\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: OUTGOING_NSC_NAME\n          value: icmp-responder\n        - name: OUTGOING_NSC_LABELS\n          value: app=vppagent-endpoint\n        resources:\n          limits:\n            networkservicemesh.io/socket: 1\n            cpu: 500m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04295",
    "policy_id": "env_var_secret",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"kurl-proxy-kotsadm\" is invalid: \n* metadata.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')"
    ]
  },
  {
    "id": "04296",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"kurl-proxy-kotsadm\" is invalid: \n* metadata.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')"
    ]
  },
  {
    "id": "04297",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"kurl-proxy-kotsadm\" is invalid: \n* metadata.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')"
    ]
  },
  {
    "id": "04298",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"kurl-proxy-kotsadm\" is invalid: \n* metadata.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')"
    ]
  },
  {
    "id": "04299",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"kurl-proxy-kotsadm\" is invalid: \n* metadata.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.labels: Invalid value: \"\\\\\\\"true\\\\\\\"\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')"
    ]
  },
  {
    "id": "04300",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04301",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04302",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04303",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04304",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04305",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04306",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04307",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04308",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          runAsNonRoot: true\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04309",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04310",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04311",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04312",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: cilium\n    kubernetes.io/cluster-service: 'true'\n  name: cilium\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: cilium\n      kubernetes.io/cluster-service: 'true'\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n        scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"dedicated\",\"operator\":\"Equal\",\"value\":\"master\",\"effect\":\"NoSchedule\"}]'\n      labels:\n        k8s-app: cilium\n        kubernetes.io/cluster-service: 'true'\n    spec:\n      containers:\n      - args:\n        - --kvstore=etcd\n        - --kvstore-opt=etcd.config=/var/lib/etcd-config/etcd.config\n        - --config-dir=/tmp/cilium/config-map\n        command:\n        - cilium-agent\n        env:\n        - name: K8S_NODE_NAME\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: spec.nodeName\n        - name: CILIUM_K8S_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: CILIUM_FLANNEL_MASTER_DEVICE\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-master-device\n              name: cilium-config\n              optional: true\n        - name: CILIUM_FLANNEL_UNINSTALL_ON_EXIT\n          valueFrom:\n            configMapKeyRef:\n              key: flannel-uninstall-on-exit\n              name: cilium-config\n              optional: true\n        - name: CILIUM_PROMETHEUS_SERVE_ADDR\n          valueFrom:\n            configMapKeyRef:\n              key: prometheus-serve-addr\n              name: cilium-metrics-config\n              optional: true\n        - name: CILIUM_CLUSTERMESH_CONFIG\n          value: /var/lib/cilium/clustermesh/\n        image: docker.io/cilium/cilium:stable\n        imagePullPolicy: Always\n        livenessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 10\n          initialDelaySeconds: 120\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: cilium-agent\n        ports:\n        - containerPort: 9090\n          hostPort: 9090\n          name: prometheus\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - cilium\n            - status\n            - --brief\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 30\n          successThreshold: 1\n          timeoutSeconds: 5\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        - mountPath: /host/opt/cni/bin\n          name: cni-path\n        - mountPath: /host/etc/cni/net.d\n          name: etc-cni-netd\n        - mountPath: /var/run/docker.sock\n          name: docker-socket\n          readOnly: true\n        - mountPath: /var/lib/etcd-config\n          name: etcd-config-path\n          readOnly: true\n        - mountPath: /var/lib/etcd-secrets\n          name: etcd-secrets\n          readOnly: true\n        - mountPath: /var/lib/cilium/clustermesh\n          name: clustermesh-secrets\n          readOnly: true\n        - mountPath: /tmp/cilium/config-map\n          name: cilium-config-path\n          readOnly: true\n        - mountPath: /lib/modules\n          name: lib-modules\n          readOnly: true\n        - mountPath: /sbin/modprobe\n          name: sbin-modprobe\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - command:\n        - /init-container.sh\n        env:\n        - name: CILIUM_ALL_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_BPF_STATE\n          valueFrom:\n            configMapKeyRef:\n              key: clean-cilium-bpf-state\n              name: cilium-config\n              optional: true\n        - name: CILIUM_WAIT_BPF_MOUNT\n          valueFrom:\n            configMapKeyRef:\n              key: wait-bpf-mount\n              name: cilium-config\n              optional: true\n        image: docker.io/cilium/cilium-init:2019-04-05\n        imagePullPolicy: IfNotPresent\n        name: clean-cilium-state\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /sys/fs/bpf\n          name: bpf-maps\n        - mountPath: /var/run/cilium\n          name: cilium-run\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccount: cilium\n      serviceAccountName: cilium\n      volumes:\n      - hostPath:\n          path: /var/run/cilium\n          type: DirectoryOrCreate\n        name: cilium-run\n      - hostPath:\n          path: /sys/fs/bpf\n          type: DirectoryOrCreate\n        name: bpf-maps\n      - hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n        name: docker-socket\n      - hostPath:\n          path: /opt/cni/bin\n          type: DirectoryOrCreate\n        name: cni-path\n      - hostPath:\n          path: /etc/cni/net.d\n          type: DirectoryOrCreate\n        name: etc-cni-netd\n      - hostPath:\n          path: /lib/modules\n          type: Directory\n        name: lib-modules\n      - hostPath:\n          path: /sbin/modprobe\n          type: File\n        name: sbin-modprobe\n      - configMap:\n          defaultMode: 420\n          items:\n          - key: etcd-config\n            path: etcd.config\n          name: cilium-config\n        name: etcd-config-path\n      - name: etcd-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-etcd-secrets\n      - name: clustermesh-secrets\n        secret:\n          defaultMode: 420\n          optional: true\n          secretName: cilium-clustermesh\n      - configMap:\n          name: cilium-config\n        name: cilium-config-path\n",
    "errors": []
  },
  {
    "id": "04313",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app.kubernetes.io/part-of: prow\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20200910-8c70361b39\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --continue-on-error=true\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --job-config-path=/etc/job-config\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04314",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app.kubernetes.io/part-of: prow\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20200910-8c70361b39\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --continue-on-error=true\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --job-config-path=/etc/job-config\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04315",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app.kubernetes.io/part-of: prow\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20200910-8c70361b39\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --continue-on-error=true\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --job-config-path=/etc/job-config\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04316",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app.kubernetes.io/part-of: prow\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20200910-8c70361b39\n        imagePullPolicy: Always\n        args:\n        - --config-path=/etc/config/config.yaml\n        - --continue-on-error=true\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --job-config-path=/etc/job-config\n        - --plugin-config=/etc/plugins/plugins.yaml\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04317",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"litmus\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "04318",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"litmus\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "04319",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"litmus\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "04320",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"litmus\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "04321",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: canary\n  labels:\n    app: canary\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: canary\n      pipecd.dev/variant: primary\n  template:\n    metadata:\n      labels:\n        app: canary\n        pipecd.dev/variant: primary\n    spec:\n      containers:\n      - name: helloworld\n        image: gcr.io/pipecd/helloworld:v0.6.0\n        args:\n        - server\n        ports:\n        - containerPort: 9085\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04322",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: canary\n  labels:\n    app: canary\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: canary\n      pipecd.dev/variant: primary\n  template:\n    metadata:\n      labels:\n        app: canary\n        pipecd.dev/variant: primary\n    spec:\n      containers:\n      - name: helloworld\n        image: gcr.io/pipecd/helloworld:v0.6.0\n        args:\n        - server\n        ports:\n        - containerPort: 9085\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04323",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: canary\n  labels:\n    app: canary\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: canary\n      pipecd.dev/variant: primary\n  template:\n    metadata:\n      labels:\n        app: canary\n        pipecd.dev/variant: primary\n    spec:\n      containers:\n      - name: helloworld\n        image: gcr.io/pipecd/helloworld:v0.6.0\n        args:\n        - server\n        ports:\n        - containerPort: 9085\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04324",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: canary\n  labels:\n    app: canary\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: canary\n      pipecd.dev/variant: primary\n  template:\n    metadata:\n      labels:\n        app: canary\n        pipecd.dev/variant: primary\n    spec:\n      containers:\n      - name: helloworld\n        image: gcr.io/pipecd/helloworld:v0.6.0\n        args:\n        - server\n        ports:\n        - containerPort: 9085\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04325",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: s01-deployment\n  namespace: scenario01\n  labels:\n    app: s01-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: s01-app\n  template:\n    metadata:\n      labels:\n        app: s01-app\n    spec:\n      containers:\n      - name: container\n        image: wordpress:latast\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04326",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: s01-deployment\n  namespace: scenario01\n  labels:\n    app: s01-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: s01-app\n  template:\n    metadata:\n      labels:\n        app: s01-app\n    spec:\n      containers:\n      - name: container\n        image: wordpress:latast\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04327",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: s01-deployment\n  namespace: scenario01\n  labels:\n    app: s01-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: s01-app\n  template:\n    metadata:\n      labels:\n        app: s01-app\n    spec:\n      containers:\n      - name: container\n        image: wordpress:latast\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04328",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: s01-deployment\n  namespace: scenario01\n  labels:\n    app: s01-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: s01-app\n  template:\n    metadata:\n      labels:\n        app: s01-app\n    spec:\n      containers:\n      - name: container\n        image: wordpress:latast\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04329",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.1-transformer-translate-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04330",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.1-transformer-translate-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04331",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.1-transformer-translate-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04332",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.1-transformer-translate-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04333",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.1-transformer-translate-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04334",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.1-transformer-translate-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04335",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.1-transformer-translate-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04336",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.1-transformer-translate-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04337",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.1-transformer-translate-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04338",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.1-transformer-translate-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04339",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-r2.3.1-transformer-translate-conv-v2-32\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04340",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: load\n  labels:\n    service: load\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      service: load\n  template:\n    metadata:\n      labels:\n        service: load\n    spec:\n      containers:\n      - name: load\n        env:\n        - name: HOST\n          value: http://payment.robotshop:8080/health\n        - name: NUM_CLIENTS\n          value: '15'\n        - name: SILENT\n          value: '1'\n        - name: ERROR\n          value: '1'\n        image: robotshop/rs-load:stable\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04341",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: load\n  labels:\n    service: load\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      service: load\n  template:\n    metadata:\n      labels:\n        service: load\n    spec:\n      containers:\n      - name: load\n        env:\n        - name: HOST\n          value: http://payment.robotshop:8080/health\n        - name: NUM_CLIENTS\n          value: '15'\n        - name: SILENT\n          value: '1'\n        - name: ERROR\n          value: '1'\n        image: robotshop/rs-load:stable\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04342",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: load\n  labels:\n    service: load\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      service: load\n  template:\n    metadata:\n      labels:\n        service: load\n    spec:\n      containers:\n      - name: load\n        env:\n        - name: HOST\n          value: http://payment.robotshop:8080/health\n        - name: NUM_CLIENTS\n          value: '15'\n        - name: SILENT\n          value: '1'\n        - name: ERROR\n          value: '1'\n        image: robotshop/rs-load:stable\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04343",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"tf-ssdmobilenet-default-1024-26\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04344",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"tf-ssdmobilenet-default-1024-26\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04345",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"tf-ssdmobilenet-default-1024-26\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04346",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"tf-ssdmobilenet-default-1024-26\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04347",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"tf-ssdmobilenet-default-1024-26\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04348",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ebs-csi-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04349",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ebs-csi-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04350",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ebs-csi-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04351",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ebs-csi-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04352",
    "policy_id": "drop_capabilities",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ebs-csi-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04353",
    "policy_id": "no_privileged",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ebs-csi-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04354",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ebs-csi-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04355",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ebs-csi-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04356",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ebs-csi-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04357",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ebs-csi-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04358",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ebs-csi-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04359",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ebs-csi-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04360",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ebs-csi-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04361",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ebs-csi-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04362",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"ebs-csi-node\" is invalid: spec.template.spec.containers[0].volumeMounts.mountPropagation: Forbidden: Bidirectional mount propagation is available only to privileged containers"
    ]
  },
  {
    "id": "04363",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smi-adapter-istio\n  namespace: istio-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: smi-adapter-istio\n  template:\n    metadata:\n      labels:\n        name: smi-adapter-istio\n      annotations:\n        sidecar.istio.io/inject: 'false'\n    spec:\n      serviceAccountName: smi-adapter-istio\n      containers:\n      - name: smi-adapter-istio\n        image: layer5/smi-istio:stable\n        command:\n        - smi-adapter-istio\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: smi-adapter-istio\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04364",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smi-adapter-istio\n  namespace: istio-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: smi-adapter-istio\n  template:\n    metadata:\n      labels:\n        name: smi-adapter-istio\n      annotations:\n        sidecar.istio.io/inject: 'false'\n    spec:\n      serviceAccountName: smi-adapter-istio\n      containers:\n      - name: smi-adapter-istio\n        image: layer5/smi-istio:stable\n        command:\n        - smi-adapter-istio\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: smi-adapter-istio\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04365",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smi-adapter-istio\n  namespace: istio-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: smi-adapter-istio\n  template:\n    metadata:\n      labels:\n        name: smi-adapter-istio\n      annotations:\n        sidecar.istio.io/inject: 'false'\n    spec:\n      serviceAccountName: smi-adapter-istio\n      containers:\n      - name: smi-adapter-istio\n        image: layer5/smi-istio:stable\n        command:\n        - smi-adapter-istio\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: smi-adapter-istio\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04366",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smi-adapter-istio\n  namespace: istio-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: smi-adapter-istio\n  template:\n    metadata:\n      labels:\n        name: smi-adapter-istio\n      annotations:\n        sidecar.istio.io/inject: 'false'\n    spec:\n      serviceAccountName: smi-adapter-istio\n      containers:\n      - name: smi-adapter-istio\n        image: layer5/smi-istio:stable\n        command:\n        - smi-adapter-istio\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: smi-adapter-istio\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04367",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smi-adapter-istio\n  namespace: istio-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: smi-adapter-istio\n  template:\n    metadata:\n      labels:\n        name: smi-adapter-istio\n      annotations:\n        sidecar.istio.io/inject: 'false'\n    spec:\n      serviceAccountName: smi-adapter-istio\n      containers:\n      - name: smi-adapter-istio\n        image: layer5/smi-istio:stable\n        command:\n        - smi-adapter-istio\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: smi-adapter-istio\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04368",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"ca-certificates-(( random.String 5 \\\"[a-z]\\\" ))\" is invalid: \n* metadata.name: Invalid value: \"ca-certificates-(( random.String 5 \\\"[a-z]\\\" ))\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.template.labels: Invalid value: \"ca-certificates-(( random.String 5 \\\"[a-z]\\\" ))\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04369",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"ca-certificates-(( random.String 5 \\\"[a-z]\\\" ))\" is invalid: \n* metadata.name: Invalid value: \"ca-certificates-(( random.String 5 \\\"[a-z]\\\" ))\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.template.labels: Invalid value: \"ca-certificates-(( random.String 5 \\\"[a-z]\\\" ))\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04370",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"ca-certificates-(( random.String 5 \\\"[a-z]\\\" ))\" is invalid: \n* metadata.name: Invalid value: \"ca-certificates-(( random.String 5 \\\"[a-z]\\\" ))\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.template.labels: Invalid value: \"ca-certificates-(( random.String 5 \\\"[a-z]\\\" ))\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04371",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"ca-certificates-(( random.String 5 \\\"[a-z]\\\" ))\" is invalid: \n* metadata.name: Invalid value: \"ca-certificates-(( random.String 5 \\\"[a-z]\\\" ))\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.template.labels: Invalid value: \"ca-certificates-(( random.String 5 \\\"[a-z]\\\" ))\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n* spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04372",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: jaeger-operator\n  template:\n    metadata:\n      labels:\n        name: jaeger-operator\n    spec:\n      serviceAccountName: jaeger-operator\n      containers:\n      - name: jaeger-operator\n        image: jaegertracing/jaeger-operator:1.8.2\n        ports:\n        - containerPort: 60000\n          name: metrics\n        args:\n        - start\n        - --platform=openshift\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: jaeger-operator\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04373",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: jaeger-operator\n  template:\n    metadata:\n      labels:\n        name: jaeger-operator\n    spec:\n      serviceAccountName: jaeger-operator\n      containers:\n      - name: jaeger-operator\n        image: jaegertracing/jaeger-operator:1.8.2\n        ports:\n        - containerPort: 60000\n          name: metrics\n        args:\n        - start\n        - --platform=openshift\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: jaeger-operator\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04374",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: jaeger-operator\n  template:\n    metadata:\n      labels:\n        name: jaeger-operator\n    spec:\n      serviceAccountName: jaeger-operator\n      containers:\n      - name: jaeger-operator\n        image: jaegertracing/jaeger-operator:1.8.2\n        ports:\n        - containerPort: 60000\n          name: metrics\n        args:\n        - start\n        - --platform=openshift\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: jaeger-operator\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04375",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger-operator\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: jaeger-operator\n  template:\n    metadata:\n      labels:\n        name: jaeger-operator\n    spec:\n      serviceAccountName: jaeger-operator\n      containers:\n      - name: jaeger-operator\n        image: jaegertracing/jaeger-operator:1.8.2\n        ports:\n        - containerPort: 60000\n          name: metrics\n        args:\n        - start\n        - --platform=openshift\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: OPERATOR_NAME\n          value: jaeger-operator\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04376",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/component: repo-server\n  name: argocd-repo-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-repo-server\n    spec:\n      containers:\n      - name: argocd-repo-server\n        image: quay.io/argoproj/argocd:stable\n        imagePullPolicy: Always\n        command:\n        - uid_entrypoint.sh\n        - argocd-repo-server\n        - --redis\n        - $(ARGOCD_REDIS_SERVICE):6379\n        ports:\n        - containerPort: 8081\n        - containerPort: 8084\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: 8084\n          initialDelaySeconds: 30\n          periodSeconds: 5\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8084\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        volumeMounts:\n        - name: ssh-known-hosts\n          mountPath: /app/config/ssh\n        - name: tls-certs\n          mountPath: /app/config/tls\n        - name: gpg-keys\n          mountPath: /app/config/gpg/source\n        - name: gpg-keyring\n          mountPath: /app/config/gpg/keys\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: ssh-known-hosts\n        configMap:\n          name: argocd-ssh-known-hosts-cm\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: gpg-keys\n        configMap:\n          name: argocd-gpg-keys-cm\n      - name: gpg-keyring\n        emptyDir: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: kubernetes.io/hostname\n          - weight: 5\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n",
    "errors": []
  },
  {
    "id": "04377",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/component: repo-server\n  name: argocd-repo-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-repo-server\n    spec:\n      containers:\n      - name: argocd-repo-server\n        image: quay.io/argoproj/argocd:stable\n        imagePullPolicy: Always\n        command:\n        - uid_entrypoint.sh\n        - argocd-repo-server\n        - --redis\n        - $(ARGOCD_REDIS_SERVICE):6379\n        ports:\n        - containerPort: 8081\n        - containerPort: 8084\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: 8084\n          initialDelaySeconds: 30\n          periodSeconds: 5\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8084\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        volumeMounts:\n        - name: ssh-known-hosts\n          mountPath: /app/config/ssh\n        - name: tls-certs\n          mountPath: /app/config/tls\n        - name: gpg-keys\n          mountPath: /app/config/gpg/source\n        - name: gpg-keyring\n          mountPath: /app/config/gpg/keys\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: ssh-known-hosts\n        configMap:\n          name: argocd-ssh-known-hosts-cm\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: gpg-keys\n        configMap:\n          name: argocd-gpg-keys-cm\n      - name: gpg-keyring\n        emptyDir: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: kubernetes.io/hostname\n          - weight: 5\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n",
    "errors": []
  },
  {
    "id": "04378",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/component: repo-server\n  name: argocd-repo-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-repo-server\n    spec:\n      containers:\n      - name: argocd-repo-server\n        image: quay.io/argoproj/argocd:stable\n        imagePullPolicy: Always\n        command:\n        - uid_entrypoint.sh\n        - argocd-repo-server\n        - --redis\n        - $(ARGOCD_REDIS_SERVICE):6379\n        ports:\n        - containerPort: 8081\n        - containerPort: 8084\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: 8084\n          initialDelaySeconds: 30\n          periodSeconds: 5\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8084\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        volumeMounts:\n        - name: ssh-known-hosts\n          mountPath: /app/config/ssh\n        - name: tls-certs\n          mountPath: /app/config/tls\n        - name: gpg-keys\n          mountPath: /app/config/gpg/source\n        - name: gpg-keyring\n          mountPath: /app/config/gpg/keys\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: ssh-known-hosts\n        configMap:\n          name: argocd-ssh-known-hosts-cm\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: gpg-keys\n        configMap:\n          name: argocd-gpg-keys-cm\n      - name: gpg-keyring\n        emptyDir: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: kubernetes.io/hostname\n          - weight: 5\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n",
    "errors": []
  },
  {
    "id": "04379",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/component: repo-server\n  name: argocd-repo-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-repo-server\n    spec:\n      containers:\n      - name: argocd-repo-server\n        image: quay.io/argoproj/argocd:stable\n        imagePullPolicy: Always\n        command:\n        - uid_entrypoint.sh\n        - argocd-repo-server\n        - --redis\n        - $(ARGOCD_REDIS_SERVICE):6379\n        ports:\n        - containerPort: 8081\n        - containerPort: 8084\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: 8084\n          initialDelaySeconds: 30\n          periodSeconds: 5\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8084\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        volumeMounts:\n        - name: ssh-known-hosts\n          mountPath: /app/config/ssh\n        - name: tls-certs\n          mountPath: /app/config/tls\n        - name: gpg-keys\n          mountPath: /app/config/gpg/source\n        - name: gpg-keyring\n          mountPath: /app/config/gpg/keys\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: ssh-known-hosts\n        configMap:\n          name: argocd-ssh-known-hosts-cm\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: gpg-keys\n        configMap:\n          name: argocd-gpg-keys-cm\n      - name: gpg-keyring\n        emptyDir: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: kubernetes.io/hostname\n          - weight: 5\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n",
    "errors": []
  },
  {
    "id": "04380",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/component: repo-server\n  name: argocd-repo-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-repo-server\n    spec:\n      containers:\n      - name: argocd-repo-server\n        image: quay.io/argoproj/argocd:stable\n        imagePullPolicy: Always\n        command:\n        - uid_entrypoint.sh\n        - argocd-repo-server\n        - --redis\n        - $(ARGOCD_REDIS_SERVICE):6379\n        ports:\n        - containerPort: 8081\n        - containerPort: 8084\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: 8084\n          initialDelaySeconds: 30\n          periodSeconds: 5\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8084\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        volumeMounts:\n        - name: ssh-known-hosts\n          mountPath: /app/config/ssh\n        - name: tls-certs\n          mountPath: /app/config/tls\n        - name: gpg-keys\n          mountPath: /app/config/gpg/source\n        - name: gpg-keyring\n          mountPath: /app/config/gpg/keys\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: ssh-known-hosts\n        configMap:\n          name: argocd-ssh-known-hosts-cm\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: gpg-keys\n        configMap:\n          name: argocd-gpg-keys-cm\n      - name: gpg-keyring\n        emptyDir: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: kubernetes.io/hostname\n          - weight: 5\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n",
    "errors": []
  },
  {
    "id": "04381",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20200416-dd6c31b18\n        args:\n        - --github-workers=5\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --slack-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --gcs-workers=1\n        - --kubernetes-gcs-workers=1\n        - --kubeconfig=/etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "errors": []
  },
  {
    "id": "04382",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20200416-dd6c31b18\n        args:\n        - --github-workers=5\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --slack-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --gcs-workers=1\n        - --kubernetes-gcs-workers=1\n        - --kubeconfig=/etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "errors": []
  },
  {
    "id": "04383",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20200416-dd6c31b18\n        args:\n        - --github-workers=5\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --slack-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --gcs-workers=1\n        - --kubernetes-gcs-workers=1\n        - --kubeconfig=/etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "errors": []
  },
  {
    "id": "04384",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20200416-dd6c31b18\n        args:\n        - --github-workers=5\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --slack-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --gcs-workers=1\n        - --kubernetes-gcs-workers=1\n        - --kubeconfig=/etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "errors": []
  },
  {
    "id": "04385",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod03\n  annotations:\n    cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.14.1\n    volumeMounts:\n    - mountPath: /var/local/aaa\n      name: mydir\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: mydir\n    emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04386",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod03\n  annotations:\n    cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.14.1\n    volumeMounts:\n    - mountPath: /var/local/aaa\n      name: mydir\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: mydir\n    emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04387",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod03\n  annotations:\n    cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.14.1\n    volumeMounts:\n    - mountPath: /var/local/aaa\n      name: mydir\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  volumes:\n  - name: mydir\n    emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04388",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod03\n  annotations:\n    cluster-autoscaler.kubernetes.io/safe-to-evict: 'true'\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.14.1\n    volumeMounts:\n    - mountPath: /var/local/aaa\n      name: mydir\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  volumes:\n  - name: mydir\n    emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04389",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: debian-debug\n  namespace: default\n  annotations:\n    injector.tumblr.com/request: test1\nspec:\n  containers:\n  - image: debian:jessie\n    command:\n    - sleep\n    - '3600'\n    imagePullPolicy: IfNotPresent\n    name: debian-debug\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04390",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: debian-debug\n  namespace: default\n  annotations:\n    injector.tumblr.com/request: test1\nspec:\n  containers:\n  - image: debian:jessie\n    command:\n    - sleep\n    - '3600'\n    imagePullPolicy: IfNotPresent\n    name: debian-debug\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04391",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: debian-debug\n  namespace: default\n  annotations:\n    injector.tumblr.com/request: test1\nspec:\n  containers:\n  - image: debian:jessie\n    command:\n    - sleep\n    - '3600'\n    imagePullPolicy: IfNotPresent\n    name: debian-debug\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04392",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: debian-debug\n  namespace: default\n  annotations:\n    injector.tumblr.com/request: test1\nspec:\n  containers:\n  - image: debian:jessie\n    command:\n    - sleep\n    - '3600'\n    imagePullPolicy: IfNotPresent\n    name: debian-debug\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04393",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-world\nspec:\n  selector:\n    matchLabels:\n      run: load-balancer-example\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: load-balancer-example\n    spec:\n      containers:\n      - name: hello-world\n        image: gcr.io/google-samples/node-hello:1.0\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04394",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-world\nspec:\n  selector:\n    matchLabels:\n      run: load-balancer-example\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: load-balancer-example\n    spec:\n      containers:\n      - name: hello-world\n        image: gcr.io/google-samples/node-hello:1.0\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04395",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-world\nspec:\n  selector:\n    matchLabels:\n      run: load-balancer-example\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: load-balancer-example\n    spec:\n      containers:\n      - name: hello-world\n        image: gcr.io/google-samples/node-hello:1.0\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04396",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-world\nspec:\n  selector:\n    matchLabels:\n      run: load-balancer-example\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: load-balancer-example\n    spec:\n      containers:\n      - name: hello-world\n        image: gcr.io/google-samples/node-hello:1.0\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04397",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pod-identity-webhook\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: pod-identity-webhook\n  template:\n    metadata:\n      labels:\n        app: pod-identity-webhook\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - pod-identity-webhook\n              topologyKey: kubernetes.io/hostname\n          - weight: 50\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - pod-identity-webhook\n              topologyKey: topology.kubernetes.io/zone\n      serviceAccountName: pod-identity-webhook\n      containers:\n      - name: pod-identity-webhook\n        image: IMAGE:stable\n        imagePullPolicy: Always\n        command:\n        - /webhook\n        - --in-cluster\n        - --namespace=kube-system\n        - --service-name=pod-identity-webhook\n        - --tls-secret=pod-identity-webhook\n        - --annotation-prefix=eks.amazonaws.com\n        - --token-audience=sts.amazonaws.com\n        - --logtostderr\n        resources:\n          limits:\n            cpu: 200m\n            memory: 64Mi\n          requests:\n            cpu: 200m\n            memory: 64Mi\n        volumeMounts:\n        - name: webhook-certs\n          mountPath: /var/run/app/certs\n          readOnly: false\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: webhook-certs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04398",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pod-identity-webhook\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: pod-identity-webhook\n  template:\n    metadata:\n      labels:\n        app: pod-identity-webhook\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - pod-identity-webhook\n              topologyKey: kubernetes.io/hostname\n          - weight: 50\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - pod-identity-webhook\n              topologyKey: topology.kubernetes.io/zone\n      serviceAccountName: pod-identity-webhook\n      containers:\n      - name: pod-identity-webhook\n        image: IMAGE:stable\n        imagePullPolicy: Always\n        command:\n        - /webhook\n        - --in-cluster\n        - --namespace=kube-system\n        - --service-name=pod-identity-webhook\n        - --tls-secret=pod-identity-webhook\n        - --annotation-prefix=eks.amazonaws.com\n        - --token-audience=sts.amazonaws.com\n        - --logtostderr\n        resources:\n          limits:\n            cpu: 200m\n            memory: 64Mi\n          requests:\n            cpu: 200m\n            memory: 64Mi\n        volumeMounts:\n        - name: webhook-certs\n          mountPath: /var/run/app/certs\n          readOnly: false\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: webhook-certs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04399",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pod-identity-webhook\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: pod-identity-webhook\n  template:\n    metadata:\n      labels:\n        app: pod-identity-webhook\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - pod-identity-webhook\n              topologyKey: kubernetes.io/hostname\n          - weight: 50\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - pod-identity-webhook\n              topologyKey: topology.kubernetes.io/zone\n      serviceAccountName: pod-identity-webhook\n      containers:\n      - name: pod-identity-webhook\n        image: IMAGE:stable\n        imagePullPolicy: Always\n        command:\n        - /webhook\n        - --in-cluster\n        - --namespace=kube-system\n        - --service-name=pod-identity-webhook\n        - --tls-secret=pod-identity-webhook\n        - --annotation-prefix=eks.amazonaws.com\n        - --token-audience=sts.amazonaws.com\n        - --logtostderr\n        resources:\n          limits:\n            cpu: 200m\n            memory: 64Mi\n          requests:\n            cpu: 200m\n            memory: 64Mi\n        volumeMounts:\n        - name: webhook-certs\n          mountPath: /var/run/app/certs\n          readOnly: false\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: webhook-certs\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04400",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: '1'\n  labels:\n    crunchy-pgha-scope: some-name-required\n    deployment-name: some-name-required\n    name: some-name-required\n    pg-cluster: some-name-required\n    pgo-pg-database: 'true'\n    pgo-version: 1.2.0\n    pgouser: admin\n    service-name: some-name-required\n    vendor: crunchydata\n  name: some-name-required\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      deployment-name: some-name-required\n      pg-cluster: some-name-required\n      pgo-pg-database: 'true'\n      vendor: crunchydata\n  template:\n    metadata:\n      annotations:\n        keep-backups: 'false'\n        keep-data: 'false'\n      labels:\n        crunchy-pgha-scope: some-name-required\n        deployment-name: some-name-required\n        name: some-name-required\n        pg-cluster: some-name-required\n        pg-pod-anti-affinity: required\n        pgo-pg-database: 'true'\n        pgo-version: 1.2.0\n        pgouser: admin\n        vendor: crunchydata\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: vendor\n                operator: In\n                values:\n                - crunchydata\n              - key: pg-pod-anti-affinity\n                operator: In\n                values:\n                - required\n                - require\n              - key: pg-cluster\n                operator: In\n                values:\n                - some-name-required\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - env:\n        - name: MODE\n          value: postgres\n        - name: PGHA_PG_PORT\n          value: '5432'\n        - name: PGHA_USER\n          value: postgres\n        - name: PGHA_INIT\n          valueFrom:\n            configMapKeyRef:\n              key: init\n              name: some-name-required-pgha-config\n        - name: PATRONI_POSTGRESQL_DATA_DIR\n          value: /pgdata/some-name-required\n        - name: PGBACKREST_STANZA\n          value: db\n        - name: PGBACKREST_REPO1_HOST\n          value: some-name-required-backrest-shared-repo\n        - name: BACKREST_SKIP_CREATE_STANZA\n          value: 'true'\n        - name: PGHA_PGBACKREST\n          value: 'true'\n        - name: PGBACKREST_REPO1_PATH\n          value: /backrestrepo/some-name-required-backrest-shared-repo\n        - name: PGBACKREST_DB_PATH\n          value: /pgdata/some-name-required\n        - name: ENABLE_SSHD\n          value: 'true'\n        - name: PGBACKREST_LOG_PATH\n          value: /tmp\n        - name: PGBACKREST_PG1_SOCKET_PATH\n          value: /tmp\n        - name: PGBACKREST_PG1_PORT\n          value: '5432'\n        - name: PGBACKREST_REPO1_TYPE\n          value: posix\n        - name: PGHA_PGBACKREST_LOCAL_S3_STORAGE\n          value: 'false'\n        - name: PGHA_PGBACKREST_LOCAL_GCS_STORAGE\n          value: 'false'\n        - name: PGHA_DATABASE\n          value: some-name-required\n        - name: PGHA_REPLICA_REINIT_ON_START_FAIL\n          value: 'true'\n        - name: PGHA_SYNC_REPLICATION\n          value: 'false'\n        - name: PGHA_TLS_ENABLED\n          value: 'false'\n        - name: PGHA_TLS_ONLY\n          value: 'false'\n        - name: PGHA_PASSWORD_TYPE\n          valueFrom:\n            secretKeyRef:\n              name: some-name-required-backrest-repo-config\n              key: pgha_password_type\n        - name: PGHA_STANDBY\n          value: 'false'\n        - name: PATRONI_KUBERNETES_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: PATRONI_KUBERNETES_SCOPE_LABEL\n          value: crunchy-pgha-scope\n        - name: PATRONI_SCOPE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.labels['crunchy-pgha-scope']\n        - name: PATRONI_KUBERNETES_LABELS\n          value: '{vendor: \"crunchydata\"}'\n        - name: PATRONI_LOG_LEVEL\n          value: INFO\n        - name: PGHOST\n          value: /tmp\n        - name: LD_PRELOAD\n          value: /usr/lib64/libnss_wrapper.so\n        - name: NSS_WRAPPER_PASSWD\n          value: /tmp/nss_wrapper/postgres/passwd\n        - name: NSS_WRAPPER_GROUP\n          value: /tmp/nss_wrapper/postgres/group\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          exec:\n            command:\n            - /opt/crunchy/bin/postgres-ha/health/pgha-liveness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 10\n        name: database\n        ports:\n        - containerPort: 5432\n          name: postgres\n          protocol: TCP\n        - containerPort: 8009\n          name: patroni\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - /opt/crunchy/bin/postgres-ha/health/pgha-readiness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 15\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            memory: 128Mi\n            cpu: 100m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /pgdata\n          name: pgdata\n        - mountPath: /pgconf/pguser\n          name: user-volume\n        - mountPath: /pgconf/pgreplicator\n          name: primary-volume\n        - mountPath: /pgconf/pgsuper\n          name: root-volume\n        - mountPath: /sshd\n          name: sshd\n          readOnly: true\n        - mountPath: /etc/ssh\n          name: ssh-config\n          readOnly: true\n        - mountPath: /pgconf\n          name: pgconf-volume\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /etc/pgbackrest/conf.d\n          name: pgbackrest-config\n        - mountPath: /etc/podinfo\n          name: podinfo\n        - mountPath: /tmp\n          name: tmp\n        image: busybox:stable\n      securityContext:\n        supplementalGroups:\n        - 1001\n      serviceAccount: pgo-pg\n      serviceAccountName: pgo-pg\n      volumes:\n      - name: pgdata\n        persistentVolumeClaim:\n          claimName: some-name-required\n      - name: user-volume\n        secret:\n          defaultMode: 420\n          secretName: some-name-required-some-name-secret\n      - name: primary-volume\n        secret:\n          defaultMode: 420\n          secretName: some-name-required-primaryuser-secret\n      - name: sshd\n        secret:\n          defaultMode: 420\n          secretName: some-name-required-backrest-repo-config\n      - name: ssh-config\n        secret:\n          defaultMode: 420\n          items:\n          - key: config\n            path: ssh_config\n          secretName: some-name-required-backrest-repo-config\n      - name: root-volume\n        secret:\n          defaultMode: 420\n          secretName: some-name-required-postgres-secret\n      - emptyDir:\n          medium: Memory\n          sizeLimit: 64Mi\n        name: report\n      - emptyDir:\n          medium: Memory\n        name: dshm\n      - emptyDir:\n          medium: Memory\n          sizeLimit: 16Mi\n        name: tmp\n      - name: pgbackrest-config\n        projected:\n          defaultMode: 420\n          sources:\n          - configMap:\n              name: some-name-required-config-backrest\n              optional: true\n          - secret:\n              name: some-name-required-config-backrest\n              optional: true\n      - name: pgconf-volume\n        projected:\n          defaultMode: 420\n          sources:\n          - configMap:\n              name: some-name-required-pgha-config\n              optional: true\n      - downwardAPI:\n          defaultMode: 420\n          items:\n          - path: cpu_limit\n            resourceFieldRef:\n              containerName: database\n              divisor: 1m\n              resource: limits.cpu\n          - path: cpu_request\n            resourceFieldRef:\n              containerName: database\n              divisor: 1m\n              resource: requests.cpu\n          - path: mem_limit\n            resourceFieldRef:\n              containerName: database\n              divisor: '0'\n              resource: limits.memory\n          - path: mem_request\n            resourceFieldRef:\n              containerName: database\n              divisor: '0'\n              resource: requests.memory\n          - fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.labels\n            path: labels\n          - fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.annotations\n            path: annotations\n        name: podinfo\n",
    "errors": []
  },
  {
    "id": "04401",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: '1'\n  labels:\n    crunchy-pgha-scope: some-name-required\n    deployment-name: some-name-required\n    name: some-name-required\n    pg-cluster: some-name-required\n    pgo-pg-database: 'true'\n    pgo-version: 1.2.0\n    pgouser: admin\n    service-name: some-name-required\n    vendor: crunchydata\n  name: some-name-required\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      deployment-name: some-name-required\n      pg-cluster: some-name-required\n      pgo-pg-database: 'true'\n      vendor: crunchydata\n  template:\n    metadata:\n      annotations:\n        keep-backups: 'false'\n        keep-data: 'false'\n      labels:\n        crunchy-pgha-scope: some-name-required\n        deployment-name: some-name-required\n        name: some-name-required\n        pg-cluster: some-name-required\n        pg-pod-anti-affinity: required\n        pgo-pg-database: 'true'\n        pgo-version: 1.2.0\n        pgouser: admin\n        vendor: crunchydata\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: vendor\n                operator: In\n                values:\n                - crunchydata\n              - key: pg-pod-anti-affinity\n                operator: In\n                values:\n                - required\n                - require\n              - key: pg-cluster\n                operator: In\n                values:\n                - some-name-required\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - env:\n        - name: MODE\n          value: postgres\n        - name: PGHA_PG_PORT\n          value: '5432'\n        - name: PGHA_USER\n          value: postgres\n        - name: PGHA_INIT\n          valueFrom:\n            configMapKeyRef:\n              key: init\n              name: some-name-required-pgha-config\n        - name: PATRONI_POSTGRESQL_DATA_DIR\n          value: /pgdata/some-name-required\n        - name: PGBACKREST_STANZA\n          value: db\n        - name: PGBACKREST_REPO1_HOST\n          value: some-name-required-backrest-shared-repo\n        - name: BACKREST_SKIP_CREATE_STANZA\n          value: 'true'\n        - name: PGHA_PGBACKREST\n          value: 'true'\n        - name: PGBACKREST_REPO1_PATH\n          value: /backrestrepo/some-name-required-backrest-shared-repo\n        - name: PGBACKREST_DB_PATH\n          value: /pgdata/some-name-required\n        - name: ENABLE_SSHD\n          value: 'true'\n        - name: PGBACKREST_LOG_PATH\n          value: /tmp\n        - name: PGBACKREST_PG1_SOCKET_PATH\n          value: /tmp\n        - name: PGBACKREST_PG1_PORT\n          value: '5432'\n        - name: PGBACKREST_REPO1_TYPE\n          value: posix\n        - name: PGHA_PGBACKREST_LOCAL_S3_STORAGE\n          value: 'false'\n        - name: PGHA_PGBACKREST_LOCAL_GCS_STORAGE\n          value: 'false'\n        - name: PGHA_DATABASE\n          value: some-name-required\n        - name: PGHA_REPLICA_REINIT_ON_START_FAIL\n          value: 'true'\n        - name: PGHA_SYNC_REPLICATION\n          value: 'false'\n        - name: PGHA_TLS_ENABLED\n          value: 'false'\n        - name: PGHA_TLS_ONLY\n          value: 'false'\n        - name: PGHA_PASSWORD_TYPE\n          valueFrom:\n            secretKeyRef:\n              name: some-name-required-backrest-repo-config\n              key: pgha_password_type\n        - name: PGHA_STANDBY\n          value: 'false'\n        - name: PATRONI_KUBERNETES_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: PATRONI_KUBERNETES_SCOPE_LABEL\n          value: crunchy-pgha-scope\n        - name: PATRONI_SCOPE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.labels['crunchy-pgha-scope']\n        - name: PATRONI_KUBERNETES_LABELS\n          value: '{vendor: \"crunchydata\"}'\n        - name: PATRONI_LOG_LEVEL\n          value: INFO\n        - name: PGHOST\n          value: /tmp\n        - name: LD_PRELOAD\n          value: /usr/lib64/libnss_wrapper.so\n        - name: NSS_WRAPPER_PASSWD\n          value: /tmp/nss_wrapper/postgres/passwd\n        - name: NSS_WRAPPER_GROUP\n          value: /tmp/nss_wrapper/postgres/group\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          exec:\n            command:\n            - /opt/crunchy/bin/postgres-ha/health/pgha-liveness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 10\n        name: database\n        ports:\n        - containerPort: 5432\n          name: postgres\n          protocol: TCP\n        - containerPort: 8009\n          name: patroni\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - /opt/crunchy/bin/postgres-ha/health/pgha-readiness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 15\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            memory: 128Mi\n            cpu: 100m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          privileged: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n        volumeMounts:\n        - mountPath: /pgdata\n          name: pgdata\n        - mountPath: /pgconf/pguser\n          name: user-volume\n        - mountPath: /pgconf/pgreplicator\n          name: primary-volume\n        - mountPath: /pgconf/pgsuper\n          name: root-volume\n        - mountPath: /sshd\n          name: sshd\n          readOnly: true\n        - mountPath: /etc/ssh\n          name: ssh-config\n          readOnly: true\n        - mountPath: /pgconf\n          name: pgconf-volume\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /etc/pgbackrest/conf.d\n          name: pgbackrest-config\n        - mountPath: /etc/podinfo\n          name: podinfo\n        - mountPath: /tmp\n          name: tmp\n        image: busybox:stable\n      securityContext:\n        supplementalGroups:\n        - 1001\n      serviceAccount: pgo-pg\n      serviceAccountName: pgo-pg\n      volumes:\n      - name: pgdata\n        persistentVolumeClaim:\n          claimName: some-name-required\n      - name: user-volume\n        secret:\n          defaultMode: 420\n          secretName: some-name-required-some-name-secret\n      - name: primary-volume\n        secret:\n          defaultMode: 420\n          secretName: some-name-required-primaryuser-secret\n      - name: sshd\n        secret:\n          defaultMode: 420\n          secretName: some-name-required-backrest-repo-config\n      - name: ssh-config\n        secret:\n          defaultMode: 420\n          items:\n          - key: config\n            path: ssh_config\n          secretName: some-name-required-backrest-repo-config\n      - name: root-volume\n        secret:\n          defaultMode: 420\n          secretName: some-name-required-postgres-secret\n      - emptyDir:\n          medium: Memory\n          sizeLimit: 64Mi\n        name: report\n      - emptyDir:\n          medium: Memory\n        name: dshm\n      - emptyDir:\n          medium: Memory\n          sizeLimit: 16Mi\n        name: tmp\n      - name: pgbackrest-config\n        projected:\n          defaultMode: 420\n          sources:\n          - configMap:\n              name: some-name-required-config-backrest\n              optional: true\n          - secret:\n              name: some-name-required-config-backrest\n              optional: true\n      - name: pgconf-volume\n        projected:\n          defaultMode: 420\n          sources:\n          - configMap:\n              name: some-name-required-pgha-config\n              optional: true\n      - downwardAPI:\n          defaultMode: 420\n          items:\n          - path: cpu_limit\n            resourceFieldRef:\n              containerName: database\n              divisor: 1m\n              resource: limits.cpu\n          - path: cpu_request\n            resourceFieldRef:\n              containerName: database\n              divisor: 1m\n              resource: requests.cpu\n          - path: mem_limit\n            resourceFieldRef:\n              containerName: database\n              divisor: '0'\n              resource: limits.memory\n          - path: mem_request\n            resourceFieldRef:\n              containerName: database\n              divisor: '0'\n              resource: requests.memory\n          - fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.labels\n            path: labels\n          - fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.annotations\n            path: annotations\n        name: podinfo\n",
    "errors": []
  },
  {
    "id": "04402",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: '1'\n  labels:\n    crunchy-pgha-scope: some-name-required\n    deployment-name: some-name-required\n    name: some-name-required\n    pg-cluster: some-name-required\n    pgo-pg-database: 'true'\n    pgo-version: 1.2.0\n    pgouser: admin\n    service-name: some-name-required\n    vendor: crunchydata\n  name: some-name-required\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      deployment-name: some-name-required\n      pg-cluster: some-name-required\n      pgo-pg-database: 'true'\n      vendor: crunchydata\n  template:\n    metadata:\n      annotations:\n        keep-backups: 'false'\n        keep-data: 'false'\n      labels:\n        crunchy-pgha-scope: some-name-required\n        deployment-name: some-name-required\n        name: some-name-required\n        pg-cluster: some-name-required\n        pg-pod-anti-affinity: required\n        pgo-pg-database: 'true'\n        pgo-version: 1.2.0\n        pgouser: admin\n        vendor: crunchydata\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: vendor\n                operator: In\n                values:\n                - crunchydata\n              - key: pg-pod-anti-affinity\n                operator: In\n                values:\n                - required\n                - require\n              - key: pg-cluster\n                operator: In\n                values:\n                - some-name-required\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - env:\n        - name: MODE\n          value: postgres\n        - name: PGHA_PG_PORT\n          value: '5432'\n        - name: PGHA_USER\n          value: postgres\n        - name: PGHA_INIT\n          valueFrom:\n            configMapKeyRef:\n              key: init\n              name: some-name-required-pgha-config\n        - name: PATRONI_POSTGRESQL_DATA_DIR\n          value: /pgdata/some-name-required\n        - name: PGBACKREST_STANZA\n          value: db\n        - name: PGBACKREST_REPO1_HOST\n          value: some-name-required-backrest-shared-repo\n        - name: BACKREST_SKIP_CREATE_STANZA\n          value: 'true'\n        - name: PGHA_PGBACKREST\n          value: 'true'\n        - name: PGBACKREST_REPO1_PATH\n          value: /backrestrepo/some-name-required-backrest-shared-repo\n        - name: PGBACKREST_DB_PATH\n          value: /pgdata/some-name-required\n        - name: ENABLE_SSHD\n          value: 'true'\n        - name: PGBACKREST_LOG_PATH\n          value: /tmp\n        - name: PGBACKREST_PG1_SOCKET_PATH\n          value: /tmp\n        - name: PGBACKREST_PG1_PORT\n          value: '5432'\n        - name: PGBACKREST_REPO1_TYPE\n          value: posix\n        - name: PGHA_PGBACKREST_LOCAL_S3_STORAGE\n          value: 'false'\n        - name: PGHA_PGBACKREST_LOCAL_GCS_STORAGE\n          value: 'false'\n        - name: PGHA_DATABASE\n          value: some-name-required\n        - name: PGHA_REPLICA_REINIT_ON_START_FAIL\n          value: 'true'\n        - name: PGHA_SYNC_REPLICATION\n          value: 'false'\n        - name: PGHA_TLS_ENABLED\n          value: 'false'\n        - name: PGHA_TLS_ONLY\n          value: 'false'\n        - name: PGHA_PASSWORD_TYPE\n          valueFrom:\n            secretKeyRef:\n              name: some-name-required-backrest-repo-config\n              key: pgha_password_type\n        - name: PGHA_STANDBY\n          value: 'false'\n        - name: PATRONI_KUBERNETES_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: PATRONI_KUBERNETES_SCOPE_LABEL\n          value: crunchy-pgha-scope\n        - name: PATRONI_SCOPE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.labels['crunchy-pgha-scope']\n        - name: PATRONI_KUBERNETES_LABELS\n          value: '{vendor: \"crunchydata\"}'\n        - name: PATRONI_LOG_LEVEL\n          value: INFO\n        - name: PGHOST\n          value: /tmp\n        - name: LD_PRELOAD\n          value: /usr/lib64/libnss_wrapper.so\n        - name: NSS_WRAPPER_PASSWD\n          value: /tmp/nss_wrapper/postgres/passwd\n        - name: NSS_WRAPPER_GROUP\n          value: /tmp/nss_wrapper/postgres/group\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          exec:\n            command:\n            - /opt/crunchy/bin/postgres-ha/health/pgha-liveness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 10\n        name: database\n        ports:\n        - containerPort: 5432\n          name: postgres\n          protocol: TCP\n        - containerPort: 8009\n          name: patroni\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - /opt/crunchy/bin/postgres-ha/health/pgha-readiness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 15\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            memory: 128Mi\n            cpu: 100m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /pgdata\n          name: pgdata\n        - mountPath: /pgconf/pguser\n          name: user-volume\n        - mountPath: /pgconf/pgreplicator\n          name: primary-volume\n        - mountPath: /pgconf/pgsuper\n          name: root-volume\n        - mountPath: /sshd\n          name: sshd\n          readOnly: true\n        - mountPath: /etc/ssh\n          name: ssh-config\n          readOnly: true\n        - mountPath: /pgconf\n          name: pgconf-volume\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /etc/pgbackrest/conf.d\n          name: pgbackrest-config\n        - mountPath: /etc/podinfo\n          name: podinfo\n        - mountPath: /tmp\n          name: tmp\n        image: busybox:stable\n      securityContext:\n        supplementalGroups:\n        - 1001\n      serviceAccount: pgo-pg\n      serviceAccountName: pgo-pg\n      volumes:\n      - name: pgdata\n        persistentVolumeClaim:\n          claimName: some-name-required\n      - name: user-volume\n        secret:\n          defaultMode: 420\n          secretName: some-name-required-some-name-secret\n      - name: primary-volume\n        secret:\n          defaultMode: 420\n          secretName: some-name-required-primaryuser-secret\n      - name: sshd\n        secret:\n          defaultMode: 420\n          secretName: some-name-required-backrest-repo-config\n      - name: ssh-config\n        secret:\n          defaultMode: 420\n          items:\n          - key: config\n            path: ssh_config\n          secretName: some-name-required-backrest-repo-config\n      - name: root-volume\n        secret:\n          defaultMode: 420\n          secretName: some-name-required-postgres-secret\n      - emptyDir:\n          medium: Memory\n          sizeLimit: 64Mi\n        name: report\n      - emptyDir:\n          medium: Memory\n        name: dshm\n      - emptyDir:\n          medium: Memory\n          sizeLimit: 16Mi\n        name: tmp\n      - name: pgbackrest-config\n        projected:\n          defaultMode: 420\n          sources:\n          - configMap:\n              name: some-name-required-config-backrest\n              optional: true\n          - secret:\n              name: some-name-required-config-backrest\n              optional: true\n      - name: pgconf-volume\n        projected:\n          defaultMode: 420\n          sources:\n          - configMap:\n              name: some-name-required-pgha-config\n              optional: true\n      - downwardAPI:\n          defaultMode: 420\n          items:\n          - path: cpu_limit\n            resourceFieldRef:\n              containerName: database\n              divisor: 1m\n              resource: limits.cpu\n          - path: cpu_request\n            resourceFieldRef:\n              containerName: database\n              divisor: 1m\n              resource: requests.cpu\n          - path: mem_limit\n            resourceFieldRef:\n              containerName: database\n              divisor: '0'\n              resource: limits.memory\n          - path: mem_request\n            resourceFieldRef:\n              containerName: database\n              divisor: '0'\n              resource: requests.memory\n          - fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.labels\n            path: labels\n          - fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.annotations\n            path: annotations\n        name: podinfo\n",
    "errors": []
  },
  {
    "id": "04403",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: '1'\n  labels:\n    crunchy-pgha-scope: some-name-required\n    deployment-name: some-name-required\n    name: some-name-required\n    pg-cluster: some-name-required\n    pgo-pg-database: 'true'\n    pgo-version: 1.2.0\n    pgouser: admin\n    service-name: some-name-required\n    vendor: crunchydata\n  name: some-name-required\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      deployment-name: some-name-required\n      pg-cluster: some-name-required\n      pgo-pg-database: 'true'\n      vendor: crunchydata\n  template:\n    metadata:\n      annotations:\n        keep-backups: 'false'\n        keep-data: 'false'\n      labels:\n        crunchy-pgha-scope: some-name-required\n        deployment-name: some-name-required\n        name: some-name-required\n        pg-cluster: some-name-required\n        pg-pod-anti-affinity: required\n        pgo-pg-database: 'true'\n        pgo-version: 1.2.0\n        pgouser: admin\n        vendor: crunchydata\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: vendor\n                operator: In\n                values:\n                - crunchydata\n              - key: pg-pod-anti-affinity\n                operator: In\n                values:\n                - required\n                - require\n              - key: pg-cluster\n                operator: In\n                values:\n                - some-name-required\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - env:\n        - name: MODE\n          value: postgres\n        - name: PGHA_PG_PORT\n          value: '5432'\n        - name: PGHA_USER\n          value: postgres\n        - name: PGHA_INIT\n          valueFrom:\n            configMapKeyRef:\n              key: init\n              name: some-name-required-pgha-config\n        - name: PATRONI_POSTGRESQL_DATA_DIR\n          value: /pgdata/some-name-required\n        - name: PGBACKREST_STANZA\n          value: db\n        - name: PGBACKREST_REPO1_HOST\n          value: some-name-required-backrest-shared-repo\n        - name: BACKREST_SKIP_CREATE_STANZA\n          value: 'true'\n        - name: PGHA_PGBACKREST\n          value: 'true'\n        - name: PGBACKREST_REPO1_PATH\n          value: /backrestrepo/some-name-required-backrest-shared-repo\n        - name: PGBACKREST_DB_PATH\n          value: /pgdata/some-name-required\n        - name: ENABLE_SSHD\n          value: 'true'\n        - name: PGBACKREST_LOG_PATH\n          value: /tmp\n        - name: PGBACKREST_PG1_SOCKET_PATH\n          value: /tmp\n        - name: PGBACKREST_PG1_PORT\n          value: '5432'\n        - name: PGBACKREST_REPO1_TYPE\n          value: posix\n        - name: PGHA_PGBACKREST_LOCAL_S3_STORAGE\n          value: 'false'\n        - name: PGHA_PGBACKREST_LOCAL_GCS_STORAGE\n          value: 'false'\n        - name: PGHA_DATABASE\n          value: some-name-required\n        - name: PGHA_REPLICA_REINIT_ON_START_FAIL\n          value: 'true'\n        - name: PGHA_SYNC_REPLICATION\n          value: 'false'\n        - name: PGHA_TLS_ENABLED\n          value: 'false'\n        - name: PGHA_TLS_ONLY\n          value: 'false'\n        - name: PGHA_PASSWORD_TYPE\n          valueFrom:\n            secretKeyRef:\n              name: some-name-required-backrest-repo-config\n              key: pgha_password_type\n        - name: PGHA_STANDBY\n          value: 'false'\n        - name: PATRONI_KUBERNETES_NAMESPACE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.namespace\n        - name: PATRONI_KUBERNETES_SCOPE_LABEL\n          value: crunchy-pgha-scope\n        - name: PATRONI_SCOPE\n          valueFrom:\n            fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.labels['crunchy-pgha-scope']\n        - name: PATRONI_KUBERNETES_LABELS\n          value: '{vendor: \"crunchydata\"}'\n        - name: PATRONI_LOG_LEVEL\n          value: INFO\n        - name: PGHOST\n          value: /tmp\n        - name: LD_PRELOAD\n          value: /usr/lib64/libnss_wrapper.so\n        - name: NSS_WRAPPER_PASSWD\n          value: /tmp/nss_wrapper/postgres/passwd\n        - name: NSS_WRAPPER_GROUP\n          value: /tmp/nss_wrapper/postgres/group\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          exec:\n            command:\n            - /opt/crunchy/bin/postgres-ha/health/pgha-liveness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 10\n        name: database\n        ports:\n        - containerPort: 5432\n          name: postgres\n          protocol: TCP\n        - containerPort: 8009\n          name: patroni\n          protocol: TCP\n        readinessProbe:\n          exec:\n            command:\n            - /opt/crunchy/bin/postgres-ha/health/pgha-readiness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 15\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            memory: 128Mi\n            cpu: 100m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /pgdata\n          name: pgdata\n        - mountPath: /pgconf/pguser\n          name: user-volume\n        - mountPath: /pgconf/pgreplicator\n          name: primary-volume\n        - mountPath: /pgconf/pgsuper\n          name: root-volume\n        - mountPath: /sshd\n          name: sshd\n          readOnly: true\n        - mountPath: /etc/ssh\n          name: ssh-config\n          readOnly: true\n        - mountPath: /pgconf\n          name: pgconf-volume\n        - mountPath: /dev/shm\n          name: dshm\n        - mountPath: /etc/pgbackrest/conf.d\n          name: pgbackrest-config\n        - mountPath: /etc/podinfo\n          name: podinfo\n        - mountPath: /tmp\n          name: tmp\n        image: busybox:stable\n      securityContext:\n        supplementalGroups:\n        - 1001\n      serviceAccount: pgo-pg\n      serviceAccountName: pgo-pg\n      volumes:\n      - name: pgdata\n        persistentVolumeClaim:\n          claimName: some-name-required\n      - name: user-volume\n        secret:\n          defaultMode: 420\n          secretName: some-name-required-some-name-secret\n      - name: primary-volume\n        secret:\n          defaultMode: 420\n          secretName: some-name-required-primaryuser-secret\n      - name: sshd\n        secret:\n          defaultMode: 420\n          secretName: some-name-required-backrest-repo-config\n      - name: ssh-config\n        secret:\n          defaultMode: 420\n          items:\n          - key: config\n            path: ssh_config\n          secretName: some-name-required-backrest-repo-config\n      - name: root-volume\n        secret:\n          defaultMode: 420\n          secretName: some-name-required-postgres-secret\n      - emptyDir:\n          medium: Memory\n          sizeLimit: 64Mi\n        name: report\n      - emptyDir:\n          medium: Memory\n        name: dshm\n      - emptyDir:\n          medium: Memory\n          sizeLimit: 16Mi\n        name: tmp\n      - name: pgbackrest-config\n        projected:\n          defaultMode: 420\n          sources:\n          - configMap:\n              name: some-name-required-config-backrest\n              optional: true\n          - secret:\n              name: some-name-required-config-backrest\n              optional: true\n      - name: pgconf-volume\n        projected:\n          defaultMode: 420\n          sources:\n          - configMap:\n              name: some-name-required-pgha-config\n              optional: true\n      - downwardAPI:\n          defaultMode: 420\n          items:\n          - path: cpu_limit\n            resourceFieldRef:\n              containerName: database\n              divisor: 1m\n              resource: limits.cpu\n          - path: cpu_request\n            resourceFieldRef:\n              containerName: database\n              divisor: 1m\n              resource: requests.cpu\n          - path: mem_limit\n            resourceFieldRef:\n              containerName: database\n              divisor: '0'\n              resource: limits.memory\n          - path: mem_request\n            resourceFieldRef:\n              containerName: database\n              divisor: '0'\n              resource: requests.memory\n          - fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.labels\n            path: labels\n          - fieldRef:\n              apiVersion: v1\n              fieldPath: metadata.annotations\n            path: annotations\n        name: podinfo\n",
    "errors": []
  },
  {
    "id": "04404",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    clusterctl.cluster.x-k8s.io/core: capi-operator\n    control-plane: controller-manager\n  name: capi-operator-controller-manager\n  namespace: openshift-cluster-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      clusterctl.cluster.x-k8s.io/core: capi-operator\n      control-plane: controller-manager\n  template:\n    metadata:\n      labels:\n        clusterctl.cluster.x-k8s.io/core: capi-operator\n        control-plane: controller-manager\n    spec:\n      containers:\n      - args:\n        - --secure-listen-address=0.0.0.0:8443\n        - --upstream=http://127.0.0.1:8080/\n        - --logtostderr=true\n        - --v=10\n        image: gcr.io/kubebuilder/kube-rbac-proxy:v0.5.0\n        name: kube-rbac-proxy\n        ports:\n        - containerPort: 8443\n          name: https\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - --metrics-bind-addr=127.0.0.1:8080\n        - --leader-elect\n        command:\n        - /manager\n        image: controller:stable\n        name: manager\n        resources:\n          limits:\n            cpu: 100m\n            memory: 150Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04405",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    clusterctl.cluster.x-k8s.io/core: capi-operator\n    control-plane: controller-manager\n  name: capi-operator-controller-manager\n  namespace: openshift-cluster-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      clusterctl.cluster.x-k8s.io/core: capi-operator\n      control-plane: controller-manager\n  template:\n    metadata:\n      labels:\n        clusterctl.cluster.x-k8s.io/core: capi-operator\n        control-plane: controller-manager\n    spec:\n      containers:\n      - args:\n        - --secure-listen-address=0.0.0.0:8443\n        - --upstream=http://127.0.0.1:8080/\n        - --logtostderr=true\n        - --v=10\n        image: gcr.io/kubebuilder/kube-rbac-proxy:v0.5.0\n        name: kube-rbac-proxy\n        ports:\n        - containerPort: 8443\n          name: https\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - --metrics-bind-addr=127.0.0.1:8080\n        - --leader-elect\n        command:\n        - /manager\n        image: controller:stable\n        name: manager\n        resources:\n          limits:\n            cpu: 100m\n            memory: 150Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04406",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    clusterctl.cluster.x-k8s.io/core: capi-operator\n    control-plane: controller-manager\n  name: capi-operator-controller-manager\n  namespace: openshift-cluster-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      clusterctl.cluster.x-k8s.io/core: capi-operator\n      control-plane: controller-manager\n  template:\n    metadata:\n      labels:\n        clusterctl.cluster.x-k8s.io/core: capi-operator\n        control-plane: controller-manager\n    spec:\n      containers:\n      - args:\n        - --secure-listen-address=0.0.0.0:8443\n        - --upstream=http://127.0.0.1:8080/\n        - --logtostderr=true\n        - --v=10\n        image: gcr.io/kubebuilder/kube-rbac-proxy:v0.5.0\n        name: kube-rbac-proxy\n        ports:\n        - containerPort: 8443\n          name: https\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - --metrics-bind-addr=127.0.0.1:8080\n        - --leader-elect\n        command:\n        - /manager\n        image: controller:stable\n        name: manager\n        resources:\n          limits:\n            cpu: 100m\n            memory: 150Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04407",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    clusterctl.cluster.x-k8s.io/core: capi-operator\n    control-plane: controller-manager\n  name: capi-operator-controller-manager\n  namespace: openshift-cluster-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      clusterctl.cluster.x-k8s.io/core: capi-operator\n      control-plane: controller-manager\n  template:\n    metadata:\n      labels:\n        clusterctl.cluster.x-k8s.io/core: capi-operator\n        control-plane: controller-manager\n    spec:\n      containers:\n      - args:\n        - --secure-listen-address=0.0.0.0:8443\n        - --upstream=http://127.0.0.1:8080/\n        - --logtostderr=true\n        - --v=10\n        image: gcr.io/kubebuilder/kube-rbac-proxy:v0.5.0\n        name: kube-rbac-proxy\n        ports:\n        - containerPort: 8443\n          name: https\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - --metrics-bind-addr=127.0.0.1:8080\n        - --leader-elect\n        command:\n        - /manager\n        image: controller:stable\n        name: manager\n        resources:\n          limits:\n            cpu: 100m\n            memory: 150Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04408",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    clusterctl.cluster.x-k8s.io/core: capi-operator\n    control-plane: controller-manager\n  name: capi-operator-controller-manager\n  namespace: openshift-cluster-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      clusterctl.cluster.x-k8s.io/core: capi-operator\n      control-plane: controller-manager\n  template:\n    metadata:\n      labels:\n        clusterctl.cluster.x-k8s.io/core: capi-operator\n        control-plane: controller-manager\n    spec:\n      containers:\n      - args:\n        - --secure-listen-address=0.0.0.0:8443\n        - --upstream=http://127.0.0.1:8080/\n        - --logtostderr=true\n        - --v=10\n        image: gcr.io/kubebuilder/kube-rbac-proxy:v0.5.0\n        name: kube-rbac-proxy\n        ports:\n        - containerPort: 8443\n          name: https\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - --metrics-bind-addr=127.0.0.1:8080\n        - --leader-elect\n        command:\n        - /manager\n        image: controller:stable\n        name: manager\n        resources:\n          limits:\n            cpu: 100m\n            memory: 150Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04409",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    clusterctl.cluster.x-k8s.io/core: capi-operator\n    control-plane: controller-manager\n  name: capi-operator-controller-manager\n  namespace: openshift-cluster-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      clusterctl.cluster.x-k8s.io/core: capi-operator\n      control-plane: controller-manager\n  template:\n    metadata:\n      labels:\n        clusterctl.cluster.x-k8s.io/core: capi-operator\n        control-plane: controller-manager\n    spec:\n      containers:\n      - args:\n        - --secure-listen-address=0.0.0.0:8443\n        - --upstream=http://127.0.0.1:8080/\n        - --logtostderr=true\n        - --v=10\n        image: gcr.io/kubebuilder/kube-rbac-proxy:v0.5.0\n        name: kube-rbac-proxy\n        ports:\n        - containerPort: 8443\n          name: https\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - args:\n        - --metrics-bind-addr=127.0.0.1:8080\n        - --leader-elect\n        command:\n        - /manager\n        image: controller:stable\n        name: manager\n        resources:\n          limits:\n            cpu: 100m\n            memory: 150Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04410",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    clusterctl.cluster.x-k8s.io/core: capi-operator\n    control-plane: controller-manager\n  name: capi-operator-controller-manager\n  namespace: openshift-cluster-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      clusterctl.cluster.x-k8s.io/core: capi-operator\n      control-plane: controller-manager\n  template:\n    metadata:\n      labels:\n        clusterctl.cluster.x-k8s.io/core: capi-operator\n        control-plane: controller-manager\n    spec:\n      containers:\n      - args:\n        - --secure-listen-address=0.0.0.0:8443\n        - --upstream=http://127.0.0.1:8080/\n        - --logtostderr=true\n        - --v=10\n        image: gcr.io/kubebuilder/kube-rbac-proxy:v0.5.0\n        name: kube-rbac-proxy\n        ports:\n        - containerPort: 8443\n          name: https\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - args:\n        - --metrics-bind-addr=127.0.0.1:8080\n        - --leader-elect\n        command:\n        - /manager\n        image: controller:stable\n        name: manager\n        resources:\n          limits:\n            cpu: 100m\n            memory: 150Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04411",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"ibmmq-producer\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04412",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"ibmmq-producer\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04413",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"ibmmq-producer\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04414",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"ibmmq-producer\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04415",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"ibmmq-producer\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04416",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"label-sync\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04417",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"label-sync\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04418",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"label-sync\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04419",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"label-sync\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04420",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes6\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - name: volume-rbd\n    rbd:\n      image: testing\n      monitors:\n      - testing\n",
    "errors": []
  },
  {
    "id": "04421",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes6\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - name: volume-rbd\n    rbd:\n      image: testing\n      monitors:\n      - testing\n",
    "errors": []
  },
  {
    "id": "04422",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes6\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - name: volume-rbd\n    rbd:\n      image: testing\n      monitors:\n      - testing\n",
    "errors": []
  },
  {
    "id": "04423",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes6\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - name: volume-rbd\n    rbd:\n      image: testing\n      monitors:\n      - testing\n",
    "errors": []
  },
  {
    "id": "04424",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes6\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - name: volume-rbd\n    rbd:\n      image: testing\n      monitors:\n      - testing\n",
    "errors": []
  },
  {
    "id": "04425",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes6\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - name: volume-rbd\n    rbd:\n      image: testing\n      monitors:\n      - testing\n",
    "errors": []
  },
  {
    "id": "04426",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes6\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - name: volume-rbd\n    rbd:\n      image: testing\n      monitors:\n      - testing\n",
    "errors": []
  },
  {
    "id": "04427",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: restrictedvolumes6\nspec:\n  containers:\n  - image: k8s.gcr.io/pause:stable\n    name: container1\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  initContainers:\n  - image: k8s.gcr.io/pause:stable\n    name: initcontainer1\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  securityContext:\n    runAsNonRoot: true\n  volumes:\n  - name: volume-rbd\n    rbd:\n      image: testing\n      monitors:\n      - testing\n",
    "errors": []
  },
  {
    "id": "04428",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress\n  namespace: nginx-ingress\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx-ingress\n  template:\n    metadata:\n      labels:\n        app: nginx-ingress\n      annotations:\n        co.elastic.logs/module: nginx\n        co.elastic.logs/fileset.stdout: access\n        co.elastic.logs/fileset.stderr: error\n        co.elastic.metrics/module: nginx\n        co.elastic.metrics/hosts: ${data.host}:${data.port}\n    spec:\n      serviceAccountName: nginx-ingress\n      containers:\n      - image: wangsiming519/nginx-ingress:opentracing_1.7.0\n        imagePullPolicy: Always\n        name: nginx-ingress\n        ports:\n        - name: http\n          containerPort: 80\n        - name: https\n          containerPort: 443\n        securityContext:\n          allowPrivilegeEscalation: false\n          runAsUser: 101\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n            add:\n            - NET_BIND_SERVICE\n          privileged: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        args:\n        - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config\n        - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: jaeger-agent\n        image: jaegertracing/jaeger-agent:stable\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        args:\n        - --reporter.grpc.host-port=grpc-apm-service.default.svc.cluster.local:14250\n        - --reporter.type=grpc\n        - --reporter.grpc.tls.enabled=true\n        - --reporter.grpc.tls.skip-host-verify=true\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04429",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress\n  namespace: nginx-ingress\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx-ingress\n  template:\n    metadata:\n      labels:\n        app: nginx-ingress\n      annotations:\n        co.elastic.logs/module: nginx\n        co.elastic.logs/fileset.stdout: access\n        co.elastic.logs/fileset.stderr: error\n        co.elastic.metrics/module: nginx\n        co.elastic.metrics/hosts: ${data.host}:${data.port}\n    spec:\n      serviceAccountName: nginx-ingress\n      containers:\n      - image: wangsiming519/nginx-ingress:opentracing_1.7.0\n        imagePullPolicy: Always\n        name: nginx-ingress\n        ports:\n        - name: http\n          containerPort: 80\n        - name: https\n          containerPort: 443\n        securityContext:\n          allowPrivilegeEscalation: false\n          runAsUser: 101\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n            add:\n            - NET_BIND_SERVICE\n          readOnlyRootFilesystem: true\n          privileged: false\n          runAsNonRoot: true\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        args:\n        - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config\n        - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: jaeger-agent\n        image: jaegertracing/jaeger-agent:stable\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        args:\n        - --reporter.grpc.host-port=grpc-apm-service.default.svc.cluster.local:14250\n        - --reporter.type=grpc\n        - --reporter.grpc.tls.enabled=true\n        - --reporter.grpc.tls.skip-host-verify=true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04430",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress\n  namespace: nginx-ingress\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx-ingress\n  template:\n    metadata:\n      labels:\n        app: nginx-ingress\n      annotations:\n        co.elastic.logs/module: nginx\n        co.elastic.logs/fileset.stdout: access\n        co.elastic.logs/fileset.stderr: error\n        co.elastic.metrics/module: nginx\n        co.elastic.metrics/hosts: ${data.host}:${data.port}\n    spec:\n      serviceAccountName: nginx-ingress\n      containers:\n      - image: wangsiming519/nginx-ingress:opentracing_1.7.0\n        imagePullPolicy: Always\n        name: nginx-ingress\n        ports:\n        - name: http\n          containerPort: 80\n        - name: https\n          containerPort: 443\n        securityContext:\n          allowPrivilegeEscalation: false\n          runAsUser: 101\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n            add:\n            - NET_BIND_SERVICE\n          readOnlyRootFilesystem: true\n          privileged: false\n          runAsNonRoot: true\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        args:\n        - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config\n        - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: jaeger-agent\n        image: jaegertracing/jaeger-agent:stable\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        args:\n        - --reporter.grpc.host-port=grpc-apm-service.default.svc.cluster.local:14250\n        - --reporter.type=grpc\n        - --reporter.grpc.tls.enabled=true\n        - --reporter.grpc.tls.skip-host-verify=true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04431",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress\n  namespace: nginx-ingress\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx-ingress\n  template:\n    metadata:\n      labels:\n        app: nginx-ingress\n      annotations:\n        co.elastic.logs/module: nginx\n        co.elastic.logs/fileset.stdout: access\n        co.elastic.logs/fileset.stderr: error\n        co.elastic.metrics/module: nginx\n        co.elastic.metrics/hosts: ${data.host}:${data.port}\n    spec:\n      serviceAccountName: nginx-ingress\n      containers:\n      - image: wangsiming519/nginx-ingress:opentracing_1.7.0\n        imagePullPolicy: Always\n        name: nginx-ingress\n        ports:\n        - name: http\n          containerPort: 80\n        - name: https\n          containerPort: 443\n        securityContext:\n          allowPrivilegeEscalation: false\n          runAsUser: 101\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n            add:\n            - NET_BIND_SERVICE\n          privileged: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        args:\n        - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config\n        - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: jaeger-agent\n        image: jaegertracing/jaeger-agent:stable\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        args:\n        - --reporter.grpc.host-port=grpc-apm-service.default.svc.cluster.local:14250\n        - --reporter.type=grpc\n        - --reporter.grpc.tls.enabled=true\n        - --reporter.grpc.tls.skip-host-verify=true\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04432",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress\n  namespace: nginx-ingress\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx-ingress\n  template:\n    metadata:\n      labels:\n        app: nginx-ingress\n      annotations:\n        co.elastic.logs/module: nginx\n        co.elastic.logs/fileset.stdout: access\n        co.elastic.logs/fileset.stderr: error\n        co.elastic.metrics/module: nginx\n        co.elastic.metrics/hosts: ${data.host}:${data.port}\n    spec:\n      serviceAccountName: nginx-ingress\n      containers:\n      - image: wangsiming519/nginx-ingress:opentracing_1.7.0\n        imagePullPolicy: Always\n        name: nginx-ingress\n        ports:\n        - name: http\n          containerPort: 80\n        - name: https\n          containerPort: 443\n        securityContext:\n          allowPrivilegeEscalation: false\n          runAsUser: 101\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n            add:\n            - NET_BIND_SERVICE\n          runAsNonRoot: true\n          privileged: false\n          readOnlyRootFilesystem: true\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        args:\n        - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config\n        - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: jaeger-agent\n        image: jaegertracing/jaeger-agent:stable\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        args:\n        - --reporter.grpc.host-port=grpc-apm-service.default.svc.cluster.local:14250\n        - --reporter.type=grpc\n        - --reporter.grpc.tls.enabled=true\n        - --reporter.grpc.tls.skip-host-verify=true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04433",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress\n  namespace: nginx-ingress\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx-ingress\n  template:\n    metadata:\n      labels:\n        app: nginx-ingress\n      annotations:\n        co.elastic.logs/module: nginx\n        co.elastic.logs/fileset.stdout: access\n        co.elastic.logs/fileset.stderr: error\n        co.elastic.metrics/module: nginx\n        co.elastic.metrics/hosts: ${data.host}:${data.port}\n    spec:\n      serviceAccountName: nginx-ingress\n      containers:\n      - image: wangsiming519/nginx-ingress:opentracing_1.7.0\n        imagePullPolicy: Always\n        name: nginx-ingress\n        ports:\n        - name: http\n          containerPort: 80\n        - name: https\n          containerPort: 443\n        securityContext:\n          allowPrivilegeEscalation: false\n          runAsUser: 101\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n            add:\n            - NET_BIND_SERVICE\n          privileged: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        args:\n        - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config\n        - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: jaeger-agent\n        image: jaegertracing/jaeger-agent:stable\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        args:\n        - --reporter.grpc.host-port=grpc-apm-service.default.svc.cluster.local:14250\n        - --reporter.type=grpc\n        - --reporter.grpc.tls.enabled=true\n        - --reporter.grpc.tls.skip-host-verify=true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04434",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress\n  namespace: nginx-ingress\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx-ingress\n  template:\n    metadata:\n      labels:\n        app: nginx-ingress\n      annotations:\n        co.elastic.logs/module: nginx\n        co.elastic.logs/fileset.stdout: access\n        co.elastic.logs/fileset.stderr: error\n        co.elastic.metrics/module: nginx\n        co.elastic.metrics/hosts: ${data.host}:${data.port}\n    spec:\n      serviceAccountName: nginx-ingress\n      containers:\n      - image: wangsiming519/nginx-ingress:opentracing_1.7.0\n        imagePullPolicy: Always\n        name: nginx-ingress\n        ports:\n        - name: http\n          containerPort: 80\n        - name: https\n          containerPort: 443\n        securityContext:\n          allowPrivilegeEscalation: false\n          runAsUser: 101\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n            add:\n            - NET_BIND_SERVICE\n          privileged: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        args:\n        - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config\n        - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: jaeger-agent\n        image: jaegertracing/jaeger-agent:stable\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        args:\n        - --reporter.grpc.host-port=grpc-apm-service.default.svc.cluster.local:14250\n        - --reporter.type=grpc\n        - --reporter.grpc.tls.enabled=true\n        - --reporter.grpc.tls.skip-host-verify=true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04435",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress\n  namespace: nginx-ingress\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx-ingress\n  template:\n    metadata:\n      labels:\n        app: nginx-ingress\n      annotations:\n        co.elastic.logs/module: nginx\n        co.elastic.logs/fileset.stdout: access\n        co.elastic.logs/fileset.stderr: error\n        co.elastic.metrics/module: nginx\n        co.elastic.metrics/hosts: ${data.host}:${data.port}\n    spec:\n      serviceAccountName: nginx-ingress\n      containers:\n      - image: wangsiming519/nginx-ingress:opentracing_1.7.0\n        imagePullPolicy: Always\n        name: nginx-ingress\n        ports:\n        - name: http\n          containerPort: 80\n        - name: https\n          containerPort: 443\n        securityContext:\n          allowPrivilegeEscalation: false\n          runAsUser: 101\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n            add:\n            - NET_BIND_SERVICE\n          privileged: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        args:\n        - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config\n        - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: jaeger-agent\n        image: jaegertracing/jaeger-agent:stable\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        args:\n        - --reporter.grpc.host-port=grpc-apm-service.default.svc.cluster.local:14250\n        - --reporter.type=grpc\n        - --reporter.grpc.tls.enabled=true\n        - --reporter.grpc.tls.skip-host-verify=true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04436",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ingress\n  namespace: nginx-ingress\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx-ingress\n  template:\n    metadata:\n      labels:\n        app: nginx-ingress\n      annotations:\n        co.elastic.logs/module: nginx\n        co.elastic.logs/fileset.stdout: access\n        co.elastic.logs/fileset.stderr: error\n        co.elastic.metrics/module: nginx\n        co.elastic.metrics/hosts: ${data.host}:${data.port}\n    spec:\n      serviceAccountName: nginx-ingress\n      containers:\n      - image: wangsiming519/nginx-ingress:opentracing_1.7.0\n        imagePullPolicy: Always\n        name: nginx-ingress\n        ports:\n        - name: http\n          containerPort: 80\n        - name: https\n          containerPort: 443\n        securityContext:\n          allowPrivilegeEscalation: false\n          runAsUser: 101\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n            add:\n            - NET_BIND_SERVICE\n          privileged: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        args:\n        - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config\n        - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: jaeger-agent\n        image: jaegertracing/jaeger-agent:stable\n        ports:\n        - containerPort: 5775\n          protocol: UDP\n        - containerPort: 6831\n          protocol: UDP\n        - containerPort: 6832\n          protocol: UDP\n        - containerPort: 5778\n          protocol: TCP\n        args:\n        - --reporter.grpc.host-port=grpc-apm-service.default.svc.cluster.local:14250\n        - --reporter.type=grpc\n        - --reporter.grpc.tls.enabled=true\n        - --reporter.grpc.tls.skip-host-verify=true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04437",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5490\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04438",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5490\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04439",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5490\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04440",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5490\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04441",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5490\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04442",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: image-reflector-controller\n  labels:\n    control-plane: controller-manager\nspec:\n  selector:\n    matchLabels:\n      app: image-reflector-controller\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: image-reflector-controller\n    spec:\n      containers:\n      - command:\n        - /manager\n        args:\n        - --enable-leader-election\n        image: squaremo/image-reflector-controller:stable\n        name: manager\n        resources:\n          limits:\n            cpu: 100m\n            memory: 30Mi\n          requests:\n            cpu: 100m\n            memory: 20Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04443",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: image-reflector-controller\n  labels:\n    control-plane: controller-manager\nspec:\n  selector:\n    matchLabels:\n      app: image-reflector-controller\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: image-reflector-controller\n    spec:\n      containers:\n      - command:\n        - /manager\n        args:\n        - --enable-leader-election\n        image: squaremo/image-reflector-controller:stable\n        name: manager\n        resources:\n          limits:\n            cpu: 100m\n            memory: 30Mi\n          requests:\n            cpu: 100m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04444",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: image-reflector-controller\n  labels:\n    control-plane: controller-manager\nspec:\n  selector:\n    matchLabels:\n      app: image-reflector-controller\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: image-reflector-controller\n    spec:\n      containers:\n      - command:\n        - /manager\n        args:\n        - --enable-leader-election\n        image: squaremo/image-reflector-controller:stable\n        name: manager\n        resources:\n          limits:\n            cpu: 100m\n            memory: 30Mi\n          requests:\n            cpu: 100m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04445",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-keeper\n  labels:\n    chart: lighthouse-1.1.51\n    app: lighthouse-keeper\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-keeper\n  template:\n    metadata:\n      annotations:\n        ad.datadoghq.com/keeper.logs: '[{\"source\":\"lighthouse\",\"service\":\"keeper\"}]'\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        jenkins-x.io/hash: a042ef704bc21bfd8abcd79f32e9788ecad0bdb70e7653aff9458eda85bafe3b\n      labels:\n        app: lighthouse-keeper\n    spec:\n      serviceAccountName: lighthouse-keeper\n      containers:\n      - name: lighthouse-keeper\n        image: ghcr.io/jenkins-x/lighthouse-keeper:1.1.51\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        ports:\n        - name: http\n          containerPort: 8888\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /\n            port: http\n          initialDelaySeconds: 120\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /\n            port: http\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: skreet2k\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.51\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: LIGHTHOUSE_KEEPER_STATUS_CONTEXT_LABEL\n          value: Lighthouse Merge Status\n        - name: LIGHTHOUSE_TRIGGER_ON_MISSING\n          value: enable\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        resources:\n          limits:\n            cpu: 400m\n            memory: 512Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04446",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-keeper\n  labels:\n    chart: lighthouse-1.1.51\n    app: lighthouse-keeper\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-keeper\n  template:\n    metadata:\n      annotations:\n        ad.datadoghq.com/keeper.logs: '[{\"source\":\"lighthouse\",\"service\":\"keeper\"}]'\n        prometheus.io/port: '9090'\n        prometheus.io/scrape: 'true'\n        jenkins-x.io/hash: a042ef704bc21bfd8abcd79f32e9788ecad0bdb70e7653aff9458eda85bafe3b\n      labels:\n        app: lighthouse-keeper\n    spec:\n      serviceAccountName: lighthouse-keeper\n      containers:\n      - name: lighthouse-keeper\n        image: ghcr.io/jenkins-x/lighthouse-keeper:1.1.51\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        ports:\n        - name: http\n          containerPort: 8888\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /\n            port: http\n          initialDelaySeconds: 120\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /\n            port: http\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: skreet2k\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.51\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: LIGHTHOUSE_KEEPER_STATUS_CONTEXT_LABEL\n          value: Lighthouse Merge Status\n        - name: LIGHTHOUSE_TRIGGER_ON_MISSING\n          value: enable\n        envFrom:\n        - secretRef:\n            name: jx-boot-job-env-vars\n            optional: true\n        resources:\n          limits:\n            cpu: 400m\n            memory: 512Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04447",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: privileged\nspec:\n  securityContext:\n    runAsNonRoot: true\n  containers:\n  - name: privileged\n    image: busybox:stable\n    command:\n    - sleep\n    - '9999'\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04448",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: privileged\nspec:\n  securityContext:\n    runAsNonRoot: true\n  containers:\n  - name: privileged\n    image: busybox:stable\n    command:\n    - sleep\n    - '9999'\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04449",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: privileged\nspec:\n  securityContext:\n    runAsNonRoot: true\n  containers:\n  - name: privileged\n    image: busybox:stable\n    command:\n    - sleep\n    - '9999'\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04450",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: privileged\nspec:\n  securityContext:\n    runAsNonRoot: true\n  containers:\n  - name: privileged\n    image: busybox:stable\n    command:\n    - sleep\n    - '9999'\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04451",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: privileged\nspec:\n  securityContext:\n    runAsNonRoot: true\n  containers:\n  - name: privileged\n    image: busybox:stable\n    command:\n    - sleep\n    - '9999'\n    securityContext:\n      allowPrivilegeEscalation: false\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04452",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: azure-cloud-controller-manager\n  namespace: kube-system\nspec:\n  containers:\n  - name: cloud-controller-manager\n    image: mcr.microsoft.com/oss/kubernetes/azure-cloud-controller-manager:v1.0.0\n    imagePullPolicy: IfNotPresent\n    command:\n    - cloud-controller-manager\n    args:\n    - --cloud-provider=azure\n    - --controllers=cloud-node\n    - --kubeconfig=/etc/kubernetes/secrets/kubeconfig\n    - --cloud-config=/etc/kubernetes/configs/cloud.conf\n    - --leader-elect=false\n    - --port=10267\n    - -v=2\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 10267\n      initialDelaySeconds: 20\n      periodSeconds: 10\n      timeoutSeconds: 5\n    volumeMounts:\n    - name: secrets\n      mountPath: /etc/kubernetes/secrets\n    - name: configs\n      mountPath: /etc/kubernetes/configs\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: secrets\n    hostPath:\n      path: /etc/kubernetes/bootstrap-secrets\n  - name: configs\n    hostPath:\n      path: /etc/kubernetes/bootstrap-configs\n",
    "errors": []
  },
  {
    "id": "04453",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: azure-cloud-controller-manager\n  namespace: kube-system\nspec:\n  containers:\n  - name: cloud-controller-manager\n    image: mcr.microsoft.com/oss/kubernetes/azure-cloud-controller-manager:v1.0.0\n    imagePullPolicy: IfNotPresent\n    command:\n    - cloud-controller-manager\n    args:\n    - --cloud-provider=azure\n    - --controllers=cloud-node\n    - --kubeconfig=/etc/kubernetes/secrets/kubeconfig\n    - --cloud-config=/etc/kubernetes/configs/cloud.conf\n    - --leader-elect=false\n    - --port=10267\n    - -v=2\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 10267\n      initialDelaySeconds: 20\n      periodSeconds: 10\n      timeoutSeconds: 5\n    volumeMounts:\n    - name: secrets\n      mountPath: /etc/kubernetes/secrets\n    - name: configs\n      mountPath: /etc/kubernetes/configs\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: secrets\n    hostPath:\n      path: /etc/kubernetes/bootstrap-secrets\n  - name: configs\n    hostPath:\n      path: /etc/kubernetes/bootstrap-configs\n",
    "errors": []
  },
  {
    "id": "04454",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: azure-cloud-controller-manager\n  namespace: kube-system\nspec:\n  containers:\n  - name: cloud-controller-manager\n    image: mcr.microsoft.com/oss/kubernetes/azure-cloud-controller-manager:v1.0.0\n    imagePullPolicy: IfNotPresent\n    command:\n    - cloud-controller-manager\n    args:\n    - --cloud-provider=azure\n    - --controllers=cloud-node\n    - --kubeconfig=/etc/kubernetes/secrets/kubeconfig\n    - --cloud-config=/etc/kubernetes/configs/cloud.conf\n    - --leader-elect=false\n    - --port=10267\n    - -v=2\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 10267\n      initialDelaySeconds: 20\n      periodSeconds: 10\n      timeoutSeconds: 5\n    volumeMounts:\n    - name: secrets\n      mountPath: /etc/kubernetes/secrets\n    - name: configs\n      mountPath: /etc/kubernetes/configs\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  volumes:\n  - name: secrets\n    hostPath:\n      path: /etc/kubernetes/bootstrap-secrets\n  - name: configs\n    hostPath:\n      path: /etc/kubernetes/bootstrap-configs\n",
    "errors": []
  },
  {
    "id": "04455",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: azure-cloud-controller-manager\n  namespace: kube-system\nspec:\n  containers:\n  - name: cloud-controller-manager\n    image: mcr.microsoft.com/oss/kubernetes/azure-cloud-controller-manager:v1.0.0\n    imagePullPolicy: IfNotPresent\n    command:\n    - cloud-controller-manager\n    args:\n    - --cloud-provider=azure\n    - --controllers=cloud-node\n    - --kubeconfig=/etc/kubernetes/secrets/kubeconfig\n    - --cloud-config=/etc/kubernetes/configs/cloud.conf\n    - --leader-elect=false\n    - --port=10267\n    - -v=2\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 10267\n      initialDelaySeconds: 20\n      periodSeconds: 10\n      timeoutSeconds: 5\n    volumeMounts:\n    - name: secrets\n      mountPath: /etc/kubernetes/secrets\n    - name: configs\n      mountPath: /etc/kubernetes/configs\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  volumes:\n  - name: secrets\n    hostPath:\n      path: /etc/kubernetes/bootstrap-secrets\n  - name: configs\n    hostPath:\n      path: /etc/kubernetes/bootstrap-configs\n",
    "errors": []
  },
  {
    "id": "04456",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: ci\n  name: statusreconciler\n  labels:\n    app: prow\n    component: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow\n      component: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: prow\n        component: statusreconciler\n    spec:\n      serviceAccountName: statusreconciler\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20220115-3e20513bd7\n        imagePullPolicy: IfNotPresent\n        args:\n        - --dry-run=false\n        - --continue-on-error=true\n        - --plugin-config=/etc/plugins/plugins.yaml\n        - --supplemental-plugin-config-dir=/etc/plugins\n        - --config-path=/etc/config/config.yaml\n        - --supplemental-prow-config-dir=/etc/config\n        - --github-app-id=$(GITHUB_APP_ID)\n        - --github-app-private-key-path=/etc/github/cert\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-graphql-endpoint=http://ghproxy/graphql\n        - --job-config-path=/etc/job-config\n        - --projected-token-file=/var/sa-token/token\n        env:\n        - name: GITHUB_APP_ID\n          valueFrom:\n            secretKeyRef:\n              name: openshift-prow-github-app\n              key: appid\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: service-account-token\n          mountPath: /var/sa-token\n        - name: github-app-credentials\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 20m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: service-account-token\n        projected:\n          sources:\n          - serviceAccountToken:\n              path: token\n      - name: github-app-credentials\n        secret:\n          secretName: openshift-prow-github-app\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        projected:\n          sources:\n          - configMap:\n              name: job-config-misc\n          - configMap:\n              name: job-config-master-periodics\n          - configMap:\n              name: job-config-master-postsubmits\n          - configMap:\n              name: job-config-master-presubmits\n          - configMap:\n              name: job-config-3.x\n          - configMap:\n              name: job-config-4.1\n          - configMap:\n              name: job-config-4.2\n          - configMap:\n              name: job-config-4.3\n          - configMap:\n              name: job-config-4.4\n          - configMap:\n              name: job-config-4.5\n          - configMap:\n              name: job-config-4.6\n          - configMap:\n              name: job-config-4.7\n          - configMap:\n              name: job-config-4.8\n          - configMap:\n              name: job-config-4.9\n          - configMap:\n              name: job-config-4.10\n          - configMap:\n              name: job-config-4.11\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04457",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: ci\n  name: statusreconciler\n  labels:\n    app: prow\n    component: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow\n      component: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: prow\n        component: statusreconciler\n    spec:\n      serviceAccountName: statusreconciler\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20220115-3e20513bd7\n        imagePullPolicy: IfNotPresent\n        args:\n        - --dry-run=false\n        - --continue-on-error=true\n        - --plugin-config=/etc/plugins/plugins.yaml\n        - --supplemental-plugin-config-dir=/etc/plugins\n        - --config-path=/etc/config/config.yaml\n        - --supplemental-prow-config-dir=/etc/config\n        - --github-app-id=$(GITHUB_APP_ID)\n        - --github-app-private-key-path=/etc/github/cert\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-graphql-endpoint=http://ghproxy/graphql\n        - --job-config-path=/etc/job-config\n        - --projected-token-file=/var/sa-token/token\n        env:\n        - name: GITHUB_APP_ID\n          valueFrom:\n            secretKeyRef:\n              name: openshift-prow-github-app\n              key: appid\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: service-account-token\n          mountPath: /var/sa-token\n        - name: github-app-credentials\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 20m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: service-account-token\n        projected:\n          sources:\n          - serviceAccountToken:\n              path: token\n      - name: github-app-credentials\n        secret:\n          secretName: openshift-prow-github-app\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        projected:\n          sources:\n          - configMap:\n              name: job-config-misc\n          - configMap:\n              name: job-config-master-periodics\n          - configMap:\n              name: job-config-master-postsubmits\n          - configMap:\n              name: job-config-master-presubmits\n          - configMap:\n              name: job-config-3.x\n          - configMap:\n              name: job-config-4.1\n          - configMap:\n              name: job-config-4.2\n          - configMap:\n              name: job-config-4.3\n          - configMap:\n              name: job-config-4.4\n          - configMap:\n              name: job-config-4.5\n          - configMap:\n              name: job-config-4.6\n          - configMap:\n              name: job-config-4.7\n          - configMap:\n              name: job-config-4.8\n          - configMap:\n              name: job-config-4.9\n          - configMap:\n              name: job-config-4.10\n          - configMap:\n              name: job-config-4.11\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04458",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: ci\n  name: statusreconciler\n  labels:\n    app: prow\n    component: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prow\n      component: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: prow\n        component: statusreconciler\n    spec:\n      serviceAccountName: statusreconciler\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20220115-3e20513bd7\n        imagePullPolicy: IfNotPresent\n        args:\n        - --dry-run=false\n        - --continue-on-error=true\n        - --plugin-config=/etc/plugins/plugins.yaml\n        - --supplemental-plugin-config-dir=/etc/plugins\n        - --config-path=/etc/config/config.yaml\n        - --supplemental-prow-config-dir=/etc/config\n        - --github-app-id=$(GITHUB_APP_ID)\n        - --github-app-private-key-path=/etc/github/cert\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-graphql-endpoint=http://ghproxy/graphql\n        - --job-config-path=/etc/job-config\n        - --projected-token-file=/var/sa-token/token\n        env:\n        - name: GITHUB_APP_ID\n          valueFrom:\n            secretKeyRef:\n              name: openshift-prow-github-app\n              key: appid\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: service-account-token\n          mountPath: /var/sa-token\n        - name: github-app-credentials\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            memory: 200Mi\n            cpu: 20m\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: service-account-token\n        projected:\n          sources:\n          - serviceAccountToken:\n              path: token\n      - name: github-app-credentials\n        secret:\n          secretName: openshift-prow-github-app\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        projected:\n          sources:\n          - configMap:\n              name: job-config-misc\n          - configMap:\n              name: job-config-master-periodics\n          - configMap:\n              name: job-config-master-postsubmits\n          - configMap:\n              name: job-config-master-presubmits\n          - configMap:\n              name: job-config-3.x\n          - configMap:\n              name: job-config-4.1\n          - configMap:\n              name: job-config-4.2\n          - configMap:\n              name: job-config-4.3\n          - configMap:\n              name: job-config-4.4\n          - configMap:\n              name: job-config-4.5\n          - configMap:\n              name: job-config-4.6\n          - configMap:\n              name: job-config-4.7\n          - configMap:\n              name: job-config-4.8\n          - configMap:\n              name: job-config-4.9\n          - configMap:\n              name: job-config-4.10\n          - configMap:\n              name: job-config-4.11\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04459",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-ceph-tools\n  namespace: rook-ceph\n  labels:\n    app: rook-ceph-tools\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-ceph-tools\n  template:\n    metadata:\n      labels:\n        app: rook-ceph-tools\n    spec:\n      containers:\n      - name: rook-ceph-tools\n        image: rook/ceph:v1.2.2\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_ADMIN_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: admin-secret\n        volumeMounts:\n        - mountPath: /etc/ceph\n          name: ceph-config\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n      - name: ceph-config\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04460",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-ceph-tools\n  namespace: rook-ceph\n  labels:\n    app: rook-ceph-tools\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-ceph-tools\n  template:\n    metadata:\n      labels:\n        app: rook-ceph-tools\n    spec:\n      containers:\n      - name: rook-ceph-tools\n        image: rook/ceph:v1.2.2\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_ADMIN_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: admin-secret\n        volumeMounts:\n        - mountPath: /etc/ceph\n          name: ceph-config\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n      - name: ceph-config\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04461",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-ceph-tools\n  namespace: rook-ceph\n  labels:\n    app: rook-ceph-tools\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-ceph-tools\n  template:\n    metadata:\n      labels:\n        app: rook-ceph-tools\n    spec:\n      containers:\n      - name: rook-ceph-tools\n        image: rook/ceph:v1.2.2\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_ADMIN_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: admin-secret\n        volumeMounts:\n        - mountPath: /etc/ceph\n          name: ceph-config\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n      - name: ceph-config\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04462",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-ceph-tools\n  namespace: rook-ceph\n  labels:\n    app: rook-ceph-tools\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-ceph-tools\n  template:\n    metadata:\n      labels:\n        app: rook-ceph-tools\n    spec:\n      containers:\n      - name: rook-ceph-tools\n        image: rook/ceph:v1.2.2\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_ADMIN_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: admin-secret\n        volumeMounts:\n        - mountPath: /etc/ceph\n          name: ceph-config\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n      - name: ceph-config\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04463",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: litmus-experiment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: litmus-experiment\n  template:\n    metadata:\n      labels:\n        app: litmus-experiment\n    spec:\n      serviceAccountName: pod-io-error-retval-sa\n      containers:\n      - name: gotest\n        image: busybox:stable\n        command:\n        - sleep\n        - '3600'\n        env:\n        - name: APP_NAMESPACE\n          value: default\n        - name: APP_LABEL\n          value: run=nginx\n        - name: APP_KIND\n          value: deployment\n        - name: TOTAL_CHAOS_DURATION\n          value: '60'\n        - name: CHAOS_INTERVAL\n          value: '10'\n        - name: MEMORY_CONSUMPTION\n          value: '500'\n        - name: PODS_AFFECTED_PERC\n          value: '100'\n        - name: LIB\n          value: litmus\n        - name: TARGET_POD\n          value: ''\n        - name: TARGET_CONTAINER\n          value: ''\n        - name: SEQUENCE\n          value: parallel\n        - name: CHAOS_NAMESPACE\n          value: default\n        - name: RAMP_TIME\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04464",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: litmus-experiment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: litmus-experiment\n  template:\n    metadata:\n      labels:\n        app: litmus-experiment\n    spec:\n      serviceAccountName: pod-io-error-retval-sa\n      containers:\n      - name: gotest\n        image: busybox:stable\n        command:\n        - sleep\n        - '3600'\n        env:\n        - name: APP_NAMESPACE\n          value: default\n        - name: APP_LABEL\n          value: run=nginx\n        - name: APP_KIND\n          value: deployment\n        - name: TOTAL_CHAOS_DURATION\n          value: '60'\n        - name: CHAOS_INTERVAL\n          value: '10'\n        - name: MEMORY_CONSUMPTION\n          value: '500'\n        - name: PODS_AFFECTED_PERC\n          value: '100'\n        - name: LIB\n          value: litmus\n        - name: TARGET_POD\n          value: ''\n        - name: TARGET_CONTAINER\n          value: ''\n        - name: SEQUENCE\n          value: parallel\n        - name: CHAOS_NAMESPACE\n          value: default\n        - name: RAMP_TIME\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04465",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: litmus-experiment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: litmus-experiment\n  template:\n    metadata:\n      labels:\n        app: litmus-experiment\n    spec:\n      serviceAccountName: pod-io-error-retval-sa\n      containers:\n      - name: gotest\n        image: busybox:stable\n        command:\n        - sleep\n        - '3600'\n        env:\n        - name: APP_NAMESPACE\n          value: default\n        - name: APP_LABEL\n          value: run=nginx\n        - name: APP_KIND\n          value: deployment\n        - name: TOTAL_CHAOS_DURATION\n          value: '60'\n        - name: CHAOS_INTERVAL\n          value: '10'\n        - name: MEMORY_CONSUMPTION\n          value: '500'\n        - name: PODS_AFFECTED_PERC\n          value: '100'\n        - name: LIB\n          value: litmus\n        - name: TARGET_POD\n          value: ''\n        - name: TARGET_CONTAINER\n          value: ''\n        - name: SEQUENCE\n          value: parallel\n        - name: CHAOS_NAMESPACE\n          value: default\n        - name: RAMP_TIME\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04466",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: litmus-experiment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: litmus-experiment\n  template:\n    metadata:\n      labels:\n        app: litmus-experiment\n    spec:\n      serviceAccountName: pod-io-error-retval-sa\n      containers:\n      - name: gotest\n        image: busybox:stable\n        command:\n        - sleep\n        - '3600'\n        env:\n        - name: APP_NAMESPACE\n          value: default\n        - name: APP_LABEL\n          value: run=nginx\n        - name: APP_KIND\n          value: deployment\n        - name: TOTAL_CHAOS_DURATION\n          value: '60'\n        - name: CHAOS_INTERVAL\n          value: '10'\n        - name: MEMORY_CONSUMPTION\n          value: '500'\n        - name: PODS_AFFECTED_PERC\n          value: '100'\n        - name: LIB\n          value: litmus\n        - name: TARGET_POD\n          value: ''\n        - name: TARGET_CONTAINER\n          value: ''\n        - name: SEQUENCE\n          value: parallel\n        - name: CHAOS_NAMESPACE\n          value: default\n        - name: RAMP_TIME\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04467",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: litmus-experiment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: litmus-experiment\n  template:\n    metadata:\n      labels:\n        app: litmus-experiment\n    spec:\n      serviceAccountName: pod-io-error-retval-sa\n      containers:\n      - name: gotest\n        image: busybox:stable\n        command:\n        - sleep\n        - '3600'\n        env:\n        - name: APP_NAMESPACE\n          value: default\n        - name: APP_LABEL\n          value: run=nginx\n        - name: APP_KIND\n          value: deployment\n        - name: TOTAL_CHAOS_DURATION\n          value: '60'\n        - name: CHAOS_INTERVAL\n          value: '10'\n        - name: MEMORY_CONSUMPTION\n          value: '500'\n        - name: PODS_AFFECTED_PERC\n          value: '100'\n        - name: LIB\n          value: litmus\n        - name: TARGET_POD\n          value: ''\n        - name: TARGET_CONTAINER\n          value: ''\n        - name: SEQUENCE\n          value: parallel\n        - name: CHAOS_NAMESPACE\n          value: default\n        - name: RAMP_TIME\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04468",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: frontend\nspec:\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google_samples/gb-frontend:v3\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04469",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: frontend\nspec:\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google_samples/gb-frontend:v3\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04470",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: frontend\nspec:\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google_samples/gb-frontend:v3\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04471",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"litmus\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "04472",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"litmus\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "04473",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"litmus\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "04474",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: error when retrieving current configuration of:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"\", Namespace: \"litmus\"\nfrom server for: \"STDIN\": resource name may not be empty"
    ]
  },
  {
    "id": "04475",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: demo\n  name: demo\nspec:\n  containers:\n  - image: in-cluster:stable\n    name: demo\n    imagePullPolicy: Never\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04476",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: demo\n  name: demo\nspec:\n  containers:\n  - image: in-cluster:stable\n    name: demo\n    imagePullPolicy: Never\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04477",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: demo\n  name: demo\nspec:\n  containers:\n  - image: in-cluster:stable\n    name: demo\n    imagePullPolicy: Never\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04478",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: demo\n  name: demo\nspec:\n  containers:\n  - image: in-cluster:stable\n    name: demo\n    imagePullPolicy: Never\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04479",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: demo\n  name: demo\nspec:\n  containers:\n  - image: in-cluster:stable\n    name: demo\n    imagePullPolicy: Never\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04480",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kafka-background-producer-deployment\nspec:\n  selector:\n    matchLabels:\n      app: kafka-background-producer\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: kafka-background-producer\n    spec:\n      containers:\n      - name: kafka-background-producer\n        image: ${BACKENDV2_IMAGE}:stable\n        command:\n        - npm\n        - run\n        - background-producer\n        imagePullPolicy: Always\n        resources:\n          requests:\n            memory: 300Mi\n            cpu: 100m\n          limits:\n            memory: 500Mi\n            cpu: 500m\n        env:\n        - name: NODE_ENV\n          value: production\n        - name: REDIS_HOST\n          value: quizzes-backend-redis-master.default.svc.cluster.local\n        - name: REDIS_PORT\n          value: '6379'\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: quizzes-backend-redis\n              key: redis-password\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: POSTGRES_DATABASE\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: POSTGRES_HOST\n        - name: DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: POSTGRES_PASSWORD\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: POSTGRES_USERNAME\n        - name: KAFKA_HOST\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: KAFKA_HOST\n        - name: MESSAGE_FORMAT_VERSION\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: MESSAGE_FORMAT_VERSION\n        - name: NEW_RELIC_LICENSE_KEY\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: NEW_RELIC_LICENSE_KEY\n        - name: NEW_RELIC_APP_NAME\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: NEW_RELIC_APP_NAME\n        - name: NEW_RELIC_NO_CONFIG_FILE\n          value: 'true'\n        - name: SERVICE_ID\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: SERVICE_ID\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: SENTRY_DSN\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04481",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kafka-background-producer-deployment\nspec:\n  selector:\n    matchLabels:\n      app: kafka-background-producer\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: kafka-background-producer\n    spec:\n      containers:\n      - name: kafka-background-producer\n        image: ${BACKENDV2_IMAGE}:stable\n        command:\n        - npm\n        - run\n        - background-producer\n        imagePullPolicy: Always\n        resources:\n          requests:\n            memory: 300Mi\n            cpu: 100m\n          limits:\n            memory: 500Mi\n            cpu: 500m\n        env:\n        - name: NODE_ENV\n          value: production\n        - name: REDIS_HOST\n          value: quizzes-backend-redis-master.default.svc.cluster.local\n        - name: REDIS_PORT\n          value: '6379'\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: quizzes-backend-redis\n              key: redis-password\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: POSTGRES_DATABASE\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: POSTGRES_HOST\n        - name: DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: POSTGRES_PASSWORD\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: POSTGRES_USERNAME\n        - name: KAFKA_HOST\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: KAFKA_HOST\n        - name: MESSAGE_FORMAT_VERSION\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: MESSAGE_FORMAT_VERSION\n        - name: NEW_RELIC_LICENSE_KEY\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: NEW_RELIC_LICENSE_KEY\n        - name: NEW_RELIC_APP_NAME\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: NEW_RELIC_APP_NAME\n        - name: NEW_RELIC_NO_CONFIG_FILE\n          value: 'true'\n        - name: SERVICE_ID\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: SERVICE_ID\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: SENTRY_DSN\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04482",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kafka-background-producer-deployment\nspec:\n  selector:\n    matchLabels:\n      app: kafka-background-producer\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: kafka-background-producer\n    spec:\n      containers:\n      - name: kafka-background-producer\n        image: ${BACKENDV2_IMAGE}:stable\n        command:\n        - npm\n        - run\n        - background-producer\n        imagePullPolicy: Always\n        resources:\n          requests:\n            memory: 300Mi\n            cpu: 100m\n          limits:\n            memory: 500Mi\n            cpu: 500m\n        env:\n        - name: NODE_ENV\n          value: production\n        - name: REDIS_HOST\n          value: quizzes-backend-redis-master.default.svc.cluster.local\n        - name: REDIS_PORT\n          value: '6379'\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: quizzes-backend-redis\n              key: redis-password\n        - name: DB_NAME\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: POSTGRES_DATABASE\n        - name: DB_HOST\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: POSTGRES_HOST\n        - name: DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: POSTGRES_PASSWORD\n        - name: DB_USER\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: POSTGRES_USERNAME\n        - name: KAFKA_HOST\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: KAFKA_HOST\n        - name: MESSAGE_FORMAT_VERSION\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: MESSAGE_FORMAT_VERSION\n        - name: NEW_RELIC_LICENSE_KEY\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: NEW_RELIC_LICENSE_KEY\n        - name: NEW_RELIC_APP_NAME\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: NEW_RELIC_APP_NAME\n        - name: NEW_RELIC_NO_CONFIG_FILE\n          value: 'true'\n        - name: SERVICE_ID\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: SERVICE_ID\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: backend-database-secret\n              key: SENTRY_DSN\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04483",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: paymentservice\n        image: vladimir44/microservices-demo-payment-service:0.0.2\n        ports:\n        - containerPort: 50051\n        env:\n        - name: PORT\n          value: '50051'\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04484",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: paymentservice\n        image: vladimir44/microservices-demo-payment-service:0.0.2\n        ports:\n        - containerPort: 50051\n        env:\n        - name: PORT\n          value: '50051'\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04485",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: paymentservice\n        image: vladimir44/microservices-demo-payment-service:0.0.2\n        ports:\n        - containerPort: 50051\n        env:\n        - name: PORT\n          value: '50051'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04486",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: paymentservice\n        image: vladimir44/microservices-demo-payment-service:0.0.2\n        ports:\n        - containerPort: 50051\n        env:\n        - name: PORT\n          value: '50051'\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04487",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ebs-csi-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ebs-csi-controller\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-controller\n    spec:\n      serviceAccount: ebs-csi-controller-sa\n      containers:\n      - name: ebs-plugin\n        image: amazon/aws-ebs-csi-driver:stable\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: key_id\n              optional: true\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: access_key\n              optional: true\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.5.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --feature-gates=Topology=true\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v1.2.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --leader-election=true\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04488",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ebs-csi-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ebs-csi-controller\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-controller\n    spec:\n      serviceAccount: ebs-csi-controller-sa\n      containers:\n      - name: ebs-plugin\n        image: amazon/aws-ebs-csi-driver:stable\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: key_id\n              optional: true\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: access_key\n              optional: true\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.5.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --feature-gates=Topology=true\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v1.2.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --leader-election=true\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04489",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ebs-csi-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ebs-csi-controller\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-controller\n    spec:\n      serviceAccount: ebs-csi-controller-sa\n      containers:\n      - name: ebs-plugin\n        image: amazon/aws-ebs-csi-driver:stable\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: key_id\n              optional: true\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: access_key\n              optional: true\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.5.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --feature-gates=Topology=true\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v1.2.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --leader-election=true\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04490",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ebs-csi-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ebs-csi-controller\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-controller\n    spec:\n      serviceAccount: ebs-csi-controller-sa\n      containers:\n      - name: ebs-plugin\n        image: amazon/aws-ebs-csi-driver:stable\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: key_id\n              optional: true\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: access_key\n              optional: true\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.5.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --feature-gates=Topology=true\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v1.2.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --leader-election=true\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04491",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ebs-csi-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ebs-csi-controller\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-controller\n    spec:\n      serviceAccount: ebs-csi-controller-sa\n      containers:\n      - name: ebs-plugin\n        image: amazon/aws-ebs-csi-driver:stable\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: key_id\n              optional: true\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: access_key\n              optional: true\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.5.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --feature-gates=Topology=true\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v1.2.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --leader-election=true\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04492",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ebs-csi-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ebs-csi-controller\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-controller\n    spec:\n      serviceAccount: ebs-csi-controller-sa\n      containers:\n      - name: ebs-plugin\n        image: amazon/aws-ebs-csi-driver:stable\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: key_id\n              optional: true\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: access_key\n              optional: true\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.5.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --feature-gates=Topology=true\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v1.2.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --leader-election=true\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04493",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ebs-csi-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ebs-csi-controller\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-controller\n    spec:\n      serviceAccount: ebs-csi-controller-sa\n      containers:\n      - name: ebs-plugin\n        image: amazon/aws-ebs-csi-driver:stable\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: key_id\n              optional: true\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: access_key\n              optional: true\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.5.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --feature-gates=Topology=true\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v1.2.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --leader-election=true\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04494",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ebs-csi-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ebs-csi-controller\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-controller\n    spec:\n      serviceAccount: ebs-csi-controller-sa\n      containers:\n      - name: ebs-plugin\n        image: amazon/aws-ebs-csi-driver:stable\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: key_id\n              optional: true\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: access_key\n              optional: true\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.5.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --feature-gates=Topology=true\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v1.2.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --leader-election=true\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04495",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ebs-csi-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ebs-csi-controller\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-controller\n    spec:\n      serviceAccount: ebs-csi-controller-sa\n      containers:\n      - name: ebs-plugin\n        image: amazon/aws-ebs-csi-driver:stable\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: key_id\n              optional: true\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: access_key\n              optional: true\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.5.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --feature-gates=Topology=true\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v1.2.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --leader-election=true\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04496",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ebs-csi-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ebs-csi-controller\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-controller\n    spec:\n      serviceAccount: ebs-csi-controller-sa\n      containers:\n      - name: ebs-plugin\n        image: amazon/aws-ebs-csi-driver:stable\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: key_id\n              optional: true\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: access_key\n              optional: true\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.5.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --feature-gates=Topology=true\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v1.2.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --leader-election=true\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04497",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ebs-csi-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ebs-csi-controller\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-controller\n    spec:\n      serviceAccount: ebs-csi-controller-sa\n      containers:\n      - name: ebs-plugin\n        image: amazon/aws-ebs-csi-driver:stable\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: key_id\n              optional: true\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: access_key\n              optional: true\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.5.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --feature-gates=Topology=true\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v1.2.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --leader-election=true\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04498",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ebs-csi-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ebs-csi-controller\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-controller\n    spec:\n      serviceAccount: ebs-csi-controller-sa\n      containers:\n      - name: ebs-plugin\n        image: amazon/aws-ebs-csi-driver:stable\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: key_id\n              optional: true\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: access_key\n              optional: true\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.5.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --feature-gates=Topology=true\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v1.2.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --leader-election=true\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04499",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ebs-csi-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ebs-csi-controller\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-controller\n    spec:\n      serviceAccount: ebs-csi-controller-sa\n      containers:\n      - name: ebs-plugin\n        image: amazon/aws-ebs-csi-driver:stable\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: key_id\n              optional: true\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: access_key\n              optional: true\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.5.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --feature-gates=Topology=true\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v1.2.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --leader-election=true\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04500",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ebs-csi-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ebs-csi-controller\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-controller\n    spec:\n      serviceAccount: ebs-csi-controller-sa\n      containers:\n      - name: ebs-plugin\n        image: amazon/aws-ebs-csi-driver:stable\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: key_id\n              optional: true\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: access_key\n              optional: true\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.5.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --feature-gates=Topology=true\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v1.2.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --leader-election=true\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04501",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ebs-csi-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ebs-csi-controller\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-controller\n    spec:\n      serviceAccount: ebs-csi-controller-sa\n      containers:\n      - name: ebs-plugin\n        image: amazon/aws-ebs-csi-driver:stable\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: key_id\n              optional: true\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: access_key\n              optional: true\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.5.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --feature-gates=Topology=true\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v1.2.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --leader-election=true\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04502",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ebs-csi-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ebs-csi-controller\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-controller\n    spec:\n      serviceAccount: ebs-csi-controller-sa\n      containers:\n      - name: ebs-plugin\n        image: amazon/aws-ebs-csi-driver:stable\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: key_id\n              optional: true\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: access_key\n              optional: true\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.5.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --feature-gates=Topology=true\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v1.2.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --leader-election=true\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04503",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ebs-csi-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ebs-csi-controller\n  template:\n    metadata:\n      labels:\n        app: ebs-csi-controller\n    spec:\n      serviceAccount: ebs-csi-controller-sa\n      containers:\n      - name: ebs-plugin\n        image: amazon/aws-ebs-csi-driver:stable\n        args:\n        - --endpoint=$(CSI_ENDPOINT)\n        - --logtostderr\n        - --v=5\n        env:\n        - name: CSI_ENDPOINT\n          value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: key_id\n              optional: true\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            secretKeyRef:\n              name: aws-secret\n              key: access_key\n              optional: true\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        ports:\n        - name: healthz\n          containerPort: 9808\n          protocol: TCP\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n          periodSeconds: 10\n          failureThreshold: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: csi-provisioner\n        image: quay.io/k8scsi/csi-provisioner:v1.5.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --feature-gates=Topology=true\n        - --enable-leader-election\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: quay.io/k8scsi/csi-attacher:v1.2.0\n        args:\n        - --csi-address=$(ADDRESS)\n        - --v=5\n        - --leader-election=true\n        - --leader-election-type=leases\n        env:\n        - name: ADDRESS\n          value: /var/lib/csi/sockets/pluginproxy/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /var/lib/csi/sockets/pluginproxy/\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: quay.io/k8scsi/livenessprobe:v1.1.0\n        args:\n        - --csi-address=/csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04504",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: reviews-v2\n  labels:\n    app: reviews\n    version: v2\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: reviews\n      version: v2\n  template:\n    metadata:\n      labels:\n        app: reviews\n        version: v2\n    spec:\n      containers:\n      - name: reviews\n        image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: LOG_DIR\n          value: /tmp/logs\n        ports:\n        - containerPort: 9080\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        - name: wlp-output\n          mountPath: /opt/ibm/wlp/output\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: wlp-output\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04505",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: reviews-v2\n  labels:\n    app: reviews\n    version: v2\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: reviews\n      version: v2\n  template:\n    metadata:\n      labels:\n        app: reviews\n        version: v2\n    spec:\n      containers:\n      - name: reviews\n        image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: LOG_DIR\n          value: /tmp/logs\n        ports:\n        - containerPort: 9080\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        - name: wlp-output\n          mountPath: /opt/ibm/wlp/output\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: wlp-output\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04506",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: reviews-v2\n  labels:\n    app: reviews\n    version: v2\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: reviews\n      version: v2\n  template:\n    metadata:\n      labels:\n        app: reviews\n        version: v2\n    spec:\n      containers:\n      - name: reviews\n        image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: LOG_DIR\n          value: /tmp/logs\n        ports:\n        - containerPort: 9080\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        - name: wlp-output\n          mountPath: /opt/ibm/wlp/output\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: wlp-output\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04507",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: reviews-v2\n  labels:\n    app: reviews\n    version: v2\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: reviews\n      version: v2\n  template:\n    metadata:\n      labels:\n        app: reviews\n        version: v2\n    spec:\n      containers:\n      - name: reviews\n        image: docker.io/istio/examples-bookinfo-reviews-v2:1.16.0\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: LOG_DIR\n          value: /tmp/logs\n        ports:\n        - containerPort: 9080\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        - name: wlp-output\n          mountPath: /opt/ibm/wlp/output\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: wlp-output\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04508",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"burpsuite\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04509",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"burpsuite\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04510",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"burpsuite\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04511",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"burpsuite\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04512",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: project-dep\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: project-app\n  template:\n    metadata:\n      labels:\n        app: project-app\n    spec:\n      volumes:\n      - name: shared-data\n        persistentVolumeClaim:\n          claimName: local-claim\n      - name: config\n        configMap:\n          name: project-app-config\n          items:\n          - key: app.properties\n            path: config.js\n      containers:\n      - name: project-app\n        image: robsondepaula/project:1_13\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: shared-data\n          mountPath: /data\n        - name: config\n          mountPath: /usr/share/nginx/html/config.js\n          subPath: config.js\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: project-service\n        image: robsondepaula/project-service:1_13\n        ports:\n        - containerPort: 3001\n        volumeMounts:\n        - name: shared-data\n          mountPath: /data\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04513",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: project-dep\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: project-app\n  template:\n    metadata:\n      labels:\n        app: project-app\n    spec:\n      volumes:\n      - name: shared-data\n        persistentVolumeClaim:\n          claimName: local-claim\n      - name: config\n        configMap:\n          name: project-app-config\n          items:\n          - key: app.properties\n            path: config.js\n      containers:\n      - name: project-app\n        image: robsondepaula/project:1_13\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: shared-data\n          mountPath: /data\n        - name: config\n          mountPath: /usr/share/nginx/html/config.js\n          subPath: config.js\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: project-service\n        image: robsondepaula/project-service:1_13\n        ports:\n        - containerPort: 3001\n        volumeMounts:\n        - name: shared-data\n          mountPath: /data\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04514",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: project-dep\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: project-app\n  template:\n    metadata:\n      labels:\n        app: project-app\n    spec:\n      volumes:\n      - name: shared-data\n        persistentVolumeClaim:\n          claimName: local-claim\n      - name: config\n        configMap:\n          name: project-app-config\n          items:\n          - key: app.properties\n            path: config.js\n      containers:\n      - name: project-app\n        image: robsondepaula/project:1_13\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: shared-data\n          mountPath: /data\n        - name: config\n          mountPath: /usr/share/nginx/html/config.js\n          subPath: config.js\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: project-service\n        image: robsondepaula/project-service:1_13\n        ports:\n        - containerPort: 3001\n        volumeMounts:\n        - name: shared-data\n          mountPath: /data\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04515",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: project-dep\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: project-app\n  template:\n    metadata:\n      labels:\n        app: project-app\n    spec:\n      volumes:\n      - name: shared-data\n        persistentVolumeClaim:\n          claimName: local-claim\n      - name: config\n        configMap:\n          name: project-app-config\n          items:\n          - key: app.properties\n            path: config.js\n      containers:\n      - name: project-app\n        image: robsondepaula/project:1_13\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: shared-data\n          mountPath: /data\n        - name: config\n          mountPath: /usr/share/nginx/html/config.js\n          subPath: config.js\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: project-service\n        image: robsondepaula/project-service:1_13\n        ports:\n        - containerPort: 3001\n        volumeMounts:\n        - name: shared-data\n          mountPath: /data\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04516",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: project-dep\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: project-app\n  template:\n    metadata:\n      labels:\n        app: project-app\n    spec:\n      volumes:\n      - name: shared-data\n        persistentVolumeClaim:\n          claimName: local-claim\n      - name: config\n        configMap:\n          name: project-app-config\n          items:\n          - key: app.properties\n            path: config.js\n      containers:\n      - name: project-app\n        image: robsondepaula/project:1_13\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: shared-data\n          mountPath: /data\n        - name: config\n          mountPath: /usr/share/nginx/html/config.js\n          subPath: config.js\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: project-service\n        image: robsondepaula/project-service:1_13\n        ports:\n        - containerPort: 3001\n        volumeMounts:\n        - name: shared-data\n          mountPath: /data\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04517",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: project-dep\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: project-app\n  template:\n    metadata:\n      labels:\n        app: project-app\n    spec:\n      volumes:\n      - name: shared-data\n        persistentVolumeClaim:\n          claimName: local-claim\n      - name: config\n        configMap:\n          name: project-app-config\n          items:\n          - key: app.properties\n            path: config.js\n      containers:\n      - name: project-app\n        image: robsondepaula/project:1_13\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: shared-data\n          mountPath: /data\n        - name: config\n          mountPath: /usr/share/nginx/html/config.js\n          subPath: config.js\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: project-service\n        image: robsondepaula/project-service:1_13\n        ports:\n        - containerPort: 3001\n        volumeMounts:\n        - name: shared-data\n          mountPath: /data\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04518",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: project-dep\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: project-app\n  template:\n    metadata:\n      labels:\n        app: project-app\n    spec:\n      volumes:\n      - name: shared-data\n        persistentVolumeClaim:\n          claimName: local-claim\n      - name: config\n        configMap:\n          name: project-app-config\n          items:\n          - key: app.properties\n            path: config.js\n      containers:\n      - name: project-app\n        image: robsondepaula/project:1_13\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: shared-data\n          mountPath: /data\n        - name: config\n          mountPath: /usr/share/nginx/html/config.js\n          subPath: config.js\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: project-service\n        image: robsondepaula/project-service:1_13\n        ports:\n        - containerPort: 3001\n        volumeMounts:\n        - name: shared-data\n          mountPath: /data\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04519",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: project-dep\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: project-app\n  template:\n    metadata:\n      labels:\n        app: project-app\n    spec:\n      volumes:\n      - name: shared-data\n        persistentVolumeClaim:\n          claimName: local-claim\n      - name: config\n        configMap:\n          name: project-app-config\n          items:\n          - key: app.properties\n            path: config.js\n      containers:\n      - name: project-app\n        image: robsondepaula/project:1_13\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: shared-data\n          mountPath: /data\n        - name: config\n          mountPath: /usr/share/nginx/html/config.js\n          subPath: config.js\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: project-service\n        image: robsondepaula/project-service:1_13\n        ports:\n        - containerPort: 3001\n        volumeMounts:\n        - name: shared-data\n          mountPath: /data\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04520",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: buildkitd\nspec:\n  containers:\n  - name: buildkitd\n    image: moby/buildkit:master\n    readinessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    livenessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    securityContext:\n      privileged: false\n      readOnlyRootFilesystem: true\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04521",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: buildkitd\nspec:\n  containers:\n  - name: buildkitd\n    image: moby/buildkit:master\n    readinessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    livenessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04522",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: buildkitd\nspec:\n  containers:\n  - name: buildkitd\n    image: moby/buildkit:master\n    readinessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    livenessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04523",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: buildkitd\nspec:\n  containers:\n  - name: buildkitd\n    image: moby/buildkit:master\n    readinessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    livenessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    securityContext:\n      privileged: false\n      runAsNonRoot: true\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04524",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: buildkitd\nspec:\n  containers:\n  - name: buildkitd\n    image: moby/buildkit:master\n    readinessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    livenessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04525",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: buildkitd\nspec:\n  containers:\n  - name: buildkitd\n    image: moby/buildkit:master\n    readinessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    livenessProbe:\n      exec:\n        command:\n        - buildctl\n        - debug\n        - workers\n      initialDelaySeconds: 5\n      periodSeconds: 30\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04526",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql-test\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mysql-test\n  template:\n    metadata:\n      labels:\n        app: mysql-test\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: key\n                operator: In\n                values:\n                - value\n      containers:\n      - name: mysql-test\n        image: statemood/mysql:5.7.21\n        imagePullPolicy: Always\n        env:\n        - name: MYSQL_CONFIG_FILE\n          value: /var/lib/mysql/my.cnf\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-root-password-secret\n              key: mysql_root_password\n        volumeMounts:\n        - mountPath: /var/lib/mysql\n          name: data\n        ports:\n        - containerPort: 3306\n        resources:\n          limits:\n            cpu: 900m\n            memory: 2Gi\n          requests:\n            cpu: 900m\n            memory: 2Gi\n        livenessProbe:\n          tcpSocket:\n            port: 3306\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          periodSeconds: 20\n        readinessProbe:\n          tcpSocket:\n            port: 3306\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          periodSeconds: 20\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: data-mysql-test\n",
    "errors": []
  },
  {
    "id": "04527",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql-test\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mysql-test\n  template:\n    metadata:\n      labels:\n        app: mysql-test\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: key\n                operator: In\n                values:\n                - value\n      containers:\n      - name: mysql-test\n        image: statemood/mysql:5.7.21\n        imagePullPolicy: Always\n        env:\n        - name: MYSQL_CONFIG_FILE\n          value: /var/lib/mysql/my.cnf\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-root-password-secret\n              key: mysql_root_password\n        volumeMounts:\n        - mountPath: /var/lib/mysql\n          name: data\n        ports:\n        - containerPort: 3306\n        resources:\n          limits:\n            cpu: 900m\n            memory: 2Gi\n          requests:\n            cpu: 900m\n            memory: 2Gi\n        livenessProbe:\n          tcpSocket:\n            port: 3306\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          periodSeconds: 20\n        readinessProbe:\n          tcpSocket:\n            port: 3306\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          periodSeconds: 20\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: data-mysql-test\n",
    "errors": []
  },
  {
    "id": "04528",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo-client\n  labels:\n    app: echo-client\n    group: sample\n    version: 0.0.1\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: echo-client\n      group: sample\n      version: 0.0.1\n  template:\n    metadata:\n      labels:\n        app: echo-client\n        group: sample\n        version: 0.0.1\n    spec:\n      containers:\n      - name: echo-client\n        image: echo-client:stable\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 7001\n        - name: http-metrics\n          containerPort: 7090\n        resources:\n          limits:\n            cpu: 250m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        livenessProbe:\n          httpGet:\n            path: /live\n            port: 7090\n          initialDelaySeconds: 15\n          periodSeconds: 10\n          timeoutSeconds: 3\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 7090\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 3\n          successThreshold: 1\n          failureThreshold: 3\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04529",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo-client\n  labels:\n    app: echo-client\n    group: sample\n    version: 0.0.1\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: echo-client\n      group: sample\n      version: 0.0.1\n  template:\n    metadata:\n      labels:\n        app: echo-client\n        group: sample\n        version: 0.0.1\n    spec:\n      containers:\n      - name: echo-client\n        image: echo-client:stable\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 7001\n        - name: http-metrics\n          containerPort: 7090\n        resources:\n          limits:\n            cpu: 250m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        livenessProbe:\n          httpGet:\n            path: /live\n            port: 7090\n          initialDelaySeconds: 15\n          periodSeconds: 10\n          timeoutSeconds: 3\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 7090\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 3\n          successThreshold: 1\n          failureThreshold: 3\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04530",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echo-client\n  labels:\n    app: echo-client\n    group: sample\n    version: 0.0.1\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: echo-client\n      group: sample\n      version: 0.0.1\n  template:\n    metadata:\n      labels:\n        app: echo-client\n        group: sample\n        version: 0.0.1\n    spec:\n      containers:\n      - name: echo-client\n        image: echo-client:stable\n        imagePullPolicy: IfNotPresent\n        ports:\n        - name: http\n          containerPort: 7001\n        - name: http-metrics\n          containerPort: 7090\n        resources:\n          limits:\n            cpu: 250m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        livenessProbe:\n          httpGet:\n            path: /live\n            port: 7090\n          initialDelaySeconds: 15\n          periodSeconds: 10\n          timeoutSeconds: 3\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 7090\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 3\n          successThreshold: 1\n          failureThreshold: 3\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04531",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-directory-size-metrics\n  namespace: monitoring\n  annotations:\n    description: 'This `DaemonSet` provides metrics in Prometheus format about disk\n      usage on the nodes.\n\n      The container `read-du` reads in sizes of all directories below /mnt and writes\n      that to `/tmp/metrics`. It only reports directories larger then `100M` for now.\n\n      The other container `caddy` just hands out the contents of that file on request\n      via `http` on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n      These are scheduled on every node in the Kubernetes cluster.\n\n      To choose directories from the node to check, just mount them on the `read-du`\n      container below `/mnt`.\n\n      '\nspec:\n  selector:\n    matchLabels:\n      app: node-directory-size-metrics\n  template:\n    metadata:\n      labels:\n        app: node-directory-size-metrics\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9102'\n        description: 'This `Pod` provides metrics in Prometheus format about disk\n          usage on the node.\n\n          The container `read-du` reads in sizes of all directories below /mnt and\n          writes that to `/tmp/metrics`. It only reports directories larger then `100M`\n          for now.\n\n          The other container `caddy` just hands out the contents of that file on\n          request on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n          This `Pod` is scheduled on every node in the Kubernetes cluster.\n\n          To choose directories from the node to check just mount them on `read-du`\n          below `/mnt`.\n\n          '\n    spec:\n      containers:\n      - name: read-du\n        image: giantswarm/tiny-tools:stable\n        imagePullPolicy: Always\n        command:\n        - fish\n        - --command\n        - \"touch /tmp/metrics-temp\\nwhile true\\n  for directory in (du --bytes --separate-dirs\\\n          \\ --threshold=100M /mnt)\\n    echo $directory | read size path\\n    echo\\\n          \\ \\\"node_directory_size_bytes{path=\\\\\\\"$path\\\\\\\"} $size\\\" \\\\\\n      >> /tmp/metrics-temp\\n\\\n          \\  end\\n  mv /tmp/metrics-temp /tmp/metrics\\n  sleep 300\\nend\\n\"\n        volumeMounts:\n        - name: host-fs-var\n          mountPath: /mnt/var\n          readOnly: true\n        - name: metrics\n          mountPath: /tmp\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: caddy\n        image: dockermuenster/caddy:0.9.3\n        command:\n        - caddy\n        - -port=9102\n        - -root=/var/www\n        ports:\n        - containerPort: 9102\n        volumeMounts:\n        - name: metrics\n          mountPath: /var/www\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: host-fs-var\n        hostPath:\n          path: /var\n      - name: metrics\n        emptyDir:\n          medium: Memory\n",
    "errors": []
  },
  {
    "id": "04532",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-directory-size-metrics\n  namespace: monitoring\n  annotations:\n    description: 'This `DaemonSet` provides metrics in Prometheus format about disk\n      usage on the nodes.\n\n      The container `read-du` reads in sizes of all directories below /mnt and writes\n      that to `/tmp/metrics`. It only reports directories larger then `100M` for now.\n\n      The other container `caddy` just hands out the contents of that file on request\n      via `http` on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n      These are scheduled on every node in the Kubernetes cluster.\n\n      To choose directories from the node to check, just mount them on the `read-du`\n      container below `/mnt`.\n\n      '\nspec:\n  selector:\n    matchLabels:\n      app: node-directory-size-metrics\n  template:\n    metadata:\n      labels:\n        app: node-directory-size-metrics\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9102'\n        description: 'This `Pod` provides metrics in Prometheus format about disk\n          usage on the node.\n\n          The container `read-du` reads in sizes of all directories below /mnt and\n          writes that to `/tmp/metrics`. It only reports directories larger then `100M`\n          for now.\n\n          The other container `caddy` just hands out the contents of that file on\n          request on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n          This `Pod` is scheduled on every node in the Kubernetes cluster.\n\n          To choose directories from the node to check just mount them on `read-du`\n          below `/mnt`.\n\n          '\n    spec:\n      containers:\n      - name: read-du\n        image: giantswarm/tiny-tools:stable\n        imagePullPolicy: Always\n        command:\n        - fish\n        - --command\n        - \"touch /tmp/metrics-temp\\nwhile true\\n  for directory in (du --bytes --separate-dirs\\\n          \\ --threshold=100M /mnt)\\n    echo $directory | read size path\\n    echo\\\n          \\ \\\"node_directory_size_bytes{path=\\\\\\\"$path\\\\\\\"} $size\\\" \\\\\\n      >> /tmp/metrics-temp\\n\\\n          \\  end\\n  mv /tmp/metrics-temp /tmp/metrics\\n  sleep 300\\nend\\n\"\n        volumeMounts:\n        - name: host-fs-var\n          mountPath: /mnt/var\n          readOnly: true\n        - name: metrics\n          mountPath: /tmp\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: caddy\n        image: dockermuenster/caddy:0.9.3\n        command:\n        - caddy\n        - -port=9102\n        - -root=/var/www\n        ports:\n        - containerPort: 9102\n        volumeMounts:\n        - name: metrics\n          mountPath: /var/www\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: host-fs-var\n        hostPath:\n          path: /var\n      - name: metrics\n        emptyDir:\n          medium: Memory\n",
    "errors": []
  },
  {
    "id": "04533",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-directory-size-metrics\n  namespace: monitoring\n  annotations:\n    description: 'This `DaemonSet` provides metrics in Prometheus format about disk\n      usage on the nodes.\n\n      The container `read-du` reads in sizes of all directories below /mnt and writes\n      that to `/tmp/metrics`. It only reports directories larger then `100M` for now.\n\n      The other container `caddy` just hands out the contents of that file on request\n      via `http` on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n      These are scheduled on every node in the Kubernetes cluster.\n\n      To choose directories from the node to check, just mount them on the `read-du`\n      container below `/mnt`.\n\n      '\nspec:\n  selector:\n    matchLabels:\n      app: node-directory-size-metrics\n  template:\n    metadata:\n      labels:\n        app: node-directory-size-metrics\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9102'\n        description: 'This `Pod` provides metrics in Prometheus format about disk\n          usage on the node.\n\n          The container `read-du` reads in sizes of all directories below /mnt and\n          writes that to `/tmp/metrics`. It only reports directories larger then `100M`\n          for now.\n\n          The other container `caddy` just hands out the contents of that file on\n          request on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n          This `Pod` is scheduled on every node in the Kubernetes cluster.\n\n          To choose directories from the node to check just mount them on `read-du`\n          below `/mnt`.\n\n          '\n    spec:\n      containers:\n      - name: read-du\n        image: giantswarm/tiny-tools:stable\n        imagePullPolicy: Always\n        command:\n        - fish\n        - --command\n        - \"touch /tmp/metrics-temp\\nwhile true\\n  for directory in (du --bytes --separate-dirs\\\n          \\ --threshold=100M /mnt)\\n    echo $directory | read size path\\n    echo\\\n          \\ \\\"node_directory_size_bytes{path=\\\\\\\"$path\\\\\\\"} $size\\\" \\\\\\n      >> /tmp/metrics-temp\\n\\\n          \\  end\\n  mv /tmp/metrics-temp /tmp/metrics\\n  sleep 300\\nend\\n\"\n        volumeMounts:\n        - name: host-fs-var\n          mountPath: /mnt/var\n          readOnly: true\n        - name: metrics\n          mountPath: /tmp\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: caddy\n        image: dockermuenster/caddy:0.9.3\n        command:\n        - caddy\n        - -port=9102\n        - -root=/var/www\n        ports:\n        - containerPort: 9102\n        volumeMounts:\n        - name: metrics\n          mountPath: /var/www\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: host-fs-var\n        hostPath:\n          path: /var\n      - name: metrics\n        emptyDir:\n          medium: Memory\n",
    "errors": []
  },
  {
    "id": "04534",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-directory-size-metrics\n  namespace: monitoring\n  annotations:\n    description: 'This `DaemonSet` provides metrics in Prometheus format about disk\n      usage on the nodes.\n\n      The container `read-du` reads in sizes of all directories below /mnt and writes\n      that to `/tmp/metrics`. It only reports directories larger then `100M` for now.\n\n      The other container `caddy` just hands out the contents of that file on request\n      via `http` on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n      These are scheduled on every node in the Kubernetes cluster.\n\n      To choose directories from the node to check, just mount them on the `read-du`\n      container below `/mnt`.\n\n      '\nspec:\n  selector:\n    matchLabels:\n      app: node-directory-size-metrics\n  template:\n    metadata:\n      labels:\n        app: node-directory-size-metrics\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9102'\n        description: 'This `Pod` provides metrics in Prometheus format about disk\n          usage on the node.\n\n          The container `read-du` reads in sizes of all directories below /mnt and\n          writes that to `/tmp/metrics`. It only reports directories larger then `100M`\n          for now.\n\n          The other container `caddy` just hands out the contents of that file on\n          request on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n          This `Pod` is scheduled on every node in the Kubernetes cluster.\n\n          To choose directories from the node to check just mount them on `read-du`\n          below `/mnt`.\n\n          '\n    spec:\n      containers:\n      - name: read-du\n        image: giantswarm/tiny-tools:stable\n        imagePullPolicy: Always\n        command:\n        - fish\n        - --command\n        - \"touch /tmp/metrics-temp\\nwhile true\\n  for directory in (du --bytes --separate-dirs\\\n          \\ --threshold=100M /mnt)\\n    echo $directory | read size path\\n    echo\\\n          \\ \\\"node_directory_size_bytes{path=\\\\\\\"$path\\\\\\\"} $size\\\" \\\\\\n      >> /tmp/metrics-temp\\n\\\n          \\  end\\n  mv /tmp/metrics-temp /tmp/metrics\\n  sleep 300\\nend\\n\"\n        volumeMounts:\n        - name: host-fs-var\n          mountPath: /mnt/var\n          readOnly: true\n        - name: metrics\n          mountPath: /tmp\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: caddy\n        image: dockermuenster/caddy:0.9.3\n        command:\n        - caddy\n        - -port=9102\n        - -root=/var/www\n        ports:\n        - containerPort: 9102\n        volumeMounts:\n        - name: metrics\n          mountPath: /var/www\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: host-fs-var\n        hostPath:\n          path: /var\n      - name: metrics\n        emptyDir:\n          medium: Memory\n",
    "errors": []
  },
  {
    "id": "04535",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-directory-size-metrics\n  namespace: monitoring\n  annotations:\n    description: 'This `DaemonSet` provides metrics in Prometheus format about disk\n      usage on the nodes.\n\n      The container `read-du` reads in sizes of all directories below /mnt and writes\n      that to `/tmp/metrics`. It only reports directories larger then `100M` for now.\n\n      The other container `caddy` just hands out the contents of that file on request\n      via `http` on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n      These are scheduled on every node in the Kubernetes cluster.\n\n      To choose directories from the node to check, just mount them on the `read-du`\n      container below `/mnt`.\n\n      '\nspec:\n  selector:\n    matchLabels:\n      app: node-directory-size-metrics\n  template:\n    metadata:\n      labels:\n        app: node-directory-size-metrics\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9102'\n        description: 'This `Pod` provides metrics in Prometheus format about disk\n          usage on the node.\n\n          The container `read-du` reads in sizes of all directories below /mnt and\n          writes that to `/tmp/metrics`. It only reports directories larger then `100M`\n          for now.\n\n          The other container `caddy` just hands out the contents of that file on\n          request on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n          This `Pod` is scheduled on every node in the Kubernetes cluster.\n\n          To choose directories from the node to check just mount them on `read-du`\n          below `/mnt`.\n\n          '\n    spec:\n      containers:\n      - name: read-du\n        image: giantswarm/tiny-tools:stable\n        imagePullPolicy: Always\n        command:\n        - fish\n        - --command\n        - \"touch /tmp/metrics-temp\\nwhile true\\n  for directory in (du --bytes --separate-dirs\\\n          \\ --threshold=100M /mnt)\\n    echo $directory | read size path\\n    echo\\\n          \\ \\\"node_directory_size_bytes{path=\\\\\\\"$path\\\\\\\"} $size\\\" \\\\\\n      >> /tmp/metrics-temp\\n\\\n          \\  end\\n  mv /tmp/metrics-temp /tmp/metrics\\n  sleep 300\\nend\\n\"\n        volumeMounts:\n        - name: host-fs-var\n          mountPath: /mnt/var\n          readOnly: true\n        - name: metrics\n          mountPath: /tmp\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: caddy\n        image: dockermuenster/caddy:0.9.3\n        command:\n        - caddy\n        - -port=9102\n        - -root=/var/www\n        ports:\n        - containerPort: 9102\n        volumeMounts:\n        - name: metrics\n          mountPath: /var/www\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: host-fs-var\n        hostPath:\n          path: /var\n      - name: metrics\n        emptyDir:\n          medium: Memory\n",
    "errors": []
  },
  {
    "id": "04536",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-directory-size-metrics\n  namespace: monitoring\n  annotations:\n    description: 'This `DaemonSet` provides metrics in Prometheus format about disk\n      usage on the nodes.\n\n      The container `read-du` reads in sizes of all directories below /mnt and writes\n      that to `/tmp/metrics`. It only reports directories larger then `100M` for now.\n\n      The other container `caddy` just hands out the contents of that file on request\n      via `http` on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n      These are scheduled on every node in the Kubernetes cluster.\n\n      To choose directories from the node to check, just mount them on the `read-du`\n      container below `/mnt`.\n\n      '\nspec:\n  selector:\n    matchLabels:\n      app: node-directory-size-metrics\n  template:\n    metadata:\n      labels:\n        app: node-directory-size-metrics\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9102'\n        description: 'This `Pod` provides metrics in Prometheus format about disk\n          usage on the node.\n\n          The container `read-du` reads in sizes of all directories below /mnt and\n          writes that to `/tmp/metrics`. It only reports directories larger then `100M`\n          for now.\n\n          The other container `caddy` just hands out the contents of that file on\n          request on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n          This `Pod` is scheduled on every node in the Kubernetes cluster.\n\n          To choose directories from the node to check just mount them on `read-du`\n          below `/mnt`.\n\n          '\n    spec:\n      containers:\n      - name: read-du\n        image: giantswarm/tiny-tools:stable\n        imagePullPolicy: Always\n        command:\n        - fish\n        - --command\n        - \"touch /tmp/metrics-temp\\nwhile true\\n  for directory in (du --bytes --separate-dirs\\\n          \\ --threshold=100M /mnt)\\n    echo $directory | read size path\\n    echo\\\n          \\ \\\"node_directory_size_bytes{path=\\\\\\\"$path\\\\\\\"} $size\\\" \\\\\\n      >> /tmp/metrics-temp\\n\\\n          \\  end\\n  mv /tmp/metrics-temp /tmp/metrics\\n  sleep 300\\nend\\n\"\n        volumeMounts:\n        - name: host-fs-var\n          mountPath: /mnt/var\n          readOnly: true\n        - name: metrics\n          mountPath: /tmp\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: caddy\n        image: dockermuenster/caddy:0.9.3\n        command:\n        - caddy\n        - -port=9102\n        - -root=/var/www\n        ports:\n        - containerPort: 9102\n        volumeMounts:\n        - name: metrics\n          mountPath: /var/www\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: host-fs-var\n        hostPath:\n          path: /var\n      - name: metrics\n        emptyDir:\n          medium: Memory\n",
    "errors": []
  },
  {
    "id": "04537",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-directory-size-metrics\n  namespace: monitoring\n  annotations:\n    description: 'This `DaemonSet` provides metrics in Prometheus format about disk\n      usage on the nodes.\n\n      The container `read-du` reads in sizes of all directories below /mnt and writes\n      that to `/tmp/metrics`. It only reports directories larger then `100M` for now.\n\n      The other container `caddy` just hands out the contents of that file on request\n      via `http` on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n      These are scheduled on every node in the Kubernetes cluster.\n\n      To choose directories from the node to check, just mount them on the `read-du`\n      container below `/mnt`.\n\n      '\nspec:\n  selector:\n    matchLabels:\n      app: node-directory-size-metrics\n  template:\n    metadata:\n      labels:\n        app: node-directory-size-metrics\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9102'\n        description: 'This `Pod` provides metrics in Prometheus format about disk\n          usage on the node.\n\n          The container `read-du` reads in sizes of all directories below /mnt and\n          writes that to `/tmp/metrics`. It only reports directories larger then `100M`\n          for now.\n\n          The other container `caddy` just hands out the contents of that file on\n          request on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n          This `Pod` is scheduled on every node in the Kubernetes cluster.\n\n          To choose directories from the node to check just mount them on `read-du`\n          below `/mnt`.\n\n          '\n    spec:\n      containers:\n      - name: read-du\n        image: giantswarm/tiny-tools:stable\n        imagePullPolicy: Always\n        command:\n        - fish\n        - --command\n        - \"touch /tmp/metrics-temp\\nwhile true\\n  for directory in (du --bytes --separate-dirs\\\n          \\ --threshold=100M /mnt)\\n    echo $directory | read size path\\n    echo\\\n          \\ \\\"node_directory_size_bytes{path=\\\\\\\"$path\\\\\\\"} $size\\\" \\\\\\n      >> /tmp/metrics-temp\\n\\\n          \\  end\\n  mv /tmp/metrics-temp /tmp/metrics\\n  sleep 300\\nend\\n\"\n        volumeMounts:\n        - name: host-fs-var\n          mountPath: /mnt/var\n          readOnly: true\n        - name: metrics\n          mountPath: /tmp\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: caddy\n        image: dockermuenster/caddy:0.9.3\n        command:\n        - caddy\n        - -port=9102\n        - -root=/var/www\n        ports:\n        - containerPort: 9102\n        volumeMounts:\n        - name: metrics\n          mountPath: /var/www\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: host-fs-var\n        hostPath:\n          path: /var\n      - name: metrics\n        emptyDir:\n          medium: Memory\n",
    "errors": []
  },
  {
    "id": "04538",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-directory-size-metrics\n  namespace: monitoring\n  annotations:\n    description: 'This `DaemonSet` provides metrics in Prometheus format about disk\n      usage on the nodes.\n\n      The container `read-du` reads in sizes of all directories below /mnt and writes\n      that to `/tmp/metrics`. It only reports directories larger then `100M` for now.\n\n      The other container `caddy` just hands out the contents of that file on request\n      via `http` on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n      These are scheduled on every node in the Kubernetes cluster.\n\n      To choose directories from the node to check, just mount them on the `read-du`\n      container below `/mnt`.\n\n      '\nspec:\n  selector:\n    matchLabels:\n      app: node-directory-size-metrics\n  template:\n    metadata:\n      labels:\n        app: node-directory-size-metrics\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9102'\n        description: 'This `Pod` provides metrics in Prometheus format about disk\n          usage on the node.\n\n          The container `read-du` reads in sizes of all directories below /mnt and\n          writes that to `/tmp/metrics`. It only reports directories larger then `100M`\n          for now.\n\n          The other container `caddy` just hands out the contents of that file on\n          request on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n          This `Pod` is scheduled on every node in the Kubernetes cluster.\n\n          To choose directories from the node to check just mount them on `read-du`\n          below `/mnt`.\n\n          '\n    spec:\n      containers:\n      - name: read-du\n        image: giantswarm/tiny-tools:stable\n        imagePullPolicy: Always\n        command:\n        - fish\n        - --command\n        - \"touch /tmp/metrics-temp\\nwhile true\\n  for directory in (du --bytes --separate-dirs\\\n          \\ --threshold=100M /mnt)\\n    echo $directory | read size path\\n    echo\\\n          \\ \\\"node_directory_size_bytes{path=\\\\\\\"$path\\\\\\\"} $size\\\" \\\\\\n      >> /tmp/metrics-temp\\n\\\n          \\  end\\n  mv /tmp/metrics-temp /tmp/metrics\\n  sleep 300\\nend\\n\"\n        volumeMounts:\n        - name: host-fs-var\n          mountPath: /mnt/var\n          readOnly: true\n        - name: metrics\n          mountPath: /tmp\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: caddy\n        image: dockermuenster/caddy:0.9.3\n        command:\n        - caddy\n        - -port=9102\n        - -root=/var/www\n        ports:\n        - containerPort: 9102\n        volumeMounts:\n        - name: metrics\n          mountPath: /var/www\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: host-fs-var\n        hostPath:\n          path: /var\n      - name: metrics\n        emptyDir:\n          medium: Memory\n",
    "errors": []
  },
  {
    "id": "04539",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-directory-size-metrics\n  namespace: monitoring\n  annotations:\n    description: 'This `DaemonSet` provides metrics in Prometheus format about disk\n      usage on the nodes.\n\n      The container `read-du` reads in sizes of all directories below /mnt and writes\n      that to `/tmp/metrics`. It only reports directories larger then `100M` for now.\n\n      The other container `caddy` just hands out the contents of that file on request\n      via `http` on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n      These are scheduled on every node in the Kubernetes cluster.\n\n      To choose directories from the node to check, just mount them on the `read-du`\n      container below `/mnt`.\n\n      '\nspec:\n  selector:\n    matchLabels:\n      app: node-directory-size-metrics\n  template:\n    metadata:\n      labels:\n        app: node-directory-size-metrics\n      annotations:\n        prometheus.io/scrape: 'true'\n        prometheus.io/port: '9102'\n        description: 'This `Pod` provides metrics in Prometheus format about disk\n          usage on the node.\n\n          The container `read-du` reads in sizes of all directories below /mnt and\n          writes that to `/tmp/metrics`. It only reports directories larger then `100M`\n          for now.\n\n          The other container `caddy` just hands out the contents of that file on\n          request on `/metrics` at port `9102` which are the defaults for Prometheus.\n\n          This `Pod` is scheduled on every node in the Kubernetes cluster.\n\n          To choose directories from the node to check just mount them on `read-du`\n          below `/mnt`.\n\n          '\n    spec:\n      containers:\n      - name: read-du\n        image: giantswarm/tiny-tools:stable\n        imagePullPolicy: Always\n        command:\n        - fish\n        - --command\n        - \"touch /tmp/metrics-temp\\nwhile true\\n  for directory in (du --bytes --separate-dirs\\\n          \\ --threshold=100M /mnt)\\n    echo $directory | read size path\\n    echo\\\n          \\ \\\"node_directory_size_bytes{path=\\\\\\\"$path\\\\\\\"} $size\\\" \\\\\\n      >> /tmp/metrics-temp\\n\\\n          \\  end\\n  mv /tmp/metrics-temp /tmp/metrics\\n  sleep 300\\nend\\n\"\n        volumeMounts:\n        - name: host-fs-var\n          mountPath: /mnt/var\n          readOnly: true\n        - name: metrics\n          mountPath: /tmp\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: caddy\n        image: dockermuenster/caddy:0.9.3\n        command:\n        - caddy\n        - -port=9102\n        - -root=/var/www\n        ports:\n        - containerPort: 9102\n        volumeMounts:\n        - name: metrics\n          mountPath: /var/www\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: host-fs-var\n        hostPath:\n          path: /var\n      - name: metrics\n        emptyDir:\n          medium: Memory\n",
    "errors": []
  },
  {
    "id": "04540",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: localingress-ds\n  namespace: localingress\n  labels:\n    component: localingress\nspec:\n  selector:\n    matchLabels:\n      component: localingress\n  template:\n    metadata:\n      labels:\n        component: localingress\n    spec:\n      volumes:\n      - name: localingress-config\n        configMap:\n          name: localingress-config\n      containers:\n      - name: ingress\n        image: docker.io/library/haproxy:2.2.4\n        volumeMounts:\n        - name: localingress-config\n          mountPath: /usr/local/etc/haproxy/\n        ports:\n        - containerPort: 443\n          hostPort: 443\n        - containerPort: 80\n          hostPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04541",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: localingress-ds\n  namespace: localingress\n  labels:\n    component: localingress\nspec:\n  selector:\n    matchLabels:\n      component: localingress\n  template:\n    metadata:\n      labels:\n        component: localingress\n    spec:\n      volumes:\n      - name: localingress-config\n        configMap:\n          name: localingress-config\n      containers:\n      - name: ingress\n        image: docker.io/library/haproxy:2.2.4\n        volumeMounts:\n        - name: localingress-config\n          mountPath: /usr/local/etc/haproxy/\n        ports:\n        - containerPort: 443\n          hostPort: 443\n        - containerPort: 80\n          hostPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04542",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: localingress-ds\n  namespace: localingress\n  labels:\n    component: localingress\nspec:\n  selector:\n    matchLabels:\n      component: localingress\n  template:\n    metadata:\n      labels:\n        component: localingress\n    spec:\n      volumes:\n      - name: localingress-config\n        configMap:\n          name: localingress-config\n      containers:\n      - name: ingress\n        image: docker.io/library/haproxy:2.2.4\n        volumeMounts:\n        - name: localingress-config\n          mountPath: /usr/local/etc/haproxy/\n        ports:\n        - containerPort: 443\n          hostPort: 443\n        - containerPort: 80\n          hostPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04543",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: localingress-ds\n  namespace: localingress\n  labels:\n    component: localingress\nspec:\n  selector:\n    matchLabels:\n      component: localingress\n  template:\n    metadata:\n      labels:\n        component: localingress\n    spec:\n      volumes:\n      - name: localingress-config\n        configMap:\n          name: localingress-config\n      containers:\n      - name: ingress\n        image: docker.io/library/haproxy:2.2.4\n        volumeMounts:\n        - name: localingress-config\n          mountPath: /usr/local/etc/haproxy/\n        ports:\n        - containerPort: 443\n          hostPort: 443\n        - containerPort: 80\n          hostPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04544",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-direct-mount\n  namespace: rook-ceph\n  labels:\n    app: rook-direct-mount\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-direct-mount\n  template:\n    metadata:\n      labels:\n        app: rook-direct-mount\n    spec:\n      containers:\n      - name: rook-direct-mount\n        image: rook/ceph:master\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_CEPH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-username\n        - name: ROOK_CEPH_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-secret\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /dev\n          name: dev\n        - mountPath: /sys/bus\n          name: sysbus\n        - mountPath: /lib/modules\n          name: libmodules\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: sysbus\n        hostPath:\n          path: /sys/bus\n      - name: libmodules\n        hostPath:\n          path: /lib/modules\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n",
    "errors": []
  },
  {
    "id": "04545",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-direct-mount\n  namespace: rook-ceph\n  labels:\n    app: rook-direct-mount\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-direct-mount\n  template:\n    metadata:\n      labels:\n        app: rook-direct-mount\n    spec:\n      containers:\n      - name: rook-direct-mount\n        image: rook/ceph:master\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_CEPH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-username\n        - name: ROOK_CEPH_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-secret\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /dev\n          name: dev\n        - mountPath: /sys/bus\n          name: sysbus\n        - mountPath: /lib/modules\n          name: libmodules\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: sysbus\n        hostPath:\n          path: /sys/bus\n      - name: libmodules\n        hostPath:\n          path: /lib/modules\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n",
    "errors": []
  },
  {
    "id": "04546",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-direct-mount\n  namespace: rook-ceph\n  labels:\n    app: rook-direct-mount\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-direct-mount\n  template:\n    metadata:\n      labels:\n        app: rook-direct-mount\n    spec:\n      containers:\n      - name: rook-direct-mount\n        image: rook/ceph:master\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_CEPH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-username\n        - name: ROOK_CEPH_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-secret\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /dev\n          name: dev\n        - mountPath: /sys/bus\n          name: sysbus\n        - mountPath: /lib/modules\n          name: libmodules\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: sysbus\n        hostPath:\n          path: /sys/bus\n      - name: libmodules\n        hostPath:\n          path: /lib/modules\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n",
    "errors": []
  },
  {
    "id": "04547",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-direct-mount\n  namespace: rook-ceph\n  labels:\n    app: rook-direct-mount\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-direct-mount\n  template:\n    metadata:\n      labels:\n        app: rook-direct-mount\n    spec:\n      containers:\n      - name: rook-direct-mount\n        image: rook/ceph:master\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_CEPH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-username\n        - name: ROOK_CEPH_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-secret\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /dev\n          name: dev\n        - mountPath: /sys/bus\n          name: sysbus\n        - mountPath: /lib/modules\n          name: libmodules\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: sysbus\n        hostPath:\n          path: /sys/bus\n      - name: libmodules\n        hostPath:\n          path: /lib/modules\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n",
    "errors": []
  },
  {
    "id": "04548",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-direct-mount\n  namespace: rook-ceph\n  labels:\n    app: rook-direct-mount\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-direct-mount\n  template:\n    metadata:\n      labels:\n        app: rook-direct-mount\n    spec:\n      containers:\n      - name: rook-direct-mount\n        image: rook/ceph:master\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_CEPH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-username\n        - name: ROOK_CEPH_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-secret\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /dev\n          name: dev\n        - mountPath: /sys/bus\n          name: sysbus\n        - mountPath: /lib/modules\n          name: libmodules\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: sysbus\n        hostPath:\n          path: /sys/bus\n      - name: libmodules\n        hostPath:\n          path: /lib/modules\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n",
    "errors": []
  },
  {
    "id": "04549",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rook-direct-mount\n  namespace: rook-ceph\n  labels:\n    app: rook-direct-mount\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: rook-direct-mount\n  template:\n    metadata:\n      labels:\n        app: rook-direct-mount\n    spec:\n      containers:\n      - name: rook-direct-mount\n        image: rook/ceph:master\n        command:\n        - /tini\n        args:\n        - -g\n        - --\n        - /usr/local/bin/toolbox.sh\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: ROOK_CEPH_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-username\n        - name: ROOK_CEPH_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: rook-ceph-mon\n              key: ceph-secret\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /dev\n          name: dev\n        - mountPath: /sys/bus\n          name: sysbus\n        - mountPath: /lib/modules\n          name: libmodules\n        - name: mon-endpoint-volume\n          mountPath: /etc/rook\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: sysbus\n        hostPath:\n          path: /sys/bus\n      - name: libmodules\n        hostPath:\n          path: /lib/modules\n      - name: mon-endpoint-volume\n        configMap:\n          name: rook-ceph-mon-endpoints\n          items:\n          - key: data\n            path: mon-endpoints\n",
    "errors": []
  },
  {
    "id": "04550",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cassandra-stress-normal\n  labels:\n    app: cassandra-stress\nspec:\n  volumes:\n  - name: cassandra-stress-profile-volume\n    configMap:\n      name: cassandra-stress-normal\n  securityContext:\n    fsGroup: 1\n    runAsNonRoot: true\n    runAsUser: 1006\n    supplementalGroups:\n    - 1\n  containers:\n  - name: cassie1-cassandra-stress\n    image: cassandra:stable\n    imagePullPolicy: IfNotPresent\n    securityContext:\n      capabilities:\n        add:\n        - IPC_LOCK\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    command:\n    - /bin/sh\n    args:\n    - -c\n    - cassandra-stress 'user profile=/opt/cassandra-stress/normal_stress.yaml ops(insert=10,query_by_sub_id=8)\n      duration=120m cl=one -node cassandra-demo -mode native cql3 user=bench password=monbench\n      -rate threads=30 -pop seq=0..100M -tokenrange -graph file=/tmp/stress-normal.html'\n      && echo END && while true ; do sleep 60; done\n    resources:\n      limits:\n        cpu: '3'\n        memory: 8Gi\n      requests:\n        cpu: '3'\n        memory: 8Gi\n    volumeMounts:\n    - name: cassandra-stress-profile-volume\n      mountPath: /opt/cassandra-stress\n",
    "errors": []
  },
  {
    "id": "04551",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cassandra-stress-normal\n  labels:\n    app: cassandra-stress\nspec:\n  volumes:\n  - name: cassandra-stress-profile-volume\n    configMap:\n      name: cassandra-stress-normal\n  securityContext:\n    fsGroup: 1\n    runAsNonRoot: true\n    runAsUser: 1006\n    supplementalGroups:\n    - 1\n  containers:\n  - name: cassie1-cassandra-stress\n    image: cassandra:stable\n    imagePullPolicy: IfNotPresent\n    securityContext:\n      capabilities:\n        add:\n        - IPC_LOCK\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      readOnlyRootFilesystem: true\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    command:\n    - /bin/sh\n    args:\n    - -c\n    - cassandra-stress 'user profile=/opt/cassandra-stress/normal_stress.yaml ops(insert=10,query_by_sub_id=8)\n      duration=120m cl=one -node cassandra-demo -mode native cql3 user=bench password=monbench\n      -rate threads=30 -pop seq=0..100M -tokenrange -graph file=/tmp/stress-normal.html'\n      && echo END && while true ; do sleep 60; done\n    resources:\n      limits:\n        cpu: '3'\n        memory: 8Gi\n      requests:\n        cpu: '3'\n        memory: 8Gi\n    volumeMounts:\n    - name: cassandra-stress-profile-volume\n      mountPath: /opt/cassandra-stress\n",
    "errors": []
  },
  {
    "id": "04552",
    "policy_id": "env_var_secret",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": false,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "environment variable NEO4J_PASSWORD must use secretKeyRef",
      "environment variable JWT_SECRET must use secretKeyRef",
      "environment variable AGENTS_JWT_SECRET must use secretKeyRef"
    ]
  },
  {
    "id": "04553",
    "policy_id": "env_var_secret",
    "accepted": false,
    "ok_schema": true,
    "ok_policy": false,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "environment variable NEO4J_PASSWORD must use secretKeyRef",
      "environment variable JWT_SECRET must use secretKeyRef",
      "environment variable AGENTS_JWT_SECRET must use secretKeyRef"
    ]
  },
  {
    "id": "04554",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: imicros-users-deployment\nspec:\n  selector:\n    matchLabels:\n      app: imicros-users\n  template:\n    metadata:\n      labels:\n        app: imicros-users\n        version: '0.1'\n    spec:\n      containers:\n      - name: imicros-users\n        image: al66/imicros-backend:stable\n        imagePullPolicy: Always\n        env:\n        - name: SERVICES\n          value: master, user, groups, agents, acl\n        - name: MASTER_TOKEN\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: SERVICE_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: service-token\n              key: token\n        - name: TRANSPORTER_NATS\n          value: nats://nats:4222\n        - name: CASSANDRA_CONTACTPOINTS\n          value: cassandra\n        - name: CASSANDRA_DATACENTER\n          value: datacenter1\n        - name: CASSANDRA_KEYSPACE_KEYS\n          value: imicros_keys\n        - name: CASSANDRA_PORT\n          value: '9042'\n        - name: CASSANDRA_USER\n          value: cassandra\n        - name: CASSANDRA_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: cassandra-password-secret\n              key: cassandra_password\n        - name: NEO4J_URI\n          value: bolt://neo4j:7687\n        - name: NEO4J_USER\n          value: neo4j\n        - name: NEO4J_PASSWORD\n          value: neo4j\n        - name: JWT_SECRET\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: AGENTS_JWT_SECRET\n          value: my JWT secret - should be set as a Kubernetes secret\n        - name: EVENT_OWNER_ID\n          value: 096f1dff-681a-4746-b5cd-2228f69630c7\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04555",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: imicros-users-deployment\nspec:\n  selector:\n    matchLabels:\n      app: imicros-users\n  template:\n    metadata:\n      labels:\n        app: imicros-users\n        version: '0.1'\n    spec:\n      containers:\n      - name: imicros-users\n        image: al66/imicros-backend:stable\n        imagePullPolicy: Always\n        env:\n        - name: SERVICES\n          value: master, user, groups, agents, acl\n        - name: MASTER_TOKEN\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: SERVICE_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: service-token\n              key: token\n        - name: TRANSPORTER_NATS\n          value: nats://nats:4222\n        - name: CASSANDRA_CONTACTPOINTS\n          value: cassandra\n        - name: CASSANDRA_DATACENTER\n          value: datacenter1\n        - name: CASSANDRA_KEYSPACE_KEYS\n          value: imicros_keys\n        - name: CASSANDRA_PORT\n          value: '9042'\n        - name: CASSANDRA_USER\n          value: cassandra\n        - name: CASSANDRA_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: cassandra-password-secret\n              key: cassandra_password\n        - name: NEO4J_URI\n          value: bolt://neo4j:7687\n        - name: NEO4J_USER\n          value: neo4j\n        - name: NEO4J_PASSWORD\n          value: neo4j\n        - name: JWT_SECRET\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: AGENTS_JWT_SECRET\n          value: my JWT secret - should be set as a Kubernetes secret\n        - name: EVENT_OWNER_ID\n          value: 096f1dff-681a-4746-b5cd-2228f69630c7\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04556",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: imicros-users-deployment\nspec:\n  selector:\n    matchLabels:\n      app: imicros-users\n  template:\n    metadata:\n      labels:\n        app: imicros-users\n        version: '0.1'\n    spec:\n      containers:\n      - name: imicros-users\n        image: al66/imicros-backend:stable\n        imagePullPolicy: Always\n        env:\n        - name: SERVICES\n          value: master, user, groups, agents, acl\n        - name: MASTER_TOKEN\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: SERVICE_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: service-token\n              key: token\n        - name: TRANSPORTER_NATS\n          value: nats://nats:4222\n        - name: CASSANDRA_CONTACTPOINTS\n          value: cassandra\n        - name: CASSANDRA_DATACENTER\n          value: datacenter1\n        - name: CASSANDRA_KEYSPACE_KEYS\n          value: imicros_keys\n        - name: CASSANDRA_PORT\n          value: '9042'\n        - name: CASSANDRA_USER\n          value: cassandra\n        - name: CASSANDRA_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: cassandra-password-secret\n              key: cassandra_password\n        - name: NEO4J_URI\n          value: bolt://neo4j:7687\n        - name: NEO4J_USER\n          value: neo4j\n        - name: NEO4J_PASSWORD\n          value: neo4j\n        - name: JWT_SECRET\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: AGENTS_JWT_SECRET\n          value: my JWT secret - should be set as a Kubernetes secret\n        - name: EVENT_OWNER_ID\n          value: 096f1dff-681a-4746-b5cd-2228f69630c7\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04557",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: imicros-users-deployment\nspec:\n  selector:\n    matchLabels:\n      app: imicros-users\n  template:\n    metadata:\n      labels:\n        app: imicros-users\n        version: '0.1'\n    spec:\n      containers:\n      - name: imicros-users\n        image: al66/imicros-backend:stable\n        imagePullPolicy: Always\n        env:\n        - name: SERVICES\n          value: master, user, groups, agents, acl\n        - name: MASTER_TOKEN\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: SERVICE_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: service-token\n              key: token\n        - name: TRANSPORTER_NATS\n          value: nats://nats:4222\n        - name: CASSANDRA_CONTACTPOINTS\n          value: cassandra\n        - name: CASSANDRA_DATACENTER\n          value: datacenter1\n        - name: CASSANDRA_KEYSPACE_KEYS\n          value: imicros_keys\n        - name: CASSANDRA_PORT\n          value: '9042'\n        - name: CASSANDRA_USER\n          value: cassandra\n        - name: CASSANDRA_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: cassandra-password-secret\n              key: cassandra_password\n        - name: NEO4J_URI\n          value: bolt://neo4j:7687\n        - name: NEO4J_USER\n          value: neo4j\n        - name: NEO4J_PASSWORD\n          value: neo4j\n        - name: JWT_SECRET\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: AGENTS_JWT_SECRET\n          value: my JWT secret - should be set as a Kubernetes secret\n        - name: EVENT_OWNER_ID\n          value: 096f1dff-681a-4746-b5cd-2228f69630c7\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04558",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: imicros-users-deployment\nspec:\n  selector:\n    matchLabels:\n      app: imicros-users\n  template:\n    metadata:\n      labels:\n        app: imicros-users\n        version: '0.1'\n    spec:\n      containers:\n      - name: imicros-users\n        image: al66/imicros-backend:stable\n        imagePullPolicy: Always\n        env:\n        - name: SERVICES\n          value: master, user, groups, agents, acl\n        - name: MASTER_TOKEN\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: SERVICE_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: service-token\n              key: token\n        - name: TRANSPORTER_NATS\n          value: nats://nats:4222\n        - name: CASSANDRA_CONTACTPOINTS\n          value: cassandra\n        - name: CASSANDRA_DATACENTER\n          value: datacenter1\n        - name: CASSANDRA_KEYSPACE_KEYS\n          value: imicros_keys\n        - name: CASSANDRA_PORT\n          value: '9042'\n        - name: CASSANDRA_USER\n          value: cassandra\n        - name: CASSANDRA_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: cassandra-password-secret\n              key: cassandra_password\n        - name: NEO4J_URI\n          value: bolt://neo4j:7687\n        - name: NEO4J_USER\n          value: neo4j\n        - name: NEO4J_PASSWORD\n          value: neo4j\n        - name: JWT_SECRET\n          value: zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\n        - name: AGENTS_JWT_SECRET\n          value: my JWT secret - should be set as a Kubernetes secret\n        - name: EVENT_OWNER_ID\n          value: 096f1dff-681a-4746-b5cd-2228f69630c7\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04559",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  namespace: test\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 500Mi\n          limits:\n            cpu: 500m\n            memory: 1024Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04560",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  namespace: test\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 500Mi\n          limits:\n            cpu: 500m\n            memory: 1024Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04561",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  namespace: test\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:stable\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 500Mi\n          limits:\n            cpu: 500m\n            memory: 1024Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04562",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: user\n  template:\n    metadata:\n      labels:\n        app: user\n    spec:\n      containers:\n      - name: user\n        image: p3fightclub.azurecr.io/user:stable\n        ports:\n        - containerPort: 5001\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04563",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: user\n  template:\n    metadata:\n      labels:\n        app: user\n    spec:\n      containers:\n      - name: user\n        image: p3fightclub.azurecr.io/user:stable\n        ports:\n        - containerPort: 5001\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04564",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: user\n  template:\n    metadata:\n      labels:\n        app: user\n    spec:\n      containers:\n      - name: user\n        image: p3fightclub.azurecr.io/user:stable\n        ports:\n        - containerPort: 5001\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04565",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: user\n  template:\n    metadata:\n      labels:\n        app: user\n    spec:\n      containers:\n      - name: user\n        image: p3fightclub.azurecr.io/user:stable\n        ports:\n        - containerPort: 5001\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04566",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: user\n  template:\n    metadata:\n      labels:\n        app: user\n    spec:\n      containers:\n      - name: user\n        image: p3fightclub.azurecr.io/user:stable\n        ports:\n        - containerPort: 5001\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04567",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5924\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04568",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5924\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04569",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5924\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04570",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5924\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04571",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5924\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04572",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tickets-celery\n  labels:\n    app: tickets-celery\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: tickets-celery\n  template:\n    metadata:\n      labels:\n        name: tickets-celery\n    spec:\n      containers:\n      - name: tickets-celery\n        image: ckreuzberger/tickets:1.0\n        imagePullPolicy: Always\n        command:\n        - celery\n        args:\n        - -A\n        - tickets\n        - worker\n        - --loglevel=info\n        env:\n        - name: POSTGRES_USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-credentials\n              key: user\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-credentials\n              key: password\n        - name: POSTGRES_DB\n          value: tickets\n        - name: DATABASE_URL\n          value: postgres://$(POSTGRES_USER):$(POSTGRES_PASSWORD)@postgres:5432/$(POSTGRES_DB)\n        - name: DJANGO_SETTINGS_MODULE\n          value: tickets.settings.prod\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: django-secret-key\n              key: secret_key\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04573",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tickets-celery\n  labels:\n    app: tickets-celery\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: tickets-celery\n  template:\n    metadata:\n      labels:\n        name: tickets-celery\n    spec:\n      containers:\n      - name: tickets-celery\n        image: ckreuzberger/tickets:1.0\n        imagePullPolicy: Always\n        command:\n        - celery\n        args:\n        - -A\n        - tickets\n        - worker\n        - --loglevel=info\n        env:\n        - name: POSTGRES_USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-credentials\n              key: user\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-credentials\n              key: password\n        - name: POSTGRES_DB\n          value: tickets\n        - name: DATABASE_URL\n          value: postgres://$(POSTGRES_USER):$(POSTGRES_PASSWORD)@postgres:5432/$(POSTGRES_DB)\n        - name: DJANGO_SETTINGS_MODULE\n          value: tickets.settings.prod\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: django-secret-key\n              key: secret_key\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04574",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tickets-celery\n  labels:\n    app: tickets-celery\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: tickets-celery\n  template:\n    metadata:\n      labels:\n        name: tickets-celery\n    spec:\n      containers:\n      - name: tickets-celery\n        image: ckreuzberger/tickets:1.0\n        imagePullPolicy: Always\n        command:\n        - celery\n        args:\n        - -A\n        - tickets\n        - worker\n        - --loglevel=info\n        env:\n        - name: POSTGRES_USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-credentials\n              key: user\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-credentials\n              key: password\n        - name: POSTGRES_DB\n          value: tickets\n        - name: DATABASE_URL\n          value: postgres://$(POSTGRES_USER):$(POSTGRES_PASSWORD)@postgres:5432/$(POSTGRES_DB)\n        - name: DJANGO_SETTINGS_MODULE\n          value: tickets.settings.prod\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: django-secret-key\n              key: secret_key\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04575",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: tickets-celery\n  labels:\n    app: tickets-celery\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: tickets-celery\n  template:\n    metadata:\n      labels:\n        name: tickets-celery\n    spec:\n      containers:\n      - name: tickets-celery\n        image: ckreuzberger/tickets:1.0\n        imagePullPolicy: Always\n        command:\n        - celery\n        args:\n        - -A\n        - tickets\n        - worker\n        - --loglevel=info\n        env:\n        - name: POSTGRES_USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-credentials\n              key: user\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-credentials\n              key: password\n        - name: POSTGRES_DB\n          value: tickets\n        - name: DATABASE_URL\n          value: postgres://$(POSTGRES_USER):$(POSTGRES_PASSWORD)@postgres:5432/$(POSTGRES_DB)\n        - name: DJANGO_SETTINGS_MODULE\n          value: tickets.settings.prod\n        - name: SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: django-secret-key\n              key: secret_key\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04576",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/component: repo-server\n  name: argocd-repo-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-repo-server\n    spec:\n      containers:\n      - name: argocd-repo-server\n        image: quay.io/argoproj/argocd:stable\n        imagePullPolicy: Always\n        command:\n        - entrypoint.sh\n        - argocd-repo-server\n        - --redis\n        - $(ARGOCD_REDIS_SERVICE):6379\n        env:\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cm\n              key: timeout.reconciliation\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.log.format\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.log.level\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.parallelism.limit\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.disable.tls\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.minversion\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.maxversion\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.ciphers\n              optional: true\n        - name: ARGOCD_REPO_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.repo.cache.expiration\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.server\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.db\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.default.cache.expiration\n              optional: true\n        - name: HELM_CACHE_HOME\n          value: /helm-working-dir\n        - name: HELM_CONFIG_HOME\n          value: /helm-working-dir\n        - name: HELM_DATA_HOME\n          value: /helm-working-dir\n        ports:\n        - containerPort: 8081\n        - containerPort: 8084\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: 8084\n          initialDelaySeconds: 30\n          periodSeconds: 5\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8084\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        securityContext:\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - all\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n        volumeMounts:\n        - name: ssh-known-hosts\n          mountPath: /app/config/ssh\n        - name: tls-certs\n          mountPath: /app/config/tls\n        - name: gpg-keys\n          mountPath: /app/config/gpg/source\n        - name: gpg-keyring\n          mountPath: /app/config/gpg/keys\n        - name: argocd-repo-server-tls\n          mountPath: /app/config/reposerver/tls\n        - name: tmp\n          mountPath: /tmp\n        - mountPath: /helm-working-dir\n          name: helm-working-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: ssh-known-hosts\n        configMap:\n          name: argocd-ssh-known-hosts-cm\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: gpg-keys\n        configMap:\n          name: argocd-gpg-keys-cm\n      - name: gpg-keyring\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n      - name: helm-working-dir\n        emptyDir: {}\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: kubernetes.io/hostname\n          - weight: 5\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n",
    "errors": []
  },
  {
    "id": "04577",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/component: repo-server\n  name: argocd-repo-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-repo-server\n    spec:\n      containers:\n      - name: argocd-repo-server\n        image: quay.io/argoproj/argocd:stable\n        imagePullPolicy: Always\n        command:\n        - entrypoint.sh\n        - argocd-repo-server\n        - --redis\n        - $(ARGOCD_REDIS_SERVICE):6379\n        env:\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cm\n              key: timeout.reconciliation\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.log.format\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.log.level\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.parallelism.limit\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.disable.tls\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.minversion\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.maxversion\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.ciphers\n              optional: true\n        - name: ARGOCD_REPO_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.repo.cache.expiration\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.server\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.db\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.default.cache.expiration\n              optional: true\n        - name: HELM_CACHE_HOME\n          value: /helm-working-dir\n        - name: HELM_CONFIG_HOME\n          value: /helm-working-dir\n        - name: HELM_DATA_HOME\n          value: /helm-working-dir\n        ports:\n        - containerPort: 8081\n        - containerPort: 8084\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: 8084\n          initialDelaySeconds: 30\n          periodSeconds: 5\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8084\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        securityContext:\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - all\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n        volumeMounts:\n        - name: ssh-known-hosts\n          mountPath: /app/config/ssh\n        - name: tls-certs\n          mountPath: /app/config/tls\n        - name: gpg-keys\n          mountPath: /app/config/gpg/source\n        - name: gpg-keyring\n          mountPath: /app/config/gpg/keys\n        - name: argocd-repo-server-tls\n          mountPath: /app/config/reposerver/tls\n        - name: tmp\n          mountPath: /tmp\n        - mountPath: /helm-working-dir\n          name: helm-working-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: ssh-known-hosts\n        configMap:\n          name: argocd-ssh-known-hosts-cm\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: gpg-keys\n        configMap:\n          name: argocd-gpg-keys-cm\n      - name: gpg-keyring\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n      - name: helm-working-dir\n        emptyDir: {}\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: kubernetes.io/hostname\n          - weight: 5\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n",
    "errors": []
  },
  {
    "id": "04578",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/part-of: argocd\n    app.kubernetes.io/component: repo-server\n  name: argocd-repo-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-repo-server\n    spec:\n      containers:\n      - name: argocd-repo-server\n        image: quay.io/argoproj/argocd:stable\n        imagePullPolicy: Always\n        command:\n        - entrypoint.sh\n        - argocd-repo-server\n        - --redis\n        - $(ARGOCD_REDIS_SERVICE):6379\n        env:\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cm\n              key: timeout.reconciliation\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.log.format\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.log.level\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.parallelism.limit\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.disable.tls\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.minversion\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.maxversion\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.tls.ciphers\n              optional: true\n        - name: ARGOCD_REPO_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.repo.cache.expiration\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.server\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: redis.db\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              name: argocd-cmd-params-cm\n              key: reposerver.default.cache.expiration\n              optional: true\n        - name: HELM_CACHE_HOME\n          value: /helm-working-dir\n        - name: HELM_CONFIG_HOME\n          value: /helm-working-dir\n        - name: HELM_DATA_HOME\n          value: /helm-working-dir\n        ports:\n        - containerPort: 8081\n        - containerPort: 8084\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: 8084\n          initialDelaySeconds: 30\n          periodSeconds: 5\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8084\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        securityContext:\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - all\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n        volumeMounts:\n        - name: ssh-known-hosts\n          mountPath: /app/config/ssh\n        - name: tls-certs\n          mountPath: /app/config/tls\n        - name: gpg-keys\n          mountPath: /app/config/gpg/source\n        - name: gpg-keyring\n          mountPath: /app/config/gpg/keys\n        - name: argocd-repo-server-tls\n          mountPath: /app/config/reposerver/tls\n        - name: tmp\n          mountPath: /tmp\n        - mountPath: /helm-working-dir\n          name: helm-working-dir\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: ssh-known-hosts\n        configMap:\n          name: argocd-ssh-known-hosts-cm\n      - name: tls-certs\n        configMap:\n          name: argocd-tls-certs-cm\n      - name: gpg-keys\n        configMap:\n          name: argocd-gpg-keys-cm\n      - name: gpg-keyring\n        emptyDir: {}\n      - name: tmp\n        emptyDir: {}\n      - name: helm-working-dir\n        emptyDir: {}\n      - name: argocd-repo-server-tls\n        secret:\n          secretName: argocd-repo-server-tls\n          optional: true\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: kubernetes.io/hostname\n          - weight: 5\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n",
    "errors": []
  },
  {
    "id": "04579",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: tomcat\n  labels:\n    app: tomcat\nspec:\n  containers:\n  - name: tomcat\n    image: docker635067/test:preethu\n    ports:\n    - containerPort: 8080\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04580",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: tomcat\n  labels:\n    app: tomcat\nspec:\n  containers:\n  - name: tomcat\n    image: docker635067/test:preethu\n    ports:\n    - containerPort: 8080\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04581",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: tomcat\n  labels:\n    app: tomcat\nspec:\n  containers:\n  - name: tomcat\n    image: docker635067/test:preethu\n    ports:\n    - containerPort: 8080\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04582",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: tomcat\n  labels:\n    app: tomcat\nspec:\n  containers:\n  - name: tomcat\n    image: docker635067/test:preethu\n    ports:\n    - containerPort: 8080\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04583",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"label-sync\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04584",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"label-sync\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04585",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"label-sync\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04586",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"label-sync\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04587",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"istio-grafana-post-install-1.1.6\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04588",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"istio-grafana-post-install-1.1.6\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04589",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"istio-grafana-post-install-1.1.6\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04590",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"istio-grafana-post-install-1.1.6\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04591",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: task-pv-pod\nspec:\n  volumes:\n  - name: task-pv-storage\n    persistentVolumeClaim:\n      claimName: task-pv-claim\n  containers:\n  - name: task-pv-container\n    image: nginx:stable\n    ports:\n    - containerPort: 80\n      name: http-server\n    volumeMounts:\n    - mountPath: /usr/share/nginx/html\n      name: task-pv-storage\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04592",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: task-pv-pod\nspec:\n  volumes:\n  - name: task-pv-storage\n    persistentVolumeClaim:\n      claimName: task-pv-claim\n  containers:\n  - name: task-pv-container\n    image: nginx:stable\n    ports:\n    - containerPort: 80\n      name: http-server\n    volumeMounts:\n    - mountPath: /usr/share/nginx/html\n      name: task-pv-storage\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04593",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: task-pv-pod\nspec:\n  volumes:\n  - name: task-pv-storage\n    persistentVolumeClaim:\n      claimName: task-pv-claim\n  containers:\n  - name: task-pv-container\n    image: nginx:stable\n    ports:\n    - containerPort: 80\n      name: http-server\n    volumeMounts:\n    - mountPath: /usr/share/nginx/html\n      name: task-pv-storage\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04594",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: task-pv-pod\nspec:\n  volumes:\n  - name: task-pv-storage\n    persistentVolumeClaim:\n      claimName: task-pv-claim\n  containers:\n  - name: task-pv-container\n    image: nginx:stable\n    ports:\n    - containerPort: 80\n      name: http-server\n    volumeMounts:\n    - mountPath: /usr/share/nginx/html\n      name: task-pv-storage\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04595",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: task-pv-pod\nspec:\n  volumes:\n  - name: task-pv-storage\n    persistentVolumeClaim:\n      claimName: task-pv-claim\n  containers:\n  - name: task-pv-container\n    image: nginx:stable\n    ports:\n    - containerPort: 80\n      name: http-server\n    volumeMounts:\n    - mountPath: /usr/share/nginx/html\n      name: task-pv-storage\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04596",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: sensor-gen\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    app: sensor-gen\n  template:\n    metadata:\n      name: sensor-gen\n      labels:\n        app: sensor-gen\n    spec:\n      containers:\n      - name: sensor-gen\n        image: huanphan/sensor-simulator:0.2\n        ports:\n        - containerPort: 9090\n        volumeMounts:\n        - name: sensor-config\n          mountPath: /SimulateSensor/config\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: sensor-config\n        configMap:\n          name: sensor-config\n          items:\n          - key: config.cfg\n            path: config.cfg\n",
    "errors": []
  },
  {
    "id": "04597",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: sensor-gen\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    app: sensor-gen\n  template:\n    metadata:\n      name: sensor-gen\n      labels:\n        app: sensor-gen\n    spec:\n      containers:\n      - name: sensor-gen\n        image: huanphan/sensor-simulator:0.2\n        ports:\n        - containerPort: 9090\n        volumeMounts:\n        - name: sensor-config\n          mountPath: /SimulateSensor/config\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: sensor-config\n        configMap:\n          name: sensor-config\n          items:\n          - key: config.cfg\n            path: config.cfg\n",
    "errors": []
  },
  {
    "id": "04598",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: sensor-gen\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    app: sensor-gen\n  template:\n    metadata:\n      name: sensor-gen\n      labels:\n        app: sensor-gen\n    spec:\n      containers:\n      - name: sensor-gen\n        image: huanphan/sensor-simulator:0.2\n        ports:\n        - containerPort: 9090\n        volumeMounts:\n        - name: sensor-config\n          mountPath: /SimulateSensor/config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: sensor-config\n        configMap:\n          name: sensor-config\n          items:\n          - key: config.cfg\n            path: config.cfg\n",
    "errors": []
  },
  {
    "id": "04599",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: sensor-gen\n  namespace: kube-system\nspec:\n  replicas: 1\n  selector:\n    app: sensor-gen\n  template:\n    metadata:\n      name: sensor-gen\n      labels:\n        app: sensor-gen\n    spec:\n      containers:\n      - name: sensor-gen\n        image: huanphan/sensor-simulator:0.2\n        ports:\n        - containerPort: 9090\n        volumeMounts:\n        - name: sensor-config\n          mountPath: /SimulateSensor/config\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: sensor-config\n        configMap:\n          name: sensor-config\n          items:\n          - key: config.cfg\n            path: config.cfg\n",
    "errors": []
  },
  {
    "id": "04600",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4805\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04601",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4805\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04602",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4805\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04603",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4805\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04604",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4805\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04605",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: example\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04606",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: example\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04607",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: example\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04608",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: example\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04609",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: transmission\n  labels:\n    app.kubernetes.io/name: transmission\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: transmission\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: transmission\n    spec:\n      containers:\n      - name: transmission\n        image: ghcr.io/k8s-at-home/transmission:v3.00\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 50m\n            memory: 50Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        ports:\n        - name: gui-port\n          protocol: TCP\n          containerPort: 9091\n        - name: tcp-port\n          protocol: TCP\n          containerPort: 51413\n        - name: udp-port\n          protocol: UDP\n          containerPort: 51413\n        volumeMounts:\n        - name: transmission-configs\n          mountPath: /config/settings.json\n          subPath: settings.json\n        - name: transmission-config\n          mountPath: /config\n        - name: transmission-downloads\n          mountPath: /downloads\n        livenessProbe:\n          tcpSocket:\n            port: tcp-port\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        readinessProbe:\n          tcpSocket:\n            port: tcp-port\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        env:\n        - name: TZ\n          value: ${CONFIG_TIMEZONE}\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      securityContext:\n        runAsUser: 1000\n        runAsGroup: 1000\n        fsGroup: 1000\n        fsGroupChangePolicy: OnRootMismatch\n      volumes:\n      - name: transmission-configs\n        configMap:\n          name: transmission-configs\n      - name: transmission-config\n        persistentVolumeClaim:\n          claimName: transmission-config\n      - name: transmission-downloads\n        persistentVolumeClaim:\n          claimName: shared-downloads\n",
    "errors": []
  },
  {
    "id": "04610",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: transmission\n  labels:\n    app.kubernetes.io/name: transmission\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: transmission\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: transmission\n    spec:\n      containers:\n      - name: transmission\n        image: ghcr.io/k8s-at-home/transmission:v3.00\n        imagePullPolicy: IfNotPresent\n        resources:\n          requests:\n            cpu: 50m\n            memory: 50Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        ports:\n        - name: gui-port\n          protocol: TCP\n          containerPort: 9091\n        - name: tcp-port\n          protocol: TCP\n          containerPort: 51413\n        - name: udp-port\n          protocol: UDP\n          containerPort: 51413\n        volumeMounts:\n        - name: transmission-configs\n          mountPath: /config/settings.json\n          subPath: settings.json\n        - name: transmission-config\n          mountPath: /config\n        - name: transmission-downloads\n          mountPath: /downloads\n        livenessProbe:\n          tcpSocket:\n            port: tcp-port\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        readinessProbe:\n          tcpSocket:\n            port: tcp-port\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n          periodSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        env:\n        - name: TZ\n          value: ${CONFIG_TIMEZONE}\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      securityContext:\n        runAsUser: 1000\n        runAsGroup: 1000\n        fsGroup: 1000\n        fsGroupChangePolicy: OnRootMismatch\n      volumes:\n      - name: transmission-configs\n        configMap:\n          name: transmission-configs\n      - name: transmission-config\n        persistentVolumeClaim:\n          claimName: transmission-config\n      - name: transmission-downloads\n        persistentVolumeClaim:\n          claimName: shared-downloads\n",
    "errors": []
  },
  {
    "id": "04611",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kube-dns-metrics-bash\n  namespace: kube-system\n  labels:\n    application: kube-dns-metrics-bash\n    version: v0.0.4\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      application: kube-dns-metrics-bash\n  template:\n    metadata:\n      labels:\n        application: kube-dns-metrics-bash\n        version: v0.0.4\n    spec:\n      containers:\n      - image: pierone.stups.zalan.do/teapot/kube-dns-metrics-bash:v0.0.5\n        name: kube-dns-metrics-bash\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 25m\n            memory: 100Mi\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n        ports:\n        - containerPort: 8080\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04612",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kube-dns-metrics-bash\n  namespace: kube-system\n  labels:\n    application: kube-dns-metrics-bash\n    version: v0.0.4\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      application: kube-dns-metrics-bash\n  template:\n    metadata:\n      labels:\n        application: kube-dns-metrics-bash\n        version: v0.0.4\n    spec:\n      containers:\n      - image: pierone.stups.zalan.do/teapot/kube-dns-metrics-bash:v0.0.5\n        name: kube-dns-metrics-bash\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 25m\n            memory: 100Mi\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n            scheme: HTTP\n          initialDelaySeconds: 10\n          timeoutSeconds: 3\n        ports:\n        - containerPort: 8080\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04613",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"redis-master\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"redis-master-volume\""
    ]
  },
  {
    "id": "04614",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"redis-master\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"redis-master-volume\""
    ]
  },
  {
    "id": "04615",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"redis-master\" is invalid: spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"redis-master-volume\""
    ]
  },
  {
    "id": "04616",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: kuard\n  name: kuard\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      run: kuard\n  template:\n    metadata:\n      labels:\n        run: kuard\n    spec:\n      containers:\n      - image: gcr.io/kuar-demo/kuard-amd64:blue\n        name: kuard\n        resources:\n          limits:\n            cpu: 50m\n            memory: 0.1G\n          requests:\n            cpu: 50m\n            memory: 0.1G\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04617",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: kuard\n  name: kuard\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      run: kuard\n  template:\n    metadata:\n      labels:\n        run: kuard\n    spec:\n      containers:\n      - image: gcr.io/kuar-demo/kuard-amd64:blue\n        name: kuard\n        resources:\n          limits:\n            cpu: 50m\n            memory: 0.1G\n          requests:\n            cpu: 50m\n            memory: 0.1G\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04618",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    kustomize.component: iap-ingress\n  name: iap-enabler\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      kustomize.component: iap-ingress\n  template:\n    metadata:\n      labels:\n        kustomize.component: iap-ingress\n        service: iap-enabler\n    spec:\n      containers:\n      - command:\n        - bash\n        - /var/envoy-config/setup_backend.sh\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/run/secrets/sa/admin-gcp-sa.json\n        - name: NAMESPACE\n          value: istio-system\n        - name: SERVICE\n          value: istio-ingressgateway\n        - name: INGRESS_NAME\n          value: envoy-ingress\n        - name: ENVOY_ADMIN\n          value: http://localhost:8001\n        - name: USE_ISTIO\n          value: 'true'\n        image: gcr.io/kubeflow-images-public/ingress-setup:stable\n        name: iap\n        volumeMounts:\n        - mountPath: /var/run/secrets/sa\n          name: sa-key\n          readOnly: true\n        - mountPath: /var/envoy-config/\n          name: config-volume\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: kf-admin\n      volumes:\n      - name: sa-key\n        secret:\n          secretName: admin-gcp-sa\n      - configMap:\n          name: envoy-config\n        name: config-volume\n",
    "errors": []
  },
  {
    "id": "04619",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    kustomize.component: iap-ingress\n  name: iap-enabler\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      kustomize.component: iap-ingress\n  template:\n    metadata:\n      labels:\n        kustomize.component: iap-ingress\n        service: iap-enabler\n    spec:\n      containers:\n      - command:\n        - bash\n        - /var/envoy-config/setup_backend.sh\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/run/secrets/sa/admin-gcp-sa.json\n        - name: NAMESPACE\n          value: istio-system\n        - name: SERVICE\n          value: istio-ingressgateway\n        - name: INGRESS_NAME\n          value: envoy-ingress\n        - name: ENVOY_ADMIN\n          value: http://localhost:8001\n        - name: USE_ISTIO\n          value: 'true'\n        image: gcr.io/kubeflow-images-public/ingress-setup:stable\n        name: iap\n        volumeMounts:\n        - mountPath: /var/run/secrets/sa\n          name: sa-key\n          readOnly: true\n        - mountPath: /var/envoy-config/\n          name: config-volume\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: kf-admin\n      volumes:\n      - name: sa-key\n        secret:\n          secretName: admin-gcp-sa\n      - configMap:\n          name: envoy-config\n        name: config-volume\n",
    "errors": []
  },
  {
    "id": "04620",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    kustomize.component: iap-ingress\n  name: iap-enabler\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      kustomize.component: iap-ingress\n  template:\n    metadata:\n      labels:\n        kustomize.component: iap-ingress\n        service: iap-enabler\n    spec:\n      containers:\n      - command:\n        - bash\n        - /var/envoy-config/setup_backend.sh\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/run/secrets/sa/admin-gcp-sa.json\n        - name: NAMESPACE\n          value: istio-system\n        - name: SERVICE\n          value: istio-ingressgateway\n        - name: INGRESS_NAME\n          value: envoy-ingress\n        - name: ENVOY_ADMIN\n          value: http://localhost:8001\n        - name: USE_ISTIO\n          value: 'true'\n        image: gcr.io/kubeflow-images-public/ingress-setup:stable\n        name: iap\n        volumeMounts:\n        - mountPath: /var/run/secrets/sa\n          name: sa-key\n          readOnly: true\n        - mountPath: /var/envoy-config/\n          name: config-volume\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: kf-admin\n      volumes:\n      - name: sa-key\n        secret:\n          secretName: admin-gcp-sa\n      - configMap:\n          name: envoy-config\n        name: config-volume\n",
    "errors": []
  },
  {
    "id": "04621",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    kustomize.component: iap-ingress\n  name: iap-enabler\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      kustomize.component: iap-ingress\n  template:\n    metadata:\n      labels:\n        kustomize.component: iap-ingress\n        service: iap-enabler\n    spec:\n      containers:\n      - command:\n        - bash\n        - /var/envoy-config/setup_backend.sh\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/run/secrets/sa/admin-gcp-sa.json\n        - name: NAMESPACE\n          value: istio-system\n        - name: SERVICE\n          value: istio-ingressgateway\n        - name: INGRESS_NAME\n          value: envoy-ingress\n        - name: ENVOY_ADMIN\n          value: http://localhost:8001\n        - name: USE_ISTIO\n          value: 'true'\n        image: gcr.io/kubeflow-images-public/ingress-setup:stable\n        name: iap\n        volumeMounts:\n        - mountPath: /var/run/secrets/sa\n          name: sa-key\n          readOnly: true\n        - mountPath: /var/envoy-config/\n          name: config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      serviceAccountName: kf-admin\n      volumes:\n      - name: sa-key\n        secret:\n          secretName: admin-gcp-sa\n      - configMap:\n          name: envoy-config\n        name: config-volume\n",
    "errors": []
  },
  {
    "id": "04622",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    kustomize.component: iap-ingress\n  name: iap-enabler\n  namespace: kubeflow\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      kustomize.component: iap-ingress\n  template:\n    metadata:\n      labels:\n        kustomize.component: iap-ingress\n        service: iap-enabler\n    spec:\n      containers:\n      - command:\n        - bash\n        - /var/envoy-config/setup_backend.sh\n        env:\n        - name: GOOGLE_APPLICATION_CREDENTIALS\n          value: /var/run/secrets/sa/admin-gcp-sa.json\n        - name: NAMESPACE\n          value: istio-system\n        - name: SERVICE\n          value: istio-ingressgateway\n        - name: INGRESS_NAME\n          value: envoy-ingress\n        - name: ENVOY_ADMIN\n          value: http://localhost:8001\n        - name: USE_ISTIO\n          value: 'true'\n        image: gcr.io/kubeflow-images-public/ingress-setup:stable\n        name: iap\n        volumeMounts:\n        - mountPath: /var/run/secrets/sa\n          name: sa-key\n          readOnly: true\n        - mountPath: /var/envoy-config/\n          name: config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      serviceAccountName: kf-admin\n      volumes:\n      - name: sa-key\n        secret:\n          secretName: admin-gcp-sa\n      - configMap:\n          name: envoy-config\n        name: config-volume\n",
    "errors": []
  },
  {
    "id": "04623",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9619\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04624",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9619\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04625",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9619\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04626",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9619\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04627",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9619\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04628",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: packageserver\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: packageserver\n  template:\n    metadata:\n      labels:\n        app: packageserver\n        hypershift.openshift.io/control-plane-component: packageserver\n    spec:\n      containers:\n      - name: socks5-proxy\n        command:\n        - /usr/bin/konnectivity-socks5-proxy\n        args:\n        - run\n        image: SOCKS5_PROXY_IMAGE:stable\n        env:\n        - name: KUBECONFIG\n          value: /etc/openshift/kubeconfig/kubeconfig\n        ports:\n        - containerPort: 8090\n        volumeMounts:\n        - mountPath: /etc/konnectivity-proxy-tls\n          name: oas-konnectivity-proxy-cert\n          readOnly: true\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - command:\n        - /bin/package-server\n        - -v=4\n        - --secure-port\n        - '5443'\n        - --global-namespace\n        - openshift-marketplace\n        - --kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authentication-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authorization-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        env:\n        - name: OPERATOR_CONDITION_NAME\n          value: packageserver\n        - name: GRPC_PROXY\n          value: socks5://127.0.0.1:8090\n        - name: NO_PROXY\n          value: kube-apiserver,redhat-operators,certified-operators,community-operators,redhat-marketplace\n        image: OLM_OPERATOR_IMAGE:stable\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: packageserver\n        ports:\n        - containerPort: 5443\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmpfs\n        - mountPath: /apiserver.local.config/certificates\n          name: apiservice-cert\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: webhook-cert\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      securityContext: {}\n      volumes:\n      - emptyDir: {}\n        name: tmpfs\n      - name: apiservice-cert\n        secret:\n          defaultMode: 420\n          items:\n          - key: tls.crt\n            path: apiserver.crt\n          - key: tls.key\n            path: apiserver.key\n          secretName: packageserver-cert\n      - name: webhook-cert\n        secret:\n          defaultMode: 420\n          secretName: packageserver-cert\n      - name: kubeconfig\n        secret:\n          secretName: service-network-admin-kubeconfig\n      - name: oas-konnectivity-proxy-cert\n        secret:\n          secretName: konnectivity-client\n",
    "errors": []
  },
  {
    "id": "04629",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: packageserver\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: packageserver\n  template:\n    metadata:\n      labels:\n        app: packageserver\n        hypershift.openshift.io/control-plane-component: packageserver\n    spec:\n      containers:\n      - name: socks5-proxy\n        command:\n        - /usr/bin/konnectivity-socks5-proxy\n        args:\n        - run\n        image: SOCKS5_PROXY_IMAGE:stable\n        env:\n        - name: KUBECONFIG\n          value: /etc/openshift/kubeconfig/kubeconfig\n        ports:\n        - containerPort: 8090\n        volumeMounts:\n        - mountPath: /etc/konnectivity-proxy-tls\n          name: oas-konnectivity-proxy-cert\n          readOnly: true\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - command:\n        - /bin/package-server\n        - -v=4\n        - --secure-port\n        - '5443'\n        - --global-namespace\n        - openshift-marketplace\n        - --kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authentication-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authorization-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        env:\n        - name: OPERATOR_CONDITION_NAME\n          value: packageserver\n        - name: GRPC_PROXY\n          value: socks5://127.0.0.1:8090\n        - name: NO_PROXY\n          value: kube-apiserver,redhat-operators,certified-operators,community-operators,redhat-marketplace\n        image: OLM_OPERATOR_IMAGE:stable\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: packageserver\n        ports:\n        - containerPort: 5443\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmpfs\n        - mountPath: /apiserver.local.config/certificates\n          name: apiservice-cert\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: webhook-cert\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      securityContext: {}\n      volumes:\n      - emptyDir: {}\n        name: tmpfs\n      - name: apiservice-cert\n        secret:\n          defaultMode: 420\n          items:\n          - key: tls.crt\n            path: apiserver.crt\n          - key: tls.key\n            path: apiserver.key\n          secretName: packageserver-cert\n      - name: webhook-cert\n        secret:\n          defaultMode: 420\n          secretName: packageserver-cert\n      - name: kubeconfig\n        secret:\n          secretName: service-network-admin-kubeconfig\n      - name: oas-konnectivity-proxy-cert\n        secret:\n          secretName: konnectivity-client\n",
    "errors": []
  },
  {
    "id": "04630",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: packageserver\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: packageserver\n  template:\n    metadata:\n      labels:\n        app: packageserver\n        hypershift.openshift.io/control-plane-component: packageserver\n    spec:\n      containers:\n      - name: socks5-proxy\n        command:\n        - /usr/bin/konnectivity-socks5-proxy\n        args:\n        - run\n        image: SOCKS5_PROXY_IMAGE:stable\n        env:\n        - name: KUBECONFIG\n          value: /etc/openshift/kubeconfig/kubeconfig\n        ports:\n        - containerPort: 8090\n        volumeMounts:\n        - mountPath: /etc/konnectivity-proxy-tls\n          name: oas-konnectivity-proxy-cert\n          readOnly: true\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - command:\n        - /bin/package-server\n        - -v=4\n        - --secure-port\n        - '5443'\n        - --global-namespace\n        - openshift-marketplace\n        - --kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authentication-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authorization-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        env:\n        - name: OPERATOR_CONDITION_NAME\n          value: packageserver\n        - name: GRPC_PROXY\n          value: socks5://127.0.0.1:8090\n        - name: NO_PROXY\n          value: kube-apiserver,redhat-operators,certified-operators,community-operators,redhat-marketplace\n        image: OLM_OPERATOR_IMAGE:stable\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: packageserver\n        ports:\n        - containerPort: 5443\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmpfs\n        - mountPath: /apiserver.local.config/certificates\n          name: apiservice-cert\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: webhook-cert\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      securityContext: {}\n      volumes:\n      - emptyDir: {}\n        name: tmpfs\n      - name: apiservice-cert\n        secret:\n          defaultMode: 420\n          items:\n          - key: tls.crt\n            path: apiserver.crt\n          - key: tls.key\n            path: apiserver.key\n          secretName: packageserver-cert\n      - name: webhook-cert\n        secret:\n          defaultMode: 420\n          secretName: packageserver-cert\n      - name: kubeconfig\n        secret:\n          secretName: service-network-admin-kubeconfig\n      - name: oas-konnectivity-proxy-cert\n        secret:\n          secretName: konnectivity-client\n",
    "errors": []
  },
  {
    "id": "04631",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: packageserver\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: packageserver\n  template:\n    metadata:\n      labels:\n        app: packageserver\n        hypershift.openshift.io/control-plane-component: packageserver\n    spec:\n      containers:\n      - name: socks5-proxy\n        command:\n        - /usr/bin/konnectivity-socks5-proxy\n        args:\n        - run\n        image: SOCKS5_PROXY_IMAGE:stable\n        env:\n        - name: KUBECONFIG\n          value: /etc/openshift/kubeconfig/kubeconfig\n        ports:\n        - containerPort: 8090\n        volumeMounts:\n        - mountPath: /etc/konnectivity-proxy-tls\n          name: oas-konnectivity-proxy-cert\n          readOnly: true\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - command:\n        - /bin/package-server\n        - -v=4\n        - --secure-port\n        - '5443'\n        - --global-namespace\n        - openshift-marketplace\n        - --kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authentication-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authorization-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        env:\n        - name: OPERATOR_CONDITION_NAME\n          value: packageserver\n        - name: GRPC_PROXY\n          value: socks5://127.0.0.1:8090\n        - name: NO_PROXY\n          value: kube-apiserver,redhat-operators,certified-operators,community-operators,redhat-marketplace\n        image: OLM_OPERATOR_IMAGE:stable\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: packageserver\n        ports:\n        - containerPort: 5443\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmpfs\n        - mountPath: /apiserver.local.config/certificates\n          name: apiservice-cert\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: webhook-cert\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      securityContext: {}\n      volumes:\n      - emptyDir: {}\n        name: tmpfs\n      - name: apiservice-cert\n        secret:\n          defaultMode: 420\n          items:\n          - key: tls.crt\n            path: apiserver.crt\n          - key: tls.key\n            path: apiserver.key\n          secretName: packageserver-cert\n      - name: webhook-cert\n        secret:\n          defaultMode: 420\n          secretName: packageserver-cert\n      - name: kubeconfig\n        secret:\n          secretName: service-network-admin-kubeconfig\n      - name: oas-konnectivity-proxy-cert\n        secret:\n          secretName: konnectivity-client\n",
    "errors": []
  },
  {
    "id": "04632",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: packageserver\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: packageserver\n  template:\n    metadata:\n      labels:\n        app: packageserver\n        hypershift.openshift.io/control-plane-component: packageserver\n    spec:\n      containers:\n      - name: socks5-proxy\n        command:\n        - /usr/bin/konnectivity-socks5-proxy\n        args:\n        - run\n        image: SOCKS5_PROXY_IMAGE:stable\n        env:\n        - name: KUBECONFIG\n          value: /etc/openshift/kubeconfig/kubeconfig\n        ports:\n        - containerPort: 8090\n        volumeMounts:\n        - mountPath: /etc/konnectivity-proxy-tls\n          name: oas-konnectivity-proxy-cert\n          readOnly: true\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - command:\n        - /bin/package-server\n        - -v=4\n        - --secure-port\n        - '5443'\n        - --global-namespace\n        - openshift-marketplace\n        - --kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authentication-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authorization-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        env:\n        - name: OPERATOR_CONDITION_NAME\n          value: packageserver\n        - name: GRPC_PROXY\n          value: socks5://127.0.0.1:8090\n        - name: NO_PROXY\n          value: kube-apiserver,redhat-operators,certified-operators,community-operators,redhat-marketplace\n        image: OLM_OPERATOR_IMAGE:stable\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: packageserver\n        ports:\n        - containerPort: 5443\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmpfs\n        - mountPath: /apiserver.local.config/certificates\n          name: apiservice-cert\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: webhook-cert\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      securityContext: {}\n      volumes:\n      - emptyDir: {}\n        name: tmpfs\n      - name: apiservice-cert\n        secret:\n          defaultMode: 420\n          items:\n          - key: tls.crt\n            path: apiserver.crt\n          - key: tls.key\n            path: apiserver.key\n          secretName: packageserver-cert\n      - name: webhook-cert\n        secret:\n          defaultMode: 420\n          secretName: packageserver-cert\n      - name: kubeconfig\n        secret:\n          secretName: service-network-admin-kubeconfig\n      - name: oas-konnectivity-proxy-cert\n        secret:\n          secretName: konnectivity-client\n",
    "errors": []
  },
  {
    "id": "04633",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: packageserver\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: packageserver\n  template:\n    metadata:\n      labels:\n        app: packageserver\n        hypershift.openshift.io/control-plane-component: packageserver\n    spec:\n      containers:\n      - name: socks5-proxy\n        command:\n        - /usr/bin/konnectivity-socks5-proxy\n        args:\n        - run\n        image: SOCKS5_PROXY_IMAGE:stable\n        env:\n        - name: KUBECONFIG\n          value: /etc/openshift/kubeconfig/kubeconfig\n        ports:\n        - containerPort: 8090\n        volumeMounts:\n        - mountPath: /etc/konnectivity-proxy-tls\n          name: oas-konnectivity-proxy-cert\n          readOnly: true\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - command:\n        - /bin/package-server\n        - -v=4\n        - --secure-port\n        - '5443'\n        - --global-namespace\n        - openshift-marketplace\n        - --kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authentication-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authorization-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        env:\n        - name: OPERATOR_CONDITION_NAME\n          value: packageserver\n        - name: GRPC_PROXY\n          value: socks5://127.0.0.1:8090\n        - name: NO_PROXY\n          value: kube-apiserver,redhat-operators,certified-operators,community-operators,redhat-marketplace\n        image: OLM_OPERATOR_IMAGE:stable\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: packageserver\n        ports:\n        - containerPort: 5443\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmpfs\n        - mountPath: /apiserver.local.config/certificates\n          name: apiservice-cert\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: webhook-cert\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      securityContext: {}\n      volumes:\n      - emptyDir: {}\n        name: tmpfs\n      - name: apiservice-cert\n        secret:\n          defaultMode: 420\n          items:\n          - key: tls.crt\n            path: apiserver.crt\n          - key: tls.key\n            path: apiserver.key\n          secretName: packageserver-cert\n      - name: webhook-cert\n        secret:\n          defaultMode: 420\n          secretName: packageserver-cert\n      - name: kubeconfig\n        secret:\n          secretName: service-network-admin-kubeconfig\n      - name: oas-konnectivity-proxy-cert\n        secret:\n          secretName: konnectivity-client\n",
    "errors": []
  },
  {
    "id": "04634",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: packageserver\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: packageserver\n  template:\n    metadata:\n      labels:\n        app: packageserver\n        hypershift.openshift.io/control-plane-component: packageserver\n    spec:\n      containers:\n      - name: socks5-proxy\n        command:\n        - /usr/bin/konnectivity-socks5-proxy\n        args:\n        - run\n        image: SOCKS5_PROXY_IMAGE:stable\n        env:\n        - name: KUBECONFIG\n          value: /etc/openshift/kubeconfig/kubeconfig\n        ports:\n        - containerPort: 8090\n        volumeMounts:\n        - mountPath: /etc/konnectivity-proxy-tls\n          name: oas-konnectivity-proxy-cert\n          readOnly: true\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - command:\n        - /bin/package-server\n        - -v=4\n        - --secure-port\n        - '5443'\n        - --global-namespace\n        - openshift-marketplace\n        - --kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authentication-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authorization-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        env:\n        - name: OPERATOR_CONDITION_NAME\n          value: packageserver\n        - name: GRPC_PROXY\n          value: socks5://127.0.0.1:8090\n        - name: NO_PROXY\n          value: kube-apiserver,redhat-operators,certified-operators,community-operators,redhat-marketplace\n        image: OLM_OPERATOR_IMAGE:stable\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: packageserver\n        ports:\n        - containerPort: 5443\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmpfs\n        - mountPath: /apiserver.local.config/certificates\n          name: apiservice-cert\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: webhook-cert\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      securityContext: {}\n      volumes:\n      - emptyDir: {}\n        name: tmpfs\n      - name: apiservice-cert\n        secret:\n          defaultMode: 420\n          items:\n          - key: tls.crt\n            path: apiserver.crt\n          - key: tls.key\n            path: apiserver.key\n          secretName: packageserver-cert\n      - name: webhook-cert\n        secret:\n          defaultMode: 420\n          secretName: packageserver-cert\n      - name: kubeconfig\n        secret:\n          secretName: service-network-admin-kubeconfig\n      - name: oas-konnectivity-proxy-cert\n        secret:\n          secretName: konnectivity-client\n",
    "errors": []
  },
  {
    "id": "04635",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: packageserver\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: packageserver\n  template:\n    metadata:\n      labels:\n        app: packageserver\n        hypershift.openshift.io/control-plane-component: packageserver\n    spec:\n      containers:\n      - name: socks5-proxy\n        command:\n        - /usr/bin/konnectivity-socks5-proxy\n        args:\n        - run\n        image: SOCKS5_PROXY_IMAGE:stable\n        env:\n        - name: KUBECONFIG\n          value: /etc/openshift/kubeconfig/kubeconfig\n        ports:\n        - containerPort: 8090\n        volumeMounts:\n        - mountPath: /etc/konnectivity-proxy-tls\n          name: oas-konnectivity-proxy-cert\n          readOnly: true\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - command:\n        - /bin/package-server\n        - -v=4\n        - --secure-port\n        - '5443'\n        - --global-namespace\n        - openshift-marketplace\n        - --kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authentication-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authorization-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        env:\n        - name: OPERATOR_CONDITION_NAME\n          value: packageserver\n        - name: GRPC_PROXY\n          value: socks5://127.0.0.1:8090\n        - name: NO_PROXY\n          value: kube-apiserver,redhat-operators,certified-operators,community-operators,redhat-marketplace\n        image: OLM_OPERATOR_IMAGE:stable\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: packageserver\n        ports:\n        - containerPort: 5443\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmpfs\n        - mountPath: /apiserver.local.config/certificates\n          name: apiservice-cert\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: webhook-cert\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      securityContext: {}\n      volumes:\n      - emptyDir: {}\n        name: tmpfs\n      - name: apiservice-cert\n        secret:\n          defaultMode: 420\n          items:\n          - key: tls.crt\n            path: apiserver.crt\n          - key: tls.key\n            path: apiserver.key\n          secretName: packageserver-cert\n      - name: webhook-cert\n        secret:\n          defaultMode: 420\n          secretName: packageserver-cert\n      - name: kubeconfig\n        secret:\n          secretName: service-network-admin-kubeconfig\n      - name: oas-konnectivity-proxy-cert\n        secret:\n          secretName: konnectivity-client\n",
    "errors": []
  },
  {
    "id": "04636",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: packageserver\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: packageserver\n  template:\n    metadata:\n      labels:\n        app: packageserver\n        hypershift.openshift.io/control-plane-component: packageserver\n    spec:\n      containers:\n      - name: socks5-proxy\n        command:\n        - /usr/bin/konnectivity-socks5-proxy\n        args:\n        - run\n        image: SOCKS5_PROXY_IMAGE:stable\n        env:\n        - name: KUBECONFIG\n          value: /etc/openshift/kubeconfig/kubeconfig\n        ports:\n        - containerPort: 8090\n        volumeMounts:\n        - mountPath: /etc/konnectivity-proxy-tls\n          name: oas-konnectivity-proxy-cert\n          readOnly: true\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - command:\n        - /bin/package-server\n        - -v=4\n        - --secure-port\n        - '5443'\n        - --global-namespace\n        - openshift-marketplace\n        - --kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authentication-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        - --authorization-kubeconfig\n        - /etc/openshift/kubeconfig/kubeconfig\n        env:\n        - name: OPERATOR_CONDITION_NAME\n          value: packageserver\n        - name: GRPC_PROXY\n          value: socks5://127.0.0.1:8090\n        - name: NO_PROXY\n          value: kube-apiserver,redhat-operators,certified-operators,community-operators,redhat-marketplace\n        image: OLM_OPERATOR_IMAGE:stable\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: packageserver\n        ports:\n        - containerPort: 5443\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 5443\n            scheme: HTTPS\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 10m\n            memory: 70Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        volumeMounts:\n        - mountPath: /tmp\n          name: tmpfs\n        - mountPath: /apiserver.local.config/certificates\n          name: apiservice-cert\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: webhook-cert\n        - mountPath: /etc/openshift/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      securityContext: {}\n      volumes:\n      - emptyDir: {}\n        name: tmpfs\n      - name: apiservice-cert\n        secret:\n          defaultMode: 420\n          items:\n          - key: tls.crt\n            path: apiserver.crt\n          - key: tls.key\n            path: apiserver.key\n          secretName: packageserver-cert\n      - name: webhook-cert\n        secret:\n          defaultMode: 420\n          secretName: packageserver-cert\n      - name: kubeconfig\n        secret:\n          secretName: service-network-admin-kubeconfig\n      - name: oas-konnectivity-proxy-cert\n        secret:\n          secretName: konnectivity-client\n",
    "errors": []
  },
  {
    "id": "04637",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello\nspec:\n  containers:\n  - name: hello\n    image: raelga/hello:stable\n    resources:\n      limits:\n        cpu: 50m\n        memory: 0.1G\n      requests:\n        cpu: 50m\n        memory: 0.1G\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04638",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello\nspec:\n  containers:\n  - name: hello\n    image: raelga/hello:stable\n    resources:\n      limits:\n        cpu: 50m\n        memory: 0.1G\n      requests:\n        cpu: 50m\n        memory: 0.1G\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04639",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello\nspec:\n  containers:\n  - name: hello\n    image: raelga/hello:stable\n    resources:\n      limits:\n        cpu: 50m\n        memory: 0.1G\n      requests:\n        cpu: 50m\n        memory: 0.1G\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04640",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\n  namespace: workshop-303\nspec:\n  containers:\n  - name: first-container\n    image: fedora:29\n    command:\n    - sleep\n    - '36000'\n    env:\n    - name: SECRET_USERNAME\n      valueFrom:\n        secretKeyRef:\n          name: my-secret\n          key: username\n    - name: SECRET_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: my-secret\n          key: password\n    volumeMounts:\n    - name: my-configmap\n      mountPath: /config\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: my-configmap\n    configMap:\n      name: my-configmap\n",
    "errors": []
  },
  {
    "id": "04641",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\n  namespace: workshop-303\nspec:\n  containers:\n  - name: first-container\n    image: fedora:29\n    command:\n    - sleep\n    - '36000'\n    env:\n    - name: SECRET_USERNAME\n      valueFrom:\n        secretKeyRef:\n          name: my-secret\n          key: username\n    - name: SECRET_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: my-secret\n          key: password\n    volumeMounts:\n    - name: my-configmap\n      mountPath: /config\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: my-configmap\n    configMap:\n      name: my-configmap\n",
    "errors": []
  },
  {
    "id": "04642",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\n  namespace: workshop-303\nspec:\n  containers:\n  - name: first-container\n    image: fedora:29\n    command:\n    - sleep\n    - '36000'\n    env:\n    - name: SECRET_USERNAME\n      valueFrom:\n        secretKeyRef:\n          name: my-secret\n          key: username\n    - name: SECRET_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: my-secret\n          key: password\n    volumeMounts:\n    - name: my-configmap\n      mountPath: /config\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  volumes:\n  - name: my-configmap\n    configMap:\n      name: my-configmap\n",
    "errors": []
  },
  {
    "id": "04643",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\n  namespace: workshop-303\nspec:\n  containers:\n  - name: first-container\n    image: fedora:29\n    command:\n    - sleep\n    - '36000'\n    env:\n    - name: SECRET_USERNAME\n      valueFrom:\n        secretKeyRef:\n          name: my-secret\n          key: username\n    - name: SECRET_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: my-secret\n          key: password\n    volumeMounts:\n    - name: my-configmap\n      mountPath: /config\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  volumes:\n  - name: my-configmap\n    configMap:\n      name: my-configmap\n",
    "errors": []
  },
  {
    "id": "04644",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: selenium-node-chrome\n  namespace: selenium\n  labels:\n    app: selenium-node\n    browser: chrome\nspec:\n  selector:\n    matchLabels:\n      app: selenium-node\n      browser: chrome\n  template:\n    metadata:\n      labels:\n        app: selenium-node\n        browser: chrome\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: cloud.google.com/gke-preemptible\n                operator: DoesNotExist\n              - key: eks.amazonaws.com/capacityType\n                operator: NotIn\n                values:\n                - SPOT\n              - key: kubernetes.azure.com/scalesetpriority\n                operator: NotIn\n                values:\n                - spot\n      securityContext:\n        runAsNonRoot: true\n      containers:\n      - name: selenium-node-chrome\n        image: selenium/node-chrome:90.0\n        ports:\n        - containerPort: 5555\n        - containerPort: 5900\n        - containerPort: 7900\n        env:\n        - name: JAVA_OPTS\n          value: -Xmx512m -Dselenium.LOGGER.level=WARNING\n        - name: SE_OPTS\n          value: ''\n        - name: SE_EVENT_BUS_HOST\n          value: selenium-hub\n        - name: SE_EVENT_BUS_PUBLISH_PORT\n          value: '4442'\n        - name: SE_EVENT_BUS_SUBSCRIBE_PORT\n          value: '4443'\n        - name: VNC_NO_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: vnc-no-password-secret\n              key: vnc_no_password\n        readinessProbe:\n          httpGet:\n            path: /status\n            port: 5555\n          initialDelaySeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /status\n            port: 5555\n          initialDelaySeconds: 30\n        resources:\n          limits:\n            cpu: 500m\n            memory: 1Gi\n          requests:\n            cpu: 300m\n            memory: 615Mi\n        volumeMounts:\n        - name: dshm\n          mountPath: /dev/shm\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n",
    "errors": []
  },
  {
    "id": "04645",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20200409-becd20a71\n        args:\n        - --github-workers=5\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --slack-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --gcs-workers=1\n        - --kubernetes-gcs-workers=1\n        - --kubeconfig=/etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "errors": []
  },
  {
    "id": "04646",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20200409-becd20a71\n        args:\n        - --github-workers=5\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --slack-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --gcs-workers=1\n        - --kubernetes-gcs-workers=1\n        - --kubeconfig=/etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "errors": []
  },
  {
    "id": "04647",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20200409-becd20a71\n        args:\n        - --github-workers=5\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --slack-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --gcs-workers=1\n        - --kubernetes-gcs-workers=1\n        - --kubeconfig=/etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "errors": []
  },
  {
    "id": "04648",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: crier\n  labels:\n    app: crier\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crier\n  template:\n    metadata:\n      labels:\n        app: crier\n    spec:\n      serviceAccountName: crier\n      containers:\n      - name: crier\n        image: gcr.io/k8s-prow/crier:v20200409-becd20a71\n        args:\n        - --github-workers=5\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --slack-workers=1\n        - --slack-token-file=/etc/slack/token\n        - --gcs-workers=1\n        - --kubernetes-gcs-workers=1\n        - --kubeconfig=/etc/kubeconfig/config\n        volumeMounts:\n        - mountPath: /etc/kubeconfig\n          name: kubeconfig\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: slack\n          mountPath: /etc/slack\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: slack\n        secret:\n          secretName: slack-token\n      - name: kubeconfig\n        secret:\n          defaultMode: 420\n          secretName: kubeconfig\n",
    "errors": []
  },
  {
    "id": "04649",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube2iam\n  namespace: kube-system\n  labels:\n    application: kube2iam\n    version: 0.10.7\nspec:\n  selector:\n    matchLabels:\n      application: kube2iam\n  template:\n    metadata:\n      labels:\n        application: kube2iam\n        version: 0.10.7\n    spec:\n      serviceAccountName: kube2iam\n      containers:\n      - image: registry.opensource.zalan.do/teapot/kube2iam:0.10.7\n        name: kube2iam\n        args:\n        - --auto-discover-base-arn\n        - --verbose\n        - --node=$(NODE_NAME)\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        ports:\n        - containerPort: 8181\n          hostPort: 8181\n          name: http\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8181\n          timeoutSeconds: 3\n        resources:\n          requests:\n            cpu: 25m\n            memory: 100Mi\n            ephemeral-storage: 256Mi\n          limits:\n            cpu: 25m\n            memory: 100Mi\n",
    "errors": []
  },
  {
    "id": "04650",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube2iam\n  namespace: kube-system\n  labels:\n    application: kube2iam\n    version: 0.10.7\nspec:\n  selector:\n    matchLabels:\n      application: kube2iam\n  template:\n    metadata:\n      labels:\n        application: kube2iam\n        version: 0.10.7\n    spec:\n      serviceAccountName: kube2iam\n      containers:\n      - image: registry.opensource.zalan.do/teapot/kube2iam:0.10.7\n        name: kube2iam\n        args:\n        - --auto-discover-base-arn\n        - --verbose\n        - --node=$(NODE_NAME)\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        ports:\n        - containerPort: 8181\n          hostPort: 8181\n          name: http\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8181\n          timeoutSeconds: 3\n        resources:\n          requests:\n            cpu: 25m\n            memory: 100Mi\n            ephemeral-storage: 256Mi\n          limits:\n            cpu: 25m\n            memory: 100Mi\n",
    "errors": []
  },
  {
    "id": "04651",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube2iam\n  namespace: kube-system\n  labels:\n    application: kube2iam\n    version: 0.10.7\nspec:\n  selector:\n    matchLabels:\n      application: kube2iam\n  template:\n    metadata:\n      labels:\n        application: kube2iam\n        version: 0.10.7\n    spec:\n      serviceAccountName: kube2iam\n      containers:\n      - image: registry.opensource.zalan.do/teapot/kube2iam:0.10.7\n        name: kube2iam\n        args:\n        - --auto-discover-base-arn\n        - --verbose\n        - --node=$(NODE_NAME)\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        ports:\n        - containerPort: 8181\n          hostPort: 8181\n          name: http\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8181\n          timeoutSeconds: 3\n        resources:\n          requests:\n            cpu: 25m\n            memory: 100Mi\n            ephemeral-storage: 256Mi\n          limits:\n            cpu: 25m\n            memory: 100Mi\n",
    "errors": []
  },
  {
    "id": "04652",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube2iam\n  namespace: kube-system\n  labels:\n    application: kube2iam\n    version: 0.10.7\nspec:\n  selector:\n    matchLabels:\n      application: kube2iam\n  template:\n    metadata:\n      labels:\n        application: kube2iam\n        version: 0.10.7\n    spec:\n      serviceAccountName: kube2iam\n      containers:\n      - image: registry.opensource.zalan.do/teapot/kube2iam:0.10.7\n        name: kube2iam\n        args:\n        - --auto-discover-base-arn\n        - --verbose\n        - --node=$(NODE_NAME)\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        ports:\n        - containerPort: 8181\n          hostPort: 8181\n          name: http\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8181\n          timeoutSeconds: 3\n        resources:\n          requests:\n            cpu: 25m\n            memory: 100Mi\n            ephemeral-storage: 256Mi\n          limits:\n            cpu: 25m\n            memory: 100Mi\n",
    "errors": []
  },
  {
    "id": "04653",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"web-app\" is invalid: spec.template.metadata.labels: Invalid value: {\"app\":\"myapp\"}: `selector` does not match template `labels`"
    ]
  },
  {
    "id": "04654",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"web-app\" is invalid: spec.template.metadata.labels: Invalid value: {\"app\":\"myapp\"}: `selector` does not match template `labels`"
    ]
  },
  {
    "id": "04655",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"web-app\" is invalid: spec.template.metadata.labels: Invalid value: {\"app\":\"myapp\"}: `selector` does not match template `labels`"
    ]
  },
  {
    "id": "04656",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"web-app\" is invalid: spec.template.metadata.labels: Invalid value: {\"app\":\"myapp\"}: `selector` does not match template `labels`"
    ]
  },
  {
    "id": "04657",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"nvidiaheartbeat\" is invalid: spec.template.metadata.labels: Invalid value: {\"nvidiaheartbeat-node\":\"pod\"}: `selector` does not match template `labels`"
    ]
  },
  {
    "id": "04658",
    "policy_id": "drop_capabilities",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"nvidiaheartbeat\" is invalid: spec.template.metadata.labels: Invalid value: {\"nvidiaheartbeat-node\":\"pod\"}: `selector` does not match template `labels`"
    ]
  },
  {
    "id": "04659",
    "policy_id": "no_privileged",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"nvidiaheartbeat\" is invalid: spec.template.metadata.labels: Invalid value: {\"nvidiaheartbeat-node\":\"pod\"}: `selector` does not match template `labels`"
    ]
  },
  {
    "id": "04660",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"nvidiaheartbeat\" is invalid: spec.template.metadata.labels: Invalid value: {\"nvidiaheartbeat-node\":\"pod\"}: `selector` does not match template `labels`"
    ]
  },
  {
    "id": "04661",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"nvidiaheartbeat\" is invalid: spec.template.metadata.labels: Invalid value: {\"nvidiaheartbeat-node\":\"pod\"}: `selector` does not match template `labels`"
    ]
  },
  {
    "id": "04662",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The DaemonSet \"nvidiaheartbeat\" is invalid: spec.template.metadata.labels: Invalid value: {\"nvidiaheartbeat-node\":\"pod\"}: `selector` does not match template `labels`"
    ]
  },
  {
    "id": "04663",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-8112\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04664",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-8112\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04665",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-8112\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04666",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-8112\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04667",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-8112\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04668",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kube-state-metrics-deployment\n  namespace: monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app: kube-state-metrics\n    spec:\n      containers:\n      - name: kube-state-metrics\n        image: k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0\n        ports:\n        - containerPort: 8080\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04669",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kube-state-metrics-deployment\n  namespace: monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app: kube-state-metrics\n    spec:\n      containers:\n      - name: kube-state-metrics\n        image: k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0\n        ports:\n        - containerPort: 8080\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04670",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kube-state-metrics-deployment\n  namespace: monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app: kube-state-metrics\n    spec:\n      containers:\n      - name: kube-state-metrics\n        image: k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04671",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kube-state-metrics-deployment\n  namespace: monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: kube-state-metrics\n  template:\n    metadata:\n      labels:\n        app: kube-state-metrics\n    spec:\n      containers:\n      - name: kube-state-metrics\n        image: k8s.gcr.io/kube-state-metrics/kube-state-metrics:v2.0.0\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04672",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"controller-manager\" is invalid: \n* spec.template.spec.affinity.nodeAffinity.preferredDuringSchedulingIgnoredDuringExecution[0].preference.matchExpressions[0].key: Invalid value: \"${K8S_CP_LABEL:=node-role.kubernetes.io/control-plane}\": prefix part a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.template.spec.affinity.nodeAffinity.preferredDuringSchedulingIgnoredDuringExecution[0].preference.matchExpressions[0].key: Invalid value: \"${K8S_CP_LABEL:=node-role.kubernetes.io/control-plane}\": name part must consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyName',  or 'my.name',  or '123-abc', regex used for validation is '([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9]')"
    ]
  },
  {
    "id": "04673",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"controller-manager\" is invalid: \n* spec.template.spec.affinity.nodeAffinity.preferredDuringSchedulingIgnoredDuringExecution[0].preference.matchExpressions[0].key: Invalid value: \"${K8S_CP_LABEL:=node-role.kubernetes.io/control-plane}\": prefix part a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.template.spec.affinity.nodeAffinity.preferredDuringSchedulingIgnoredDuringExecution[0].preference.matchExpressions[0].key: Invalid value: \"${K8S_CP_LABEL:=node-role.kubernetes.io/control-plane}\": name part must consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyName',  or 'my.name',  or '123-abc', regex used for validation is '([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9]')"
    ]
  },
  {
    "id": "04674",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"controller-manager\" is invalid: \n* spec.template.spec.affinity.nodeAffinity.preferredDuringSchedulingIgnoredDuringExecution[0].preference.matchExpressions[0].key: Invalid value: \"${K8S_CP_LABEL:=node-role.kubernetes.io/control-plane}\": prefix part a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.template.spec.affinity.nodeAffinity.preferredDuringSchedulingIgnoredDuringExecution[0].preference.matchExpressions[0].key: Invalid value: \"${K8S_CP_LABEL:=node-role.kubernetes.io/control-plane}\": name part must consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyName',  or 'my.name',  or '123-abc', regex used for validation is '([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9]')"
    ]
  },
  {
    "id": "04675",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"controller-manager\" is invalid: \n* spec.template.spec.affinity.nodeAffinity.preferredDuringSchedulingIgnoredDuringExecution[0].preference.matchExpressions[0].key: Invalid value: \"${K8S_CP_LABEL:=node-role.kubernetes.io/control-plane}\": prefix part a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.template.spec.affinity.nodeAffinity.preferredDuringSchedulingIgnoredDuringExecution[0].preference.matchExpressions[0].key: Invalid value: \"${K8S_CP_LABEL:=node-role.kubernetes.io/control-plane}\": name part must consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyName',  or 'my.name',  or '123-abc', regex used for validation is '([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9]')"
    ]
  },
  {
    "id": "04676",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"controller-manager\" is invalid: \n* spec.template.spec.affinity.nodeAffinity.preferredDuringSchedulingIgnoredDuringExecution[0].preference.matchExpressions[0].key: Invalid value: \"${K8S_CP_LABEL:=node-role.kubernetes.io/control-plane}\": prefix part a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')\n* spec.template.spec.affinity.nodeAffinity.preferredDuringSchedulingIgnoredDuringExecution[0].preference.matchExpressions[0].key: Invalid value: \"${K8S_CP_LABEL:=node-role.kubernetes.io/control-plane}\": name part must consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyName',  or 'my.name',  or '123-abc', regex used for validation is '([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9]')"
    ]
  },
  {
    "id": "04677",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: echoheaders-https\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: echoheaders-https\n    spec:\n      containers:\n      - name: echoheaders-https\n        image: gcr.io/google_containers/echoserver:1.10\n        ports:\n        - containerPort: 8080\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04678",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: echoheaders-https\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: echoheaders-https\n    spec:\n      containers:\n      - name: echoheaders-https\n        image: gcr.io/google_containers/echoserver:1.10\n        ports:\n        - containerPort: 8080\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04679",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: echoheaders-https\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: echoheaders-https\n    spec:\n      containers:\n      - name: echoheaders-https\n        image: gcr.io/google_containers/echoserver:1.10\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04680",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: echoheaders-https\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: echoheaders-https\n    spec:\n      containers:\n      - name: echoheaders-https\n        image: gcr.io/google_containers/echoserver:1.10\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04681",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9533\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04682",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9533\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04683",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9533\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04684",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9533\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04685",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9533\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04686",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: aqua-gateway\n  name: aqua-gateway\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: aqua-gateway\n  template:\n    metadata:\n      labels:\n        app: aqua-gateway\n      name: aqua-gateway\n    spec:\n      serviceAccount: aqua-sa\n      containers:\n      - name: aqua-gateway\n        image: registry.aquasec.com/gateway:6.5\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        env:\n        - name: AQUA_CONSOLE_SECURE_ADDRESS\n          value: aqua-web:443\n        - name: SCALOCK_GATEWAY_PUBLIC_IP\n          value: aqua-gateway\n        - name: SCALOCK_DBUSER\n          value: postgres\n        - name: SCALOCK_DBPASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: aqua-db\n        - name: SCALOCK_DBNAME\n          value: scalock\n        - name: SCALOCK_DBHOST\n          value: aqua-db\n        - name: SCALOCK_DBPORT\n          value: '5432'\n        - name: SCALOCK_AUDIT_DBUSER\n          value: postgres\n        - name: SCALOCK_AUDIT_DBPASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: aqua-db\n        - name: SCALOCK_AUDIT_DBNAME\n          value: slk_audit\n        - name: SCALOCK_AUDIT_DBHOST\n          value: aqua-db\n        - name: SCALOCK_AUDIT_DBPORT\n          value: '5432'\n        ports:\n        - containerPort: 3622\n          protocol: TCP\n        - containerPort: 8443\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04687",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: aqua-gateway\n  name: aqua-gateway\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: aqua-gateway\n  template:\n    metadata:\n      labels:\n        app: aqua-gateway\n      name: aqua-gateway\n    spec:\n      serviceAccount: aqua-sa\n      containers:\n      - name: aqua-gateway\n        image: registry.aquasec.com/gateway:6.5\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: AQUA_CONSOLE_SECURE_ADDRESS\n          value: aqua-web:443\n        - name: SCALOCK_GATEWAY_PUBLIC_IP\n          value: aqua-gateway\n        - name: SCALOCK_DBUSER\n          value: postgres\n        - name: SCALOCK_DBPASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: aqua-db\n        - name: SCALOCK_DBNAME\n          value: scalock\n        - name: SCALOCK_DBHOST\n          value: aqua-db\n        - name: SCALOCK_DBPORT\n          value: '5432'\n        - name: SCALOCK_AUDIT_DBUSER\n          value: postgres\n        - name: SCALOCK_AUDIT_DBPASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: aqua-db\n        - name: SCALOCK_AUDIT_DBNAME\n          value: slk_audit\n        - name: SCALOCK_AUDIT_DBHOST\n          value: aqua-db\n        - name: SCALOCK_AUDIT_DBPORT\n          value: '5432'\n        ports:\n        - containerPort: 3622\n          protocol: TCP\n        - containerPort: 8443\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04688",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: aqua-gateway\n  name: aqua-gateway\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: aqua-gateway\n  template:\n    metadata:\n      labels:\n        app: aqua-gateway\n      name: aqua-gateway\n    spec:\n      serviceAccount: aqua-sa\n      containers:\n      - name: aqua-gateway\n        image: registry.aquasec.com/gateway:6.5\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: AQUA_CONSOLE_SECURE_ADDRESS\n          value: aqua-web:443\n        - name: SCALOCK_GATEWAY_PUBLIC_IP\n          value: aqua-gateway\n        - name: SCALOCK_DBUSER\n          value: postgres\n        - name: SCALOCK_DBPASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: aqua-db\n        - name: SCALOCK_DBNAME\n          value: scalock\n        - name: SCALOCK_DBHOST\n          value: aqua-db\n        - name: SCALOCK_DBPORT\n          value: '5432'\n        - name: SCALOCK_AUDIT_DBUSER\n          value: postgres\n        - name: SCALOCK_AUDIT_DBPASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: aqua-db\n        - name: SCALOCK_AUDIT_DBNAME\n          value: slk_audit\n        - name: SCALOCK_AUDIT_DBHOST\n          value: aqua-db\n        - name: SCALOCK_AUDIT_DBPORT\n          value: '5432'\n        ports:\n        - containerPort: 3622\n          protocol: TCP\n        - containerPort: 8443\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04689",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: aqua-gateway\n  name: aqua-gateway\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: aqua-gateway\n  template:\n    metadata:\n      labels:\n        app: aqua-gateway\n      name: aqua-gateway\n    spec:\n      serviceAccount: aqua-sa\n      containers:\n      - name: aqua-gateway\n        image: registry.aquasec.com/gateway:6.5\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        env:\n        - name: AQUA_CONSOLE_SECURE_ADDRESS\n          value: aqua-web:443\n        - name: SCALOCK_GATEWAY_PUBLIC_IP\n          value: aqua-gateway\n        - name: SCALOCK_DBUSER\n          value: postgres\n        - name: SCALOCK_DBPASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: aqua-db\n        - name: SCALOCK_DBNAME\n          value: scalock\n        - name: SCALOCK_DBHOST\n          value: aqua-db\n        - name: SCALOCK_DBPORT\n          value: '5432'\n        - name: SCALOCK_AUDIT_DBUSER\n          value: postgres\n        - name: SCALOCK_AUDIT_DBPASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: aqua-db\n        - name: SCALOCK_AUDIT_DBNAME\n          value: slk_audit\n        - name: SCALOCK_AUDIT_DBHOST\n          value: aqua-db\n        - name: SCALOCK_AUDIT_DBPORT\n          value: '5432'\n        ports:\n        - containerPort: 3622\n          protocol: TCP\n        - containerPort: 8443\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04690",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: aqua-gateway\n  name: aqua-gateway\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: aqua-gateway\n  template:\n    metadata:\n      labels:\n        app: aqua-gateway\n      name: aqua-gateway\n    spec:\n      serviceAccount: aqua-sa\n      containers:\n      - name: aqua-gateway\n        image: registry.aquasec.com/gateway:6.5\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: AQUA_CONSOLE_SECURE_ADDRESS\n          value: aqua-web:443\n        - name: SCALOCK_GATEWAY_PUBLIC_IP\n          value: aqua-gateway\n        - name: SCALOCK_DBUSER\n          value: postgres\n        - name: SCALOCK_DBPASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: aqua-db\n        - name: SCALOCK_DBNAME\n          value: scalock\n        - name: SCALOCK_DBHOST\n          value: aqua-db\n        - name: SCALOCK_DBPORT\n          value: '5432'\n        - name: SCALOCK_AUDIT_DBUSER\n          value: postgres\n        - name: SCALOCK_AUDIT_DBPASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: aqua-db\n        - name: SCALOCK_AUDIT_DBNAME\n          value: slk_audit\n        - name: SCALOCK_AUDIT_DBHOST\n          value: aqua-db\n        - name: SCALOCK_AUDIT_DBPORT\n          value: '5432'\n        ports:\n        - containerPort: 3622\n          protocol: TCP\n        - containerPort: 8443\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04691",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: aqua-gateway\n  name: aqua-gateway\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: aqua-gateway\n  template:\n    metadata:\n      labels:\n        app: aqua-gateway\n      name: aqua-gateway\n    spec:\n      serviceAccount: aqua-sa\n      containers:\n      - name: aqua-gateway\n        image: registry.aquasec.com/gateway:6.5\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        env:\n        - name: AQUA_CONSOLE_SECURE_ADDRESS\n          value: aqua-web:443\n        - name: SCALOCK_GATEWAY_PUBLIC_IP\n          value: aqua-gateway\n        - name: SCALOCK_DBUSER\n          value: postgres\n        - name: SCALOCK_DBPASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: aqua-db\n        - name: SCALOCK_DBNAME\n          value: scalock\n        - name: SCALOCK_DBHOST\n          value: aqua-db\n        - name: SCALOCK_DBPORT\n          value: '5432'\n        - name: SCALOCK_AUDIT_DBUSER\n          value: postgres\n        - name: SCALOCK_AUDIT_DBPASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: password\n              name: aqua-db\n        - name: SCALOCK_AUDIT_DBNAME\n          value: slk_audit\n        - name: SCALOCK_AUDIT_DBHOST\n          value: aqua-db\n        - name: SCALOCK_AUDIT_DBPORT\n          value: '5432'\n        ports:\n        - containerPort: 3622\n          protocol: TCP\n        - containerPort: 8443\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04692",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: loadgenerator\nspec:\n  selector:\n    matchLabels:\n      app: loadgenerator\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: loadgenerator\n        version: v1\n      annotations:\n        sidecar.istio.io/rewriteAppHTTPProbers: 'true'\n    spec:\n      containers:\n      - name: main\n        image: sitaramiyer/bookstore-demo:loadgenerator-v0.1.2\n        env:\n        - name: FRONTEND_ADDR\n          value: frontend:80\n        - name: USERS\n          value: '10'\n        resources:\n          requests:\n            cpu: 300m\n            memory: 256Mi\n          limits:\n            cpu: 500m\n            memory: 512Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04693",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: loadgenerator\nspec:\n  selector:\n    matchLabels:\n      app: loadgenerator\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: loadgenerator\n        version: v1\n      annotations:\n        sidecar.istio.io/rewriteAppHTTPProbers: 'true'\n    spec:\n      containers:\n      - name: main\n        image: sitaramiyer/bookstore-demo:loadgenerator-v0.1.2\n        env:\n        - name: FRONTEND_ADDR\n          value: frontend:80\n        - name: USERS\n          value: '10'\n        resources:\n          requests:\n            cpu: 300m\n            memory: 256Mi\n          limits:\n            cpu: 500m\n            memory: 512Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04694",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"import-named-polls-cronjob\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04695",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"import-named-polls-cronjob\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04696",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"import-named-polls-cronjob\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04697",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"import-named-polls-cronjob\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04698",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kubia-deploy\n  namespace: chp16-set1612\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: kubia-deploy\n  template:\n    metadata:\n      name: kubia-deploy\n      labels:\n        app: kubia-deploy\n    spec:\n      securityContext:\n        runAsUser: 1000\n        runAsNonRoot: true\n      serviceAccountName: foo\n      containers:\n      - image: georgebaptista/kubia:stable\n        name: kubia-deploy\n        securityContext:\n          allowPrivilegeEscalation: false\n          privileged: false\n          runAsNonRoot: true\n          runAsUser: 1000\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n        resources:\n          limits:\n            cpu: 200m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n",
    "errors": []
  },
  {
    "id": "04699",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kubia-deploy\n  namespace: chp16-set1612\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: kubia-deploy\n  template:\n    metadata:\n      name: kubia-deploy\n      labels:\n        app: kubia-deploy\n    spec:\n      securityContext:\n        runAsUser: 1000\n        runAsNonRoot: true\n      serviceAccountName: foo\n      containers:\n      - image: georgebaptista/kubia:stable\n        name: kubia-deploy\n        securityContext:\n          allowPrivilegeEscalation: false\n          privileged: false\n          runAsNonRoot: true\n          runAsUser: 1000\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n        resources:\n          limits:\n            cpu: 200m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n",
    "errors": []
  },
  {
    "id": "04700",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kubia-deploy\n  namespace: chp16-set1612\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: kubia-deploy\n  template:\n    metadata:\n      name: kubia-deploy\n      labels:\n        app: kubia-deploy\n    spec:\n      securityContext:\n        runAsUser: 1000\n        runAsNonRoot: true\n      serviceAccountName: foo\n      containers:\n      - image: georgebaptista/kubia:stable\n        name: kubia-deploy\n        securityContext:\n          allowPrivilegeEscalation: false\n          privileged: false\n          runAsNonRoot: true\n          runAsUser: 1000\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n        resources:\n          limits:\n            cpu: 200m\n            memory: 256Mi\n          requests:\n            cpu: 100m\n            memory: 128Mi\n",
    "errors": []
  },
  {
    "id": "04701",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dss\n  labels:\n    app: dss\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dss\n  template:\n    metadata:\n      labels:\n        app: dss\n    spec:\n      securityContext:\n        fsGroup: 1000\n      containers:\n      - name: dss\n        image: dss-node-image:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/bash\n        args:\n        - -ci\n        - ./startup.sh\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: kubectl-config\n          mountPath: /home/ubuntu/.kube\n        - name: shared-storage\n          mountPath: /share\n        - name: gitlab-registry-cred\n          mountPath: /gitlab-repo/credentials\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:19.03.9-dind\n        resources:\n          requests:\n            cpu: 250m\n            memory: 250Mi\n          limits:\n            cpu: 250m\n            memory: 250Mi\n        env:\n        - name: DOCKER_TLS_CERTDIR\n          value: ''\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: docker-storage\n          mountPath: /var/lib/docker\n      - name: dood\n        image: docker:19.03.8\n        command:\n        - tail\n        - -f\n        - /dev/null\n        resources:\n          requests:\n            cpu: 200m\n            memory: 250Mi\n          limits:\n            cpu: 200m\n            memory: 250Mi\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        envFrom:\n        - secretRef:\n            name: gitlab-registry-cred\n        volumeMounts:\n        - name: docker-sock\n          mountPath: /var/run\n        - name: shared-storage\n          mountPath: /share\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: docker-storage\n        emptyDir: {}\n      - name: docker-sock\n        hostPath:\n          path: /var/run\n      - name: shared-storage\n        emptyDir: {}\n      - name: kubectl-config\n        secret:\n          secretName: kubectl-config\n          defaultMode: 256\n      - name: gitlab-registry-cred\n        secret:\n          secretName: gitlab-registry-cred\n",
    "errors": []
  },
  {
    "id": "04702",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dss\n  labels:\n    app: dss\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dss\n  template:\n    metadata:\n      labels:\n        app: dss\n    spec:\n      securityContext:\n        fsGroup: 1000\n      containers:\n      - name: dss\n        image: dss-node-image:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/bash\n        args:\n        - -ci\n        - ./startup.sh\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - name: kubectl-config\n          mountPath: /home/ubuntu/.kube\n        - name: shared-storage\n          mountPath: /share\n        - name: gitlab-registry-cred\n          mountPath: /gitlab-repo/credentials\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:19.03.9-dind\n        resources:\n          requests:\n            cpu: 250m\n            memory: 250Mi\n          limits:\n            cpu: 250m\n            memory: 250Mi\n        env:\n        - name: DOCKER_TLS_CERTDIR\n          value: ''\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - name: docker-storage\n          mountPath: /var/lib/docker\n      - name: dood\n        image: docker:19.03.8\n        command:\n        - tail\n        - -f\n        - /dev/null\n        resources:\n          requests:\n            cpu: 200m\n            memory: 250Mi\n          limits:\n            cpu: 200m\n            memory: 250Mi\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        envFrom:\n        - secretRef:\n            name: gitlab-registry-cred\n        volumeMounts:\n        - name: docker-sock\n          mountPath: /var/run\n        - name: shared-storage\n          mountPath: /share\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: docker-storage\n        emptyDir: {}\n      - name: docker-sock\n        hostPath:\n          path: /var/run\n      - name: shared-storage\n        emptyDir: {}\n      - name: kubectl-config\n        secret:\n          secretName: kubectl-config\n          defaultMode: 256\n      - name: gitlab-registry-cred\n        secret:\n          secretName: gitlab-registry-cred\n",
    "errors": []
  },
  {
    "id": "04703",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dss\n  labels:\n    app: dss\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dss\n  template:\n    metadata:\n      labels:\n        app: dss\n    spec:\n      securityContext:\n        fsGroup: 1000\n      containers:\n      - name: dss\n        image: dss-node-image:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/bash\n        args:\n        - -ci\n        - ./startup.sh\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - name: kubectl-config\n          mountPath: /home/ubuntu/.kube\n        - name: shared-storage\n          mountPath: /share\n        - name: gitlab-registry-cred\n          mountPath: /gitlab-repo/credentials\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:19.03.9-dind\n        resources:\n          requests:\n            cpu: 250m\n            memory: 250Mi\n          limits:\n            cpu: 250m\n            memory: 250Mi\n        env:\n        - name: DOCKER_TLS_CERTDIR\n          value: ''\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - name: docker-storage\n          mountPath: /var/lib/docker\n      - name: dood\n        image: docker:19.03.8\n        command:\n        - tail\n        - -f\n        - /dev/null\n        resources:\n          requests:\n            cpu: 200m\n            memory: 250Mi\n          limits:\n            cpu: 200m\n            memory: 250Mi\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        envFrom:\n        - secretRef:\n            name: gitlab-registry-cred\n        volumeMounts:\n        - name: docker-sock\n          mountPath: /var/run\n        - name: shared-storage\n          mountPath: /share\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: docker-storage\n        emptyDir: {}\n      - name: docker-sock\n        hostPath:\n          path: /var/run\n      - name: shared-storage\n        emptyDir: {}\n      - name: kubectl-config\n        secret:\n          secretName: kubectl-config\n          defaultMode: 256\n      - name: gitlab-registry-cred\n        secret:\n          secretName: gitlab-registry-cred\n",
    "errors": []
  },
  {
    "id": "04704",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dss\n  labels:\n    app: dss\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dss\n  template:\n    metadata:\n      labels:\n        app: dss\n    spec:\n      securityContext:\n        fsGroup: 1000\n      containers:\n      - name: dss\n        image: dss-node-image:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/bash\n        args:\n        - -ci\n        - ./startup.sh\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - name: kubectl-config\n          mountPath: /home/ubuntu/.kube\n        - name: shared-storage\n          mountPath: /share\n        - name: gitlab-registry-cred\n          mountPath: /gitlab-repo/credentials\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:19.03.9-dind\n        resources:\n          requests:\n            cpu: 250m\n            memory: 250Mi\n          limits:\n            cpu: 250m\n            memory: 250Mi\n        env:\n        - name: DOCKER_TLS_CERTDIR\n          value: ''\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - name: docker-storage\n          mountPath: /var/lib/docker\n      - name: dood\n        image: docker:19.03.8\n        command:\n        - tail\n        - -f\n        - /dev/null\n        resources:\n          requests:\n            cpu: 200m\n            memory: 250Mi\n          limits:\n            cpu: 200m\n            memory: 250Mi\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        envFrom:\n        - secretRef:\n            name: gitlab-registry-cred\n        volumeMounts:\n        - name: docker-sock\n          mountPath: /var/run\n        - name: shared-storage\n          mountPath: /share\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: docker-storage\n        emptyDir: {}\n      - name: docker-sock\n        hostPath:\n          path: /var/run\n      - name: shared-storage\n        emptyDir: {}\n      - name: kubectl-config\n        secret:\n          secretName: kubectl-config\n          defaultMode: 256\n      - name: gitlab-registry-cred\n        secret:\n          secretName: gitlab-registry-cred\n",
    "errors": []
  },
  {
    "id": "04705",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dss\n  labels:\n    app: dss\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dss\n  template:\n    metadata:\n      labels:\n        app: dss\n    spec:\n      securityContext:\n        fsGroup: 1000\n      containers:\n      - name: dss\n        image: dss-node-image:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/bash\n        args:\n        - -ci\n        - ./startup.sh\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: kubectl-config\n          mountPath: /home/ubuntu/.kube\n        - name: shared-storage\n          mountPath: /share\n        - name: gitlab-registry-cred\n          mountPath: /gitlab-repo/credentials\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:19.03.9-dind\n        resources:\n          requests:\n            cpu: 250m\n            memory: 250Mi\n          limits:\n            cpu: 250m\n            memory: 250Mi\n        env:\n        - name: DOCKER_TLS_CERTDIR\n          value: ''\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: docker-storage\n          mountPath: /var/lib/docker\n      - name: dood\n        image: docker:19.03.8\n        command:\n        - tail\n        - -f\n        - /dev/null\n        resources:\n          requests:\n            cpu: 200m\n            memory: 250Mi\n          limits:\n            cpu: 200m\n            memory: 250Mi\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        envFrom:\n        - secretRef:\n            name: gitlab-registry-cred\n        volumeMounts:\n        - name: docker-sock\n          mountPath: /var/run\n        - name: shared-storage\n          mountPath: /share\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: docker-storage\n        emptyDir: {}\n      - name: docker-sock\n        hostPath:\n          path: /var/run\n      - name: shared-storage\n        emptyDir: {}\n      - name: kubectl-config\n        secret:\n          secretName: kubectl-config\n          defaultMode: 256\n      - name: gitlab-registry-cred\n        secret:\n          secretName: gitlab-registry-cred\n",
    "errors": []
  },
  {
    "id": "04706",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dss\n  labels:\n    app: dss\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dss\n  template:\n    metadata:\n      labels:\n        app: dss\n    spec:\n      securityContext:\n        fsGroup: 1000\n      containers:\n      - name: dss\n        image: dss-node-image:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/bash\n        args:\n        - -ci\n        - ./startup.sh\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: kubectl-config\n          mountPath: /home/ubuntu/.kube\n        - name: shared-storage\n          mountPath: /share\n        - name: gitlab-registry-cred\n          mountPath: /gitlab-repo/credentials\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:19.03.9-dind\n        resources:\n          requests:\n            cpu: 250m\n            memory: 250Mi\n          limits:\n            cpu: 250m\n            memory: 250Mi\n        env:\n        - name: DOCKER_TLS_CERTDIR\n          value: ''\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: docker-storage\n          mountPath: /var/lib/docker\n      - name: dood\n        image: docker:19.03.8\n        command:\n        - tail\n        - -f\n        - /dev/null\n        resources:\n          requests:\n            cpu: 200m\n            memory: 250Mi\n          limits:\n            cpu: 200m\n            memory: 250Mi\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        envFrom:\n        - secretRef:\n            name: gitlab-registry-cred\n        volumeMounts:\n        - name: docker-sock\n          mountPath: /var/run\n        - name: shared-storage\n          mountPath: /share\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: docker-storage\n        emptyDir: {}\n      - name: docker-sock\n        hostPath:\n          path: /var/run\n      - name: shared-storage\n        emptyDir: {}\n      - name: kubectl-config\n        secret:\n          secretName: kubectl-config\n          defaultMode: 256\n      - name: gitlab-registry-cred\n        secret:\n          secretName: gitlab-registry-cred\n",
    "errors": []
  },
  {
    "id": "04707",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dss\n  labels:\n    app: dss\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dss\n  template:\n    metadata:\n      labels:\n        app: dss\n    spec:\n      securityContext:\n        fsGroup: 1000\n      containers:\n      - name: dss\n        image: dss-node-image:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/bash\n        args:\n        - -ci\n        - ./startup.sh\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: kubectl-config\n          mountPath: /home/ubuntu/.kube\n        - name: shared-storage\n          mountPath: /share\n        - name: gitlab-registry-cred\n          mountPath: /gitlab-repo/credentials\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:19.03.9-dind\n        resources:\n          requests:\n            cpu: 250m\n            memory: 250Mi\n          limits:\n            cpu: 250m\n            memory: 250Mi\n        env:\n        - name: DOCKER_TLS_CERTDIR\n          value: ''\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: docker-storage\n          mountPath: /var/lib/docker\n      - name: dood\n        image: docker:19.03.8\n        command:\n        - tail\n        - -f\n        - /dev/null\n        resources:\n          requests:\n            cpu: 200m\n            memory: 250Mi\n          limits:\n            cpu: 200m\n            memory: 250Mi\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        envFrom:\n        - secretRef:\n            name: gitlab-registry-cred\n        volumeMounts:\n        - name: docker-sock\n          mountPath: /var/run\n        - name: shared-storage\n          mountPath: /share\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: docker-storage\n        emptyDir: {}\n      - name: docker-sock\n        hostPath:\n          path: /var/run\n      - name: shared-storage\n        emptyDir: {}\n      - name: kubectl-config\n        secret:\n          secretName: kubectl-config\n          defaultMode: 256\n      - name: gitlab-registry-cred\n        secret:\n          secretName: gitlab-registry-cred\n",
    "errors": []
  },
  {
    "id": "04708",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dss\n  labels:\n    app: dss\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dss\n  template:\n    metadata:\n      labels:\n        app: dss\n    spec:\n      securityContext:\n        fsGroup: 1000\n      containers:\n      - name: dss\n        image: dss-node-image:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/bash\n        args:\n        - -ci\n        - ./startup.sh\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: kubectl-config\n          mountPath: /home/ubuntu/.kube\n        - name: shared-storage\n          mountPath: /share\n        - name: gitlab-registry-cred\n          mountPath: /gitlab-repo/credentials\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:19.03.9-dind\n        resources:\n          requests:\n            cpu: 250m\n            memory: 250Mi\n          limits:\n            cpu: 250m\n            memory: 250Mi\n        env:\n        - name: DOCKER_TLS_CERTDIR\n          value: ''\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: docker-storage\n          mountPath: /var/lib/docker\n      - name: dood\n        image: docker:19.03.8\n        command:\n        - tail\n        - -f\n        - /dev/null\n        resources:\n          requests:\n            cpu: 200m\n            memory: 250Mi\n          limits:\n            cpu: 200m\n            memory: 250Mi\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        envFrom:\n        - secretRef:\n            name: gitlab-registry-cred\n        volumeMounts:\n        - name: docker-sock\n          mountPath: /var/run\n        - name: shared-storage\n          mountPath: /share\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: docker-storage\n        emptyDir: {}\n      - name: docker-sock\n        hostPath:\n          path: /var/run\n      - name: shared-storage\n        emptyDir: {}\n      - name: kubectl-config\n        secret:\n          secretName: kubectl-config\n          defaultMode: 256\n      - name: gitlab-registry-cred\n        secret:\n          secretName: gitlab-registry-cred\n",
    "errors": []
  },
  {
    "id": "04709",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dss\n  labels:\n    app: dss\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dss\n  template:\n    metadata:\n      labels:\n        app: dss\n    spec:\n      securityContext:\n        fsGroup: 1000\n      containers:\n      - name: dss\n        image: dss-node-image:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/bash\n        args:\n        - -ci\n        - ./startup.sh\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: kubectl-config\n          mountPath: /home/ubuntu/.kube\n        - name: shared-storage\n          mountPath: /share\n        - name: gitlab-registry-cred\n          mountPath: /gitlab-repo/credentials\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:19.03.9-dind\n        resources:\n          requests:\n            cpu: 250m\n            memory: 250Mi\n          limits:\n            cpu: 250m\n            memory: 250Mi\n        env:\n        - name: DOCKER_TLS_CERTDIR\n          value: ''\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: docker-storage\n          mountPath: /var/lib/docker\n      - name: dood\n        image: docker:19.03.8\n        command:\n        - tail\n        - -f\n        - /dev/null\n        resources:\n          requests:\n            cpu: 200m\n            memory: 250Mi\n          limits:\n            cpu: 200m\n            memory: 250Mi\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        envFrom:\n        - secretRef:\n            name: gitlab-registry-cred\n        volumeMounts:\n        - name: docker-sock\n          mountPath: /var/run\n        - name: shared-storage\n          mountPath: /share\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: docker-storage\n        emptyDir: {}\n      - name: docker-sock\n        hostPath:\n          path: /var/run\n      - name: shared-storage\n        emptyDir: {}\n      - name: kubectl-config\n        secret:\n          secretName: kubectl-config\n          defaultMode: 256\n      - name: gitlab-registry-cred\n        secret:\n          secretName: gitlab-registry-cred\n",
    "errors": []
  },
  {
    "id": "04710",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dss\n  labels:\n    app: dss\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dss\n  template:\n    metadata:\n      labels:\n        app: dss\n    spec:\n      securityContext:\n        fsGroup: 1000\n      containers:\n      - name: dss\n        image: dss-node-image:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/bash\n        args:\n        - -ci\n        - ./startup.sh\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: kubectl-config\n          mountPath: /home/ubuntu/.kube\n        - name: shared-storage\n          mountPath: /share\n        - name: gitlab-registry-cred\n          mountPath: /gitlab-repo/credentials\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:19.03.9-dind\n        resources:\n          requests:\n            cpu: 250m\n            memory: 250Mi\n          limits:\n            cpu: 250m\n            memory: 250Mi\n        env:\n        - name: DOCKER_TLS_CERTDIR\n          value: ''\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: docker-storage\n          mountPath: /var/lib/docker\n      - name: dood\n        image: docker:19.03.8\n        command:\n        - tail\n        - -f\n        - /dev/null\n        resources:\n          requests:\n            cpu: 200m\n            memory: 250Mi\n          limits:\n            cpu: 200m\n            memory: 250Mi\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        envFrom:\n        - secretRef:\n            name: gitlab-registry-cred\n        volumeMounts:\n        - name: docker-sock\n          mountPath: /var/run\n        - name: shared-storage\n          mountPath: /share\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: docker-storage\n        emptyDir: {}\n      - name: docker-sock\n        hostPath:\n          path: /var/run\n      - name: shared-storage\n        emptyDir: {}\n      - name: kubectl-config\n        secret:\n          secretName: kubectl-config\n          defaultMode: 256\n      - name: gitlab-registry-cred\n        secret:\n          secretName: gitlab-registry-cred\n",
    "errors": []
  },
  {
    "id": "04711",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dss\n  labels:\n    app: dss\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dss\n  template:\n    metadata:\n      labels:\n        app: dss\n    spec:\n      securityContext:\n        fsGroup: 1000\n      containers:\n      - name: dss\n        image: dss-node-image:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/bash\n        args:\n        - -ci\n        - ./startup.sh\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: kubectl-config\n          mountPath: /home/ubuntu/.kube\n        - name: shared-storage\n          mountPath: /share\n        - name: gitlab-registry-cred\n          mountPath: /gitlab-repo/credentials\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:19.03.9-dind\n        resources:\n          requests:\n            cpu: 250m\n            memory: 250Mi\n          limits:\n            cpu: 250m\n            memory: 250Mi\n        env:\n        - name: DOCKER_TLS_CERTDIR\n          value: ''\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: docker-storage\n          mountPath: /var/lib/docker\n      - name: dood\n        image: docker:19.03.8\n        command:\n        - tail\n        - -f\n        - /dev/null\n        resources:\n          requests:\n            cpu: 200m\n            memory: 250Mi\n          limits:\n            cpu: 200m\n            memory: 250Mi\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        envFrom:\n        - secretRef:\n            name: gitlab-registry-cred\n        volumeMounts:\n        - name: docker-sock\n          mountPath: /var/run\n        - name: shared-storage\n          mountPath: /share\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: docker-storage\n        emptyDir: {}\n      - name: docker-sock\n        hostPath:\n          path: /var/run\n      - name: shared-storage\n        emptyDir: {}\n      - name: kubectl-config\n        secret:\n          secretName: kubectl-config\n          defaultMode: 256\n      - name: gitlab-registry-cred\n        secret:\n          secretName: gitlab-registry-cred\n",
    "errors": []
  },
  {
    "id": "04712",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dss\n  labels:\n    app: dss\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dss\n  template:\n    metadata:\n      labels:\n        app: dss\n    spec:\n      securityContext:\n        fsGroup: 1000\n      containers:\n      - name: dss\n        image: dss-node-image:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/bash\n        args:\n        - -ci\n        - ./startup.sh\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: kubectl-config\n          mountPath: /home/ubuntu/.kube\n        - name: shared-storage\n          mountPath: /share\n        - name: gitlab-registry-cred\n          mountPath: /gitlab-repo/credentials\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:19.03.9-dind\n        resources:\n          requests:\n            cpu: 250m\n            memory: 250Mi\n          limits:\n            cpu: 250m\n            memory: 250Mi\n        env:\n        - name: DOCKER_TLS_CERTDIR\n          value: ''\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: docker-storage\n          mountPath: /var/lib/docker\n      - name: dood\n        image: docker:19.03.8\n        command:\n        - tail\n        - -f\n        - /dev/null\n        resources:\n          requests:\n            cpu: 200m\n            memory: 250Mi\n          limits:\n            cpu: 200m\n            memory: 250Mi\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        envFrom:\n        - secretRef:\n            name: gitlab-registry-cred\n        volumeMounts:\n        - name: docker-sock\n          mountPath: /var/run\n        - name: shared-storage\n          mountPath: /share\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: docker-storage\n        emptyDir: {}\n      - name: docker-sock\n        hostPath:\n          path: /var/run\n      - name: shared-storage\n        emptyDir: {}\n      - name: kubectl-config\n        secret:\n          secretName: kubectl-config\n          defaultMode: 256\n      - name: gitlab-registry-cred\n        secret:\n          secretName: gitlab-registry-cred\n",
    "errors": []
  },
  {
    "id": "04713",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dss\n  labels:\n    app: dss\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dss\n  template:\n    metadata:\n      labels:\n        app: dss\n    spec:\n      securityContext:\n        fsGroup: 1000\n      containers:\n      - name: dss\n        image: dss-node-image:stable\n        imagePullPolicy: Always\n        command:\n        - /bin/bash\n        args:\n        - -ci\n        - ./startup.sh\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        - name: DOCKER_HOST\n          value: tcp://localhost:2375\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: kubectl-config\n          mountPath: /home/ubuntu/.kube\n        - name: shared-storage\n          mountPath: /share\n        - name: gitlab-registry-cred\n          mountPath: /gitlab-repo/credentials\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: dind\n        image: docker:19.03.9-dind\n        resources:\n          requests:\n            cpu: 250m\n            memory: 250Mi\n          limits:\n            cpu: 250m\n            memory: 250Mi\n        env:\n        - name: DOCKER_TLS_CERTDIR\n          value: ''\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: docker-storage\n          mountPath: /var/lib/docker\n      - name: dood\n        image: docker:19.03.8\n        command:\n        - tail\n        - -f\n        - /dev/null\n        resources:\n          requests:\n            cpu: 200m\n            memory: 250Mi\n          limits:\n            cpu: 200m\n            memory: 250Mi\n        env:\n        - name: DSS_NODE_TYPE\n          valueFrom:\n            configMapKeyRef:\n              name: dss-node-type\n              key: DSS_NODE_TYPE\n        envFrom:\n        - secretRef:\n            name: gitlab-registry-cred\n        volumeMounts:\n        - name: docker-sock\n          mountPath: /var/run\n        - name: shared-storage\n          mountPath: /share\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: docker-storage\n        emptyDir: {}\n      - name: docker-sock\n        hostPath:\n          path: /var/run\n      - name: shared-storage\n        emptyDir: {}\n      - name: kubectl-config\n        secret:\n          secretName: kubectl-config\n          defaultMode: 256\n      - name: gitlab-registry-cred\n        secret:\n          secretName: gitlab-registry-cred\n",
    "errors": []
  },
  {
    "id": "04714",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    aci-containers-config-version: dummy\n    network-plugin: aci-containers\n  name: aci-containers-host\n  namespace: aci-containers-system\nspec:\n  selector:\n    matchLabels:\n      name: aci-containers-host\n      network-plugin: aci-containers\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9612'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aci-containers-host\n        network-plugin: aci-containers\n    spec:\n      containers:\n      - env:\n        - name: KUBERNETES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: TENANT\n          value: csrtest\n        - name: NODE_EPG\n          value: aci-containers-nodes\n        - name: OPFLEX_MODE\n          value: overlay\n        - name: DURATION_WAIT_FOR_NETWORK\n          value: '210'\n        image: noirolabs/aci-containers-host:ci_test\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /status\n            port: 8090\n            scheme: HTTP\n          initialDelaySeconds: 120\n          periodSeconds: 60\n          successThreshold: 1\n          timeoutSeconds: 30\n        name: aci-containers-host\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        - mountPath: /mnt/cni-conf\n          name: cni-conf\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/aci-containers/\n          name: host-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - env:\n        - name: REBOOT_WITH_OVS\n          value: 'true'\n        - name: SSL_MODE\n          value: disabled\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-agent\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/opflex-agent-ovs/conf.d\n          name: opflex-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - /usr/local/bin/launch-opflexserver.sh\n        command:\n        - /bin/sh\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-server\n        ports:\n        - containerPort: 19999\n        - containerPort: 9632\n          name: metrics\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/opflex-server\n          name: opflex-server-config-volume\n        - mountPath: /usr/local/var\n          name: hostvar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - image: noirolabs/cnideploy:6.0.0.0.0ef4718\n        imagePullPolicy: Always\n        name: cnideploy\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: aci-containers-host-agent\n      volumes:\n      - hostPath:\n          path: /var/lib\n        name: cni-bin\n      - hostPath:\n          path: /etc/kubernetes\n        name: cni-conf\n      - hostPath:\n          path: /var\n        name: hostvar\n      - hostPath:\n          path: /run\n        name: hostrun\n      - configMap:\n          items:\n          - key: host-agent-config\n            path: host-agent.conf\n          name: aci-containers-config\n        name: host-config-volume\n      - emptyDir:\n          medium: Memory\n        name: opflex-hostconfig-volume\n      - configMap:\n          items:\n          - key: opflex-agent-config\n            path: local.conf\n          name: aci-containers-config\n        name: opflex-config-volume\n      - name: opflex-server-config-volume\n",
    "errors": []
  },
  {
    "id": "04715",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    aci-containers-config-version: dummy\n    network-plugin: aci-containers\n  name: aci-containers-host\n  namespace: aci-containers-system\nspec:\n  selector:\n    matchLabels:\n      name: aci-containers-host\n      network-plugin: aci-containers\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9612'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aci-containers-host\n        network-plugin: aci-containers\n    spec:\n      containers:\n      - env:\n        - name: KUBERNETES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: TENANT\n          value: csrtest\n        - name: NODE_EPG\n          value: aci-containers-nodes\n        - name: OPFLEX_MODE\n          value: overlay\n        - name: DURATION_WAIT_FOR_NETWORK\n          value: '210'\n        image: noirolabs/aci-containers-host:ci_test\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /status\n            port: 8090\n            scheme: HTTP\n          initialDelaySeconds: 120\n          periodSeconds: 60\n          successThreshold: 1\n          timeoutSeconds: 30\n        name: aci-containers-host\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        - mountPath: /mnt/cni-conf\n          name: cni-conf\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/aci-containers/\n          name: host-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - env:\n        - name: REBOOT_WITH_OVS\n          value: 'true'\n        - name: SSL_MODE\n          value: disabled\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-agent\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/opflex-agent-ovs/conf.d\n          name: opflex-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - /usr/local/bin/launch-opflexserver.sh\n        command:\n        - /bin/sh\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-server\n        ports:\n        - containerPort: 19999\n        - containerPort: 9632\n          name: metrics\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/opflex-server\n          name: opflex-server-config-volume\n        - mountPath: /usr/local/var\n          name: hostvar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - image: noirolabs/cnideploy:6.0.0.0.0ef4718\n        imagePullPolicy: Always\n        name: cnideploy\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: aci-containers-host-agent\n      volumes:\n      - hostPath:\n          path: /var/lib\n        name: cni-bin\n      - hostPath:\n          path: /etc/kubernetes\n        name: cni-conf\n      - hostPath:\n          path: /var\n        name: hostvar\n      - hostPath:\n          path: /run\n        name: hostrun\n      - configMap:\n          items:\n          - key: host-agent-config\n            path: host-agent.conf\n          name: aci-containers-config\n        name: host-config-volume\n      - emptyDir:\n          medium: Memory\n        name: opflex-hostconfig-volume\n      - configMap:\n          items:\n          - key: opflex-agent-config\n            path: local.conf\n          name: aci-containers-config\n        name: opflex-config-volume\n      - name: opflex-server-config-volume\n",
    "errors": []
  },
  {
    "id": "04716",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    aci-containers-config-version: dummy\n    network-plugin: aci-containers\n  name: aci-containers-host\n  namespace: aci-containers-system\nspec:\n  selector:\n    matchLabels:\n      name: aci-containers-host\n      network-plugin: aci-containers\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9612'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aci-containers-host\n        network-plugin: aci-containers\n    spec:\n      containers:\n      - env:\n        - name: KUBERNETES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: TENANT\n          value: csrtest\n        - name: NODE_EPG\n          value: aci-containers-nodes\n        - name: OPFLEX_MODE\n          value: overlay\n        - name: DURATION_WAIT_FOR_NETWORK\n          value: '210'\n        image: noirolabs/aci-containers-host:ci_test\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /status\n            port: 8090\n            scheme: HTTP\n          initialDelaySeconds: 120\n          periodSeconds: 60\n          successThreshold: 1\n          timeoutSeconds: 30\n        name: aci-containers-host\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        - mountPath: /mnt/cni-conf\n          name: cni-conf\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/aci-containers/\n          name: host-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - env:\n        - name: REBOOT_WITH_OVS\n          value: 'true'\n        - name: SSL_MODE\n          value: disabled\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-agent\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/opflex-agent-ovs/conf.d\n          name: opflex-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - /usr/local/bin/launch-opflexserver.sh\n        command:\n        - /bin/sh\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-server\n        ports:\n        - containerPort: 19999\n        - containerPort: 9632\n          name: metrics\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/opflex-server\n          name: opflex-server-config-volume\n        - mountPath: /usr/local/var\n          name: hostvar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - image: noirolabs/cnideploy:6.0.0.0.0ef4718\n        imagePullPolicy: Always\n        name: cnideploy\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: aci-containers-host-agent\n      volumes:\n      - hostPath:\n          path: /var/lib\n        name: cni-bin\n      - hostPath:\n          path: /etc/kubernetes\n        name: cni-conf\n      - hostPath:\n          path: /var\n        name: hostvar\n      - hostPath:\n          path: /run\n        name: hostrun\n      - configMap:\n          items:\n          - key: host-agent-config\n            path: host-agent.conf\n          name: aci-containers-config\n        name: host-config-volume\n      - emptyDir:\n          medium: Memory\n        name: opflex-hostconfig-volume\n      - configMap:\n          items:\n          - key: opflex-agent-config\n            path: local.conf\n          name: aci-containers-config\n        name: opflex-config-volume\n      - name: opflex-server-config-volume\n",
    "errors": []
  },
  {
    "id": "04717",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    aci-containers-config-version: dummy\n    network-plugin: aci-containers\n  name: aci-containers-host\n  namespace: aci-containers-system\nspec:\n  selector:\n    matchLabels:\n      name: aci-containers-host\n      network-plugin: aci-containers\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9612'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aci-containers-host\n        network-plugin: aci-containers\n    spec:\n      containers:\n      - env:\n        - name: KUBERNETES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: TENANT\n          value: csrtest\n        - name: NODE_EPG\n          value: aci-containers-nodes\n        - name: OPFLEX_MODE\n          value: overlay\n        - name: DURATION_WAIT_FOR_NETWORK\n          value: '210'\n        image: noirolabs/aci-containers-host:ci_test\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /status\n            port: 8090\n            scheme: HTTP\n          initialDelaySeconds: 120\n          periodSeconds: 60\n          successThreshold: 1\n          timeoutSeconds: 30\n        name: aci-containers-host\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        - mountPath: /mnt/cni-conf\n          name: cni-conf\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/aci-containers/\n          name: host-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - env:\n        - name: REBOOT_WITH_OVS\n          value: 'true'\n        - name: SSL_MODE\n          value: disabled\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-agent\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/opflex-agent-ovs/conf.d\n          name: opflex-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - /usr/local/bin/launch-opflexserver.sh\n        command:\n        - /bin/sh\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-server\n        ports:\n        - containerPort: 19999\n        - containerPort: 9632\n          name: metrics\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/opflex-server\n          name: opflex-server-config-volume\n        - mountPath: /usr/local/var\n          name: hostvar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - image: noirolabs/cnideploy:6.0.0.0.0ef4718\n        imagePullPolicy: Always\n        name: cnideploy\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: aci-containers-host-agent\n      volumes:\n      - hostPath:\n          path: /var/lib\n        name: cni-bin\n      - hostPath:\n          path: /etc/kubernetes\n        name: cni-conf\n      - hostPath:\n          path: /var\n        name: hostvar\n      - hostPath:\n          path: /run\n        name: hostrun\n      - configMap:\n          items:\n          - key: host-agent-config\n            path: host-agent.conf\n          name: aci-containers-config\n        name: host-config-volume\n      - emptyDir:\n          medium: Memory\n        name: opflex-hostconfig-volume\n      - configMap:\n          items:\n          - key: opflex-agent-config\n            path: local.conf\n          name: aci-containers-config\n        name: opflex-config-volume\n      - name: opflex-server-config-volume\n",
    "errors": []
  },
  {
    "id": "04718",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    aci-containers-config-version: dummy\n    network-plugin: aci-containers\n  name: aci-containers-host\n  namespace: aci-containers-system\nspec:\n  selector:\n    matchLabels:\n      name: aci-containers-host\n      network-plugin: aci-containers\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9612'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aci-containers-host\n        network-plugin: aci-containers\n    spec:\n      containers:\n      - env:\n        - name: KUBERNETES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: TENANT\n          value: csrtest\n        - name: NODE_EPG\n          value: aci-containers-nodes\n        - name: OPFLEX_MODE\n          value: overlay\n        - name: DURATION_WAIT_FOR_NETWORK\n          value: '210'\n        image: noirolabs/aci-containers-host:ci_test\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /status\n            port: 8090\n            scheme: HTTP\n          initialDelaySeconds: 120\n          periodSeconds: 60\n          successThreshold: 1\n          timeoutSeconds: 30\n        name: aci-containers-host\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        - mountPath: /mnt/cni-conf\n          name: cni-conf\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/aci-containers/\n          name: host-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - env:\n        - name: REBOOT_WITH_OVS\n          value: 'true'\n        - name: SSL_MODE\n          value: disabled\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-agent\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/opflex-agent-ovs/conf.d\n          name: opflex-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - /usr/local/bin/launch-opflexserver.sh\n        command:\n        - /bin/sh\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-server\n        ports:\n        - containerPort: 19999\n        - containerPort: 9632\n          name: metrics\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/opflex-server\n          name: opflex-server-config-volume\n        - mountPath: /usr/local/var\n          name: hostvar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - image: noirolabs/cnideploy:6.0.0.0.0ef4718\n        imagePullPolicy: Always\n        name: cnideploy\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: aci-containers-host-agent\n      volumes:\n      - hostPath:\n          path: /var/lib\n        name: cni-bin\n      - hostPath:\n          path: /etc/kubernetes\n        name: cni-conf\n      - hostPath:\n          path: /var\n        name: hostvar\n      - hostPath:\n          path: /run\n        name: hostrun\n      - configMap:\n          items:\n          - key: host-agent-config\n            path: host-agent.conf\n          name: aci-containers-config\n        name: host-config-volume\n      - emptyDir:\n          medium: Memory\n        name: opflex-hostconfig-volume\n      - configMap:\n          items:\n          - key: opflex-agent-config\n            path: local.conf\n          name: aci-containers-config\n        name: opflex-config-volume\n      - name: opflex-server-config-volume\n",
    "errors": []
  },
  {
    "id": "04719",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    aci-containers-config-version: dummy\n    network-plugin: aci-containers\n  name: aci-containers-host\n  namespace: aci-containers-system\nspec:\n  selector:\n    matchLabels:\n      name: aci-containers-host\n      network-plugin: aci-containers\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9612'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aci-containers-host\n        network-plugin: aci-containers\n    spec:\n      containers:\n      - env:\n        - name: KUBERNETES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: TENANT\n          value: csrtest\n        - name: NODE_EPG\n          value: aci-containers-nodes\n        - name: OPFLEX_MODE\n          value: overlay\n        - name: DURATION_WAIT_FOR_NETWORK\n          value: '210'\n        image: noirolabs/aci-containers-host:ci_test\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /status\n            port: 8090\n            scheme: HTTP\n          initialDelaySeconds: 120\n          periodSeconds: 60\n          successThreshold: 1\n          timeoutSeconds: 30\n        name: aci-containers-host\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        - mountPath: /mnt/cni-conf\n          name: cni-conf\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/aci-containers/\n          name: host-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - env:\n        - name: REBOOT_WITH_OVS\n          value: 'true'\n        - name: SSL_MODE\n          value: disabled\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-agent\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/opflex-agent-ovs/conf.d\n          name: opflex-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - /usr/local/bin/launch-opflexserver.sh\n        command:\n        - /bin/sh\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-server\n        ports:\n        - containerPort: 19999\n        - containerPort: 9632\n          name: metrics\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/opflex-server\n          name: opflex-server-config-volume\n        - mountPath: /usr/local/var\n          name: hostvar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - image: noirolabs/cnideploy:6.0.0.0.0ef4718\n        imagePullPolicy: Always\n        name: cnideploy\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: aci-containers-host-agent\n      volumes:\n      - hostPath:\n          path: /var/lib\n        name: cni-bin\n      - hostPath:\n          path: /etc/kubernetes\n        name: cni-conf\n      - hostPath:\n          path: /var\n        name: hostvar\n      - hostPath:\n          path: /run\n        name: hostrun\n      - configMap:\n          items:\n          - key: host-agent-config\n            path: host-agent.conf\n          name: aci-containers-config\n        name: host-config-volume\n      - emptyDir:\n          medium: Memory\n        name: opflex-hostconfig-volume\n      - configMap:\n          items:\n          - key: opflex-agent-config\n            path: local.conf\n          name: aci-containers-config\n        name: opflex-config-volume\n      - name: opflex-server-config-volume\n",
    "errors": []
  },
  {
    "id": "04720",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    aci-containers-config-version: dummy\n    network-plugin: aci-containers\n  name: aci-containers-host\n  namespace: aci-containers-system\nspec:\n  selector:\n    matchLabels:\n      name: aci-containers-host\n      network-plugin: aci-containers\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9612'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aci-containers-host\n        network-plugin: aci-containers\n    spec:\n      containers:\n      - env:\n        - name: KUBERNETES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: TENANT\n          value: csrtest\n        - name: NODE_EPG\n          value: aci-containers-nodes\n        - name: OPFLEX_MODE\n          value: overlay\n        - name: DURATION_WAIT_FOR_NETWORK\n          value: '210'\n        image: noirolabs/aci-containers-host:ci_test\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /status\n            port: 8090\n            scheme: HTTP\n          initialDelaySeconds: 120\n          periodSeconds: 60\n          successThreshold: 1\n          timeoutSeconds: 30\n        name: aci-containers-host\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        - mountPath: /mnt/cni-conf\n          name: cni-conf\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/aci-containers/\n          name: host-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - env:\n        - name: REBOOT_WITH_OVS\n          value: 'true'\n        - name: SSL_MODE\n          value: disabled\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-agent\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/opflex-agent-ovs/conf.d\n          name: opflex-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - /usr/local/bin/launch-opflexserver.sh\n        command:\n        - /bin/sh\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-server\n        ports:\n        - containerPort: 19999\n        - containerPort: 9632\n          name: metrics\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/opflex-server\n          name: opflex-server-config-volume\n        - mountPath: /usr/local/var\n          name: hostvar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - image: noirolabs/cnideploy:6.0.0.0.0ef4718\n        imagePullPolicy: Always\n        name: cnideploy\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: aci-containers-host-agent\n      volumes:\n      - hostPath:\n          path: /var/lib\n        name: cni-bin\n      - hostPath:\n          path: /etc/kubernetes\n        name: cni-conf\n      - hostPath:\n          path: /var\n        name: hostvar\n      - hostPath:\n          path: /run\n        name: hostrun\n      - configMap:\n          items:\n          - key: host-agent-config\n            path: host-agent.conf\n          name: aci-containers-config\n        name: host-config-volume\n      - emptyDir:\n          medium: Memory\n        name: opflex-hostconfig-volume\n      - configMap:\n          items:\n          - key: opflex-agent-config\n            path: local.conf\n          name: aci-containers-config\n        name: opflex-config-volume\n      - name: opflex-server-config-volume\n",
    "errors": []
  },
  {
    "id": "04721",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    aci-containers-config-version: dummy\n    network-plugin: aci-containers\n  name: aci-containers-host\n  namespace: aci-containers-system\nspec:\n  selector:\n    matchLabels:\n      name: aci-containers-host\n      network-plugin: aci-containers\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9612'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aci-containers-host\n        network-plugin: aci-containers\n    spec:\n      containers:\n      - env:\n        - name: KUBERNETES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: TENANT\n          value: csrtest\n        - name: NODE_EPG\n          value: aci-containers-nodes\n        - name: OPFLEX_MODE\n          value: overlay\n        - name: DURATION_WAIT_FOR_NETWORK\n          value: '210'\n        image: noirolabs/aci-containers-host:ci_test\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /status\n            port: 8090\n            scheme: HTTP\n          initialDelaySeconds: 120\n          periodSeconds: 60\n          successThreshold: 1\n          timeoutSeconds: 30\n        name: aci-containers-host\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        - mountPath: /mnt/cni-conf\n          name: cni-conf\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/aci-containers/\n          name: host-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - env:\n        - name: REBOOT_WITH_OVS\n          value: 'true'\n        - name: SSL_MODE\n          value: disabled\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-agent\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/opflex-agent-ovs/conf.d\n          name: opflex-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - /usr/local/bin/launch-opflexserver.sh\n        command:\n        - /bin/sh\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-server\n        ports:\n        - containerPort: 19999\n        - containerPort: 9632\n          name: metrics\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/opflex-server\n          name: opflex-server-config-volume\n        - mountPath: /usr/local/var\n          name: hostvar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - image: noirolabs/cnideploy:6.0.0.0.0ef4718\n        imagePullPolicy: Always\n        name: cnideploy\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: aci-containers-host-agent\n      volumes:\n      - hostPath:\n          path: /var/lib\n        name: cni-bin\n      - hostPath:\n          path: /etc/kubernetes\n        name: cni-conf\n      - hostPath:\n          path: /var\n        name: hostvar\n      - hostPath:\n          path: /run\n        name: hostrun\n      - configMap:\n          items:\n          - key: host-agent-config\n            path: host-agent.conf\n          name: aci-containers-config\n        name: host-config-volume\n      - emptyDir:\n          medium: Memory\n        name: opflex-hostconfig-volume\n      - configMap:\n          items:\n          - key: opflex-agent-config\n            path: local.conf\n          name: aci-containers-config\n        name: opflex-config-volume\n      - name: opflex-server-config-volume\n",
    "errors": []
  },
  {
    "id": "04722",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    aci-containers-config-version: dummy\n    network-plugin: aci-containers\n  name: aci-containers-host\n  namespace: aci-containers-system\nspec:\n  selector:\n    matchLabels:\n      name: aci-containers-host\n      network-plugin: aci-containers\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9612'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aci-containers-host\n        network-plugin: aci-containers\n    spec:\n      containers:\n      - env:\n        - name: KUBERNETES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: TENANT\n          value: csrtest\n        - name: NODE_EPG\n          value: aci-containers-nodes\n        - name: OPFLEX_MODE\n          value: overlay\n        - name: DURATION_WAIT_FOR_NETWORK\n          value: '210'\n        image: noirolabs/aci-containers-host:ci_test\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /status\n            port: 8090\n            scheme: HTTP\n          initialDelaySeconds: 120\n          periodSeconds: 60\n          successThreshold: 1\n          timeoutSeconds: 30\n        name: aci-containers-host\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        - mountPath: /mnt/cni-conf\n          name: cni-conf\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/aci-containers/\n          name: host-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - env:\n        - name: REBOOT_WITH_OVS\n          value: 'true'\n        - name: SSL_MODE\n          value: disabled\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-agent\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/opflex-agent-ovs/conf.d\n          name: opflex-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - /usr/local/bin/launch-opflexserver.sh\n        command:\n        - /bin/sh\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-server\n        ports:\n        - containerPort: 19999\n        - containerPort: 9632\n          name: metrics\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/opflex-server\n          name: opflex-server-config-volume\n        - mountPath: /usr/local/var\n          name: hostvar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - image: noirolabs/cnideploy:6.0.0.0.0ef4718\n        imagePullPolicy: Always\n        name: cnideploy\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: aci-containers-host-agent\n      volumes:\n      - hostPath:\n          path: /var/lib\n        name: cni-bin\n      - hostPath:\n          path: /etc/kubernetes\n        name: cni-conf\n      - hostPath:\n          path: /var\n        name: hostvar\n      - hostPath:\n          path: /run\n        name: hostrun\n      - configMap:\n          items:\n          - key: host-agent-config\n            path: host-agent.conf\n          name: aci-containers-config\n        name: host-config-volume\n      - emptyDir:\n          medium: Memory\n        name: opflex-hostconfig-volume\n      - configMap:\n          items:\n          - key: opflex-agent-config\n            path: local.conf\n          name: aci-containers-config\n        name: opflex-config-volume\n      - name: opflex-server-config-volume\n",
    "errors": []
  },
  {
    "id": "04723",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    aci-containers-config-version: dummy\n    network-plugin: aci-containers\n  name: aci-containers-host\n  namespace: aci-containers-system\nspec:\n  selector:\n    matchLabels:\n      name: aci-containers-host\n      network-plugin: aci-containers\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9612'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aci-containers-host\n        network-plugin: aci-containers\n    spec:\n      containers:\n      - env:\n        - name: KUBERNETES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: TENANT\n          value: csrtest\n        - name: NODE_EPG\n          value: aci-containers-nodes\n        - name: OPFLEX_MODE\n          value: overlay\n        - name: DURATION_WAIT_FOR_NETWORK\n          value: '210'\n        image: noirolabs/aci-containers-host:ci_test\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /status\n            port: 8090\n            scheme: HTTP\n          initialDelaySeconds: 120\n          periodSeconds: 60\n          successThreshold: 1\n          timeoutSeconds: 30\n        name: aci-containers-host\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        - mountPath: /mnt/cni-conf\n          name: cni-conf\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/aci-containers/\n          name: host-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - env:\n        - name: REBOOT_WITH_OVS\n          value: 'true'\n        - name: SSL_MODE\n          value: disabled\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-agent\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/opflex-agent-ovs/conf.d\n          name: opflex-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - /usr/local/bin/launch-opflexserver.sh\n        command:\n        - /bin/sh\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-server\n        ports:\n        - containerPort: 19999\n        - containerPort: 9632\n          name: metrics\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/opflex-server\n          name: opflex-server-config-volume\n        - mountPath: /usr/local/var\n          name: hostvar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - image: noirolabs/cnideploy:6.0.0.0.0ef4718\n        imagePullPolicy: Always\n        name: cnideploy\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n          privileged: false\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: aci-containers-host-agent\n      volumes:\n      - hostPath:\n          path: /var/lib\n        name: cni-bin\n      - hostPath:\n          path: /etc/kubernetes\n        name: cni-conf\n      - hostPath:\n          path: /var\n        name: hostvar\n      - hostPath:\n          path: /run\n        name: hostrun\n      - configMap:\n          items:\n          - key: host-agent-config\n            path: host-agent.conf\n          name: aci-containers-config\n        name: host-config-volume\n      - emptyDir:\n          medium: Memory\n        name: opflex-hostconfig-volume\n      - configMap:\n          items:\n          - key: opflex-agent-config\n            path: local.conf\n          name: aci-containers-config\n        name: opflex-config-volume\n      - name: opflex-server-config-volume\n",
    "errors": []
  },
  {
    "id": "04724",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    aci-containers-config-version: dummy\n    network-plugin: aci-containers\n  name: aci-containers-host\n  namespace: aci-containers-system\nspec:\n  selector:\n    matchLabels:\n      name: aci-containers-host\n      network-plugin: aci-containers\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9612'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aci-containers-host\n        network-plugin: aci-containers\n    spec:\n      containers:\n      - env:\n        - name: KUBERNETES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: TENANT\n          value: csrtest\n        - name: NODE_EPG\n          value: aci-containers-nodes\n        - name: OPFLEX_MODE\n          value: overlay\n        - name: DURATION_WAIT_FOR_NETWORK\n          value: '210'\n        image: noirolabs/aci-containers-host:ci_test\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /status\n            port: 8090\n            scheme: HTTP\n          initialDelaySeconds: 120\n          periodSeconds: 60\n          successThreshold: 1\n          timeoutSeconds: 30\n        name: aci-containers-host\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        - mountPath: /mnt/cni-conf\n          name: cni-conf\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/aci-containers/\n          name: host-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - env:\n        - name: REBOOT_WITH_OVS\n          value: 'true'\n        - name: SSL_MODE\n          value: disabled\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-agent\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/opflex-agent-ovs/conf.d\n          name: opflex-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - /usr/local/bin/launch-opflexserver.sh\n        command:\n        - /bin/sh\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-server\n        ports:\n        - containerPort: 19999\n        - containerPort: 9632\n          name: metrics\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/opflex-server\n          name: opflex-server-config-volume\n        - mountPath: /usr/local/var\n          name: hostvar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - image: noirolabs/cnideploy:6.0.0.0.0ef4718\n        imagePullPolicy: Always\n        name: cnideploy\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: aci-containers-host-agent\n      volumes:\n      - hostPath:\n          path: /var/lib\n        name: cni-bin\n      - hostPath:\n          path: /etc/kubernetes\n        name: cni-conf\n      - hostPath:\n          path: /var\n        name: hostvar\n      - hostPath:\n          path: /run\n        name: hostrun\n      - configMap:\n          items:\n          - key: host-agent-config\n            path: host-agent.conf\n          name: aci-containers-config\n        name: host-config-volume\n      - emptyDir:\n          medium: Memory\n        name: opflex-hostconfig-volume\n      - configMap:\n          items:\n          - key: opflex-agent-config\n            path: local.conf\n          name: aci-containers-config\n        name: opflex-config-volume\n      - name: opflex-server-config-volume\n",
    "errors": []
  },
  {
    "id": "04725",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    aci-containers-config-version: dummy\n    network-plugin: aci-containers\n  name: aci-containers-host\n  namespace: aci-containers-system\nspec:\n  selector:\n    matchLabels:\n      name: aci-containers-host\n      network-plugin: aci-containers\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9612'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aci-containers-host\n        network-plugin: aci-containers\n    spec:\n      containers:\n      - env:\n        - name: KUBERNETES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: TENANT\n          value: csrtest\n        - name: NODE_EPG\n          value: aci-containers-nodes\n        - name: OPFLEX_MODE\n          value: overlay\n        - name: DURATION_WAIT_FOR_NETWORK\n          value: '210'\n        image: noirolabs/aci-containers-host:ci_test\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /status\n            port: 8090\n            scheme: HTTP\n          initialDelaySeconds: 120\n          periodSeconds: 60\n          successThreshold: 1\n          timeoutSeconds: 30\n        name: aci-containers-host\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        - mountPath: /mnt/cni-conf\n          name: cni-conf\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/aci-containers/\n          name: host-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - env:\n        - name: REBOOT_WITH_OVS\n          value: 'true'\n        - name: SSL_MODE\n          value: disabled\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-agent\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/opflex-agent-ovs/conf.d\n          name: opflex-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - /usr/local/bin/launch-opflexserver.sh\n        command:\n        - /bin/sh\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-server\n        ports:\n        - containerPort: 19999\n        - containerPort: 9632\n          name: metrics\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/opflex-server\n          name: opflex-server-config-volume\n        - mountPath: /usr/local/var\n          name: hostvar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - image: noirolabs/cnideploy:6.0.0.0.0ef4718\n        imagePullPolicy: Always\n        name: cnideploy\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: aci-containers-host-agent\n      volumes:\n      - hostPath:\n          path: /var/lib\n        name: cni-bin\n      - hostPath:\n          path: /etc/kubernetes\n        name: cni-conf\n      - hostPath:\n          path: /var\n        name: hostvar\n      - hostPath:\n          path: /run\n        name: hostrun\n      - configMap:\n          items:\n          - key: host-agent-config\n            path: host-agent.conf\n          name: aci-containers-config\n        name: host-config-volume\n      - emptyDir:\n          medium: Memory\n        name: opflex-hostconfig-volume\n      - configMap:\n          items:\n          - key: opflex-agent-config\n            path: local.conf\n          name: aci-containers-config\n        name: opflex-config-volume\n      - name: opflex-server-config-volume\n",
    "errors": []
  },
  {
    "id": "04726",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    aci-containers-config-version: dummy\n    network-plugin: aci-containers\n  name: aci-containers-host\n  namespace: aci-containers-system\nspec:\n  selector:\n    matchLabels:\n      name: aci-containers-host\n      network-plugin: aci-containers\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9612'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aci-containers-host\n        network-plugin: aci-containers\n    spec:\n      containers:\n      - env:\n        - name: KUBERNETES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: TENANT\n          value: csrtest\n        - name: NODE_EPG\n          value: aci-containers-nodes\n        - name: OPFLEX_MODE\n          value: overlay\n        - name: DURATION_WAIT_FOR_NETWORK\n          value: '210'\n        image: noirolabs/aci-containers-host:ci_test\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /status\n            port: 8090\n            scheme: HTTP\n          initialDelaySeconds: 120\n          periodSeconds: 60\n          successThreshold: 1\n          timeoutSeconds: 30\n        name: aci-containers-host\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        - mountPath: /mnt/cni-conf\n          name: cni-conf\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/aci-containers/\n          name: host-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - env:\n        - name: REBOOT_WITH_OVS\n          value: 'true'\n        - name: SSL_MODE\n          value: disabled\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-agent\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/opflex-agent-ovs/conf.d\n          name: opflex-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - /usr/local/bin/launch-opflexserver.sh\n        command:\n        - /bin/sh\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-server\n        ports:\n        - containerPort: 19999\n        - containerPort: 9632\n          name: metrics\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/opflex-server\n          name: opflex-server-config-volume\n        - mountPath: /usr/local/var\n          name: hostvar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - image: noirolabs/cnideploy:6.0.0.0.0ef4718\n        imagePullPolicy: Always\n        name: cnideploy\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: aci-containers-host-agent\n      volumes:\n      - hostPath:\n          path: /var/lib\n        name: cni-bin\n      - hostPath:\n          path: /etc/kubernetes\n        name: cni-conf\n      - hostPath:\n          path: /var\n        name: hostvar\n      - hostPath:\n          path: /run\n        name: hostrun\n      - configMap:\n          items:\n          - key: host-agent-config\n            path: host-agent.conf\n          name: aci-containers-config\n        name: host-config-volume\n      - emptyDir:\n          medium: Memory\n        name: opflex-hostconfig-volume\n      - configMap:\n          items:\n          - key: opflex-agent-config\n            path: local.conf\n          name: aci-containers-config\n        name: opflex-config-volume\n      - name: opflex-server-config-volume\n",
    "errors": []
  },
  {
    "id": "04727",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    aci-containers-config-version: dummy\n    network-plugin: aci-containers\n  name: aci-containers-host\n  namespace: aci-containers-system\nspec:\n  selector:\n    matchLabels:\n      name: aci-containers-host\n      network-plugin: aci-containers\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9612'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aci-containers-host\n        network-plugin: aci-containers\n    spec:\n      containers:\n      - env:\n        - name: KUBERNETES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: TENANT\n          value: csrtest\n        - name: NODE_EPG\n          value: aci-containers-nodes\n        - name: OPFLEX_MODE\n          value: overlay\n        - name: DURATION_WAIT_FOR_NETWORK\n          value: '210'\n        image: noirolabs/aci-containers-host:ci_test\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /status\n            port: 8090\n            scheme: HTTP\n          initialDelaySeconds: 120\n          periodSeconds: 60\n          successThreshold: 1\n          timeoutSeconds: 30\n        name: aci-containers-host\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        - mountPath: /mnt/cni-conf\n          name: cni-conf\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/aci-containers/\n          name: host-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - env:\n        - name: REBOOT_WITH_OVS\n          value: 'true'\n        - name: SSL_MODE\n          value: disabled\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-agent\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/opflex-agent-ovs/conf.d\n          name: opflex-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - /usr/local/bin/launch-opflexserver.sh\n        command:\n        - /bin/sh\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-server\n        ports:\n        - containerPort: 19999\n        - containerPort: 9632\n          name: metrics\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/opflex-server\n          name: opflex-server-config-volume\n        - mountPath: /usr/local/var\n          name: hostvar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - image: noirolabs/cnideploy:6.0.0.0.0ef4718\n        imagePullPolicy: Always\n        name: cnideploy\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: aci-containers-host-agent\n      volumes:\n      - hostPath:\n          path: /var/lib\n        name: cni-bin\n      - hostPath:\n          path: /etc/kubernetes\n        name: cni-conf\n      - hostPath:\n          path: /var\n        name: hostvar\n      - hostPath:\n          path: /run\n        name: hostrun\n      - configMap:\n          items:\n          - key: host-agent-config\n            path: host-agent.conf\n          name: aci-containers-config\n        name: host-config-volume\n      - emptyDir:\n          medium: Memory\n        name: opflex-hostconfig-volume\n      - configMap:\n          items:\n          - key: opflex-agent-config\n            path: local.conf\n          name: aci-containers-config\n        name: opflex-config-volume\n      - name: opflex-server-config-volume\n",
    "errors": []
  },
  {
    "id": "04728",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    aci-containers-config-version: dummy\n    network-plugin: aci-containers\n  name: aci-containers-host\n  namespace: aci-containers-system\nspec:\n  selector:\n    matchLabels:\n      name: aci-containers-host\n      network-plugin: aci-containers\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9612'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aci-containers-host\n        network-plugin: aci-containers\n    spec:\n      containers:\n      - env:\n        - name: KUBERNETES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: TENANT\n          value: csrtest\n        - name: NODE_EPG\n          value: aci-containers-nodes\n        - name: OPFLEX_MODE\n          value: overlay\n        - name: DURATION_WAIT_FOR_NETWORK\n          value: '210'\n        image: noirolabs/aci-containers-host:ci_test\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /status\n            port: 8090\n            scheme: HTTP\n          initialDelaySeconds: 120\n          periodSeconds: 60\n          successThreshold: 1\n          timeoutSeconds: 30\n        name: aci-containers-host\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        - mountPath: /mnt/cni-conf\n          name: cni-conf\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/aci-containers/\n          name: host-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - env:\n        - name: REBOOT_WITH_OVS\n          value: 'true'\n        - name: SSL_MODE\n          value: disabled\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-agent\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/opflex-agent-ovs/conf.d\n          name: opflex-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - /usr/local/bin/launch-opflexserver.sh\n        command:\n        - /bin/sh\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-server\n        ports:\n        - containerPort: 19999\n        - containerPort: 9632\n          name: metrics\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/opflex-server\n          name: opflex-server-config-volume\n        - mountPath: /usr/local/var\n          name: hostvar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - image: noirolabs/cnideploy:6.0.0.0.0ef4718\n        imagePullPolicy: Always\n        name: cnideploy\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: aci-containers-host-agent\n      volumes:\n      - hostPath:\n          path: /var/lib\n        name: cni-bin\n      - hostPath:\n          path: /etc/kubernetes\n        name: cni-conf\n      - hostPath:\n          path: /var\n        name: hostvar\n      - hostPath:\n          path: /run\n        name: hostrun\n      - configMap:\n          items:\n          - key: host-agent-config\n            path: host-agent.conf\n          name: aci-containers-config\n        name: host-config-volume\n      - emptyDir:\n          medium: Memory\n        name: opflex-hostconfig-volume\n      - configMap:\n          items:\n          - key: opflex-agent-config\n            path: local.conf\n          name: aci-containers-config\n        name: opflex-config-volume\n      - name: opflex-server-config-volume\n",
    "errors": []
  },
  {
    "id": "04729",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    aci-containers-config-version: dummy\n    network-plugin: aci-containers\n  name: aci-containers-host\n  namespace: aci-containers-system\nspec:\n  selector:\n    matchLabels:\n      name: aci-containers-host\n      network-plugin: aci-containers\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9612'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aci-containers-host\n        network-plugin: aci-containers\n    spec:\n      containers:\n      - env:\n        - name: KUBERNETES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: TENANT\n          value: csrtest\n        - name: NODE_EPG\n          value: aci-containers-nodes\n        - name: OPFLEX_MODE\n          value: overlay\n        - name: DURATION_WAIT_FOR_NETWORK\n          value: '210'\n        image: noirolabs/aci-containers-host:ci_test\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /status\n            port: 8090\n            scheme: HTTP\n          initialDelaySeconds: 120\n          periodSeconds: 60\n          successThreshold: 1\n          timeoutSeconds: 30\n        name: aci-containers-host\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        - mountPath: /mnt/cni-conf\n          name: cni-conf\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/aci-containers/\n          name: host-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - env:\n        - name: REBOOT_WITH_OVS\n          value: 'true'\n        - name: SSL_MODE\n          value: disabled\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-agent\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/opflex-agent-ovs/conf.d\n          name: opflex-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - /usr/local/bin/launch-opflexserver.sh\n        command:\n        - /bin/sh\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-server\n        ports:\n        - containerPort: 19999\n        - containerPort: 9632\n          name: metrics\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/opflex-server\n          name: opflex-server-config-volume\n        - mountPath: /usr/local/var\n          name: hostvar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - image: noirolabs/cnideploy:6.0.0.0.0ef4718\n        imagePullPolicy: Always\n        name: cnideploy\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: aci-containers-host-agent\n      volumes:\n      - hostPath:\n          path: /var/lib\n        name: cni-bin\n      - hostPath:\n          path: /etc/kubernetes\n        name: cni-conf\n      - hostPath:\n          path: /var\n        name: hostvar\n      - hostPath:\n          path: /run\n        name: hostrun\n      - configMap:\n          items:\n          - key: host-agent-config\n            path: host-agent.conf\n          name: aci-containers-config\n        name: host-config-volume\n      - emptyDir:\n          medium: Memory\n        name: opflex-hostconfig-volume\n      - configMap:\n          items:\n          - key: opflex-agent-config\n            path: local.conf\n          name: aci-containers-config\n        name: opflex-config-volume\n      - name: opflex-server-config-volume\n",
    "errors": []
  },
  {
    "id": "04730",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    aci-containers-config-version: dummy\n    network-plugin: aci-containers\n  name: aci-containers-host\n  namespace: aci-containers-system\nspec:\n  selector:\n    matchLabels:\n      name: aci-containers-host\n      network-plugin: aci-containers\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9612'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aci-containers-host\n        network-plugin: aci-containers\n    spec:\n      containers:\n      - env:\n        - name: KUBERNETES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: TENANT\n          value: csrtest\n        - name: NODE_EPG\n          value: aci-containers-nodes\n        - name: OPFLEX_MODE\n          value: overlay\n        - name: DURATION_WAIT_FOR_NETWORK\n          value: '210'\n        image: noirolabs/aci-containers-host:ci_test\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /status\n            port: 8090\n            scheme: HTTP\n          initialDelaySeconds: 120\n          periodSeconds: 60\n          successThreshold: 1\n          timeoutSeconds: 30\n        name: aci-containers-host\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        - mountPath: /mnt/cni-conf\n          name: cni-conf\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/aci-containers/\n          name: host-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - env:\n        - name: REBOOT_WITH_OVS\n          value: 'true'\n        - name: SSL_MODE\n          value: disabled\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-agent\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/opflex-agent-ovs/conf.d\n          name: opflex-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - /usr/local/bin/launch-opflexserver.sh\n        command:\n        - /bin/sh\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-server\n        ports:\n        - containerPort: 19999\n        - containerPort: 9632\n          name: metrics\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/opflex-server\n          name: opflex-server-config-volume\n        - mountPath: /usr/local/var\n          name: hostvar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - image: noirolabs/cnideploy:6.0.0.0.0ef4718\n        imagePullPolicy: Always\n        name: cnideploy\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: aci-containers-host-agent\n      volumes:\n      - hostPath:\n          path: /var/lib\n        name: cni-bin\n      - hostPath:\n          path: /etc/kubernetes\n        name: cni-conf\n      - hostPath:\n          path: /var\n        name: hostvar\n      - hostPath:\n          path: /run\n        name: hostrun\n      - configMap:\n          items:\n          - key: host-agent-config\n            path: host-agent.conf\n          name: aci-containers-config\n        name: host-config-volume\n      - emptyDir:\n          medium: Memory\n        name: opflex-hostconfig-volume\n      - configMap:\n          items:\n          - key: opflex-agent-config\n            path: local.conf\n          name: aci-containers-config\n        name: opflex-config-volume\n      - name: opflex-server-config-volume\n",
    "errors": []
  },
  {
    "id": "04731",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  labels:\n    aci-containers-config-version: dummy\n    network-plugin: aci-containers\n  name: aci-containers-host\n  namespace: aci-containers-system\nspec:\n  selector:\n    matchLabels:\n      name: aci-containers-host\n      network-plugin: aci-containers\n  template:\n    metadata:\n      annotations:\n        prometheus.io/port: '9612'\n        prometheus.io/scrape: 'true'\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n      labels:\n        name: aci-containers-host\n        network-plugin: aci-containers\n    spec:\n      containers:\n      - env:\n        - name: KUBERNETES_NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        - name: TENANT\n          value: csrtest\n        - name: NODE_EPG\n          value: aci-containers-nodes\n        - name: OPFLEX_MODE\n          value: overlay\n        - name: DURATION_WAIT_FOR_NETWORK\n          value: '210'\n        image: noirolabs/aci-containers-host:ci_test\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 10\n          httpGet:\n            path: /status\n            port: 8090\n            scheme: HTTP\n          initialDelaySeconds: 120\n          periodSeconds: 60\n          successThreshold: 1\n          timeoutSeconds: 30\n        name: aci-containers-host\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        - mountPath: /mnt/cni-conf\n          name: cni-conf\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/aci-containers/\n          name: host-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - env:\n        - name: REBOOT_WITH_OVS\n          value: 'true'\n        - name: SSL_MODE\n          value: disabled\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-agent\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/var\n          name: hostvar\n        - mountPath: /run\n          name: hostrun\n        - mountPath: /usr/local/run\n          name: hostrun\n        - mountPath: /usr/local/etc/opflex-agent-ovs/base-conf.d\n          name: opflex-hostconfig-volume\n        - mountPath: /usr/local/etc/opflex-agent-ovs/conf.d\n          name: opflex-config-volume\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - args:\n        - /usr/local/bin/launch-opflexserver.sh\n        command:\n        - /bin/sh\n        image: noirolabs/opflex:ci_test\n        imagePullPolicy: Always\n        name: opflex-server\n        ports:\n        - containerPort: 19999\n        - containerPort: 9632\n          name: metrics\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/opflex-server\n          name: opflex-server-config-volume\n        - mountPath: /usr/local/var\n          name: hostvar\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - image: noirolabs/cnideploy:6.0.0.0.0ef4718\n        imagePullPolicy: Always\n        name: cnideploy\n        securityContext:\n          capabilities:\n            add: []\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /mnt/cni-bin\n          name: cni-bin\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: aci-containers-host-agent\n      volumes:\n      - hostPath:\n          path: /var/lib\n        name: cni-bin\n      - hostPath:\n          path: /etc/kubernetes\n        name: cni-conf\n      - hostPath:\n          path: /var\n        name: hostvar\n      - hostPath:\n          path: /run\n        name: hostrun\n      - configMap:\n          items:\n          - key: host-agent-config\n            path: host-agent.conf\n          name: aci-containers-config\n        name: host-config-volume\n      - emptyDir:\n          medium: Memory\n        name: opflex-hostconfig-volume\n      - configMap:\n          items:\n          - key: opflex-agent-config\n            path: local.conf\n          name: aci-containers-config\n        name: opflex-config-volume\n      - name: opflex-server-config-volume\n",
    "errors": []
  },
  {
    "id": "04732",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5267\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04733",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5267\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04734",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5267\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04735",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5267\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04736",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-5267\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04737",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod\n  labels:\n    app: myapp\nspec:\n  containers:\n  - name: nginx-container\n    image: nginx:stable\n    resources:\n      limits:\n        memory: 128Mi\n        cpu: 500m\n      requests:\n        cpu: 100m\n        memory: 128Mi\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04738",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod\n  labels:\n    app: myapp\nspec:\n  containers:\n  - name: nginx-container\n    image: nginx:stable\n    resources:\n      limits:\n        memory: 128Mi\n        cpu: 500m\n      requests:\n        cpu: 100m\n        memory: 128Mi\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04739",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod\n  labels:\n    app: myapp\nspec:\n  containers:\n  - name: nginx-container\n    image: nginx:stable\n    resources:\n      limits:\n        memory: 128Mi\n        cpu: 500m\n      requests:\n        cpu: 100m\n        memory: 128Mi\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04740",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod\n  labels:\n    app: myapp\nspec:\n  containers:\n  - name: nginx-container\n    image: nginx:stable\n    resources:\n      limits:\n        memory: 128Mi\n        cpu: 500m\n      requests:\n        cpu: 100m\n        memory: 128Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04741",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20210204-de2fa22b93\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04742",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20210204-de2fa22b93\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04743",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20210204-de2fa22b93\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04744",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: needs-rebase\n  labels:\n    app: needs-rebase\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: needs-rebase\n  template:\n    metadata:\n      labels:\n        app: needs-rebase\n    spec:\n      containers:\n      - name: needs-rebase\n        image: gcr.io/k8s-prow/needs-rebase:v20210204-de2fa22b93\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: hmac\n          mountPath: /etc/webhook\n          readOnly: true\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: hmac\n        secret:\n          secretName: hmac-token\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "04745",
    "policy_id": "env_var_secret",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio\n  labels:\n    app: minio\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      containers:\n      - name: minio\n        image: gcr.io/ml-pipeline/minio:RELEASE.2019-08-14T20-37-41Z-license-compliance\n        args:\n        - gateway\n        - gcs\n        - $(GCP_PROJECT_ID)\n        env:\n        - name: GCP_PROJECT_ID\n          valueFrom:\n            configMapKeyRef:\n              name: pipeline-install-config\n              key: gcsProjectId\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: minio-secret-key-secret\n              key: minio_secret_key\n        ports:\n        - containerPort: 9000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04746",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio\n  labels:\n    app: minio\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      containers:\n      - name: minio\n        image: gcr.io/ml-pipeline/minio:RELEASE.2019-08-14T20-37-41Z-license-compliance\n        args:\n        - gateway\n        - gcs\n        - $(GCP_PROJECT_ID)\n        env:\n        - name: GCP_PROJECT_ID\n          valueFrom:\n            configMapKeyRef:\n              name: pipeline-install-config\n              key: gcsProjectId\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: minio-secret-key-secret\n              key: minio_secret_key\n        ports:\n        - containerPort: 9000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04747",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio\n  labels:\n    app: minio\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      containers:\n      - name: minio\n        image: gcr.io/ml-pipeline/minio:RELEASE.2019-08-14T20-37-41Z-license-compliance\n        args:\n        - gateway\n        - gcs\n        - $(GCP_PROJECT_ID)\n        env:\n        - name: GCP_PROJECT_ID\n          valueFrom:\n            configMapKeyRef:\n              name: pipeline-install-config\n              key: gcsProjectId\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: minio-secret-key-secret\n              key: minio_secret_key\n        ports:\n        - containerPort: 9000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04748",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio\n  labels:\n    app: minio\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      containers:\n      - name: minio\n        image: gcr.io/ml-pipeline/minio:RELEASE.2019-08-14T20-37-41Z-license-compliance\n        args:\n        - gateway\n        - gcs\n        - $(GCP_PROJECT_ID)\n        env:\n        - name: GCP_PROJECT_ID\n          valueFrom:\n            configMapKeyRef:\n              name: pipeline-install-config\n              key: gcsProjectId\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: minio-secret-key-secret\n              key: minio_secret_key\n        ports:\n        - containerPort: 9000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04749",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio\n  labels:\n    app: minio\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      containers:\n      - name: minio\n        image: gcr.io/ml-pipeline/minio:RELEASE.2019-08-14T20-37-41Z-license-compliance\n        args:\n        - gateway\n        - gcs\n        - $(GCP_PROJECT_ID)\n        env:\n        - name: GCP_PROJECT_ID\n          valueFrom:\n            configMapKeyRef:\n              name: pipeline-install-config\n              key: gcsProjectId\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          valueFrom:\n            secretKeyRef:\n              name: minio-secret-key-secret\n              key: minio_secret_key\n        ports:\n        - containerPort: 9000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04750",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"prod-cron-cancel-booking\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04751",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"prod-cron-cancel-booking\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04752",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"prod-cron-cancel-booking\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04753",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"prod-cron-cancel-booking\" namespace: \"\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04754",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9520\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04755",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9520\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04756",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9520\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04757",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9520\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04758",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-9520\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04759",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: accountapi-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: accountapi\n  template:\n    metadata:\n      labels:\n        app: accountapi\n    spec:\n      containers:\n      - name: accountapi-container\n        image: gcr.io/staffjoy-prod/accountapi:VERSION\n        ports:\n        - containerPort: 80\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 80\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 80\n        env:\n        - name: DEPLOY\n          value: VERSION\n        - name: ENV\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: sentry\n              key: dsn\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04760",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: accountapi-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: accountapi\n  template:\n    metadata:\n      labels:\n        app: accountapi\n    spec:\n      containers:\n      - name: accountapi-container\n        image: gcr.io/staffjoy-prod/accountapi:VERSION\n        ports:\n        - containerPort: 80\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 80\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 80\n        env:\n        - name: DEPLOY\n          value: VERSION\n        - name: ENV\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: sentry\n              key: dsn\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04761",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: accountapi-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: accountapi\n  template:\n    metadata:\n      labels:\n        app: accountapi\n    spec:\n      containers:\n      - name: accountapi-container\n        image: gcr.io/staffjoy-prod/accountapi:VERSION\n        ports:\n        - containerPort: 80\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 80\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 80\n        env:\n        - name: DEPLOY\n          value: VERSION\n        - name: ENV\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: sentry\n              key: dsn\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04762",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: accountapi-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: accountapi\n  template:\n    metadata:\n      labels:\n        app: accountapi\n    spec:\n      containers:\n      - name: accountapi-container\n        image: gcr.io/staffjoy-prod/accountapi:VERSION\n        ports:\n        - containerPort: 80\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 80\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 80\n        env:\n        - name: DEPLOY\n          value: VERSION\n        - name: ENV\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: sentry\n              key: dsn\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04763",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: smarter-device-manager\n  namespace: kube-system\n  labels:\n    name: smarter-device-manager\n    role: agent\nspec:\n  selector:\n    matchLabels:\n      name: smarter-device-manager\n  template:\n    metadata:\n      labels:\n        name: smarter-device-manager\n      annotations:\n        node.kubernetes.io/bootstrap-checkpoint: 'true'\n    spec:\n      containers:\n      - name: smarter-device-manager\n        image: registry.gitlab.com/arm-research/smarter/smarter-device-manager:v1.1.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          readOnlyRootFilesystem: true\n          privileged: false\n          runAsNonRoot: true\n        resources:\n          limits:\n            cpu: 100m\n            memory: 15Mi\n          requests:\n            cpu: 10m\n            memory: 15Mi\n        volumeMounts:\n        - name: device-plugin\n          mountPath: /var/lib/kubelet/device-plugins\n        - name: dev-dir\n          mountPath: /dev\n        - name: sys-dir\n          mountPath: /sys\n        - name: config\n          mountPath: /root/config\n      volumes:\n      - name: device-plugin\n        hostPath:\n          path: /var/lib/kubelet/device-plugins\n      - name: dev-dir\n        hostPath:\n          path: /dev\n      - name: sys-dir\n        hostPath:\n          path: /sys\n      - name: config\n        configMap:\n          name: smarter-device-manager\n",
    "errors": []
  },
  {
    "id": "04764",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: smarter-device-manager\n  namespace: kube-system\n  labels:\n    name: smarter-device-manager\n    role: agent\nspec:\n  selector:\n    matchLabels:\n      name: smarter-device-manager\n  template:\n    metadata:\n      labels:\n        name: smarter-device-manager\n      annotations:\n        node.kubernetes.io/bootstrap-checkpoint: 'true'\n    spec:\n      containers:\n      - name: smarter-device-manager\n        image: registry.gitlab.com/arm-research/smarter/smarter-device-manager:v1.1.2\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          runAsNonRoot: true\n          privileged: false\n          readOnlyRootFilesystem: true\n        resources:\n          limits:\n            cpu: 100m\n            memory: 15Mi\n          requests:\n            cpu: 10m\n            memory: 15Mi\n        volumeMounts:\n        - name: device-plugin\n          mountPath: /var/lib/kubelet/device-plugins\n        - name: dev-dir\n          mountPath: /dev\n        - name: sys-dir\n          mountPath: /sys\n        - name: config\n          mountPath: /root/config\n      volumes:\n      - name: device-plugin\n        hostPath:\n          path: /var/lib/kubelet/device-plugins\n      - name: dev-dir\n        hostPath:\n          path: /dev\n      - name: sys-dir\n        hostPath:\n          path: /sys\n      - name: config\n        configMap:\n          name: smarter-device-manager\n",
    "errors": []
  },
  {
    "id": "04765",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: siegetest\nspec:\n  replicas: 1\n  selector:\n    name: siegetest\n    version: 1.0.0\n  template:\n    metadata:\n      labels:\n        name: siegetest\n        version: 1.0.0\n    spec:\n      containers:\n      - name: siegetest\n        image: ipedrazas/siegetest:1.0.0\n        ports:\n        - containerPort: 8080\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04766",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: siegetest\nspec:\n  replicas: 1\n  selector:\n    name: siegetest\n    version: 1.0.0\n  template:\n    metadata:\n      labels:\n        name: siegetest\n        version: 1.0.0\n    spec:\n      containers:\n      - name: siegetest\n        image: ipedrazas/siegetest:1.0.0\n        ports:\n        - containerPort: 8080\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04767",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: siegetest\nspec:\n  replicas: 1\n  selector:\n    name: siegetest\n    version: 1.0.0\n  template:\n    metadata:\n      labels:\n        name: siegetest\n        version: 1.0.0\n    spec:\n      containers:\n      - name: siegetest\n        image: ipedrazas/siegetest:1.0.0\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04768",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: siegetest\nspec:\n  replicas: 1\n  selector:\n    name: siegetest\n    version: 1.0.0\n  template:\n    metadata:\n      labels:\n        name: siegetest\n        version: 1.0.0\n    spec:\n      containers:\n      - name: siegetest\n        image: ipedrazas/siegetest:1.0.0\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04769",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-batch\nspec:\n  containers:\n  - name: test-batch\n    image: '{{ test_batch_image.image }}:stable'\n    env:\n    - name: POD_IP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.podIP\n    - name: HAIL_TOKEN_FILE\n      value: /test-jwt/jwt\n    - name: BATCH_URL\n      value: http://batch.{{ default_ns.name }}\n    volumeMounts:\n    - mountPath: /test-jwt\n      readOnly: true\n      name: test-jwt\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: test-jwt\n    secret:\n      secretName: test-jwt\n",
    "errors": []
  },
  {
    "id": "04770",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-batch\nspec:\n  containers:\n  - name: test-batch\n    image: '{{ test_batch_image.image }}:stable'\n    env:\n    - name: POD_IP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.podIP\n    - name: HAIL_TOKEN_FILE\n      value: /test-jwt/jwt\n    - name: BATCH_URL\n      value: http://batch.{{ default_ns.name }}\n    volumeMounts:\n    - mountPath: /test-jwt\n      readOnly: true\n      name: test-jwt\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: test-jwt\n    secret:\n      secretName: test-jwt\n",
    "errors": []
  },
  {
    "id": "04771",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-batch\nspec:\n  containers:\n  - name: test-batch\n    image: '{{ test_batch_image.image }}:stable'\n    env:\n    - name: POD_IP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.podIP\n    - name: HAIL_TOKEN_FILE\n      value: /test-jwt/jwt\n    - name: BATCH_URL\n      value: http://batch.{{ default_ns.name }}\n    volumeMounts:\n    - mountPath: /test-jwt\n      readOnly: true\n      name: test-jwt\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n  volumes:\n  - name: test-jwt\n    secret:\n      secretName: test-jwt\n",
    "errors": []
  },
  {
    "id": "04772",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-batch\nspec:\n  containers:\n  - name: test-batch\n    image: '{{ test_batch_image.image }}:stable'\n    env:\n    - name: POD_IP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.podIP\n    - name: HAIL_TOKEN_FILE\n      value: /test-jwt/jwt\n    - name: BATCH_URL\n      value: http://batch.{{ default_ns.name }}\n    volumeMounts:\n    - mountPath: /test-jwt\n      readOnly: true\n      name: test-jwt\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  volumes:\n  - name: test-jwt\n    secret:\n      secretName: test-jwt\n",
    "errors": []
  },
  {
    "id": "04773",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-batch\nspec:\n  containers:\n  - name: test-batch\n    image: '{{ test_batch_image.image }}:stable'\n    env:\n    - name: POD_IP\n      valueFrom:\n        fieldRef:\n          fieldPath: status.podIP\n    - name: HAIL_TOKEN_FILE\n      value: /test-jwt/jwt\n    - name: BATCH_URL\n      value: http://batch.{{ default_ns.name }}\n    volumeMounts:\n    - mountPath: /test-jwt\n      readOnly: true\n      name: test-jwt\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n  volumes:\n  - name: test-jwt\n    secret:\n      secretName: test-jwt\n",
    "errors": []
  },
  {
    "id": "04774",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-keras-api-connection-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04775",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-keras-api-connection-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04776",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-keras-api-connection-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04777",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-keras-api-connection-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04778",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-keras-api-connection-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04779",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-keras-api-connection-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04780",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-keras-api-connection-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04781",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-keras-api-connection-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04782",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-keras-api-connection-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04783",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-keras-api-connection-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04784",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"tf-nightly-keras-api-connection-v3-8\" namespace: \"automated\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04785",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lockvalidation-dpl\n  namespace: kube-lock\n  labels:\n    app: lockvalidation\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lockvalidation\n  template:\n    metadata:\n      labels:\n        app: lockvalidation\n    spec:\n      serviceAccountName: lockvalidation-sa\n      containers:\n      - name: lockvalidation\n        image: pkotas/lockvalidation:devel\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: webhook-certs\n          mountPath: /etc/lockvalidation/cert\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: webhook-certs\n        secret:\n          secretName: lockvalidation-crt\n",
    "errors": []
  },
  {
    "id": "04786",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lockvalidation-dpl\n  namespace: kube-lock\n  labels:\n    app: lockvalidation\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lockvalidation\n  template:\n    metadata:\n      labels:\n        app: lockvalidation\n    spec:\n      serviceAccountName: lockvalidation-sa\n      containers:\n      - name: lockvalidation\n        image: pkotas/lockvalidation:devel\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: webhook-certs\n          mountPath: /etc/lockvalidation/cert\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: webhook-certs\n        secret:\n          secretName: lockvalidation-crt\n",
    "errors": []
  },
  {
    "id": "04787",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lockvalidation-dpl\n  namespace: kube-lock\n  labels:\n    app: lockvalidation\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lockvalidation\n  template:\n    metadata:\n      labels:\n        app: lockvalidation\n    spec:\n      serviceAccountName: lockvalidation-sa\n      containers:\n      - name: lockvalidation\n        image: pkotas/lockvalidation:devel\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: webhook-certs\n          mountPath: /etc/lockvalidation/cert\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: webhook-certs\n        secret:\n          secretName: lockvalidation-crt\n",
    "errors": []
  },
  {
    "id": "04788",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lockvalidation-dpl\n  namespace: kube-lock\n  labels:\n    app: lockvalidation\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lockvalidation\n  template:\n    metadata:\n      labels:\n        app: lockvalidation\n    spec:\n      serviceAccountName: lockvalidation-sa\n      containers:\n      - name: lockvalidation\n        image: pkotas/lockvalidation:devel\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: webhook-certs\n          mountPath: /etc/lockvalidation/cert\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: webhook-certs\n        secret:\n          secretName: lockvalidation-crt\n",
    "errors": []
  },
  {
    "id": "04789",
    "policy_id": "env_var_secret",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jx-pipelines-visualizer\n  labels:\n    app.kubernetes.io/name: jx-pipelines-visualizer\n    app.kubernetes.io/instance: jx-pipelines-visualizer\n    helm.sh/chart: jx-pipelines-visualizer-1.3.2\n    app.kubernetes.io/version: latest\n    app.kubernetes.io/managed-by: Helm\n    gitops.jenkins-x.io/pipeline: namespaces\n  namespace: jx\n  annotations:\n    wave.pusher.com/update-on-config-change: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: jx-pipelines-visualizer\n      app.kubernetes.io/instance: jx-pipelines-visualizer\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: jx-pipelines-visualizer\n        app.kubernetes.io/instance: jx-pipelines-visualizer\n        helm.sh/chart: jx-pipelines-visualizer-1.3.2\n        app.kubernetes.io/version: latest\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      containers:\n      - name: jx-pipelines-visualizer\n        image: gcr.io/jenkinsxio/jx-pipelines-visualizer:1.3.2\n        args:\n        - -namespace\n        - jx\n        - -resync-interval\n        - 60s\n        - -archived-logs-url-template\n        - s3://logs-jenkinsx-20210421162444587500000003/jenkins-x/logs/{{.Owner}}/{{.Repository}}/{{if\n          hasPrefix .Branch \"pr\"}}{{.Branch | upper}}{{else}}{{.Branch}}{{end}}/{{.Build}}.log\n        - -archived-pipelines-url-template\n        - s3://logs-jenkinsx-20210421162444587500000003/jenkins-x/logs/{{.Owner}}/{{.Repository}}/{{if\n          hasPrefix .Branch \"pr\"}}{{.Branch | upper}}{{else}}{{.Branch}}{{end}}/{{.Build}}.yaml\n        - -archived-pipelineruns-url-template\n        - s3://logs-jenkinsx-20210421162444587500000003/jenkins-x/pipelineruns/{{.Namespace}}/{{.Name}}.yaml\n        - -pipeline-trace-url-template\n        - http://grafana-jx-observability.18.134.92.246.nip.io/explore?left=%5B%22now%22,%22now%22,%22Tempo%22,%7B%22query%22:%22{{.TraceID}}%22%7D%5D\n        - -log-level\n        - INFO\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /home/jenkins\n        - name: GIT_SECRET_MOUNT_PATH\n          valueFrom:\n            secretKeyRef:\n              name: tekton-git\n              key: git_secret_mount_path\n        - name: AWS_REGION\n          value: eu-west-2\n        ports:\n        - name: http\n          containerPort: 8080\n        livenessProbe:\n          tcpSocket:\n            port: http\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n        volumeMounts:\n        - mountPath: /secrets/git\n          name: secrets-git\n        resources:\n          limits:\n            cpu: '1'\n            memory: 512M\n          requests:\n            cpu: '0.2'\n            memory: 128M\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      securityContext:\n        fsGroup: 1000\n      serviceAccountName: jx-pipelines-visualizer\n      volumes:\n      - name: secrets-git\n        secret:\n          defaultMode: 420\n          secretName: tekton-git\n",
    "errors": []
  },
  {
    "id": "04790",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jx-pipelines-visualizer\n  labels:\n    app.kubernetes.io/name: jx-pipelines-visualizer\n    app.kubernetes.io/instance: jx-pipelines-visualizer\n    helm.sh/chart: jx-pipelines-visualizer-1.3.2\n    app.kubernetes.io/version: latest\n    app.kubernetes.io/managed-by: Helm\n    gitops.jenkins-x.io/pipeline: namespaces\n  namespace: jx\n  annotations:\n    wave.pusher.com/update-on-config-change: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: jx-pipelines-visualizer\n      app.kubernetes.io/instance: jx-pipelines-visualizer\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: jx-pipelines-visualizer\n        app.kubernetes.io/instance: jx-pipelines-visualizer\n        helm.sh/chart: jx-pipelines-visualizer-1.3.2\n        app.kubernetes.io/version: latest\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      containers:\n      - name: jx-pipelines-visualizer\n        image: gcr.io/jenkinsxio/jx-pipelines-visualizer:1.3.2\n        args:\n        - -namespace\n        - jx\n        - -resync-interval\n        - 60s\n        - -archived-logs-url-template\n        - s3://logs-jenkinsx-20210421162444587500000003/jenkins-x/logs/{{.Owner}}/{{.Repository}}/{{if\n          hasPrefix .Branch \"pr\"}}{{.Branch | upper}}{{else}}{{.Branch}}{{end}}/{{.Build}}.log\n        - -archived-pipelines-url-template\n        - s3://logs-jenkinsx-20210421162444587500000003/jenkins-x/logs/{{.Owner}}/{{.Repository}}/{{if\n          hasPrefix .Branch \"pr\"}}{{.Branch | upper}}{{else}}{{.Branch}}{{end}}/{{.Build}}.yaml\n        - -archived-pipelineruns-url-template\n        - s3://logs-jenkinsx-20210421162444587500000003/jenkins-x/pipelineruns/{{.Namespace}}/{{.Name}}.yaml\n        - -pipeline-trace-url-template\n        - http://grafana-jx-observability.18.134.92.246.nip.io/explore?left=%5B%22now%22,%22now%22,%22Tempo%22,%7B%22query%22:%22{{.TraceID}}%22%7D%5D\n        - -log-level\n        - INFO\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /home/jenkins\n        - name: GIT_SECRET_MOUNT_PATH\n          valueFrom:\n            secretKeyRef:\n              name: tekton-git\n              key: git_secret_mount_path\n        - name: AWS_REGION\n          value: eu-west-2\n        ports:\n        - name: http\n          containerPort: 8080\n        livenessProbe:\n          tcpSocket:\n            port: http\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n        volumeMounts:\n        - mountPath: /secrets/git\n          name: secrets-git\n        resources:\n          limits:\n            cpu: '1'\n            memory: 512M\n          requests:\n            cpu: '0.2'\n            memory: 128M\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      securityContext:\n        fsGroup: 1000\n      serviceAccountName: jx-pipelines-visualizer\n      volumes:\n      - name: secrets-git\n        secret:\n          defaultMode: 420\n          secretName: tekton-git\n",
    "errors": []
  },
  {
    "id": "04791",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jx-pipelines-visualizer\n  labels:\n    app.kubernetes.io/name: jx-pipelines-visualizer\n    app.kubernetes.io/instance: jx-pipelines-visualizer\n    helm.sh/chart: jx-pipelines-visualizer-1.3.2\n    app.kubernetes.io/version: latest\n    app.kubernetes.io/managed-by: Helm\n    gitops.jenkins-x.io/pipeline: namespaces\n  namespace: jx\n  annotations:\n    wave.pusher.com/update-on-config-change: 'true'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: jx-pipelines-visualizer\n      app.kubernetes.io/instance: jx-pipelines-visualizer\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: jx-pipelines-visualizer\n        app.kubernetes.io/instance: jx-pipelines-visualizer\n        helm.sh/chart: jx-pipelines-visualizer-1.3.2\n        app.kubernetes.io/version: latest\n        app.kubernetes.io/managed-by: Helm\n    spec:\n      containers:\n      - name: jx-pipelines-visualizer\n        image: gcr.io/jenkinsxio/jx-pipelines-visualizer:1.3.2\n        args:\n        - -namespace\n        - jx\n        - -resync-interval\n        - 60s\n        - -archived-logs-url-template\n        - s3://logs-jenkinsx-20210421162444587500000003/jenkins-x/logs/{{.Owner}}/{{.Repository}}/{{if\n          hasPrefix .Branch \"pr\"}}{{.Branch | upper}}{{else}}{{.Branch}}{{end}}/{{.Build}}.log\n        - -archived-pipelines-url-template\n        - s3://logs-jenkinsx-20210421162444587500000003/jenkins-x/logs/{{.Owner}}/{{.Repository}}/{{if\n          hasPrefix .Branch \"pr\"}}{{.Branch | upper}}{{else}}{{.Branch}}{{end}}/{{.Build}}.yaml\n        - -archived-pipelineruns-url-template\n        - s3://logs-jenkinsx-20210421162444587500000003/jenkins-x/pipelineruns/{{.Namespace}}/{{.Name}}.yaml\n        - -pipeline-trace-url-template\n        - http://grafana-jx-observability.18.134.92.246.nip.io/explore?left=%5B%22now%22,%22now%22,%22Tempo%22,%7B%22query%22:%22{{.TraceID}}%22%7D%5D\n        - -log-level\n        - INFO\n        env:\n        - name: XDG_CONFIG_HOME\n          value: /home/jenkins\n        - name: GIT_SECRET_MOUNT_PATH\n          valueFrom:\n            secretKeyRef:\n              name: tekton-git\n              key: git_secret_mount_path\n        - name: AWS_REGION\n          value: eu-west-2\n        ports:\n        - name: http\n          containerPort: 8080\n        livenessProbe:\n          tcpSocket:\n            port: http\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: http\n        volumeMounts:\n        - mountPath: /secrets/git\n          name: secrets-git\n        resources:\n          limits:\n            cpu: '1'\n            memory: 512M\n          requests:\n            cpu: '0.2'\n            memory: 128M\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      securityContext:\n        fsGroup: 1000\n      serviceAccountName: jx-pipelines-visualizer\n      volumes:\n      - name: secrets-git\n        secret:\n          defaultMode: 420\n          secretName: tekton-git\n",
    "errors": []
  },
  {
    "id": "04792",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azurefile-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azurefile-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azurefile-controller\n    spec:\n      serviceAccountName: csi-azurefile-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v2.1.0\n        args:\n        - -v=2\n        - --csi-address=$(ADDRESS)\n        - --leader-election\n        - --timeout=300s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v2.2.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=120s\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v3.0.3\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.1.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - -handle-volume-inuse-error=false\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.2.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29612\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: azurefile\n        image: mcr.microsoft.com/k8s/csi/azurefile-csi:v1.1.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29614\n        ports:\n        - containerPort: 29612\n          name: healthz\n          protocol: TCP\n        - containerPort: 29614\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        - mountPath: /var/lib/waagent/ManagedIdentity-Settings\n          readOnly: true\n          name: msi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: Directory\n      - name: msi\n        hostPath:\n          path: /var/lib/waagent/ManagedIdentity-Settings\n",
    "errors": []
  },
  {
    "id": "04793",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azurefile-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azurefile-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azurefile-controller\n    spec:\n      serviceAccountName: csi-azurefile-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v2.1.0\n        args:\n        - -v=2\n        - --csi-address=$(ADDRESS)\n        - --leader-election\n        - --timeout=300s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v2.2.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=120s\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v3.0.3\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.1.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - -handle-volume-inuse-error=false\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.2.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29612\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: azurefile\n        image: mcr.microsoft.com/k8s/csi/azurefile-csi:v1.1.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29614\n        ports:\n        - containerPort: 29612\n          name: healthz\n          protocol: TCP\n        - containerPort: 29614\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        - mountPath: /var/lib/waagent/ManagedIdentity-Settings\n          readOnly: true\n          name: msi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: Directory\n      - name: msi\n        hostPath:\n          path: /var/lib/waagent/ManagedIdentity-Settings\n",
    "errors": []
  },
  {
    "id": "04794",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azurefile-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azurefile-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azurefile-controller\n    spec:\n      serviceAccountName: csi-azurefile-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v2.1.0\n        args:\n        - -v=2\n        - --csi-address=$(ADDRESS)\n        - --leader-election\n        - --timeout=300s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v2.2.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=120s\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v3.0.3\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.1.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - -handle-volume-inuse-error=false\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.2.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29612\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: azurefile\n        image: mcr.microsoft.com/k8s/csi/azurefile-csi:v1.1.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29614\n        ports:\n        - containerPort: 29612\n          name: healthz\n          protocol: TCP\n        - containerPort: 29614\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        - mountPath: /var/lib/waagent/ManagedIdentity-Settings\n          readOnly: true\n          name: msi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: Directory\n      - name: msi\n        hostPath:\n          path: /var/lib/waagent/ManagedIdentity-Settings\n",
    "errors": []
  },
  {
    "id": "04795",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azurefile-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azurefile-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azurefile-controller\n    spec:\n      serviceAccountName: csi-azurefile-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v2.1.0\n        args:\n        - -v=2\n        - --csi-address=$(ADDRESS)\n        - --leader-election\n        - --timeout=300s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v2.2.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=120s\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v3.0.3\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.1.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - -handle-volume-inuse-error=false\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.2.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29612\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: azurefile\n        image: mcr.microsoft.com/k8s/csi/azurefile-csi:v1.1.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29614\n        ports:\n        - containerPort: 29612\n          name: healthz\n          protocol: TCP\n        - containerPort: 29614\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        - mountPath: /var/lib/waagent/ManagedIdentity-Settings\n          readOnly: true\n          name: msi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: Directory\n      - name: msi\n        hostPath:\n          path: /var/lib/waagent/ManagedIdentity-Settings\n",
    "errors": []
  },
  {
    "id": "04796",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azurefile-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azurefile-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azurefile-controller\n    spec:\n      serviceAccountName: csi-azurefile-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v2.1.0\n        args:\n        - -v=2\n        - --csi-address=$(ADDRESS)\n        - --leader-election\n        - --timeout=300s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v2.2.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=120s\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v3.0.3\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.1.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - -handle-volume-inuse-error=false\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.2.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29612\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: azurefile\n        image: mcr.microsoft.com/k8s/csi/azurefile-csi:v1.1.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29614\n        ports:\n        - containerPort: 29612\n          name: healthz\n          protocol: TCP\n        - containerPort: 29614\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        - mountPath: /var/lib/waagent/ManagedIdentity-Settings\n          readOnly: true\n          name: msi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: Directory\n      - name: msi\n        hostPath:\n          path: /var/lib/waagent/ManagedIdentity-Settings\n",
    "errors": []
  },
  {
    "id": "04797",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azurefile-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azurefile-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azurefile-controller\n    spec:\n      serviceAccountName: csi-azurefile-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v2.1.0\n        args:\n        - -v=2\n        - --csi-address=$(ADDRESS)\n        - --leader-election\n        - --timeout=300s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v2.2.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=120s\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v3.0.3\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.1.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - -handle-volume-inuse-error=false\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.2.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29612\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: azurefile\n        image: mcr.microsoft.com/k8s/csi/azurefile-csi:v1.1.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29614\n        ports:\n        - containerPort: 29612\n          name: healthz\n          protocol: TCP\n        - containerPort: 29614\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        - mountPath: /var/lib/waagent/ManagedIdentity-Settings\n          readOnly: true\n          name: msi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: Directory\n      - name: msi\n        hostPath:\n          path: /var/lib/waagent/ManagedIdentity-Settings\n",
    "errors": []
  },
  {
    "id": "04798",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azurefile-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azurefile-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azurefile-controller\n    spec:\n      serviceAccountName: csi-azurefile-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v2.1.0\n        args:\n        - -v=2\n        - --csi-address=$(ADDRESS)\n        - --leader-election\n        - --timeout=300s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v2.2.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=120s\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v3.0.3\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.1.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - -handle-volume-inuse-error=false\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.2.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29612\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: azurefile\n        image: mcr.microsoft.com/k8s/csi/azurefile-csi:v1.1.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29614\n        ports:\n        - containerPort: 29612\n          name: healthz\n          protocol: TCP\n        - containerPort: 29614\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        - mountPath: /var/lib/waagent/ManagedIdentity-Settings\n          readOnly: true\n          name: msi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: Directory\n      - name: msi\n        hostPath:\n          path: /var/lib/waagent/ManagedIdentity-Settings\n",
    "errors": []
  },
  {
    "id": "04799",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azurefile-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azurefile-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azurefile-controller\n    spec:\n      serviceAccountName: csi-azurefile-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v2.1.0\n        args:\n        - -v=2\n        - --csi-address=$(ADDRESS)\n        - --leader-election\n        - --timeout=300s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v2.2.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=120s\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v3.0.3\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.1.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - -handle-volume-inuse-error=false\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.2.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29612\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: azurefile\n        image: mcr.microsoft.com/k8s/csi/azurefile-csi:v1.1.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29614\n        ports:\n        - containerPort: 29612\n          name: healthz\n          protocol: TCP\n        - containerPort: 29614\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        - mountPath: /var/lib/waagent/ManagedIdentity-Settings\n          readOnly: true\n          name: msi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: Directory\n      - name: msi\n        hostPath:\n          path: /var/lib/waagent/ManagedIdentity-Settings\n",
    "errors": []
  },
  {
    "id": "04800",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azurefile-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azurefile-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azurefile-controller\n    spec:\n      serviceAccountName: csi-azurefile-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v2.1.0\n        args:\n        - -v=2\n        - --csi-address=$(ADDRESS)\n        - --leader-election\n        - --timeout=300s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v2.2.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=120s\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v3.0.3\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.1.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - -handle-volume-inuse-error=false\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.2.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29612\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: azurefile\n        image: mcr.microsoft.com/k8s/csi/azurefile-csi:v1.1.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29614\n        ports:\n        - containerPort: 29612\n          name: healthz\n          protocol: TCP\n        - containerPort: 29614\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        - mountPath: /var/lib/waagent/ManagedIdentity-Settings\n          readOnly: true\n          name: msi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: Directory\n      - name: msi\n        hostPath:\n          path: /var/lib/waagent/ManagedIdentity-Settings\n",
    "errors": []
  },
  {
    "id": "04801",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azurefile-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azurefile-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azurefile-controller\n    spec:\n      serviceAccountName: csi-azurefile-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v2.1.0\n        args:\n        - -v=2\n        - --csi-address=$(ADDRESS)\n        - --leader-election\n        - --timeout=300s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v2.2.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=120s\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v3.0.3\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.1.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - -handle-volume-inuse-error=false\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.2.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29612\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: azurefile\n        image: mcr.microsoft.com/k8s/csi/azurefile-csi:v1.1.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29614\n        ports:\n        - containerPort: 29612\n          name: healthz\n          protocol: TCP\n        - containerPort: 29614\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        - mountPath: /var/lib/waagent/ManagedIdentity-Settings\n          readOnly: true\n          name: msi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: Directory\n      - name: msi\n        hostPath:\n          path: /var/lib/waagent/ManagedIdentity-Settings\n",
    "errors": []
  },
  {
    "id": "04802",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azurefile-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azurefile-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azurefile-controller\n    spec:\n      serviceAccountName: csi-azurefile-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v2.1.0\n        args:\n        - -v=2\n        - --csi-address=$(ADDRESS)\n        - --leader-election\n        - --timeout=300s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v2.2.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=120s\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v3.0.3\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.1.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - -handle-volume-inuse-error=false\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.2.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29612\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: azurefile\n        image: mcr.microsoft.com/k8s/csi/azurefile-csi:v1.1.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29614\n        ports:\n        - containerPort: 29612\n          name: healthz\n          protocol: TCP\n        - containerPort: 29614\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        - mountPath: /var/lib/waagent/ManagedIdentity-Settings\n          readOnly: true\n          name: msi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: Directory\n      - name: msi\n        hostPath:\n          path: /var/lib/waagent/ManagedIdentity-Settings\n",
    "errors": []
  },
  {
    "id": "04803",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: csi-azurefile-controller\n  namespace: kube-system\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: csi-azurefile-controller\n  template:\n    metadata:\n      labels:\n        app: csi-azurefile-controller\n    spec:\n      serviceAccountName: csi-azurefile-controller-sa\n      containers:\n      - name: csi-provisioner\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-provisioner:v2.1.0\n        args:\n        - -v=2\n        - --csi-address=$(ADDRESS)\n        - --leader-election\n        - --timeout=300s\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-attacher\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-attacher:v2.2.0\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -timeout=120s\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        resources:\n          limits:\n            cpu: 100m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-snapshotter\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-snapshotter:v3.0.3\n        args:\n        - -v=2\n        - -csi-address=$(ADDRESS)\n        - -leader-election\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: csi-resizer\n        image: mcr.microsoft.com/oss/kubernetes-csi/csi-resizer:v1.1.0\n        args:\n        - -csi-address=$(ADDRESS)\n        - -v=2\n        - -leader-election\n        - -handle-volume-inuse-error=false\n        env:\n        - name: ADDRESS\n          value: /csi/csi.sock\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 300Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: liveness-probe\n        image: mcr.microsoft.com/oss/kubernetes-csi/livenessprobe:v2.2.0\n        args:\n        - --csi-address=/csi/csi.sock\n        - --probe-timeout=3s\n        - --health-port=29612\n        - --v=2\n        volumeMounts:\n        - name: socket-dir\n          mountPath: /csi\n        resources:\n          limits:\n            cpu: 100m\n            memory: 100Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: azurefile\n        image: mcr.microsoft.com/k8s/csi/azurefile-csi:v1.1.0\n        imagePullPolicy: IfNotPresent\n        args:\n        - --v=5\n        - --endpoint=$(CSI_ENDPOINT)\n        - --metrics-address=0.0.0.0:29614\n        ports:\n        - containerPort: 29612\n          name: healthz\n          protocol: TCP\n        - containerPort: 29614\n          name: metrics\n          protocol: TCP\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: healthz\n          initialDelaySeconds: 30\n          timeoutSeconds: 10\n          periodSeconds: 30\n        env:\n        - name: AZURE_CREDENTIAL_FILE\n          valueFrom:\n            configMapKeyRef:\n              name: azure-cred-file\n              key: path\n              optional: true\n        - name: CSI_ENDPOINT\n          value: unix:///csi/csi.sock\n        volumeMounts:\n        - mountPath: /csi\n          name: socket-dir\n        - mountPath: /etc/kubernetes/\n          name: azure-cred\n        - mountPath: /var/lib/waagent/ManagedIdentity-Settings\n          readOnly: true\n          name: msi\n        resources:\n          limits:\n            cpu: 200m\n            memory: 200Mi\n          requests:\n            cpu: 10m\n            memory: 20Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: socket-dir\n        emptyDir: {}\n      - name: azure-cred\n        hostPath:\n          path: /etc/kubernetes/\n          type: Directory\n      - name: msi\n        hostPath:\n          path: /var/lib/waagent/ManagedIdentity-Settings\n",
    "errors": []
  },
  {
    "id": "04804",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04805",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04806",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04807",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04808",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04809",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04810",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04811",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04812",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04813",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04814",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04815",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04816",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04817",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04818",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04819",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04820",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04821",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04822",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04823",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04824",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04825",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04826",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04827",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04828",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04829",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04830",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04831",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04832",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"uninstall-aura-full\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04833",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  namespace: kube-system\n  labels:\n    k8s-app: heapster\n    name: heapster\n    version: v6\n  name: heapster\nspec:\n  replicas: 1\n  selector:\n    k8s-app: heapster\n    version: v6\n  template:\n    metadata:\n      labels:\n        k8s-app: heapster\n        version: v6\n    spec:\n      containers:\n      - name: heapster\n        image: kubernetes/heapster:canary\n        imagePullPolicy: Always\n        command:\n        - /heapster\n        - --source=kubernetes:https://Kubernetes.kubernetes:6443?inClusterConfig=true&insecure=true\n        - --sink=influxdb:http://monitoring-influxdb:8086\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04834",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  namespace: kube-system\n  labels:\n    k8s-app: heapster\n    name: heapster\n    version: v6\n  name: heapster\nspec:\n  replicas: 1\n  selector:\n    k8s-app: heapster\n    version: v6\n  template:\n    metadata:\n      labels:\n        k8s-app: heapster\n        version: v6\n    spec:\n      containers:\n      - name: heapster\n        image: kubernetes/heapster:canary\n        imagePullPolicy: Always\n        command:\n        - /heapster\n        - --source=kubernetes:https://Kubernetes.kubernetes:6443?inClusterConfig=true&insecure=true\n        - --sink=influxdb:http://monitoring-influxdb:8086\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04835",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  namespace: kube-system\n  labels:\n    k8s-app: heapster\n    name: heapster\n    version: v6\n  name: heapster\nspec:\n  replicas: 1\n  selector:\n    k8s-app: heapster\n    version: v6\n  template:\n    metadata:\n      labels:\n        k8s-app: heapster\n        version: v6\n    spec:\n      containers:\n      - name: heapster\n        image: kubernetes/heapster:canary\n        imagePullPolicy: Always\n        command:\n        - /heapster\n        - --source=kubernetes:https://Kubernetes.kubernetes:6443?inClusterConfig=true&insecure=true\n        - --sink=influxdb:http://monitoring-influxdb:8086\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04836",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  namespace: kube-system\n  labels:\n    k8s-app: heapster\n    name: heapster\n    version: v6\n  name: heapster\nspec:\n  replicas: 1\n  selector:\n    k8s-app: heapster\n    version: v6\n  template:\n    metadata:\n      labels:\n        k8s-app: heapster\n        version: v6\n    spec:\n      containers:\n      - name: heapster\n        image: kubernetes/heapster:canary\n        imagePullPolicy: Always\n        command:\n        - /heapster\n        - --source=kubernetes:https://Kubernetes.kubernetes:6443?inClusterConfig=true&insecure=true\n        - --sink=influxdb:http://monitoring-influxdb:8086\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04837",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  labels:\n    env: test\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    imagePullPolicy: IfNotPresent\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04838",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  labels:\n    env: test\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    imagePullPolicy: IfNotPresent\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04839",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  labels:\n    env: test\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    imagePullPolicy: IfNotPresent\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04840",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  labels:\n    env: test\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    imagePullPolicy: IfNotPresent\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04841",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  labels:\n    env: test\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    imagePullPolicy: IfNotPresent\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04842",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"nginx\" is invalid: spec.template.metadata.labels: Invalid value: null: `selector` does not match template `labels`"
    ]
  },
  {
    "id": "04843",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"nginx\" is invalid: spec.template.metadata.labels: Invalid value: null: `selector` does not match template `labels`"
    ]
  },
  {
    "id": "04844",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"nginx\" is invalid: spec.template.metadata.labels: Invalid value: null: `selector` does not match template `labels`"
    ]
  },
  {
    "id": "04845",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Deployment \"nginx\" is invalid: spec.template.metadata.labels: Invalid value: null: `selector` does not match template `labels`"
    ]
  },
  {
    "id": "04846",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"etcd-job\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04847",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"etcd-job\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04848",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"etcd-job\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04849",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"etcd-job\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04850",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"etcd-job\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04851",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: paymentservice\n        image: puzyrevyaroslav/hipster_frontend:v0.0.2\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04852",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: paymentservice\n        image: puzyrevyaroslav/hipster_frontend:v0.0.2\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04853",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: paymentservice\n        image: puzyrevyaroslav/hipster_frontend:v0.0.2\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04854",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: paymentservice\n  labels:\n    app: paymentservice\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: paymentservice\n  template:\n    metadata:\n      labels:\n        app: paymentservice\n    spec:\n      containers:\n      - name: paymentservice\n        image: puzyrevyaroslav/hipster_frontend:v0.0.2\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        env:\n        - name: PORT\n          value: '8080'\n        - name: PRODUCT_CATALOG_SERVICE_ADDR\n          value: productcatalogservice:3550\n        - name: CURRENCY_SERVICE_ADDR\n          value: currencyservice:7000\n        - name: CART_SERVICE_ADDR\n          value: cartservice:7070\n        - name: RECOMMENDATION_SERVICE_ADDR\n          value: recommendationservice:8080\n        - name: SHIPPING_SERVICE_ADDR\n          value: shippingservice:50051\n        - name: CHECKOUT_SERVICE_ADDR\n          value: checkoutservice:5050\n        - name: AD_SERVICE_ADDR\n          value: adservice:9555\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04855",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"mysql\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.containers[0].resources.requests: Invalid value: \"1Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.initContainers[1].volumeMounts[0].name: Not found: \"data\""
    ]
  },
  {
    "id": "04856",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"mysql\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.containers[0].resources.requests: Invalid value: \"1Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.initContainers[1].volumeMounts[0].name: Not found: \"data\""
    ]
  },
  {
    "id": "04857",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"mysql\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.containers[0].resources.requests: Invalid value: \"1Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.initContainers[1].volumeMounts[0].name: Not found: \"data\""
    ]
  },
  {
    "id": "04858",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"mysql\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.containers[0].resources.requests: Invalid value: \"1Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.initContainers[1].volumeMounts[0].name: Not found: \"data\""
    ]
  },
  {
    "id": "04859",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"mysql\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.containers[0].resources.requests: Invalid value: \"1Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.initContainers[1].volumeMounts[0].name: Not found: \"data\""
    ]
  },
  {
    "id": "04860",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"mysql\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.containers[0].resources.requests: Invalid value: \"1Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.initContainers[1].volumeMounts[0].name: Not found: \"data\""
    ]
  },
  {
    "id": "04861",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"mysql\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.containers[0].resources.requests: Invalid value: \"1Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.initContainers[1].volumeMounts[0].name: Not found: \"data\""
    ]
  },
  {
    "id": "04862",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"mysql\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.containers[0].resources.requests: Invalid value: \"1Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.initContainers[1].volumeMounts[0].name: Not found: \"data\""
    ]
  },
  {
    "id": "04863",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"mysql\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.containers[0].resources.requests: Invalid value: \"1Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.initContainers[1].volumeMounts[0].name: Not found: \"data\""
    ]
  },
  {
    "id": "04864",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"mysql\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.containers[0].resources.requests: Invalid value: \"1Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.initContainers[1].volumeMounts[0].name: Not found: \"data\""
    ]
  },
  {
    "id": "04865",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"mysql\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.containers[0].resources.requests: Invalid value: \"1Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.initContainers[1].volumeMounts[0].name: Not found: \"data\""
    ]
  },
  {
    "id": "04866",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"mysql\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.containers[0].resources.requests: Invalid value: \"1Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.initContainers[1].volumeMounts[0].name: Not found: \"data\""
    ]
  },
  {
    "id": "04867",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"mysql\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.containers[0].resources.requests: Invalid value: \"1Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.initContainers[1].volumeMounts[0].name: Not found: \"data\""
    ]
  },
  {
    "id": "04868",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The StatefulSet \"mysql\" is invalid: \n* spec.template.spec.containers[0].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.containers[0].resources.requests: Invalid value: \"1Gi\": must be less than or equal to memory limit of 256Mi\n* spec.template.spec.containers[1].volumeMounts[0].name: Not found: \"data\"\n* spec.template.spec.initContainers[1].volumeMounts[0].name: Not found: \"data\""
    ]
  },
  {
    "id": "04869",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: discord-voice-log-bot-deployment\n  labels:\n    app: discord-voice-log-bot\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: discord-voice-log-bot\n  template:\n    metadata:\n      labels:\n        app: discord-voice-log-bot\n    spec:\n      containers:\n      - name: discord-voice-log-bot\n        image: quay.io/satackey/discord-voice-log-bot:stable\n        volumeMounts:\n        - name: bot-config\n          mountPath: /app/configs\n          readOnly: true\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: bot-config\n        secret:\n          secretName: discord-voice-log-bot-secret\n          items:\n          - key: config\n            path: config.ini\n",
    "errors": []
  },
  {
    "id": "04870",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: discord-voice-log-bot-deployment\n  labels:\n    app: discord-voice-log-bot\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: discord-voice-log-bot\n  template:\n    metadata:\n      labels:\n        app: discord-voice-log-bot\n    spec:\n      containers:\n      - name: discord-voice-log-bot\n        image: quay.io/satackey/discord-voice-log-bot:stable\n        volumeMounts:\n        - name: bot-config\n          mountPath: /app/configs\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: bot-config\n        secret:\n          secretName: discord-voice-log-bot-secret\n          items:\n          - key: config\n            path: config.ini\n",
    "errors": []
  },
  {
    "id": "04871",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: discord-voice-log-bot-deployment\n  labels:\n    app: discord-voice-log-bot\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: discord-voice-log-bot\n  template:\n    metadata:\n      labels:\n        app: discord-voice-log-bot\n    spec:\n      containers:\n      - name: discord-voice-log-bot\n        image: quay.io/satackey/discord-voice-log-bot:stable\n        volumeMounts:\n        - name: bot-config\n          mountPath: /app/configs\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: bot-config\n        secret:\n          secretName: discord-voice-log-bot-secret\n          items:\n          - key: config\n            path: config.ini\n",
    "errors": []
  },
  {
    "id": "04872",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: discord-voice-log-bot-deployment\n  labels:\n    app: discord-voice-log-bot\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: discord-voice-log-bot\n  template:\n    metadata:\n      labels:\n        app: discord-voice-log-bot\n    spec:\n      containers:\n      - name: discord-voice-log-bot\n        image: quay.io/satackey/discord-voice-log-bot:stable\n        volumeMounts:\n        - name: bot-config\n          mountPath: /app/configs\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: bot-config\n        secret:\n          secretName: discord-voice-log-bot-secret\n          items:\n          - key: config\n            path: config.ini\n",
    "errors": []
  },
  {
    "id": "04873",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: discord-voice-log-bot-deployment\n  labels:\n    app: discord-voice-log-bot\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: discord-voice-log-bot\n  template:\n    metadata:\n      labels:\n        app: discord-voice-log-bot\n    spec:\n      containers:\n      - name: discord-voice-log-bot\n        image: quay.io/satackey/discord-voice-log-bot:stable\n        volumeMounts:\n        - name: bot-config\n          mountPath: /app/configs\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: bot-config\n        secret:\n          secretName: discord-voice-log-bot-secret\n          items:\n          - key: config\n            path: config.ini\n",
    "errors": []
  },
  {
    "id": "04874",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: controller-manager\n  namespace: system\n  labels:\n    control-plane: controller-manager\nspec:\n  selector:\n    matchLabels:\n      control-plane: controller-manager\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        control-plane: controller-manager\n    spec:\n      containers:\n      - command:\n        - /manager\n        args:\n        - --leader-elect\n        - --metrics-bind-addr=127.0.0.1:8080\n        - --feature-gates=MachinePool=false\n        image: controller:stable\n        name: manager\n        env:\n        - name: NO_PROXY\n          value: 127.0.0.1,localhost\n        ports:\n        - containerPort: 9440\n          name: healthz\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: healthz\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n        volumeMounts:\n        - mountPath: /var/run/docker.sock\n          name: dockersock\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: manager\n      volumes:\n      - name: dockersock\n        hostPath:\n          path: /var/run/docker.sock\n",
    "errors": []
  },
  {
    "id": "04875",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: controller-manager\n  namespace: system\n  labels:\n    control-plane: controller-manager\nspec:\n  selector:\n    matchLabels:\n      control-plane: controller-manager\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        control-plane: controller-manager\n    spec:\n      containers:\n      - command:\n        - /manager\n        args:\n        - --leader-elect\n        - --metrics-bind-addr=127.0.0.1:8080\n        - --feature-gates=MachinePool=false\n        image: controller:stable\n        name: manager\n        env:\n        - name: NO_PROXY\n          value: 127.0.0.1,localhost\n        ports:\n        - containerPort: 9440\n          name: healthz\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: healthz\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n        volumeMounts:\n        - mountPath: /var/run/docker.sock\n          name: dockersock\n        securityContext:\n          privileged: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: manager\n      volumes:\n      - name: dockersock\n        hostPath:\n          path: /var/run/docker.sock\n",
    "errors": []
  },
  {
    "id": "04876",
    "policy_id": "drop_capabilities",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: controller-manager\n  namespace: system\n  labels:\n    control-plane: controller-manager\nspec:\n  selector:\n    matchLabels:\n      control-plane: controller-manager\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        control-plane: controller-manager\n    spec:\n      containers:\n      - command:\n        - /manager\n        args:\n        - --leader-elect\n        - --metrics-bind-addr=127.0.0.1:8080\n        - --feature-gates=MachinePool=false\n        image: controller:stable\n        name: manager\n        env:\n        - name: NO_PROXY\n          value: 127.0.0.1,localhost\n        ports:\n        - containerPort: 9440\n          name: healthz\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: healthz\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n        volumeMounts:\n        - mountPath: /var/run/docker.sock\n          name: dockersock\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: manager\n      volumes:\n      - name: dockersock\n        hostPath:\n          path: /var/run/docker.sock\n",
    "errors": []
  },
  {
    "id": "04877",
    "policy_id": "no_privileged",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: controller-manager\n  namespace: system\n  labels:\n    control-plane: controller-manager\nspec:\n  selector:\n    matchLabels:\n      control-plane: controller-manager\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        control-plane: controller-manager\n    spec:\n      containers:\n      - command:\n        - /manager\n        args:\n        - --leader-elect\n        - --metrics-bind-addr=127.0.0.1:8080\n        - --feature-gates=MachinePool=false\n        image: controller:stable\n        name: manager\n        env:\n        - name: NO_PROXY\n          value: 127.0.0.1,localhost\n        ports:\n        - containerPort: 9440\n          name: healthz\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: healthz\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n        volumeMounts:\n        - mountPath: /var/run/docker.sock\n          name: dockersock\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: manager\n      volumes:\n      - name: dockersock\n        hostPath:\n          path: /var/run/docker.sock\n",
    "errors": []
  },
  {
    "id": "04878",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: controller-manager\n  namespace: system\n  labels:\n    control-plane: controller-manager\nspec:\n  selector:\n    matchLabels:\n      control-plane: controller-manager\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        control-plane: controller-manager\n    spec:\n      containers:\n      - command:\n        - /manager\n        args:\n        - --leader-elect\n        - --metrics-bind-addr=127.0.0.1:8080\n        - --feature-gates=MachinePool=false\n        image: controller:stable\n        name: manager\n        env:\n        - name: NO_PROXY\n          value: 127.0.0.1,localhost\n        ports:\n        - containerPort: 9440\n          name: healthz\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: healthz\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n        volumeMounts:\n        - mountPath: /var/run/docker.sock\n          name: dockersock\n        securityContext:\n          privileged: false\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: manager\n      volumes:\n      - name: dockersock\n        hostPath:\n          path: /var/run/docker.sock\n",
    "errors": []
  },
  {
    "id": "04879",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: controller-manager\n  namespace: system\n  labels:\n    control-plane: controller-manager\nspec:\n  selector:\n    matchLabels:\n      control-plane: controller-manager\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        control-plane: controller-manager\n    spec:\n      containers:\n      - command:\n        - /manager\n        args:\n        - --leader-elect\n        - --metrics-bind-addr=127.0.0.1:8080\n        - --feature-gates=MachinePool=false\n        image: controller:stable\n        name: manager\n        env:\n        - name: NO_PROXY\n          value: 127.0.0.1,localhost\n        ports:\n        - containerPort: 9440\n          name: healthz\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: healthz\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n        volumeMounts:\n        - mountPath: /var/run/docker.sock\n          name: dockersock\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: manager\n      volumes:\n      - name: dockersock\n        hostPath:\n          path: /var/run/docker.sock\n",
    "errors": []
  },
  {
    "id": "04880",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: controller-manager\n  namespace: system\n  labels:\n    control-plane: controller-manager\nspec:\n  selector:\n    matchLabels:\n      control-plane: controller-manager\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        control-plane: controller-manager\n    spec:\n      containers:\n      - command:\n        - /manager\n        args:\n        - --leader-elect\n        - --metrics-bind-addr=127.0.0.1:8080\n        - --feature-gates=MachinePool=false\n        image: controller:stable\n        name: manager\n        env:\n        - name: NO_PROXY\n          value: 127.0.0.1,localhost\n        ports:\n        - containerPort: 9440\n          name: healthz\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: healthz\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: healthz\n        volumeMounts:\n        - mountPath: /var/run/docker.sock\n          name: dockersock\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      serviceAccountName: manager\n      volumes:\n      - name: dockersock\n        hostPath:\n          path: /var/run/docker.sock\n",
    "errors": []
  },
  {
    "id": "04881",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-deploy\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hello\n  template:\n    metadata:\n      name: hello-pod\n      labels:\n        app: hello\n    spec:\n      containers:\n      - name: hello-container\n        image: aswroma3/hello:2021-kube\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04882",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-deploy\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hello\n  template:\n    metadata:\n      name: hello-pod\n      labels:\n        app: hello\n    spec:\n      containers:\n      - name: hello-container\n        image: aswroma3/hello:2021-kube\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04883",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-deploy\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hello\n  template:\n    metadata:\n      name: hello-pod\n      labels:\n        app: hello\n    spec:\n      containers:\n      - name: hello-container\n        image: aswroma3/hello:2021-kube\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04884",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-deploy\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hello\n  template:\n    metadata:\n      name: hello-pod\n      labels:\n        app: hello\n    spec:\n      containers:\n      - name: hello-container\n        image: aswroma3/hello:2021-kube\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04885",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: opentsdb-read\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: opentsdb-read\n  template:\n    metadata:\n      labels:\n        app: opentsdb-read\n    spec:\n      containers:\n      - name: opentsdb-read\n        image: gcr.io/cloud-solutions-images/opentsdb-bigtable:v2.1\n        ports:\n        - containerPort: 4242\n          protocol: TCP\n        volumeMounts:\n        - name: opentsdb-config\n          mountPath: /opt/opentsdb\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: opentsdb-config\n        configMap:\n          name: opentsdb-config\n          items:\n          - key: opentsdb.conf\n            path: opentsdb.conf\n",
    "errors": []
  },
  {
    "id": "04886",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: opentsdb-read\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: opentsdb-read\n  template:\n    metadata:\n      labels:\n        app: opentsdb-read\n    spec:\n      containers:\n      - name: opentsdb-read\n        image: gcr.io/cloud-solutions-images/opentsdb-bigtable:v2.1\n        ports:\n        - containerPort: 4242\n          protocol: TCP\n        volumeMounts:\n        - name: opentsdb-config\n          mountPath: /opt/opentsdb\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: opentsdb-config\n        configMap:\n          name: opentsdb-config\n          items:\n          - key: opentsdb.conf\n            path: opentsdb.conf\n",
    "errors": []
  },
  {
    "id": "04887",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: opentsdb-read\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: opentsdb-read\n  template:\n    metadata:\n      labels:\n        app: opentsdb-read\n    spec:\n      containers:\n      - name: opentsdb-read\n        image: gcr.io/cloud-solutions-images/opentsdb-bigtable:v2.1\n        ports:\n        - containerPort: 4242\n          protocol: TCP\n        volumeMounts:\n        - name: opentsdb-config\n          mountPath: /opt/opentsdb\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: opentsdb-config\n        configMap:\n          name: opentsdb-config\n          items:\n          - key: opentsdb.conf\n            path: opentsdb.conf\n",
    "errors": []
  },
  {
    "id": "04888",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: opentsdb-read\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: opentsdb-read\n  template:\n    metadata:\n      labels:\n        app: opentsdb-read\n    spec:\n      containers:\n      - name: opentsdb-read\n        image: gcr.io/cloud-solutions-images/opentsdb-bigtable:v2.1\n        ports:\n        - containerPort: 4242\n          protocol: TCP\n        volumeMounts:\n        - name: opentsdb-config\n          mountPath: /opt/opentsdb\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: opentsdb-config\n        configMap:\n          name: opentsdb-config\n          items:\n          - key: opentsdb.conf\n            path: opentsdb.conf\n",
    "errors": []
  },
  {
    "id": "04889",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: machine-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      role: machine-controller-manager\n  template:\n    metadata:\n      labels:\n        role: machine-controller-manager\n    spec:\n      containers:\n      - name: machine-controller-manager\n        image: eu.gcr.io/gardener-project/gardener/machine-controller-manager:v0.39.0\n        imagePullPolicy: Always\n        command:\n        - ./machine-controller-manager\n        - --target-kubeconfig=/var/lib/machine-controller-manager/kubeconfig\n        - --control-kubeconfig=inClusterConfig\n        - --safety-up=2\n        - --safety-down=1\n        - --machine-safety-overshooting-period=1m\n        - --v=3\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10258\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        volumeMounts:\n        - mountPath: /var/lib/machine-controller-manager\n          name: machine-controller-manager\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - command:\n        - ./machine-controller\n        - --control-kubeconfig=inClusterConfig\n        - --target-kubeconfig=/var/lib/machine-controller-manager/kubeconfig\n        - --machine-creation-timeout=20m\n        - --machine-drain-timeout=5m\n        - --machine-health-timeout=10m\n        - --machine-safety-orphan-vms-period=30m\n        - --node-conditions=ReadonlyFilesystem,KernelDeadlock,DiskPressure\n        - --v=3\n        image: eu.gcr.io/gardener-project/gardener/machine-controller-manager-provider-gcp:v0.7.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10259\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: machine-controller\n        ports:\n        - containerPort: 10259\n          name: metrics\n          protocol: TCP\n        resources:\n          limits:\n            cpu: 350m\n            memory: 3000Mi\n          requests:\n            cpu: 50m\n            memory: 64Mi\n        volumeMounts:\n        - mountPath: /var/lib/machine-controller-manager\n          name: machine-controller-manager\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      securityContext: {}\n      volumes:\n      - name: machine-controller-manager\n        secret:\n          defaultMode: 420\n          secretName: machine-controller-manager\n",
    "errors": []
  },
  {
    "id": "04890",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: machine-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      role: machine-controller-manager\n  template:\n    metadata:\n      labels:\n        role: machine-controller-manager\n    spec:\n      containers:\n      - name: machine-controller-manager\n        image: eu.gcr.io/gardener-project/gardener/machine-controller-manager:v0.39.0\n        imagePullPolicy: Always\n        command:\n        - ./machine-controller-manager\n        - --target-kubeconfig=/var/lib/machine-controller-manager/kubeconfig\n        - --control-kubeconfig=inClusterConfig\n        - --safety-up=2\n        - --safety-down=1\n        - --machine-safety-overshooting-period=1m\n        - --v=3\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10258\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        volumeMounts:\n        - mountPath: /var/lib/machine-controller-manager\n          name: machine-controller-manager\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - command:\n        - ./machine-controller\n        - --control-kubeconfig=inClusterConfig\n        - --target-kubeconfig=/var/lib/machine-controller-manager/kubeconfig\n        - --machine-creation-timeout=20m\n        - --machine-drain-timeout=5m\n        - --machine-health-timeout=10m\n        - --machine-safety-orphan-vms-period=30m\n        - --node-conditions=ReadonlyFilesystem,KernelDeadlock,DiskPressure\n        - --v=3\n        image: eu.gcr.io/gardener-project/gardener/machine-controller-manager-provider-gcp:v0.7.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10259\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: machine-controller\n        ports:\n        - containerPort: 10259\n          name: metrics\n          protocol: TCP\n        resources:\n          limits:\n            cpu: 350m\n            memory: 3000Mi\n          requests:\n            cpu: 50m\n            memory: 64Mi\n        volumeMounts:\n        - mountPath: /var/lib/machine-controller-manager\n          name: machine-controller-manager\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      securityContext: {}\n      volumes:\n      - name: machine-controller-manager\n        secret:\n          defaultMode: 420\n          secretName: machine-controller-manager\n",
    "errors": []
  },
  {
    "id": "04891",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: machine-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      role: machine-controller-manager\n  template:\n    metadata:\n      labels:\n        role: machine-controller-manager\n    spec:\n      containers:\n      - name: machine-controller-manager\n        image: eu.gcr.io/gardener-project/gardener/machine-controller-manager:v0.39.0\n        imagePullPolicy: Always\n        command:\n        - ./machine-controller-manager\n        - --target-kubeconfig=/var/lib/machine-controller-manager/kubeconfig\n        - --control-kubeconfig=inClusterConfig\n        - --safety-up=2\n        - --safety-down=1\n        - --machine-safety-overshooting-period=1m\n        - --v=3\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10258\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        volumeMounts:\n        - mountPath: /var/lib/machine-controller-manager\n          name: machine-controller-manager\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - command:\n        - ./machine-controller\n        - --control-kubeconfig=inClusterConfig\n        - --target-kubeconfig=/var/lib/machine-controller-manager/kubeconfig\n        - --machine-creation-timeout=20m\n        - --machine-drain-timeout=5m\n        - --machine-health-timeout=10m\n        - --machine-safety-orphan-vms-period=30m\n        - --node-conditions=ReadonlyFilesystem,KernelDeadlock,DiskPressure\n        - --v=3\n        image: eu.gcr.io/gardener-project/gardener/machine-controller-manager-provider-gcp:v0.7.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10259\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: machine-controller\n        ports:\n        - containerPort: 10259\n          name: metrics\n          protocol: TCP\n        resources:\n          limits:\n            cpu: 350m\n            memory: 3000Mi\n          requests:\n            cpu: 50m\n            memory: 64Mi\n        volumeMounts:\n        - mountPath: /var/lib/machine-controller-manager\n          name: machine-controller-manager\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      securityContext: {}\n      volumes:\n      - name: machine-controller-manager\n        secret:\n          defaultMode: 420\n          secretName: machine-controller-manager\n",
    "errors": []
  },
  {
    "id": "04892",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: machine-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      role: machine-controller-manager\n  template:\n    metadata:\n      labels:\n        role: machine-controller-manager\n    spec:\n      containers:\n      - name: machine-controller-manager\n        image: eu.gcr.io/gardener-project/gardener/machine-controller-manager:v0.39.0\n        imagePullPolicy: Always\n        command:\n        - ./machine-controller-manager\n        - --target-kubeconfig=/var/lib/machine-controller-manager/kubeconfig\n        - --control-kubeconfig=inClusterConfig\n        - --safety-up=2\n        - --safety-down=1\n        - --machine-safety-overshooting-period=1m\n        - --v=3\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10258\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        volumeMounts:\n        - mountPath: /var/lib/machine-controller-manager\n          name: machine-controller-manager\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - command:\n        - ./machine-controller\n        - --control-kubeconfig=inClusterConfig\n        - --target-kubeconfig=/var/lib/machine-controller-manager/kubeconfig\n        - --machine-creation-timeout=20m\n        - --machine-drain-timeout=5m\n        - --machine-health-timeout=10m\n        - --machine-safety-orphan-vms-period=30m\n        - --node-conditions=ReadonlyFilesystem,KernelDeadlock,DiskPressure\n        - --v=3\n        image: eu.gcr.io/gardener-project/gardener/machine-controller-manager-provider-gcp:v0.7.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10259\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: machine-controller\n        ports:\n        - containerPort: 10259\n          name: metrics\n          protocol: TCP\n        resources:\n          limits:\n            cpu: 350m\n            memory: 3000Mi\n          requests:\n            cpu: 50m\n            memory: 64Mi\n        volumeMounts:\n        - mountPath: /var/lib/machine-controller-manager\n          name: machine-controller-manager\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      securityContext: {}\n      volumes:\n      - name: machine-controller-manager\n        secret:\n          defaultMode: 420\n          secretName: machine-controller-manager\n",
    "errors": []
  },
  {
    "id": "04893",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: machine-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      role: machine-controller-manager\n  template:\n    metadata:\n      labels:\n        role: machine-controller-manager\n    spec:\n      containers:\n      - name: machine-controller-manager\n        image: eu.gcr.io/gardener-project/gardener/machine-controller-manager:v0.39.0\n        imagePullPolicy: Always\n        command:\n        - ./machine-controller-manager\n        - --target-kubeconfig=/var/lib/machine-controller-manager/kubeconfig\n        - --control-kubeconfig=inClusterConfig\n        - --safety-up=2\n        - --safety-down=1\n        - --machine-safety-overshooting-period=1m\n        - --v=3\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10258\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        volumeMounts:\n        - mountPath: /var/lib/machine-controller-manager\n          name: machine-controller-manager\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - command:\n        - ./machine-controller\n        - --control-kubeconfig=inClusterConfig\n        - --target-kubeconfig=/var/lib/machine-controller-manager/kubeconfig\n        - --machine-creation-timeout=20m\n        - --machine-drain-timeout=5m\n        - --machine-health-timeout=10m\n        - --machine-safety-orphan-vms-period=30m\n        - --node-conditions=ReadonlyFilesystem,KernelDeadlock,DiskPressure\n        - --v=3\n        image: eu.gcr.io/gardener-project/gardener/machine-controller-manager-provider-gcp:v0.7.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10259\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: machine-controller\n        ports:\n        - containerPort: 10259\n          name: metrics\n          protocol: TCP\n        resources:\n          limits:\n            cpu: 350m\n            memory: 3000Mi\n          requests:\n            cpu: 50m\n            memory: 64Mi\n        volumeMounts:\n        - mountPath: /var/lib/machine-controller-manager\n          name: machine-controller-manager\n          readOnly: true\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      securityContext: {}\n      volumes:\n      - name: machine-controller-manager\n        secret:\n          defaultMode: 420\n          secretName: machine-controller-manager\n",
    "errors": []
  },
  {
    "id": "04894",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: machine-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      role: machine-controller-manager\n  template:\n    metadata:\n      labels:\n        role: machine-controller-manager\n    spec:\n      containers:\n      - name: machine-controller-manager\n        image: eu.gcr.io/gardener-project/gardener/machine-controller-manager:v0.39.0\n        imagePullPolicy: Always\n        command:\n        - ./machine-controller-manager\n        - --target-kubeconfig=/var/lib/machine-controller-manager/kubeconfig\n        - --control-kubeconfig=inClusterConfig\n        - --safety-up=2\n        - --safety-down=1\n        - --machine-safety-overshooting-period=1m\n        - --v=3\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10258\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        volumeMounts:\n        - mountPath: /var/lib/machine-controller-manager\n          name: machine-controller-manager\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - command:\n        - ./machine-controller\n        - --control-kubeconfig=inClusterConfig\n        - --target-kubeconfig=/var/lib/machine-controller-manager/kubeconfig\n        - --machine-creation-timeout=20m\n        - --machine-drain-timeout=5m\n        - --machine-health-timeout=10m\n        - --machine-safety-orphan-vms-period=30m\n        - --node-conditions=ReadonlyFilesystem,KernelDeadlock,DiskPressure\n        - --v=3\n        image: eu.gcr.io/gardener-project/gardener/machine-controller-manager-provider-gcp:v0.7.0\n        imagePullPolicy: IfNotPresent\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10259\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 5\n        name: machine-controller\n        ports:\n        - containerPort: 10259\n          name: metrics\n          protocol: TCP\n        resources:\n          limits:\n            cpu: 350m\n            memory: 3000Mi\n          requests:\n            cpu: 50m\n            memory: 64Mi\n        volumeMounts:\n        - mountPath: /var/lib/machine-controller-manager\n          name: machine-controller-manager\n          readOnly: true\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      securityContext: {}\n      volumes:\n      - name: machine-controller-manager\n        secret:\n          defaultMode: 420\n          secretName: machine-controller-manager\n",
    "errors": []
  },
  {
    "id": "04895",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: menu-deployment\nspec:\n  selector:\n    matchLabels:\n      app: lunch-menu\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: lunch-menu\n    spec:\n      containers:\n      - name: menu-frontend\n        image: scilifelabdatacentre/menu-frontend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        env:\n        - name: API_URL\n          valueFrom:\n            configMapKeyRef:\n              name: lunch-menu-conf\n              key: api-url\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: menu-backend\n        image: scilifelabdatacentre/menu-backend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04896",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: menu-deployment\nspec:\n  selector:\n    matchLabels:\n      app: lunch-menu\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: lunch-menu\n    spec:\n      containers:\n      - name: menu-frontend\n        image: scilifelabdatacentre/menu-frontend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        env:\n        - name: API_URL\n          valueFrom:\n            configMapKeyRef:\n              name: lunch-menu-conf\n              key: api-url\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: menu-backend\n        image: scilifelabdatacentre/menu-backend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8000\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04897",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: menu-deployment\nspec:\n  selector:\n    matchLabels:\n      app: lunch-menu\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: lunch-menu\n    spec:\n      containers:\n      - name: menu-frontend\n        image: scilifelabdatacentre/menu-frontend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        env:\n        - name: API_URL\n          valueFrom:\n            configMapKeyRef:\n              name: lunch-menu-conf\n              key: api-url\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: menu-backend\n        image: scilifelabdatacentre/menu-backend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04898",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: menu-deployment\nspec:\n  selector:\n    matchLabels:\n      app: lunch-menu\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: lunch-menu\n    spec:\n      containers:\n      - name: menu-frontend\n        image: scilifelabdatacentre/menu-frontend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        env:\n        - name: API_URL\n          valueFrom:\n            configMapKeyRef:\n              name: lunch-menu-conf\n              key: api-url\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: menu-backend\n        image: scilifelabdatacentre/menu-backend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8000\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04899",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: menu-deployment\nspec:\n  selector:\n    matchLabels:\n      app: lunch-menu\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: lunch-menu\n    spec:\n      containers:\n      - name: menu-frontend\n        image: scilifelabdatacentre/menu-frontend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        env:\n        - name: API_URL\n          valueFrom:\n            configMapKeyRef:\n              name: lunch-menu-conf\n              key: api-url\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: menu-backend\n        image: scilifelabdatacentre/menu-backend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04900",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: menu-deployment\nspec:\n  selector:\n    matchLabels:\n      app: lunch-menu\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: lunch-menu\n    spec:\n      containers:\n      - name: menu-frontend\n        image: scilifelabdatacentre/menu-frontend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        env:\n        - name: API_URL\n          valueFrom:\n            configMapKeyRef:\n              name: lunch-menu-conf\n              key: api-url\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      - name: menu-backend\n        image: scilifelabdatacentre/menu-backend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8000\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04901",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: menu-deployment\nspec:\n  selector:\n    matchLabels:\n      app: lunch-menu\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: lunch-menu\n    spec:\n      containers:\n      - name: menu-frontend\n        image: scilifelabdatacentre/menu-frontend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        env:\n        - name: API_URL\n          valueFrom:\n            configMapKeyRef:\n              name: lunch-menu-conf\n              key: api-url\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: menu-backend\n        image: scilifelabdatacentre/menu-backend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04902",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: menu-deployment\nspec:\n  selector:\n    matchLabels:\n      app: lunch-menu\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: lunch-menu\n    spec:\n      containers:\n      - name: menu-frontend\n        image: scilifelabdatacentre/menu-frontend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        env:\n        - name: API_URL\n          valueFrom:\n            configMapKeyRef:\n              name: lunch-menu-conf\n              key: api-url\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: menu-backend\n        image: scilifelabdatacentre/menu-backend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04903",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: menu-deployment\nspec:\n  selector:\n    matchLabels:\n      app: lunch-menu\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: lunch-menu\n    spec:\n      containers:\n      - name: menu-frontend\n        image: scilifelabdatacentre/menu-frontend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        env:\n        - name: API_URL\n          valueFrom:\n            configMapKeyRef:\n              name: lunch-menu-conf\n              key: api-url\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: menu-backend\n        image: scilifelabdatacentre/menu-backend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04904",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: menu-deployment\nspec:\n  selector:\n    matchLabels:\n      app: lunch-menu\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: lunch-menu\n    spec:\n      containers:\n      - name: menu-frontend\n        image: scilifelabdatacentre/menu-frontend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        env:\n        - name: API_URL\n          valueFrom:\n            configMapKeyRef:\n              name: lunch-menu-conf\n              key: api-url\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      - name: menu-backend\n        image: scilifelabdatacentre/menu-backend:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8000\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04905",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gateway\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gateway\n  template:\n    metadata:\n      labels:\n        app: gateway\n    spec:\n      containers:\n      - envFrom:\n        - secretRef:\n            name: env\n        imagePullPolicy: Never\n        image: gateway:stable\n        name: gateway\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04906",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gateway\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gateway\n  template:\n    metadata:\n      labels:\n        app: gateway\n    spec:\n      containers:\n      - envFrom:\n        - secretRef:\n            name: env\n        imagePullPolicy: Never\n        image: gateway:stable\n        name: gateway\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04907",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gateway\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gateway\n  template:\n    metadata:\n      labels:\n        app: gateway\n    spec:\n      containers:\n      - envFrom:\n        - secretRef:\n            name: env\n        imagePullPolicy: Never\n        image: gateway:stable\n        name: gateway\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04908",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gateway\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gateway\n  template:\n    metadata:\n      labels:\n        app: gateway\n    spec:\n      containers:\n      - envFrom:\n        - secretRef:\n            name: env\n        imagePullPolicy: Never\n        image: gateway:stable\n        name: gateway\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04909",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gateway\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: gateway\n  template:\n    metadata:\n      labels:\n        app: gateway\n    spec:\n      containers:\n      - envFrom:\n        - secretRef:\n            name: env\n        imagePullPolicy: Never\n        image: gateway:stable\n        name: gateway\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04910",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1551\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04911",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1551\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04912",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1551\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04913",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1551\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04914",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-1551\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04915",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sloth\n  namespace: default\n  labels:\n    helm.sh/chart: sloth-0.1.0\n    app.kubernetes.io/managed-by: Helm\n    app: sloth\n    app.kubernetes.io/name: sloth\n    app.kubernetes.io/instance: sloth\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sloth\n      app.kubernetes.io/name: sloth\n      app.kubernetes.io/instance: sloth\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: sloth-0.1.0\n        app.kubernetes.io/managed-by: Helm\n        app: sloth\n        app.kubernetes.io/name: sloth\n        app.kubernetes.io/instance: sloth\n      annotations:\n        kubectl.kubernetes.io/default-container: sloth\n    spec:\n      serviceAccountName: sloth\n      containers:\n      - name: sloth\n        image: slok/sloth:v0.6.0\n        args:\n        - kubernetes-controller\n        - --resync-interval=3m\n        - --sli-plugins-path=/plugins\n        ports:\n        - containerPort: 8081\n          name: metrics\n          protocol: TCP\n        volumeMounts:\n        - name: sloth-common-sli-plugins\n          mountPath: /plugins/sloth-common-sli-plugins\n        resources:\n          limits:\n            memory: 150Mi\n            cpu: 500m\n          requests:\n            cpu: 5m\n            memory: 75Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: git-sync-plugins\n        image: k8s.gcr.io/git-sync/git-sync:v3.3.4\n        args:\n        - --repo=https://github.com/slok/sloth-common-sli-plugins\n        - --branch=main\n        - --wait=30\n        - --webhook-url=http://localhost:8082/-/reload\n        volumeMounts:\n        - name: sloth-common-sli-plugins\n          mountPath: /tmp/git\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 5m\n            memory: 50Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: sloth-common-sli-plugins\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04916",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sloth\n  namespace: default\n  labels:\n    helm.sh/chart: sloth-0.1.0\n    app.kubernetes.io/managed-by: Helm\n    app: sloth\n    app.kubernetes.io/name: sloth\n    app.kubernetes.io/instance: sloth\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sloth\n      app.kubernetes.io/name: sloth\n      app.kubernetes.io/instance: sloth\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: sloth-0.1.0\n        app.kubernetes.io/managed-by: Helm\n        app: sloth\n        app.kubernetes.io/name: sloth\n        app.kubernetes.io/instance: sloth\n      annotations:\n        kubectl.kubernetes.io/default-container: sloth\n    spec:\n      serviceAccountName: sloth\n      containers:\n      - name: sloth\n        image: slok/sloth:v0.6.0\n        args:\n        - kubernetes-controller\n        - --resync-interval=3m\n        - --sli-plugins-path=/plugins\n        ports:\n        - containerPort: 8081\n          name: metrics\n          protocol: TCP\n        volumeMounts:\n        - name: sloth-common-sli-plugins\n          mountPath: /plugins/sloth-common-sli-plugins\n        resources:\n          limits:\n            memory: 150Mi\n            cpu: 500m\n          requests:\n            cpu: 5m\n            memory: 75Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      - name: git-sync-plugins\n        image: k8s.gcr.io/git-sync/git-sync:v3.3.4\n        args:\n        - --repo=https://github.com/slok/sloth-common-sli-plugins\n        - --branch=main\n        - --wait=30\n        - --webhook-url=http://localhost:8082/-/reload\n        volumeMounts:\n        - name: sloth-common-sli-plugins\n          mountPath: /tmp/git\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 5m\n            memory: 50Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: sloth-common-sli-plugins\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04917",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sloth\n  namespace: default\n  labels:\n    helm.sh/chart: sloth-0.1.0\n    app.kubernetes.io/managed-by: Helm\n    app: sloth\n    app.kubernetes.io/name: sloth\n    app.kubernetes.io/instance: sloth\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sloth\n      app.kubernetes.io/name: sloth\n      app.kubernetes.io/instance: sloth\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: sloth-0.1.0\n        app.kubernetes.io/managed-by: Helm\n        app: sloth\n        app.kubernetes.io/name: sloth\n        app.kubernetes.io/instance: sloth\n      annotations:\n        kubectl.kubernetes.io/default-container: sloth\n    spec:\n      serviceAccountName: sloth\n      containers:\n      - name: sloth\n        image: slok/sloth:v0.6.0\n        args:\n        - kubernetes-controller\n        - --resync-interval=3m\n        - --sli-plugins-path=/plugins\n        ports:\n        - containerPort: 8081\n          name: metrics\n          protocol: TCP\n        volumeMounts:\n        - name: sloth-common-sli-plugins\n          mountPath: /plugins/sloth-common-sli-plugins\n        resources:\n          limits:\n            memory: 150Mi\n            cpu: 500m\n          requests:\n            cpu: 5m\n            memory: 75Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: git-sync-plugins\n        image: k8s.gcr.io/git-sync/git-sync:v3.3.4\n        args:\n        - --repo=https://github.com/slok/sloth-common-sli-plugins\n        - --branch=main\n        - --wait=30\n        - --webhook-url=http://localhost:8082/-/reload\n        volumeMounts:\n        - name: sloth-common-sli-plugins\n          mountPath: /tmp/git\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 5m\n            memory: 50Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: sloth-common-sli-plugins\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04918",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sloth\n  namespace: default\n  labels:\n    helm.sh/chart: sloth-0.1.0\n    app.kubernetes.io/managed-by: Helm\n    app: sloth\n    app.kubernetes.io/name: sloth\n    app.kubernetes.io/instance: sloth\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sloth\n      app.kubernetes.io/name: sloth\n      app.kubernetes.io/instance: sloth\n  template:\n    metadata:\n      labels:\n        helm.sh/chart: sloth-0.1.0\n        app.kubernetes.io/managed-by: Helm\n        app: sloth\n        app.kubernetes.io/name: sloth\n        app.kubernetes.io/instance: sloth\n      annotations:\n        kubectl.kubernetes.io/default-container: sloth\n    spec:\n      serviceAccountName: sloth\n      containers:\n      - name: sloth\n        image: slok/sloth:v0.6.0\n        args:\n        - kubernetes-controller\n        - --resync-interval=3m\n        - --sli-plugins-path=/plugins\n        ports:\n        - containerPort: 8081\n          name: metrics\n          protocol: TCP\n        volumeMounts:\n        - name: sloth-common-sli-plugins\n          mountPath: /plugins/sloth-common-sli-plugins\n        resources:\n          limits:\n            memory: 150Mi\n            cpu: 500m\n          requests:\n            cpu: 5m\n            memory: 75Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      - name: git-sync-plugins\n        image: k8s.gcr.io/git-sync/git-sync:v3.3.4\n        args:\n        - --repo=https://github.com/slok/sloth-common-sli-plugins\n        - --branch=main\n        - --wait=30\n        - --webhook-url=http://localhost:8082/-/reload\n        volumeMounts:\n        - name: sloth-common-sli-plugins\n          mountPath: /tmp/git\n        resources:\n          limits:\n            memory: 100Mi\n            cpu: 500m\n          requests:\n            cpu: 5m\n            memory: 50Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: sloth-common-sli-plugins\n        emptyDir: {}\n",
    "errors": []
  },
  {
    "id": "04919",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: selenium-sessions\n  namespace: selenium\n  labels:\n    app: selenium-sessions\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: selenium-sessions\n  template:\n    metadata:\n      labels:\n        app: selenium-sessions\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: cloud.google.com/gke-preemptible\n                operator: DoesNotExist\n              - key: eks.amazonaws.com/capacityType\n                operator: NotIn\n                values:\n                - SPOT\n              - key: kubernetes.azure.com/scalesetpriority\n                operator: NotIn\n                values:\n                - spot\n      securityContext:\n        runAsNonRoot: true\n      containers:\n      - name: selenium-sessions\n        image: selenium/sessions:4.0.0\n        ports:\n        - containerPort: 5556\n        env:\n        - name: JAVA_OPTS\n          value: -Xmx512m\n        - name: SE_EVENT_BUS_HOST\n          value: selenium-event-bus\n        - name: SE_EVENT_BUS_PUBLISH_PORT\n          value: '4442'\n        - name: SE_EVENT_BUS_SUBSCRIBE_PORT\n          value: '4443'\n        readinessProbe:\n          tcpSocket:\n            port: 5556\n          initialDelaySeconds: 10\n        livenessProbe:\n          tcpSocket:\n            port: 5556\n          initialDelaySeconds: 30\n        resources:\n          limits:\n            cpu: 500m\n            memory: 1Gi\n          requests:\n            cpu: 100m\n            memory: 600Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04920",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-foghorn\n  labels:\n    chart: lighthouse-1.1.52\n    app: lighthouse-foghorn\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-foghorn\n  template:\n    metadata:\n      labels:\n        app: lighthouse-foghorn\n      annotations:\n        jenkins-x.io/hash: 64d2b982dc80b5c65271f2b9ff8b94777e4a148eca3fed68a4eebb84f6342f24\n    spec:\n      serviceAccountName: lighthouse-foghorn\n      containers:\n      - name: lighthouse-foghorn\n        image: ghcr.io/jenkins-x/lighthouse-foghorn:1.1.52\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: darrendignam\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.52\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 0b85b745d799aa9f82651a8851b657ee809ef8f3\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04921",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: lighthouse-foghorn\n  labels:\n    chart: lighthouse-1.1.52\n    app: lighthouse-foghorn\n    gitops.jenkins-x.io/pipeline: namespaces\n  annotations:\n    meta.helm.sh/release-name: lighthouse\n    wave.pusher.com/update-on-config-change: 'true'\n  namespace: jx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: lighthouse-foghorn\n  template:\n    metadata:\n      labels:\n        app: lighthouse-foghorn\n      annotations:\n        jenkins-x.io/hash: 64d2b982dc80b5c65271f2b9ff8b94777e4a148eca3fed68a4eebb84f6342f24\n    spec:\n      serviceAccountName: lighthouse-foghorn\n      containers:\n      - name: lighthouse-foghorn\n        image: ghcr.io/jenkins-x/lighthouse-foghorn:1.1.52\n        imagePullPolicy: IfNotPresent\n        args:\n        - --namespace=jx\n        env:\n        - name: GIT_KIND\n          value: github\n        - name: GIT_SERVER\n          value: https://github.com\n        - name: GIT_USER\n          value: darrendignam\n        - name: GIT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-oauth-token\n              key: oauth\n        - name: HMAC_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: lighthouse-hmac-token\n              key: hmac\n              optional: false\n        - name: JX_LOG_FORMAT\n          value: json\n        - name: LOGRUS_FORMAT\n          value: json\n        - name: LOGRUS_SERVICE\n          value: lighthouse\n        - name: LOGRUS_SERVICE_VERSION\n          value: 1.1.52\n        - name: LOGRUS_STACK_SKIP\n          value: ''\n        - name: DEFAULT_PIPELINE_RUN_SERVICE_ACCOUNT\n          value: tekton-bot\n        - name: DEFAULT_PIPELINE_RUN_TIMEOUT\n          value: 2h0m0s\n        - name: FILE_BROWSER\n          value: git\n        - name: JX_DEFAULT_IMAGE\n          value: ghcr.io/jenkins-x/builder-maven:2.1.149-768\n        - name: LIGHTHOUSE_DASHBOARD_TEMPLATE\n          value: namespaces/{{ .Namespace }}/pipelineruns/{{ .PipelineRun }}\n        - name: LIGHTHOUSE_VERSIONSTREAM_JENKINS_X_JX3_PIPELINE_CATALOG\n          value: 0b85b745d799aa9f82651a8851b657ee809ef8f3\n        resources:\n          limits:\n            cpu: 100m\n            memory: 256Mi\n          requests:\n            cpu: 80m\n            memory: 128Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04922",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: tiger\n  namespace: tiger\nspec:\n  containers:\n  - image: alpine:stable\n    name: main\n    args:\n    - /bin/sh\n    - -c\n    - sleep 60; touch /tmp/healthy; sleep 86400\n    livenessProbe:\n      exec:\n        command:\n        - cat\n        - /tmp/healthy\n      initialDelaySeconds: 65\n      periodSeconds: 5\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04923",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: tiger\n  namespace: tiger\nspec:\n  containers:\n  - image: alpine:stable\n    name: main\n    args:\n    - /bin/sh\n    - -c\n    - sleep 60; touch /tmp/healthy; sleep 86400\n    livenessProbe:\n      exec:\n        command:\n        - cat\n        - /tmp/healthy\n      initialDelaySeconds: 65\n      periodSeconds: 5\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04924",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: tiger\n  namespace: tiger\nspec:\n  containers:\n  - image: alpine:stable\n    name: main\n    args:\n    - /bin/sh\n    - -c\n    - sleep 60; touch /tmp/healthy; sleep 86400\n    livenessProbe:\n      exec:\n        command:\n        - cat\n        - /tmp/healthy\n      initialDelaySeconds: 65\n      periodSeconds: 5\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04925",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: tiger\n  namespace: tiger\nspec:\n  containers:\n  - image: alpine:stable\n    name: main\n    args:\n    - /bin/sh\n    - -c\n    - sleep 60; touch /tmp/healthy; sleep 86400\n    livenessProbe:\n      exec:\n        command:\n        - cat\n        - /tmp/healthy\n      initialDelaySeconds: 65\n      periodSeconds: 5\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04926",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: tiger\n  namespace: tiger\nspec:\n  containers:\n  - image: alpine:stable\n    name: main\n    args:\n    - /bin/sh\n    - -c\n    - sleep 60; touch /tmp/healthy; sleep 86400\n    livenessProbe:\n      exec:\n        command:\n        - cat\n        - /tmp/healthy\n      initialDelaySeconds: 65\n      periodSeconds: 5\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04927",
    "policy_id": "no_latest_tag",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"tileserver-import\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04928",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"tileserver-import\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04929",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"tileserver-import\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04930",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"tileserver-import\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04931",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"tileserver-import\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "04932",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: esc\n  annotations:\n    version: 1.19.10\n  labels:\n    io.esc.service: web-server\n  name: web-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      io.esc.service: web-server\n  template:\n    metadata:\n      labels:\n        io.esc.service: web-server\n    spec:\n      containers:\n      - image: eu.gcr.io/zendphp-313619/esc-nginx:stable\n        name: web-server\n        ports:\n        - containerPort: 8080\n        - containerPort: 8081\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04933",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: esc\n  annotations:\n    version: 1.19.10\n  labels:\n    io.esc.service: web-server\n  name: web-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      io.esc.service: web-server\n  template:\n    metadata:\n      labels:\n        io.esc.service: web-server\n    spec:\n      containers:\n      - image: eu.gcr.io/zendphp-313619/esc-nginx:stable\n        name: web-server\n        ports:\n        - containerPort: 8080\n        - containerPort: 8081\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n",
    "errors": []
  },
  {
    "id": "04934",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: esc\n  annotations:\n    version: 1.19.10\n  labels:\n    io.esc.service: web-server\n  name: web-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      io.esc.service: web-server\n  template:\n    metadata:\n      labels:\n        io.esc.service: web-server\n    spec:\n      containers:\n      - image: eu.gcr.io/zendphp-313619/esc-nginx:stable\n        name: web-server\n        ports:\n        - containerPort: 8080\n        - containerPort: 8081\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04935",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: esc\n  annotations:\n    version: 1.19.10\n  labels:\n    io.esc.service: web-server\n  name: web-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      io.esc.service: web-server\n  template:\n    metadata:\n      labels:\n        io.esc.service: web-server\n    spec:\n      containers:\n      - image: eu.gcr.io/zendphp-313619/esc-nginx:stable\n        name: web-server\n        ports:\n        - containerPort: 8080\n        - containerPort: 8081\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04936",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: esc\n  annotations:\n    version: 1.19.10\n  labels:\n    io.esc.service: web-server\n  name: web-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      io.esc.service: web-server\n  template:\n    metadata:\n      labels:\n        io.esc.service: web-server\n    spec:\n      containers:\n      - image: eu.gcr.io/zendphp-313619/esc-nginx:stable\n        name: web-server\n        ports:\n        - containerPort: 8080\n        - containerPort: 8081\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04937",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-nuevo\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.9.1\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04938",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-nuevo\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.9.1\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04939",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-nuevo\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.9.1\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04940",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-nuevo\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.9.1\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04941",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"mysql-backup\" namespace: \"mariadb-galera\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04942",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"mysql-backup\" namespace: \"mariadb-galera\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04943",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"mysql-backup\" namespace: \"mariadb-galera\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04944",
    "policy_id": "set_requests_limits",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: error: resource mapping not found for name: \"mysql-backup\" namespace: \"mariadb-galera\" from \"STDIN\": no matches for kind \"CronJob\" in version \"batch/v1beta1\"\nensure CRDs are installed first"
    ]
  },
  {
    "id": "04945",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cra-boilerplate-front\n  labels:\n    app: cra-boilerplate\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: front\n  template:\n    metadata:\n      labels:\n        app: front\n    spec:\n      containers:\n      - name: cra-front\n        image: nginx:1.7.9\n        ports:\n        - containerPort: 80\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04946",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cra-boilerplate-front\n  labels:\n    app: cra-boilerplate\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: front\n  template:\n    metadata:\n      labels:\n        app: front\n    spec:\n      containers:\n      - name: cra-front\n        image: nginx:1.7.9\n        ports:\n        - containerPort: 80\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04947",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cra-boilerplate-front\n  labels:\n    app: cra-boilerplate\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: front\n  template:\n    metadata:\n      labels:\n        app: front\n    spec:\n      containers:\n      - name: cra-front\n        image: nginx:1.7.9\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04948",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: cra-boilerplate-front\n  labels:\n    app: cra-boilerplate\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: front\n  template:\n    metadata:\n      labels:\n        app: front\n    spec:\n      containers:\n      - name: cra-front\n        image: nginx:1.7.9\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04949",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gruppenname-frontend\n  namespace: sachs\n  labels:\n    app: gruppenname-frontend\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: gruppenname-frontend\n    spec:\n      containers:\n      - name: gruppenname-frontend\n        image: registry.datexis.com/ksachs/gruppenname-frontend:stable\n        ports:\n        - name: client-port\n          containerPort: 8080\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n  selector:\n    matchLabels:\n      app: gruppenname-frontend\n",
    "errors": []
  },
  {
    "id": "04950",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gruppenname-frontend\n  namespace: sachs\n  labels:\n    app: gruppenname-frontend\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: gruppenname-frontend\n    spec:\n      containers:\n      - name: gruppenname-frontend\n        image: registry.datexis.com/ksachs/gruppenname-frontend:stable\n        ports:\n        - name: client-port\n          containerPort: 8080\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n  selector:\n    matchLabels:\n      app: gruppenname-frontend\n",
    "errors": []
  },
  {
    "id": "04951",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gruppenname-frontend\n  namespace: sachs\n  labels:\n    app: gruppenname-frontend\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: gruppenname-frontend\n    spec:\n      containers:\n      - name: gruppenname-frontend\n        image: registry.datexis.com/ksachs/gruppenname-frontend:stable\n        ports:\n        - name: client-port\n          containerPort: 8080\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n  selector:\n    matchLabels:\n      app: gruppenname-frontend\n",
    "errors": []
  },
  {
    "id": "04952",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gruppenname-frontend\n  namespace: sachs\n  labels:\n    app: gruppenname-frontend\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: gruppenname-frontend\n    spec:\n      containers:\n      - name: gruppenname-frontend\n        image: registry.datexis.com/ksachs/gruppenname-frontend:stable\n        ports:\n        - name: client-port\n          containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n  selector:\n    matchLabels:\n      app: gruppenname-frontend\n",
    "errors": []
  },
  {
    "id": "04953",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: gruppenname-frontend\n  namespace: sachs\n  labels:\n    app: gruppenname-frontend\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: gruppenname-frontend\n    spec:\n      containers:\n      - name: gruppenname-frontend\n        image: registry.datexis.com/ksachs/gruppenname-frontend:stable\n        ports:\n        - name: client-port\n          containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n  selector:\n    matchLabels:\n      app: gruppenname-frontend\n",
    "errors": []
  },
  {
    "id": "04954",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger-operator\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: jaeger-operator\n  template:\n    metadata:\n      labels:\n        name: jaeger-operator\n    spec:\n      serviceAccountName: jaeger-operator\n      containers:\n      - name: jaeger-operator\n        image: jaegertracing/jaeger-operator:1.14.0\n        ports:\n        - containerPort: 8383\n          name: metrics\n        args:\n        - start\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: jaeger-operator\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04955",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger-operator\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: jaeger-operator\n  template:\n    metadata:\n      labels:\n        name: jaeger-operator\n    spec:\n      serviceAccountName: jaeger-operator\n      containers:\n      - name: jaeger-operator\n        image: jaegertracing/jaeger-operator:1.14.0\n        ports:\n        - containerPort: 8383\n          name: metrics\n        args:\n        - start\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: jaeger-operator\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04956",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger-operator\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: jaeger-operator\n  template:\n    metadata:\n      labels:\n        name: jaeger-operator\n    spec:\n      serviceAccountName: jaeger-operator\n      containers:\n      - name: jaeger-operator\n        image: jaegertracing/jaeger-operator:1.14.0\n        ports:\n        - containerPort: 8383\n          name: metrics\n        args:\n        - start\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: jaeger-operator\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04957",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jaeger-operator\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      name: jaeger-operator\n  template:\n    metadata:\n      labels:\n        name: jaeger-operator\n    spec:\n      serviceAccountName: jaeger-operator\n      containers:\n      - name: jaeger-operator\n        image: jaegertracing/jaeger-operator:1.14.0\n        ports:\n        - containerPort: 8383\n          name: metrics\n        args:\n        - start\n        imagePullPolicy: Always\n        env:\n        - name: WATCH_NAMESPACE\n          value: ''\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OPERATOR_NAME\n          value: jaeger-operator\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04958",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: airbyte-scheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      airbyte: scheduler\n  template:\n    metadata:\n      labels:\n        airbyte: scheduler\n    spec:\n      serviceAccountName: airbyte-admin\n      containers:\n      - name: airbyte-scheduler-container\n        image: airbyte/scheduler:stable\n        env:\n        - name: AIRBYTE_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AIRBYTE_VERSION\n        - name: CONFIG_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: CONFIG_ROOT\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: database-password-secret\n              key: database_password\n        - name: DATABASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_URL\n        - name: DATABASE_USER\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_USER\n        - name: TRACKING_STRATEGY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TRACKING_STRATEGY\n        - name: WAIT_BEFORE_HOSTS\n          value: '5'\n        - name: WAIT_HOSTS\n          value: airbyte-db-svc:5432\n        - name: WAIT_HOSTS_TIMEOUT\n          value: '45'\n        - name: WORKSPACE_DOCKER_MOUNT\n          value: workspace\n        - name: WORKSPACE_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKSPACE_ROOT\n        - name: WORKER_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKER_ENVIRONMENT\n        - name: LOCAL_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: LOCAL_ROOT\n        - name: WEBAPP_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WEBAPP_URL\n        - name: TEMPORAL_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_HOST\n        - name: TEMPORAL_WORKER_PORTS\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_WORKER_PORTS\n        - name: S3_LOG_BUCKET\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET\n        - name: S3_LOG_BUCKET_REGION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET_REGION\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_ACCESS_KEY_ID\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_SECRET_ACCESS_KEY\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 9000\n        - containerPort: 9001\n        - containerPort: 9002\n        - containerPort: 9003\n        - containerPort: 9004\n        - containerPort: 9005\n        - containerPort: 9006\n        - containerPort: 9007\n        - containerPort: 9008\n        - containerPort: 9009\n        - containerPort: 9010\n        - containerPort: 9011\n        - containerPort: 9012\n        - containerPort: 9013\n        - containerPort: 9014\n        - containerPort: 9015\n        - containerPort: 9016\n        - containerPort: 9017\n        - containerPort: 9018\n        - containerPort: 9019\n        - containerPort: 9020\n        - containerPort: 9021\n        - containerPort: 9022\n        - containerPort: 9023\n        - containerPort: 9024\n        - containerPort: 9025\n        - containerPort: 9026\n        - containerPort: 9027\n        - containerPort: 9028\n        - containerPort: 9029\n        - containerPort: 9030\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: airbyte-seed\n        image: airbyte/seed:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /configs/config && yes n | cp -r -i /app/seed/config /configs\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: airbyte-volume-workspace\n        persistentVolumeClaim:\n          claimName: airbyte-volume-workspace\n      - name: airbyte-volume-configs\n        persistentVolumeClaim:\n          claimName: airbyte-volume-configs\n",
    "errors": []
  },
  {
    "id": "04959",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: airbyte-scheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      airbyte: scheduler\n  template:\n    metadata:\n      labels:\n        airbyte: scheduler\n    spec:\n      serviceAccountName: airbyte-admin\n      containers:\n      - name: airbyte-scheduler-container\n        image: airbyte/scheduler:stable\n        env:\n        - name: AIRBYTE_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AIRBYTE_VERSION\n        - name: CONFIG_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: CONFIG_ROOT\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: database-password-secret\n              key: database_password\n        - name: DATABASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_URL\n        - name: DATABASE_USER\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_USER\n        - name: TRACKING_STRATEGY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TRACKING_STRATEGY\n        - name: WAIT_BEFORE_HOSTS\n          value: '5'\n        - name: WAIT_HOSTS\n          value: airbyte-db-svc:5432\n        - name: WAIT_HOSTS_TIMEOUT\n          value: '45'\n        - name: WORKSPACE_DOCKER_MOUNT\n          value: workspace\n        - name: WORKSPACE_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKSPACE_ROOT\n        - name: WORKER_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKER_ENVIRONMENT\n        - name: LOCAL_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: LOCAL_ROOT\n        - name: WEBAPP_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WEBAPP_URL\n        - name: TEMPORAL_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_HOST\n        - name: TEMPORAL_WORKER_PORTS\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_WORKER_PORTS\n        - name: S3_LOG_BUCKET\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET\n        - name: S3_LOG_BUCKET_REGION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET_REGION\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_ACCESS_KEY_ID\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_SECRET_ACCESS_KEY\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 9000\n        - containerPort: 9001\n        - containerPort: 9002\n        - containerPort: 9003\n        - containerPort: 9004\n        - containerPort: 9005\n        - containerPort: 9006\n        - containerPort: 9007\n        - containerPort: 9008\n        - containerPort: 9009\n        - containerPort: 9010\n        - containerPort: 9011\n        - containerPort: 9012\n        - containerPort: 9013\n        - containerPort: 9014\n        - containerPort: 9015\n        - containerPort: 9016\n        - containerPort: 9017\n        - containerPort: 9018\n        - containerPort: 9019\n        - containerPort: 9020\n        - containerPort: 9021\n        - containerPort: 9022\n        - containerPort: 9023\n        - containerPort: 9024\n        - containerPort: 9025\n        - containerPort: 9026\n        - containerPort: 9027\n        - containerPort: 9028\n        - containerPort: 9029\n        - containerPort: 9030\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: airbyte-seed\n        image: airbyte/seed:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /configs/config && yes n | cp -r -i /app/seed/config /configs\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: airbyte-volume-workspace\n        persistentVolumeClaim:\n          claimName: airbyte-volume-workspace\n      - name: airbyte-volume-configs\n        persistentVolumeClaim:\n          claimName: airbyte-volume-configs\n",
    "errors": []
  },
  {
    "id": "04960",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: airbyte-scheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      airbyte: scheduler\n  template:\n    metadata:\n      labels:\n        airbyte: scheduler\n    spec:\n      serviceAccountName: airbyte-admin\n      containers:\n      - name: airbyte-scheduler-container\n        image: airbyte/scheduler:stable\n        env:\n        - name: AIRBYTE_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AIRBYTE_VERSION\n        - name: CONFIG_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: CONFIG_ROOT\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: database-password-secret\n              key: database_password\n        - name: DATABASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_URL\n        - name: DATABASE_USER\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_USER\n        - name: TRACKING_STRATEGY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TRACKING_STRATEGY\n        - name: WAIT_BEFORE_HOSTS\n          value: '5'\n        - name: WAIT_HOSTS\n          value: airbyte-db-svc:5432\n        - name: WAIT_HOSTS_TIMEOUT\n          value: '45'\n        - name: WORKSPACE_DOCKER_MOUNT\n          value: workspace\n        - name: WORKSPACE_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKSPACE_ROOT\n        - name: WORKER_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKER_ENVIRONMENT\n        - name: LOCAL_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: LOCAL_ROOT\n        - name: WEBAPP_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WEBAPP_URL\n        - name: TEMPORAL_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_HOST\n        - name: TEMPORAL_WORKER_PORTS\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_WORKER_PORTS\n        - name: S3_LOG_BUCKET\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET\n        - name: S3_LOG_BUCKET_REGION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET_REGION\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_ACCESS_KEY_ID\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_SECRET_ACCESS_KEY\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 9000\n        - containerPort: 9001\n        - containerPort: 9002\n        - containerPort: 9003\n        - containerPort: 9004\n        - containerPort: 9005\n        - containerPort: 9006\n        - containerPort: 9007\n        - containerPort: 9008\n        - containerPort: 9009\n        - containerPort: 9010\n        - containerPort: 9011\n        - containerPort: 9012\n        - containerPort: 9013\n        - containerPort: 9014\n        - containerPort: 9015\n        - containerPort: 9016\n        - containerPort: 9017\n        - containerPort: 9018\n        - containerPort: 9019\n        - containerPort: 9020\n        - containerPort: 9021\n        - containerPort: 9022\n        - containerPort: 9023\n        - containerPort: 9024\n        - containerPort: 9025\n        - containerPort: 9026\n        - containerPort: 9027\n        - containerPort: 9028\n        - containerPort: 9029\n        - containerPort: 9030\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: airbyte-seed\n        image: airbyte/seed:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /configs/config && yes n | cp -r -i /app/seed/config /configs\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: airbyte-volume-workspace\n        persistentVolumeClaim:\n          claimName: airbyte-volume-workspace\n      - name: airbyte-volume-configs\n        persistentVolumeClaim:\n          claimName: airbyte-volume-configs\n",
    "errors": []
  },
  {
    "id": "04961",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: airbyte-scheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      airbyte: scheduler\n  template:\n    metadata:\n      labels:\n        airbyte: scheduler\n    spec:\n      serviceAccountName: airbyte-admin\n      containers:\n      - name: airbyte-scheduler-container\n        image: airbyte/scheduler:stable\n        env:\n        - name: AIRBYTE_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AIRBYTE_VERSION\n        - name: CONFIG_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: CONFIG_ROOT\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: database-password-secret\n              key: database_password\n        - name: DATABASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_URL\n        - name: DATABASE_USER\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_USER\n        - name: TRACKING_STRATEGY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TRACKING_STRATEGY\n        - name: WAIT_BEFORE_HOSTS\n          value: '5'\n        - name: WAIT_HOSTS\n          value: airbyte-db-svc:5432\n        - name: WAIT_HOSTS_TIMEOUT\n          value: '45'\n        - name: WORKSPACE_DOCKER_MOUNT\n          value: workspace\n        - name: WORKSPACE_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKSPACE_ROOT\n        - name: WORKER_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKER_ENVIRONMENT\n        - name: LOCAL_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: LOCAL_ROOT\n        - name: WEBAPP_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WEBAPP_URL\n        - name: TEMPORAL_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_HOST\n        - name: TEMPORAL_WORKER_PORTS\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_WORKER_PORTS\n        - name: S3_LOG_BUCKET\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET\n        - name: S3_LOG_BUCKET_REGION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET_REGION\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_ACCESS_KEY_ID\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_SECRET_ACCESS_KEY\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 9000\n        - containerPort: 9001\n        - containerPort: 9002\n        - containerPort: 9003\n        - containerPort: 9004\n        - containerPort: 9005\n        - containerPort: 9006\n        - containerPort: 9007\n        - containerPort: 9008\n        - containerPort: 9009\n        - containerPort: 9010\n        - containerPort: 9011\n        - containerPort: 9012\n        - containerPort: 9013\n        - containerPort: 9014\n        - containerPort: 9015\n        - containerPort: 9016\n        - containerPort: 9017\n        - containerPort: 9018\n        - containerPort: 9019\n        - containerPort: 9020\n        - containerPort: 9021\n        - containerPort: 9022\n        - containerPort: 9023\n        - containerPort: 9024\n        - containerPort: 9025\n        - containerPort: 9026\n        - containerPort: 9027\n        - containerPort: 9028\n        - containerPort: 9029\n        - containerPort: 9030\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: airbyte-seed\n        image: airbyte/seed:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /configs/config && yes n | cp -r -i /app/seed/config /configs\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: airbyte-volume-workspace\n        persistentVolumeClaim:\n          claimName: airbyte-volume-workspace\n      - name: airbyte-volume-configs\n        persistentVolumeClaim:\n          claimName: airbyte-volume-configs\n",
    "errors": []
  },
  {
    "id": "04962",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: airbyte-scheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      airbyte: scheduler\n  template:\n    metadata:\n      labels:\n        airbyte: scheduler\n    spec:\n      serviceAccountName: airbyte-admin\n      containers:\n      - name: airbyte-scheduler-container\n        image: airbyte/scheduler:stable\n        env:\n        - name: AIRBYTE_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AIRBYTE_VERSION\n        - name: CONFIG_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: CONFIG_ROOT\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: database-password-secret\n              key: database_password\n        - name: DATABASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_URL\n        - name: DATABASE_USER\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_USER\n        - name: TRACKING_STRATEGY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TRACKING_STRATEGY\n        - name: WAIT_BEFORE_HOSTS\n          value: '5'\n        - name: WAIT_HOSTS\n          value: airbyte-db-svc:5432\n        - name: WAIT_HOSTS_TIMEOUT\n          value: '45'\n        - name: WORKSPACE_DOCKER_MOUNT\n          value: workspace\n        - name: WORKSPACE_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKSPACE_ROOT\n        - name: WORKER_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKER_ENVIRONMENT\n        - name: LOCAL_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: LOCAL_ROOT\n        - name: WEBAPP_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WEBAPP_URL\n        - name: TEMPORAL_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_HOST\n        - name: TEMPORAL_WORKER_PORTS\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_WORKER_PORTS\n        - name: S3_LOG_BUCKET\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET\n        - name: S3_LOG_BUCKET_REGION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET_REGION\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_ACCESS_KEY_ID\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_SECRET_ACCESS_KEY\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 9000\n        - containerPort: 9001\n        - containerPort: 9002\n        - containerPort: 9003\n        - containerPort: 9004\n        - containerPort: 9005\n        - containerPort: 9006\n        - containerPort: 9007\n        - containerPort: 9008\n        - containerPort: 9009\n        - containerPort: 9010\n        - containerPort: 9011\n        - containerPort: 9012\n        - containerPort: 9013\n        - containerPort: 9014\n        - containerPort: 9015\n        - containerPort: 9016\n        - containerPort: 9017\n        - containerPort: 9018\n        - containerPort: 9019\n        - containerPort: 9020\n        - containerPort: 9021\n        - containerPort: 9022\n        - containerPort: 9023\n        - containerPort: 9024\n        - containerPort: 9025\n        - containerPort: 9026\n        - containerPort: 9027\n        - containerPort: 9028\n        - containerPort: 9029\n        - containerPort: 9030\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: airbyte-seed\n        image: airbyte/seed:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /configs/config && yes n | cp -r -i /app/seed/config /configs\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: airbyte-volume-workspace\n        persistentVolumeClaim:\n          claimName: airbyte-volume-workspace\n      - name: airbyte-volume-configs\n        persistentVolumeClaim:\n          claimName: airbyte-volume-configs\n",
    "errors": []
  },
  {
    "id": "04963",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: airbyte-scheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      airbyte: scheduler\n  template:\n    metadata:\n      labels:\n        airbyte: scheduler\n    spec:\n      serviceAccountName: airbyte-admin\n      containers:\n      - name: airbyte-scheduler-container\n        image: airbyte/scheduler:stable\n        env:\n        - name: AIRBYTE_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AIRBYTE_VERSION\n        - name: CONFIG_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: CONFIG_ROOT\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: database-password-secret\n              key: database_password\n        - name: DATABASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_URL\n        - name: DATABASE_USER\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_USER\n        - name: TRACKING_STRATEGY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TRACKING_STRATEGY\n        - name: WAIT_BEFORE_HOSTS\n          value: '5'\n        - name: WAIT_HOSTS\n          value: airbyte-db-svc:5432\n        - name: WAIT_HOSTS_TIMEOUT\n          value: '45'\n        - name: WORKSPACE_DOCKER_MOUNT\n          value: workspace\n        - name: WORKSPACE_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKSPACE_ROOT\n        - name: WORKER_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKER_ENVIRONMENT\n        - name: LOCAL_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: LOCAL_ROOT\n        - name: WEBAPP_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WEBAPP_URL\n        - name: TEMPORAL_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_HOST\n        - name: TEMPORAL_WORKER_PORTS\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_WORKER_PORTS\n        - name: S3_LOG_BUCKET\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET\n        - name: S3_LOG_BUCKET_REGION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET_REGION\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_ACCESS_KEY_ID\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_SECRET_ACCESS_KEY\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 9000\n        - containerPort: 9001\n        - containerPort: 9002\n        - containerPort: 9003\n        - containerPort: 9004\n        - containerPort: 9005\n        - containerPort: 9006\n        - containerPort: 9007\n        - containerPort: 9008\n        - containerPort: 9009\n        - containerPort: 9010\n        - containerPort: 9011\n        - containerPort: 9012\n        - containerPort: 9013\n        - containerPort: 9014\n        - containerPort: 9015\n        - containerPort: 9016\n        - containerPort: 9017\n        - containerPort: 9018\n        - containerPort: 9019\n        - containerPort: 9020\n        - containerPort: 9021\n        - containerPort: 9022\n        - containerPort: 9023\n        - containerPort: 9024\n        - containerPort: 9025\n        - containerPort: 9026\n        - containerPort: 9027\n        - containerPort: 9028\n        - containerPort: 9029\n        - containerPort: 9030\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      initContainers:\n      - name: airbyte-seed\n        image: airbyte/seed:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /configs/config && yes n | cp -r -i /app/seed/config /configs\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: airbyte-volume-workspace\n        persistentVolumeClaim:\n          claimName: airbyte-volume-workspace\n      - name: airbyte-volume-configs\n        persistentVolumeClaim:\n          claimName: airbyte-volume-configs\n",
    "errors": []
  },
  {
    "id": "04964",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: airbyte-scheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      airbyte: scheduler\n  template:\n    metadata:\n      labels:\n        airbyte: scheduler\n    spec:\n      serviceAccountName: airbyte-admin\n      containers:\n      - name: airbyte-scheduler-container\n        image: airbyte/scheduler:stable\n        env:\n        - name: AIRBYTE_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AIRBYTE_VERSION\n        - name: CONFIG_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: CONFIG_ROOT\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: database-password-secret\n              key: database_password\n        - name: DATABASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_URL\n        - name: DATABASE_USER\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_USER\n        - name: TRACKING_STRATEGY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TRACKING_STRATEGY\n        - name: WAIT_BEFORE_HOSTS\n          value: '5'\n        - name: WAIT_HOSTS\n          value: airbyte-db-svc:5432\n        - name: WAIT_HOSTS_TIMEOUT\n          value: '45'\n        - name: WORKSPACE_DOCKER_MOUNT\n          value: workspace\n        - name: WORKSPACE_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKSPACE_ROOT\n        - name: WORKER_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKER_ENVIRONMENT\n        - name: LOCAL_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: LOCAL_ROOT\n        - name: WEBAPP_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WEBAPP_URL\n        - name: TEMPORAL_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_HOST\n        - name: TEMPORAL_WORKER_PORTS\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_WORKER_PORTS\n        - name: S3_LOG_BUCKET\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET\n        - name: S3_LOG_BUCKET_REGION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET_REGION\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_ACCESS_KEY_ID\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_SECRET_ACCESS_KEY\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 9000\n        - containerPort: 9001\n        - containerPort: 9002\n        - containerPort: 9003\n        - containerPort: 9004\n        - containerPort: 9005\n        - containerPort: 9006\n        - containerPort: 9007\n        - containerPort: 9008\n        - containerPort: 9009\n        - containerPort: 9010\n        - containerPort: 9011\n        - containerPort: 9012\n        - containerPort: 9013\n        - containerPort: 9014\n        - containerPort: 9015\n        - containerPort: 9016\n        - containerPort: 9017\n        - containerPort: 9018\n        - containerPort: 9019\n        - containerPort: 9020\n        - containerPort: 9021\n        - containerPort: 9022\n        - containerPort: 9023\n        - containerPort: 9024\n        - containerPort: 9025\n        - containerPort: 9026\n        - containerPort: 9027\n        - containerPort: 9028\n        - containerPort: 9029\n        - containerPort: 9030\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: airbyte-seed\n        image: airbyte/seed:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /configs/config && yes n | cp -r -i /app/seed/config /configs\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: airbyte-volume-workspace\n        persistentVolumeClaim:\n          claimName: airbyte-volume-workspace\n      - name: airbyte-volume-configs\n        persistentVolumeClaim:\n          claimName: airbyte-volume-configs\n",
    "errors": []
  },
  {
    "id": "04965",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: airbyte-scheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      airbyte: scheduler\n  template:\n    metadata:\n      labels:\n        airbyte: scheduler\n    spec:\n      serviceAccountName: airbyte-admin\n      containers:\n      - name: airbyte-scheduler-container\n        image: airbyte/scheduler:stable\n        env:\n        - name: AIRBYTE_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AIRBYTE_VERSION\n        - name: CONFIG_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: CONFIG_ROOT\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: database-password-secret\n              key: database_password\n        - name: DATABASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_URL\n        - name: DATABASE_USER\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_USER\n        - name: TRACKING_STRATEGY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TRACKING_STRATEGY\n        - name: WAIT_BEFORE_HOSTS\n          value: '5'\n        - name: WAIT_HOSTS\n          value: airbyte-db-svc:5432\n        - name: WAIT_HOSTS_TIMEOUT\n          value: '45'\n        - name: WORKSPACE_DOCKER_MOUNT\n          value: workspace\n        - name: WORKSPACE_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKSPACE_ROOT\n        - name: WORKER_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKER_ENVIRONMENT\n        - name: LOCAL_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: LOCAL_ROOT\n        - name: WEBAPP_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WEBAPP_URL\n        - name: TEMPORAL_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_HOST\n        - name: TEMPORAL_WORKER_PORTS\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_WORKER_PORTS\n        - name: S3_LOG_BUCKET\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET\n        - name: S3_LOG_BUCKET_REGION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET_REGION\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_ACCESS_KEY_ID\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_SECRET_ACCESS_KEY\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 9000\n        - containerPort: 9001\n        - containerPort: 9002\n        - containerPort: 9003\n        - containerPort: 9004\n        - containerPort: 9005\n        - containerPort: 9006\n        - containerPort: 9007\n        - containerPort: 9008\n        - containerPort: 9009\n        - containerPort: 9010\n        - containerPort: 9011\n        - containerPort: 9012\n        - containerPort: 9013\n        - containerPort: 9014\n        - containerPort: 9015\n        - containerPort: 9016\n        - containerPort: 9017\n        - containerPort: 9018\n        - containerPort: 9019\n        - containerPort: 9020\n        - containerPort: 9021\n        - containerPort: 9022\n        - containerPort: 9023\n        - containerPort: 9024\n        - containerPort: 9025\n        - containerPort: 9026\n        - containerPort: 9027\n        - containerPort: 9028\n        - containerPort: 9029\n        - containerPort: 9030\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: airbyte-seed\n        image: airbyte/seed:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /configs/config && yes n | cp -r -i /app/seed/config /configs\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: airbyte-volume-workspace\n        persistentVolumeClaim:\n          claimName: airbyte-volume-workspace\n      - name: airbyte-volume-configs\n        persistentVolumeClaim:\n          claimName: airbyte-volume-configs\n",
    "errors": []
  },
  {
    "id": "04966",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: airbyte-scheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      airbyte: scheduler\n  template:\n    metadata:\n      labels:\n        airbyte: scheduler\n    spec:\n      serviceAccountName: airbyte-admin\n      containers:\n      - name: airbyte-scheduler-container\n        image: airbyte/scheduler:stable\n        env:\n        - name: AIRBYTE_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AIRBYTE_VERSION\n        - name: CONFIG_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: CONFIG_ROOT\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: database-password-secret\n              key: database_password\n        - name: DATABASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_URL\n        - name: DATABASE_USER\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_USER\n        - name: TRACKING_STRATEGY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TRACKING_STRATEGY\n        - name: WAIT_BEFORE_HOSTS\n          value: '5'\n        - name: WAIT_HOSTS\n          value: airbyte-db-svc:5432\n        - name: WAIT_HOSTS_TIMEOUT\n          value: '45'\n        - name: WORKSPACE_DOCKER_MOUNT\n          value: workspace\n        - name: WORKSPACE_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKSPACE_ROOT\n        - name: WORKER_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKER_ENVIRONMENT\n        - name: LOCAL_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: LOCAL_ROOT\n        - name: WEBAPP_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WEBAPP_URL\n        - name: TEMPORAL_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_HOST\n        - name: TEMPORAL_WORKER_PORTS\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_WORKER_PORTS\n        - name: S3_LOG_BUCKET\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET\n        - name: S3_LOG_BUCKET_REGION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET_REGION\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_ACCESS_KEY_ID\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_SECRET_ACCESS_KEY\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 9000\n        - containerPort: 9001\n        - containerPort: 9002\n        - containerPort: 9003\n        - containerPort: 9004\n        - containerPort: 9005\n        - containerPort: 9006\n        - containerPort: 9007\n        - containerPort: 9008\n        - containerPort: 9009\n        - containerPort: 9010\n        - containerPort: 9011\n        - containerPort: 9012\n        - containerPort: 9013\n        - containerPort: 9014\n        - containerPort: 9015\n        - containerPort: 9016\n        - containerPort: 9017\n        - containerPort: 9018\n        - containerPort: 9019\n        - containerPort: 9020\n        - containerPort: 9021\n        - containerPort: 9022\n        - containerPort: 9023\n        - containerPort: 9024\n        - containerPort: 9025\n        - containerPort: 9026\n        - containerPort: 9027\n        - containerPort: 9028\n        - containerPort: 9029\n        - containerPort: 9030\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: airbyte-seed\n        image: airbyte/seed:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /configs/config && yes n | cp -r -i /app/seed/config /configs\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: airbyte-volume-workspace\n        persistentVolumeClaim:\n          claimName: airbyte-volume-workspace\n      - name: airbyte-volume-configs\n        persistentVolumeClaim:\n          claimName: airbyte-volume-configs\n",
    "errors": []
  },
  {
    "id": "04967",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: airbyte-scheduler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      airbyte: scheduler\n  template:\n    metadata:\n      labels:\n        airbyte: scheduler\n    spec:\n      serviceAccountName: airbyte-admin\n      containers:\n      - name: airbyte-scheduler-container\n        image: airbyte/scheduler:stable\n        env:\n        - name: AIRBYTE_VERSION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AIRBYTE_VERSION\n        - name: CONFIG_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: CONFIG_ROOT\n        - name: DATABASE_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: database-password-secret\n              key: database_password\n        - name: DATABASE_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_URL\n        - name: DATABASE_USER\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: DATABASE_USER\n        - name: TRACKING_STRATEGY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TRACKING_STRATEGY\n        - name: WAIT_BEFORE_HOSTS\n          value: '5'\n        - name: WAIT_HOSTS\n          value: airbyte-db-svc:5432\n        - name: WAIT_HOSTS_TIMEOUT\n          value: '45'\n        - name: WORKSPACE_DOCKER_MOUNT\n          value: workspace\n        - name: WORKSPACE_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKSPACE_ROOT\n        - name: WORKER_ENVIRONMENT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WORKER_ENVIRONMENT\n        - name: LOCAL_ROOT\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: LOCAL_ROOT\n        - name: WEBAPP_URL\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: WEBAPP_URL\n        - name: TEMPORAL_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_HOST\n        - name: TEMPORAL_WORKER_PORTS\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: TEMPORAL_WORKER_PORTS\n        - name: S3_LOG_BUCKET\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET\n        - name: S3_LOG_BUCKET_REGION\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: S3_LOG_BUCKET_REGION\n        - name: AWS_ACCESS_KEY_ID\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_ACCESS_KEY_ID\n        - name: AWS_SECRET_ACCESS_KEY\n          valueFrom:\n            configMapKeyRef:\n              name: airbyte-env\n              key: AWS_SECRET_ACCESS_KEY\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 9000\n        - containerPort: 9001\n        - containerPort: 9002\n        - containerPort: 9003\n        - containerPort: 9004\n        - containerPort: 9005\n        - containerPort: 9006\n        - containerPort: 9007\n        - containerPort: 9008\n        - containerPort: 9009\n        - containerPort: 9010\n        - containerPort: 9011\n        - containerPort: 9012\n        - containerPort: 9013\n        - containerPort: 9014\n        - containerPort: 9015\n        - containerPort: 9016\n        - containerPort: 9017\n        - containerPort: 9018\n        - containerPort: 9019\n        - containerPort: 9020\n        - containerPort: 9021\n        - containerPort: 9022\n        - containerPort: 9023\n        - containerPort: 9024\n        - containerPort: 9025\n        - containerPort: 9026\n        - containerPort: 9027\n        - containerPort: 9028\n        - containerPort: 9029\n        - containerPort: 9030\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      initContainers:\n      - name: airbyte-seed\n        image: airbyte/seed:stable\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - mkdir -p /configs/config && yes n | cp -r -i /app/seed/config /configs\n        volumeMounts:\n        - name: airbyte-volume-configs\n          mountPath: /configs\n        - name: airbyte-volume-workspace\n          mountPath: /workspace\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: airbyte-volume-workspace\n        persistentVolumeClaim:\n          claimName: airbyte-volume-workspace\n      - name: airbyte-volume-configs\n        persistentVolumeClaim:\n          claimName: airbyte-volume-configs\n",
    "errors": []
  },
  {
    "id": "04968",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: slack-post-message\n  labels:\n    app: slack-post-message\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: slack-post-message\n  template:\n    metadata:\n      labels:\n        app: slack-post-message\n    spec:\n      containers:\n      - name: slack-post-message\n        image: gcr.io/k8s-staging-slack-infra/slack-post-message:v20200901-117c06f\n        args:\n        - --config-path=/etc/slack-post-message/config.json\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        env:\n        - name: PATH_PREFIX\n          value: /infra/post-message\n        volumeMounts:\n        - mountPath: /etc/slack-post-message\n          name: config\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            scheme: HTTP\n            port: 8080\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config\n        secret:\n          secretName: slack-post-message-config\n",
    "errors": []
  },
  {
    "id": "04969",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: slack-post-message\n  labels:\n    app: slack-post-message\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: slack-post-message\n  template:\n    metadata:\n      labels:\n        app: slack-post-message\n    spec:\n      containers:\n      - name: slack-post-message\n        image: gcr.io/k8s-staging-slack-infra/slack-post-message:v20200901-117c06f\n        args:\n        - --config-path=/etc/slack-post-message/config.json\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        env:\n        - name: PATH_PREFIX\n          value: /infra/post-message\n        volumeMounts:\n        - mountPath: /etc/slack-post-message\n          name: config\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            scheme: HTTP\n            port: 8080\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: config\n        secret:\n          secretName: slack-post-message-config\n",
    "errors": []
  },
  {
    "id": "04970",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: slack-post-message\n  labels:\n    app: slack-post-message\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: slack-post-message\n  template:\n    metadata:\n      labels:\n        app: slack-post-message\n    spec:\n      containers:\n      - name: slack-post-message\n        image: gcr.io/k8s-staging-slack-infra/slack-post-message:v20200901-117c06f\n        args:\n        - --config-path=/etc/slack-post-message/config.json\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        env:\n        - name: PATH_PREFIX\n          value: /infra/post-message\n        volumeMounts:\n        - mountPath: /etc/slack-post-message\n          name: config\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            scheme: HTTP\n            port: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        secret:\n          secretName: slack-post-message-config\n",
    "errors": []
  },
  {
    "id": "04971",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: slack-post-message\n  labels:\n    app: slack-post-message\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: slack-post-message\n  template:\n    metadata:\n      labels:\n        app: slack-post-message\n    spec:\n      containers:\n      - name: slack-post-message\n        image: gcr.io/k8s-staging-slack-infra/slack-post-message:v20200901-117c06f\n        args:\n        - --config-path=/etc/slack-post-message/config.json\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        env:\n        - name: PATH_PREFIX\n          value: /infra/post-message\n        volumeMounts:\n        - mountPath: /etc/slack-post-message\n          name: config\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            scheme: HTTP\n            port: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: config\n        secret:\n          secretName: slack-post-message-config\n",
    "errors": []
  },
  {
    "id": "04972",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: scc-broker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: scc-broker\n  template:\n    metadata:\n      labels:\n        component: scc-broker\n    spec:\n      containers:\n      - name: scc-broker\n        image: socketcluster/scc-broker:v6.0.1\n        ports:\n        - containerPort: 8888\n        env:\n        - name: SCC_STATE_SERVER_HOST\n          value: scc-state\n        - name: SOCKETCLUSTER_WORKERS\n          value: '1'\n        - name: SOCKETCLUSTER_BROKERS\n          value: '1'\n        - name: SCC_INSTANCE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: SCC_BROKER_SERVER_LOG_LEVEL\n          value: '2'\n        livenessProbe:\n          httpGet:\n            path: /health-check\n            port: 8888\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04973",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: scc-broker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: scc-broker\n  template:\n    metadata:\n      labels:\n        component: scc-broker\n    spec:\n      containers:\n      - name: scc-broker\n        image: socketcluster/scc-broker:v6.0.1\n        ports:\n        - containerPort: 8888\n        env:\n        - name: SCC_STATE_SERVER_HOST\n          value: scc-state\n        - name: SOCKETCLUSTER_WORKERS\n          value: '1'\n        - name: SOCKETCLUSTER_BROKERS\n          value: '1'\n        - name: SCC_INSTANCE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: SCC_BROKER_SERVER_LOG_LEVEL\n          value: '2'\n        livenessProbe:\n          httpGet:\n            path: /health-check\n            port: 8888\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04974",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: scc-broker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: scc-broker\n  template:\n    metadata:\n      labels:\n        component: scc-broker\n    spec:\n      containers:\n      - name: scc-broker\n        image: socketcluster/scc-broker:v6.0.1\n        ports:\n        - containerPort: 8888\n        env:\n        - name: SCC_STATE_SERVER_HOST\n          value: scc-state\n        - name: SOCKETCLUSTER_WORKERS\n          value: '1'\n        - name: SOCKETCLUSTER_BROKERS\n          value: '1'\n        - name: SCC_INSTANCE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: SCC_BROKER_SERVER_LOG_LEVEL\n          value: '2'\n        livenessProbe:\n          httpGet:\n            path: /health-check\n            port: 8888\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04975",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: scc-broker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      component: scc-broker\n  template:\n    metadata:\n      labels:\n        component: scc-broker\n    spec:\n      containers:\n      - name: scc-broker\n        image: socketcluster/scc-broker:v6.0.1\n        ports:\n        - containerPort: 8888\n        env:\n        - name: SCC_STATE_SERVER_HOST\n          value: scc-state\n        - name: SOCKETCLUSTER_WORKERS\n          value: '1'\n        - name: SOCKETCLUSTER_BROKERS\n          value: '1'\n        - name: SCC_INSTANCE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        - name: SCC_BROKER_SERVER_LOG_LEVEL\n          value: '2'\n        livenessProbe:\n          httpGet:\n            path: /health-check\n            port: 8888\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04976",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20210602-c9da972437\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --history-uri=gs://k8s-prow/tide-history.json\n        - --status-path=gs://k8s-prow/tide-status-checkpoint.yaml\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "04977",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20210602-c9da972437\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --history-uri=gs://k8s-prow/tide-history.json\n        - --status-path=gs://k8s-prow/tide-status-checkpoint.yaml\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "04978",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20210602-c9da972437\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --history-uri=gs://k8s-prow/tide-history.json\n        - --status-path=gs://k8s-prow/tide-status-checkpoint.yaml\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "04979",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: tide\n  labels:\n    app: tide\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: tide\n  template:\n    metadata:\n      labels:\n        app: tide\n    spec:\n      serviceAccountName: tide\n      containers:\n      - name: tide\n        image: gcr.io/k8s-prow/tide:v20210602-c9da972437\n        args:\n        - --dry-run=false\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --github-token-path=/etc/github/oauth\n        - --config-path=/etc/config/config.yaml\n        - --job-config-path=/etc/job-config\n        - --history-uri=gs://k8s-prow/tide-history.json\n        - --status-path=gs://k8s-prow/tide-status-checkpoint.yaml\n        ports:\n        - name: http\n          containerPort: 8888\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n",
    "errors": []
  },
  {
    "id": "04980",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: od-v1\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: od\n      version: v1\n  template:\n    metadata:\n      labels:\n        app: od\n        version: v1\n        env: production\n    spec:\n      containers:\n      - name: od\n        image: gcr.io/instructor-partition/od-fasterrcnn:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04981",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: od-v1\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: od\n      version: v1\n  template:\n    metadata:\n      labels:\n        app: od\n        version: v1\n        env: production\n    spec:\n      containers:\n      - name: od\n        image: gcr.io/instructor-partition/od-fasterrcnn:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04982",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: od-v1\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: od\n      version: v1\n  template:\n    metadata:\n      labels:\n        app: od\n        version: v1\n        env: production\n    spec:\n      containers:\n      - name: od\n        image: gcr.io/instructor-partition/od-fasterrcnn:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04983",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: od-v1\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: od\n      version: v1\n  template:\n    metadata:\n      labels:\n        app: od\n        version: v1\n        env: production\n    spec:\n      containers:\n      - name: od\n        image: gcr.io/instructor-partition/od-fasterrcnn:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04984",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: od-v1\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: od\n      version: v1\n  template:\n    metadata:\n      labels:\n        app: od\n        version: v1\n        env: production\n    spec:\n      containers:\n      - name: od\n        image: gcr.io/instructor-partition/od-fasterrcnn:stable\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04985",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-auth-service\n  annotations:\n    app.openshift.io/connects-to: '[{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"name\":\"postgres\"}]'\n  labels:\n    app.kubernetes.io/name: user-auth-service\n    app.kubernetes.io/part-of: device-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: user-auth-service\n      app.kubernetes.io/part-of: device-registry\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: user-auth-service\n        app.kubernetes.io/part-of: device-registry\n    spec:\n      initContainers:\n      - name: wait-for-client-secret\n        image: registry.access.redhat.com/ubi8-minimal:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - \"echo \\\"Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)...\\\"\\\n          \\nwhile test -z \\\"$(cat /etc/client-secret/CLIENT_SECRET)\\\"; do\\n  sleep\\\n          \\ 1\\ndone\\n\"\n        volumeMounts:\n        - mountPath: /etc/client-secret\n          name: client-secret\n          readOnly: true\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: service\n        image: ghcr.io/drogue-iot/user-auth-service:stable\n        imagePullPolicy: Always\n        env:\n        - name: RUST_LOG\n          value: debug\n        - name: BIND_ADDR\n          value: 0.0.0.0:8080\n        - name: HEALTH__BIND_ADDR\n          value: 0.0.0.0:9090\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SERVICE__PG__HOST\n          value: postgres\n        - name: SERVICE__PG__DBNAME\n          valueFrom:\n            configMapKeyRef:\n              name: postgres-config\n              key: databaseName\n        - name: SERVICE__PG__USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.username\n        - name: SERVICE__PG__PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.password\n        - name: OAUTH__SERVICES__CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_ID\n        - name: OAUTH__SERVICES__CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_SECRET\n        - name: KEYCLOAK__URL\n          value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443\n        - name: KEYCLOAK__ADMIN_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_USERNAME\n              name: credential-sso\n        - name: KEYCLOAK__ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_PASSWORD\n              name: credential-sso\n        readinessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /readiness\n        livenessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /liveness\n        ports:\n        - containerPort: 8080\n          name: api\n          protocol: TCP\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: client-secret\n        secret:\n          secretName: keycloak-client-secret-services\n",
    "errors": []
  },
  {
    "id": "04986",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-auth-service\n  annotations:\n    app.openshift.io/connects-to: '[{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"name\":\"postgres\"}]'\n  labels:\n    app.kubernetes.io/name: user-auth-service\n    app.kubernetes.io/part-of: device-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: user-auth-service\n      app.kubernetes.io/part-of: device-registry\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: user-auth-service\n        app.kubernetes.io/part-of: device-registry\n    spec:\n      initContainers:\n      - name: wait-for-client-secret\n        image: registry.access.redhat.com/ubi8-minimal:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - \"echo \\\"Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)...\\\"\\\n          \\nwhile test -z \\\"$(cat /etc/client-secret/CLIENT_SECRET)\\\"; do\\n  sleep\\\n          \\ 1\\ndone\\n\"\n        volumeMounts:\n        - mountPath: /etc/client-secret\n          name: client-secret\n          readOnly: true\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: service\n        image: ghcr.io/drogue-iot/user-auth-service:stable\n        imagePullPolicy: Always\n        env:\n        - name: RUST_LOG\n          value: debug\n        - name: BIND_ADDR\n          value: 0.0.0.0:8080\n        - name: HEALTH__BIND_ADDR\n          value: 0.0.0.0:9090\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SERVICE__PG__HOST\n          value: postgres\n        - name: SERVICE__PG__DBNAME\n          valueFrom:\n            configMapKeyRef:\n              name: postgres-config\n              key: databaseName\n        - name: SERVICE__PG__USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.username\n        - name: SERVICE__PG__PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.password\n        - name: OAUTH__SERVICES__CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_ID\n        - name: OAUTH__SERVICES__CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_SECRET\n        - name: KEYCLOAK__URL\n          value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443\n        - name: KEYCLOAK__ADMIN_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_USERNAME\n              name: credential-sso\n        - name: KEYCLOAK__ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_PASSWORD\n              name: credential-sso\n        readinessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /readiness\n        livenessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /liveness\n        ports:\n        - containerPort: 8080\n          name: api\n          protocol: TCP\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: client-secret\n        secret:\n          secretName: keycloak-client-secret-services\n",
    "errors": []
  },
  {
    "id": "04987",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-auth-service\n  annotations:\n    app.openshift.io/connects-to: '[{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"name\":\"postgres\"}]'\n  labels:\n    app.kubernetes.io/name: user-auth-service\n    app.kubernetes.io/part-of: device-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: user-auth-service\n      app.kubernetes.io/part-of: device-registry\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: user-auth-service\n        app.kubernetes.io/part-of: device-registry\n    spec:\n      initContainers:\n      - name: wait-for-client-secret\n        image: registry.access.redhat.com/ubi8-minimal:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - \"echo \\\"Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)...\\\"\\\n          \\nwhile test -z \\\"$(cat /etc/client-secret/CLIENT_SECRET)\\\"; do\\n  sleep\\\n          \\ 1\\ndone\\n\"\n        volumeMounts:\n        - mountPath: /etc/client-secret\n          name: client-secret\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: service\n        image: ghcr.io/drogue-iot/user-auth-service:stable\n        imagePullPolicy: Always\n        env:\n        - name: RUST_LOG\n          value: debug\n        - name: BIND_ADDR\n          value: 0.0.0.0:8080\n        - name: HEALTH__BIND_ADDR\n          value: 0.0.0.0:9090\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SERVICE__PG__HOST\n          value: postgres\n        - name: SERVICE__PG__DBNAME\n          valueFrom:\n            configMapKeyRef:\n              name: postgres-config\n              key: databaseName\n        - name: SERVICE__PG__USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.username\n        - name: SERVICE__PG__PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.password\n        - name: OAUTH__SERVICES__CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_ID\n        - name: OAUTH__SERVICES__CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_SECRET\n        - name: KEYCLOAK__URL\n          value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443\n        - name: KEYCLOAK__ADMIN_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_USERNAME\n              name: credential-sso\n        - name: KEYCLOAK__ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_PASSWORD\n              name: credential-sso\n        readinessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /readiness\n        livenessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /liveness\n        ports:\n        - containerPort: 8080\n          name: api\n          protocol: TCP\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: client-secret\n        secret:\n          secretName: keycloak-client-secret-services\n",
    "errors": []
  },
  {
    "id": "04988",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-auth-service\n  annotations:\n    app.openshift.io/connects-to: '[{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"name\":\"postgres\"}]'\n  labels:\n    app.kubernetes.io/name: user-auth-service\n    app.kubernetes.io/part-of: device-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: user-auth-service\n      app.kubernetes.io/part-of: device-registry\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: user-auth-service\n        app.kubernetes.io/part-of: device-registry\n    spec:\n      initContainers:\n      - name: wait-for-client-secret\n        image: registry.access.redhat.com/ubi8-minimal:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - \"echo \\\"Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)...\\\"\\\n          \\nwhile test -z \\\"$(cat /etc/client-secret/CLIENT_SECRET)\\\"; do\\n  sleep\\\n          \\ 1\\ndone\\n\"\n        volumeMounts:\n        - mountPath: /etc/client-secret\n          name: client-secret\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: service\n        image: ghcr.io/drogue-iot/user-auth-service:stable\n        imagePullPolicy: Always\n        env:\n        - name: RUST_LOG\n          value: debug\n        - name: BIND_ADDR\n          value: 0.0.0.0:8080\n        - name: HEALTH__BIND_ADDR\n          value: 0.0.0.0:9090\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SERVICE__PG__HOST\n          value: postgres\n        - name: SERVICE__PG__DBNAME\n          valueFrom:\n            configMapKeyRef:\n              name: postgres-config\n              key: databaseName\n        - name: SERVICE__PG__USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.username\n        - name: SERVICE__PG__PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.password\n        - name: OAUTH__SERVICES__CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_ID\n        - name: OAUTH__SERVICES__CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_SECRET\n        - name: KEYCLOAK__URL\n          value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443\n        - name: KEYCLOAK__ADMIN_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_USERNAME\n              name: credential-sso\n        - name: KEYCLOAK__ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_PASSWORD\n              name: credential-sso\n        readinessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /readiness\n        livenessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /liveness\n        ports:\n        - containerPort: 8080\n          name: api\n          protocol: TCP\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n      volumes:\n      - name: client-secret\n        secret:\n          secretName: keycloak-client-secret-services\n",
    "errors": []
  },
  {
    "id": "04989",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-auth-service\n  annotations:\n    app.openshift.io/connects-to: '[{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"name\":\"postgres\"}]'\n  labels:\n    app.kubernetes.io/name: user-auth-service\n    app.kubernetes.io/part-of: device-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: user-auth-service\n      app.kubernetes.io/part-of: device-registry\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: user-auth-service\n        app.kubernetes.io/part-of: device-registry\n    spec:\n      initContainers:\n      - name: wait-for-client-secret\n        image: registry.access.redhat.com/ubi8-minimal:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - \"echo \\\"Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)...\\\"\\\n          \\nwhile test -z \\\"$(cat /etc/client-secret/CLIENT_SECRET)\\\"; do\\n  sleep\\\n          \\ 1\\ndone\\n\"\n        volumeMounts:\n        - mountPath: /etc/client-secret\n          name: client-secret\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: service\n        image: ghcr.io/drogue-iot/user-auth-service:stable\n        imagePullPolicy: Always\n        env:\n        - name: RUST_LOG\n          value: debug\n        - name: BIND_ADDR\n          value: 0.0.0.0:8080\n        - name: HEALTH__BIND_ADDR\n          value: 0.0.0.0:9090\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SERVICE__PG__HOST\n          value: postgres\n        - name: SERVICE__PG__DBNAME\n          valueFrom:\n            configMapKeyRef:\n              name: postgres-config\n              key: databaseName\n        - name: SERVICE__PG__USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.username\n        - name: SERVICE__PG__PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.password\n        - name: OAUTH__SERVICES__CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_ID\n        - name: OAUTH__SERVICES__CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_SECRET\n        - name: KEYCLOAK__URL\n          value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443\n        - name: KEYCLOAK__ADMIN_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_USERNAME\n              name: credential-sso\n        - name: KEYCLOAK__ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_PASSWORD\n              name: credential-sso\n        readinessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /readiness\n        livenessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /liveness\n        ports:\n        - containerPort: 8080\n          name: api\n          protocol: TCP\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: client-secret\n        secret:\n          secretName: keycloak-client-secret-services\n",
    "errors": []
  },
  {
    "id": "04990",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-auth-service\n  annotations:\n    app.openshift.io/connects-to: '[{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"name\":\"postgres\"}]'\n  labels:\n    app.kubernetes.io/name: user-auth-service\n    app.kubernetes.io/part-of: device-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: user-auth-service\n      app.kubernetes.io/part-of: device-registry\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: user-auth-service\n        app.kubernetes.io/part-of: device-registry\n    spec:\n      initContainers:\n      - name: wait-for-client-secret\n        image: registry.access.redhat.com/ubi8-minimal:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - \"echo \\\"Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)...\\\"\\\n          \\nwhile test -z \\\"$(cat /etc/client-secret/CLIENT_SECRET)\\\"; do\\n  sleep\\\n          \\ 1\\ndone\\n\"\n        volumeMounts:\n        - mountPath: /etc/client-secret\n          name: client-secret\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n      containers:\n      - name: service\n        image: ghcr.io/drogue-iot/user-auth-service:stable\n        imagePullPolicy: Always\n        env:\n        - name: RUST_LOG\n          value: debug\n        - name: BIND_ADDR\n          value: 0.0.0.0:8080\n        - name: HEALTH__BIND_ADDR\n          value: 0.0.0.0:9090\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SERVICE__PG__HOST\n          value: postgres\n        - name: SERVICE__PG__DBNAME\n          valueFrom:\n            configMapKeyRef:\n              name: postgres-config\n              key: databaseName\n        - name: SERVICE__PG__USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.username\n        - name: SERVICE__PG__PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.password\n        - name: OAUTH__SERVICES__CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_ID\n        - name: OAUTH__SERVICES__CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_SECRET\n        - name: KEYCLOAK__URL\n          value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443\n        - name: KEYCLOAK__ADMIN_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_USERNAME\n              name: credential-sso\n        - name: KEYCLOAK__ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_PASSWORD\n              name: credential-sso\n        readinessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /readiness\n        livenessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /liveness\n        ports:\n        - containerPort: 8080\n          name: api\n          protocol: TCP\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: client-secret\n        secret:\n          secretName: keycloak-client-secret-services\n",
    "errors": []
  },
  {
    "id": "04991",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-auth-service\n  annotations:\n    app.openshift.io/connects-to: '[{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"name\":\"postgres\"}]'\n  labels:\n    app.kubernetes.io/name: user-auth-service\n    app.kubernetes.io/part-of: device-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: user-auth-service\n      app.kubernetes.io/part-of: device-registry\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: user-auth-service\n        app.kubernetes.io/part-of: device-registry\n    spec:\n      initContainers:\n      - name: wait-for-client-secret\n        image: registry.access.redhat.com/ubi8-minimal:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - \"echo \\\"Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)...\\\"\\\n          \\nwhile test -z \\\"$(cat /etc/client-secret/CLIENT_SECRET)\\\"; do\\n  sleep\\\n          \\ 1\\ndone\\n\"\n        volumeMounts:\n        - mountPath: /etc/client-secret\n          name: client-secret\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: service\n        image: ghcr.io/drogue-iot/user-auth-service:stable\n        imagePullPolicy: Always\n        env:\n        - name: RUST_LOG\n          value: debug\n        - name: BIND_ADDR\n          value: 0.0.0.0:8080\n        - name: HEALTH__BIND_ADDR\n          value: 0.0.0.0:9090\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SERVICE__PG__HOST\n          value: postgres\n        - name: SERVICE__PG__DBNAME\n          valueFrom:\n            configMapKeyRef:\n              name: postgres-config\n              key: databaseName\n        - name: SERVICE__PG__USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.username\n        - name: SERVICE__PG__PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.password\n        - name: OAUTH__SERVICES__CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_ID\n        - name: OAUTH__SERVICES__CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_SECRET\n        - name: KEYCLOAK__URL\n          value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443\n        - name: KEYCLOAK__ADMIN_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_USERNAME\n              name: credential-sso\n        - name: KEYCLOAK__ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_PASSWORD\n              name: credential-sso\n        readinessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /readiness\n        livenessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /liveness\n        ports:\n        - containerPort: 8080\n          name: api\n          protocol: TCP\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: client-secret\n        secret:\n          secretName: keycloak-client-secret-services\n",
    "errors": []
  },
  {
    "id": "04992",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-auth-service\n  annotations:\n    app.openshift.io/connects-to: '[{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"name\":\"postgres\"}]'\n  labels:\n    app.kubernetes.io/name: user-auth-service\n    app.kubernetes.io/part-of: device-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: user-auth-service\n      app.kubernetes.io/part-of: device-registry\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: user-auth-service\n        app.kubernetes.io/part-of: device-registry\n    spec:\n      initContainers:\n      - name: wait-for-client-secret\n        image: registry.access.redhat.com/ubi8-minimal:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - \"echo \\\"Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)...\\\"\\\n          \\nwhile test -z \\\"$(cat /etc/client-secret/CLIENT_SECRET)\\\"; do\\n  sleep\\\n          \\ 1\\ndone\\n\"\n        volumeMounts:\n        - mountPath: /etc/client-secret\n          name: client-secret\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: service\n        image: ghcr.io/drogue-iot/user-auth-service:stable\n        imagePullPolicy: Always\n        env:\n        - name: RUST_LOG\n          value: debug\n        - name: BIND_ADDR\n          value: 0.0.0.0:8080\n        - name: HEALTH__BIND_ADDR\n          value: 0.0.0.0:9090\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SERVICE__PG__HOST\n          value: postgres\n        - name: SERVICE__PG__DBNAME\n          valueFrom:\n            configMapKeyRef:\n              name: postgres-config\n              key: databaseName\n        - name: SERVICE__PG__USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.username\n        - name: SERVICE__PG__PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.password\n        - name: OAUTH__SERVICES__CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_ID\n        - name: OAUTH__SERVICES__CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_SECRET\n        - name: KEYCLOAK__URL\n          value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443\n        - name: KEYCLOAK__ADMIN_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_USERNAME\n              name: credential-sso\n        - name: KEYCLOAK__ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_PASSWORD\n              name: credential-sso\n        readinessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /readiness\n        livenessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /liveness\n        ports:\n        - containerPort: 8080\n          name: api\n          protocol: TCP\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: client-secret\n        secret:\n          secretName: keycloak-client-secret-services\n",
    "errors": []
  },
  {
    "id": "04993",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-auth-service\n  annotations:\n    app.openshift.io/connects-to: '[{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"name\":\"postgres\"}]'\n  labels:\n    app.kubernetes.io/name: user-auth-service\n    app.kubernetes.io/part-of: device-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: user-auth-service\n      app.kubernetes.io/part-of: device-registry\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: user-auth-service\n        app.kubernetes.io/part-of: device-registry\n    spec:\n      initContainers:\n      - name: wait-for-client-secret\n        image: registry.access.redhat.com/ubi8-minimal:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - bash\n        - -c\n        - \"echo \\\"Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)...\\\"\\\n          \\nwhile test -z \\\"$(cat /etc/client-secret/CLIENT_SECRET)\\\"; do\\n  sleep\\\n          \\ 1\\ndone\\n\"\n        volumeMounts:\n        - mountPath: /etc/client-secret\n          name: client-secret\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      containers:\n      - name: service\n        image: ghcr.io/drogue-iot/user-auth-service:stable\n        imagePullPolicy: Always\n        env:\n        - name: RUST_LOG\n          value: debug\n        - name: BIND_ADDR\n          value: 0.0.0.0:8080\n        - name: HEALTH__BIND_ADDR\n          value: 0.0.0.0:9090\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: SERVICE__PG__HOST\n          value: postgres\n        - name: SERVICE__PG__DBNAME\n          valueFrom:\n            configMapKeyRef:\n              name: postgres-config\n              key: databaseName\n        - name: SERVICE__PG__USER\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.username\n        - name: SERVICE__PG__PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgres-secret\n              key: admin.password\n        - name: OAUTH__SERVICES__CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_ID\n        - name: OAUTH__SERVICES__CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: keycloak-client-secret-services\n              key: CLIENT_SECRET\n        - name: KEYCLOAK__URL\n          value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443\n        - name: KEYCLOAK__ADMIN_USERNAME\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_USERNAME\n              name: credential-sso\n        - name: KEYCLOAK__ADMIN_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: ADMIN_PASSWORD\n              name: credential-sso\n        readinessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /readiness\n        livenessProbe:\n          initialDelaySeconds: 2\n          periodSeconds: 1\n          timeoutSeconds: 1\n          failureThreshold: 3\n          httpGet:\n            port: 9090\n            path: /liveness\n        ports:\n        - containerPort: 8080\n          name: api\n          protocol: TCP\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 500m\n          requests:\n            cpu: 100m\n            memory: 128Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n      volumes:\n      - name: client-secret\n        secret:\n          secretName: keycloak-client-secret-services\n",
    "errors": []
  },
  {
    "id": "04994",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4427\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04995",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4427\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04996",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4427\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n",
    "errors": []
  },
  {
    "id": "04997",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4427\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04998",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-4427\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n",
    "errors": []
  },
  {
    "id": "04999",
    "policy_id": "read_only_root_fs",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"cluster-keycloak-integration\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  },
  {
    "id": "05000",
    "policy_id": "run_as_non_root",
    "accepted": false,
    "ok_schema": false,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": null,
    "errors": [
      "kubectl dry-run failed: The Job \"cluster-keycloak-integration\" is invalid: spec.template.spec.restartPolicy: Required value: valid values: \"OnFailure\", \"Never\""
    ]
  }
]