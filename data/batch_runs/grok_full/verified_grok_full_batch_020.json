[
  {
    "id": "801",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pulsar-admin\nspec:\n  containers:\n  - name: pulsar-admin\n    image: apachepulsar/pulsar:stable\n    command:\n    - sh\n    - -c\n    args:\n    - 'bin/apply-config-from-env.py conf/client.conf && bin/apply-config-from-env.py\n      conf/pulsar_env.sh && bin/apply-config-from-env.py conf/pulsar_tools_env.sh\n      && sleep 10000000000\n\n      '\n    envFrom:\n    - configMapRef:\n        name: broker-config\n    env:\n    - name: webServiceUrl\n      value: http://broker:8080/\n    - name: brokerServiceUrl\n      value: pulsar://broker:6650/\n    - name: PULSAR_MEM\n      value: '\"-Xms64m -Xmx128m\"'\n    securityContext:\n      readOnlyRootFilesystem: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "802",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pulsar-admin\nspec:\n  containers:\n  - name: pulsar-admin\n    image: apachepulsar/pulsar:stable\n    command:\n    - sh\n    - -c\n    args:\n    - 'bin/apply-config-from-env.py conf/client.conf && bin/apply-config-from-env.py\n      conf/pulsar_env.sh && bin/apply-config-from-env.py conf/pulsar_tools_env.sh\n      && sleep 10000000000\n\n      '\n    envFrom:\n    - configMapRef:\n        name: broker-config\n    env:\n    - name: webServiceUrl\n      value: http://broker:8080/\n    - name: brokerServiceUrl\n      value: pulsar://broker:6650/\n    - name: PULSAR_MEM\n      value: '\"-Xms64m -Xmx128m\"'\n    securityContext:\n      runAsNonRoot: true\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "803",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pulsar-admin\nspec:\n  containers:\n  - name: pulsar-admin\n    image: apachepulsar/pulsar:stable\n    command:\n    - sh\n    - -c\n    args:\n    - 'bin/apply-config-from-env.py conf/client.conf && bin/apply-config-from-env.py\n      conf/pulsar_env.sh && bin/apply-config-from-env.py conf/pulsar_tools_env.sh\n      && sleep 10000000000\n\n      '\n    envFrom:\n    - configMapRef:\n        name: broker-config\n    env:\n    - name: webServiceUrl\n      value: http://broker:8080/\n    - name: brokerServiceUrl\n      value: pulsar://broker:6650/\n    - name: PULSAR_MEM\n      value: '\"-Xms64m -Xmx128m\"'\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "804",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pulsar-admin\nspec:\n  containers:\n  - name: pulsar-admin\n    image: apachepulsar/pulsar:stable\n    command:\n    - sh\n    - -c\n    args:\n    - 'bin/apply-config-from-env.py conf/client.conf && bin/apply-config-from-env.py\n      conf/pulsar_env.sh && bin/apply-config-from-env.py conf/pulsar_tools_env.sh\n      && sleep 10000000000\n\n      '\n    envFrom:\n    - configMapRef:\n        name: broker-config\n    env:\n    - name: webServiceUrl\n      value: http://broker:8080/\n    - name: brokerServiceUrl\n      value: pulsar://broker:6650/\n    - name: PULSAR_MEM\n      value: '\"-Xms64m -Xmx128m\"'\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 256Mi\n    securityContext:\n      privileged: false\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "805",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: open-api-doc\nspec:\n  type: ExternalName\n  externalName: open-api-doc.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "806",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: argocd-metrics\nspec:\n  type: ExternalName\n  externalName: argocd-metrics.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "807",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: drupal\n    appMajor: '8'\n    instance: datasets.lib.unb.ca\n    tier: frontend\n    uri: datasets.lib.unb.ca\n    vcsOwner: unb-libraries\n    vcsRepository: datasets.lib.unb.ca\n    vcsRef: prod\n  name: datasets-lib-unb-ca\n  namespace: prod\nspec:\n  selector:\n    matchLabels:\n      uri: datasets.lib.unb.ca\n  replicas: 1\n  revisionHistoryLimit: 2\n  minReadySeconds: 30\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n  template:\n    metadata:\n      labels:\n        app: drupal\n        appMajor: '8'\n        instance: datasets.lib.unb.ca\n        tier: frontend\n        uri: datasets.lib.unb.ca\n        vcsOwner: unb-libraries\n        vcsRepository: datasets.lib.unb.ca\n        vcsRef: prod\n    spec:\n      nodeSelector:\n        deployenv: prod\n      containers:\n      - name: datasets-lib-unb-ca\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 30\n          timeoutSeconds: 3\n          periodSeconds: 15\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 100\n          timeoutSeconds: 3\n          periodSeconds: 15\n        env:\n        - name: DEPLOY_ENV\n          value: prod\n        - name: MYSQL_HOSTNAME\n          value: drupal-mysql-lib-unb-ca\n        - name: MYSQL_PORT\n          value: '3306'\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql\n              key: root-password\n        - name: NR_INSTALL_KEY\n          valueFrom:\n            secretKeyRef:\n              name: newrelic\n              key: install-key\n        image: '||DEPLOYMENTIMAGE||:stable'\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - mountPath: /app/html/sites/default\n          name: drupal-persistent-storage\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      priorityClassName: med-priority-services\n      imagePullSecrets:\n      - name: github-container-registry-auth\n      restartPolicy: Always\n      volumes:\n      - name: drupal-persistent-storage\n        persistentVolumeClaim:\n          claimName: datasets-lib-unb-ca\n",
    "errors": []
  },
  {
    "id": "808",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: drupal\n    appMajor: '8'\n    instance: datasets.lib.unb.ca\n    tier: frontend\n    uri: datasets.lib.unb.ca\n    vcsOwner: unb-libraries\n    vcsRepository: datasets.lib.unb.ca\n    vcsRef: prod\n  name: datasets-lib-unb-ca\n  namespace: prod\nspec:\n  selector:\n    matchLabels:\n      uri: datasets.lib.unb.ca\n  replicas: 1\n  revisionHistoryLimit: 2\n  minReadySeconds: 30\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n  template:\n    metadata:\n      labels:\n        app: drupal\n        appMajor: '8'\n        instance: datasets.lib.unb.ca\n        tier: frontend\n        uri: datasets.lib.unb.ca\n        vcsOwner: unb-libraries\n        vcsRepository: datasets.lib.unb.ca\n        vcsRef: prod\n    spec:\n      nodeSelector:\n        deployenv: prod\n      containers:\n      - name: datasets-lib-unb-ca\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 30\n          timeoutSeconds: 3\n          periodSeconds: 15\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 100\n          timeoutSeconds: 3\n          periodSeconds: 15\n        env:\n        - name: DEPLOY_ENV\n          value: prod\n        - name: MYSQL_HOSTNAME\n          value: drupal-mysql-lib-unb-ca\n        - name: MYSQL_PORT\n          value: '3306'\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql\n              key: root-password\n        - name: NR_INSTALL_KEY\n          valueFrom:\n            secretKeyRef:\n              name: newrelic\n              key: install-key\n        image: '||DEPLOYMENTIMAGE||:stable'\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - mountPath: /app/html/sites/default\n          name: drupal-persistent-storage\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      priorityClassName: med-priority-services\n      imagePullSecrets:\n      - name: github-container-registry-auth\n      restartPolicy: Always\n      volumes:\n      - name: drupal-persistent-storage\n        persistentVolumeClaim:\n          claimName: datasets-lib-unb-ca\n",
    "errors": []
  },
  {
    "id": "809",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: drupal\n    appMajor: '8'\n    instance: datasets.lib.unb.ca\n    tier: frontend\n    uri: datasets.lib.unb.ca\n    vcsOwner: unb-libraries\n    vcsRepository: datasets.lib.unb.ca\n    vcsRef: prod\n  name: datasets-lib-unb-ca\n  namespace: prod\nspec:\n  selector:\n    matchLabels:\n      uri: datasets.lib.unb.ca\n  replicas: 1\n  revisionHistoryLimit: 2\n  minReadySeconds: 30\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n  template:\n    metadata:\n      labels:\n        app: drupal\n        appMajor: '8'\n        instance: datasets.lib.unb.ca\n        tier: frontend\n        uri: datasets.lib.unb.ca\n        vcsOwner: unb-libraries\n        vcsRepository: datasets.lib.unb.ca\n        vcsRef: prod\n    spec:\n      nodeSelector:\n        deployenv: prod\n      containers:\n      - name: datasets-lib-unb-ca\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 30\n          timeoutSeconds: 3\n          periodSeconds: 15\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 100\n          timeoutSeconds: 3\n          periodSeconds: 15\n        env:\n        - name: DEPLOY_ENV\n          value: prod\n        - name: MYSQL_HOSTNAME\n          value: drupal-mysql-lib-unb-ca\n        - name: MYSQL_PORT\n          value: '3306'\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql\n              key: root-password\n        - name: NR_INSTALL_KEY\n          valueFrom:\n            secretKeyRef:\n              name: newrelic\n              key: install-key\n        image: '||DEPLOYMENTIMAGE||:stable'\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - mountPath: /app/html/sites/default\n          name: drupal-persistent-storage\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      priorityClassName: med-priority-services\n      imagePullSecrets:\n      - name: github-container-registry-auth\n      restartPolicy: Always\n      volumes:\n      - name: drupal-persistent-storage\n        persistentVolumeClaim:\n          claimName: datasets-lib-unb-ca\n",
    "errors": []
  },
  {
    "id": "810",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: drupal\n    appMajor: '8'\n    instance: datasets.lib.unb.ca\n    tier: frontend\n    uri: datasets.lib.unb.ca\n    vcsOwner: unb-libraries\n    vcsRepository: datasets.lib.unb.ca\n    vcsRef: prod\n  name: datasets-lib-unb-ca\n  namespace: prod\nspec:\n  selector:\n    matchLabels:\n      uri: datasets.lib.unb.ca\n  replicas: 1\n  revisionHistoryLimit: 2\n  minReadySeconds: 30\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n  template:\n    metadata:\n      labels:\n        app: drupal\n        appMajor: '8'\n        instance: datasets.lib.unb.ca\n        tier: frontend\n        uri: datasets.lib.unb.ca\n        vcsOwner: unb-libraries\n        vcsRepository: datasets.lib.unb.ca\n        vcsRef: prod\n    spec:\n      nodeSelector:\n        deployenv: prod\n      containers:\n      - name: datasets-lib-unb-ca\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 30\n          timeoutSeconds: 3\n          periodSeconds: 15\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 100\n          timeoutSeconds: 3\n          periodSeconds: 15\n        env:\n        - name: DEPLOY_ENV\n          value: prod\n        - name: MYSQL_HOSTNAME\n          value: drupal-mysql-lib-unb-ca\n        - name: MYSQL_PORT\n          value: '3306'\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql\n              key: root-password\n        - name: NR_INSTALL_KEY\n          valueFrom:\n            secretKeyRef:\n              name: newrelic\n              key: install-key\n        image: '||DEPLOYMENTIMAGE||:stable'\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - mountPath: /app/html/sites/default\n          name: drupal-persistent-storage\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      priorityClassName: med-priority-services\n      imagePullSecrets:\n      - name: github-container-registry-auth\n      restartPolicy: Always\n      volumes:\n      - name: drupal-persistent-storage\n        persistentVolumeClaim:\n          claimName: datasets-lib-unb-ca\n",
    "errors": []
  },
  {
    "id": "811",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: drupal\n    appMajor: '8'\n    instance: datasets.lib.unb.ca\n    tier: frontend\n    uri: datasets.lib.unb.ca\n    vcsOwner: unb-libraries\n    vcsRepository: datasets.lib.unb.ca\n    vcsRef: prod\n  name: datasets-lib-unb-ca\n  namespace: prod\nspec:\n  selector:\n    matchLabels:\n      uri: datasets.lib.unb.ca\n  replicas: 1\n  revisionHistoryLimit: 2\n  minReadySeconds: 30\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n  template:\n    metadata:\n      labels:\n        app: drupal\n        appMajor: '8'\n        instance: datasets.lib.unb.ca\n        tier: frontend\n        uri: datasets.lib.unb.ca\n        vcsOwner: unb-libraries\n        vcsRepository: datasets.lib.unb.ca\n        vcsRef: prod\n    spec:\n      nodeSelector:\n        deployenv: prod\n      containers:\n      - name: datasets-lib-unb-ca\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 30\n          timeoutSeconds: 3\n          periodSeconds: 15\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 80\n          initialDelaySeconds: 100\n          timeoutSeconds: 3\n          periodSeconds: 15\n        env:\n        - name: DEPLOY_ENV\n          value: prod\n        - name: MYSQL_HOSTNAME\n          value: drupal-mysql-lib-unb-ca\n        - name: MYSQL_PORT\n          value: '3306'\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql\n              key: root-password\n        - name: NR_INSTALL_KEY\n          valueFrom:\n            secretKeyRef:\n              name: newrelic\n              key: install-key\n        image: '||DEPLOYMENTIMAGE||:stable'\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - mountPath: /app/html/sites/default\n          name: drupal-persistent-storage\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      priorityClassName: med-priority-services\n      imagePullSecrets:\n      - name: github-container-registry-auth\n      restartPolicy: Always\n      volumes:\n      - name: drupal-persistent-storage\n        persistentVolumeClaim:\n          claimName: datasets-lib-unb-ca\n",
    "errors": []
  },
  {
    "id": "812",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: boskos-metrics\n  labels:\n    app.kubernetes.io/part-of: boskos\n    app: boskos-metrics\n  namespace: boskos\nspec:\n  selector:\n    matchLabels:\n      app: boskos-metrics\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: boskos-metrics\n      namespace: test-pods\n    spec:\n      terminationGracePeriodSeconds: 30\n      containers:\n      - name: metrics\n        image: gcr.io/k8s-staging-boskos/metrics:v20200819-984516e\n        args:\n        - --resource-type=gke-perf-preset,gcp-perf-test-project,gcp-project,gke-e2e-test\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /prometheus\n            port: 8080\n          periodSeconds: 1\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 10\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      tolerations:\n      - key: dedicated\n        operator: Equal\n        value: boskos\n        effect: NoSchedule\n      nodeSelector:\n        prod: boskos\n",
    "errors": []
  },
  {
    "id": "813",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: boskos-metrics\n  labels:\n    app.kubernetes.io/part-of: boskos\n    app: boskos-metrics\n  namespace: boskos\nspec:\n  selector:\n    matchLabels:\n      app: boskos-metrics\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: boskos-metrics\n      namespace: test-pods\n    spec:\n      terminationGracePeriodSeconds: 30\n      containers:\n      - name: metrics\n        image: gcr.io/k8s-staging-boskos/metrics:v20200819-984516e\n        args:\n        - --resource-type=gke-perf-preset,gcp-perf-test-project,gcp-project,gke-e2e-test\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /prometheus\n            port: 8080\n          periodSeconds: 1\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 10\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      tolerations:\n      - key: dedicated\n        operator: Equal\n        value: boskos\n        effect: NoSchedule\n      nodeSelector:\n        prod: boskos\n",
    "errors": []
  },
  {
    "id": "814",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: boskos-metrics\n  labels:\n    app.kubernetes.io/part-of: boskos\n    app: boskos-metrics\n  namespace: boskos\nspec:\n  selector:\n    matchLabels:\n      app: boskos-metrics\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: boskos-metrics\n      namespace: test-pods\n    spec:\n      terminationGracePeriodSeconds: 30\n      containers:\n      - name: metrics\n        image: gcr.io/k8s-staging-boskos/metrics:v20200819-984516e\n        args:\n        - --resource-type=gke-perf-preset,gcp-perf-test-project,gcp-project,gke-e2e-test\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /prometheus\n            port: 8080\n          periodSeconds: 1\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 10\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      tolerations:\n      - key: dedicated\n        operator: Equal\n        value: boskos\n        effect: NoSchedule\n      nodeSelector:\n        prod: boskos\n",
    "errors": []
  },
  {
    "id": "815",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: boskos-metrics\n  labels:\n    app.kubernetes.io/part-of: boskos\n    app: boskos-metrics\n  namespace: boskos\nspec:\n  selector:\n    matchLabels:\n      app: boskos-metrics\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: boskos-metrics\n      namespace: test-pods\n    spec:\n      terminationGracePeriodSeconds: 30\n      containers:\n      - name: metrics\n        image: gcr.io/k8s-staging-boskos/metrics:v20200819-984516e\n        args:\n        - --resource-type=gke-perf-preset,gcp-perf-test-project,gcp-project,gke-e2e-test\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /prometheus\n            port: 8080\n          periodSeconds: 1\n          timeoutSeconds: 1\n          successThreshold: 1\n          failureThreshold: 10\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      tolerations:\n      - key: dedicated\n        operator: Equal\n        value: boskos\n        effect: NoSchedule\n      nodeSelector:\n        prod: boskos\n",
    "errors": []
  },
  {
    "id": "816",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      serviceAccountName: statusreconciler\n      terminationGracePeriodSeconds: 180\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20210414-378dc3ffc3\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --continue-on-error=true\n        - --plugin-config=/etc/plugins/plugins.yaml\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --job-config-path=/etc/job-config\n        - --denylist=kubernetes/kubernetes\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "817",
    "policy_id": "non_existent_service_account",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      serviceAccountName: default\n      terminationGracePeriodSeconds: 180\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20210414-378dc3ffc3\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --continue-on-error=true\n        - --plugin-config=/etc/plugins/plugins.yaml\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --job-config-path=/etc/job-config\n        - --denylist=kubernetes/kubernetes\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "818",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      serviceAccountName: statusreconciler\n      terminationGracePeriodSeconds: 180\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20210414-378dc3ffc3\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --continue-on-error=true\n        - --plugin-config=/etc/plugins/plugins.yaml\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --job-config-path=/etc/job-config\n        - --denylist=kubernetes/kubernetes\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "819",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      serviceAccountName: statusreconciler\n      terminationGracePeriodSeconds: 180\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20210414-378dc3ffc3\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --continue-on-error=true\n        - --plugin-config=/etc/plugins/plugins.yaml\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --job-config-path=/etc/job-config\n        - --denylist=kubernetes/kubernetes\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "820",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: default\n  name: statusreconciler\n  labels:\n    app: statusreconciler\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: statusreconciler\n  template:\n    metadata:\n      labels:\n        app: statusreconciler\n    spec:\n      serviceAccountName: statusreconciler\n      terminationGracePeriodSeconds: 180\n      containers:\n      - name: statusreconciler\n        image: gcr.io/k8s-prow/status-reconciler:v20210414-378dc3ffc3\n        imagePullPolicy: Always\n        args:\n        - --dry-run=false\n        - --continue-on-error=true\n        - --plugin-config=/etc/plugins/plugins.yaml\n        - --config-path=/etc/config/config.yaml\n        - --github-token-path=/etc/github/oauth\n        - --github-endpoint=http://ghproxy\n        - --github-endpoint=https://api.github.com\n        - --job-config-path=/etc/job-config\n        - --denylist=kubernetes/kubernetes\n        volumeMounts:\n        - name: oauth\n          mountPath: /etc/github\n          readOnly: true\n        - name: config\n          mountPath: /etc/config\n          readOnly: true\n        - name: job-config\n          mountPath: /etc/job-config\n          readOnly: true\n        - name: plugins\n          mountPath: /etc/plugins\n          readOnly: true\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      volumes:\n      - name: oauth\n        secret:\n          secretName: oauth-token\n      - name: config\n        configMap:\n          name: config\n      - name: job-config\n        configMap:\n          name: job-config\n      - name: plugins\n        configMap:\n          name: plugins\n",
    "errors": []
  },
  {
    "id": "821",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: kubwz0un1-cffc\n  labels:\n    app: kubwz0un1-cffc\nspec:\n  type: ExternalName\n  externalName: kubwz0un1-cffc.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "822",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  name: elasticsearch\n  labels:\n    component: elasticsearch\n    role: data\n  annotations:\n    cloud.google.com/load-balancer-type: Internal\nspec:\n  type: ExternalName\n  externalName: elasticsearch.default.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "823",
    "policy_id": "dangling_service",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    getambassador.io/config: \"---\\napiVersion: ambassador/v0\\nkind:  Mapping\\nname:\\\n      \\ webapp_mapping\\nprefix: /jupyter/\\nservice: jupyter-web-app-service.kubeflow\\n\\\n      add_request_headers:\\n  x-forwarded-prefix: /jupyter\"\n  labels:\n    app: jupyter-web-app\n    app.kubernetes.io/component: jupyter-web-app\n    app.kubernetes.io/name: jupyter-web-app\n    kustomize.component: jupyter-web-app\n    run: jupyter-web-app\n  name: jupyter-web-app-service\n  namespace: kubeflow\nspec:\n  type: ExternalName\n  externalName: jupyter-web-app-service.kubeflow.svc.cluster.local\n",
    "errors": []
  },
  {
    "id": "824",
    "policy_id": "job_ttl_after_finished",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "kind: Job\napiVersion: batch/v1\nmetadata:\n  name: holder-vcs-add-profiles\nspec:\n  template:\n    spec:\n      volumes:\n      - name: script\n        configMap:\n          name: holder-vcs-add-profiles-script\n      restartPolicy: Never\n      initContainers:\n      - name: wait\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - -c\n        - sleep 5\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: healthcheck-ready\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - 'while [[ \"$(wget -T 5 -S --spider http://${HOLDER_VCS_SERVICE_HOST}/healthcheck\n          2>&1 | grep ''200 OK'')\" == \"\" ]];\n\n          do echo \"waiting for endpoint\";\n\n          sleep 5;\n\n          done;\n\n          '\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      containers:\n      - name: holder-vcs-add-profiles\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - /opt/vcs_holder_configure.sh\n        volumeMounts:\n        - name: script\n          mountPath: /opt\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n  ttlSecondsAfterFinished: 3600\n",
    "errors": []
  },
  {
    "id": "825",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "kind: Job\napiVersion: batch/v1\nmetadata:\n  name: holder-vcs-add-profiles\nspec:\n  template:\n    spec:\n      volumes:\n      - name: script\n        configMap:\n          name: holder-vcs-add-profiles-script\n      restartPolicy: Never\n      initContainers:\n      - name: wait\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - -c\n        - sleep 5\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: healthcheck-ready\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - 'while [[ \"$(wget -T 5 -S --spider http://${HOLDER_VCS_SERVICE_HOST}/healthcheck\n          2>&1 | grep ''200 OK'')\" == \"\" ]];\n\n          do echo \"waiting for endpoint\";\n\n          sleep 5;\n\n          done;\n\n          '\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      containers:\n      - name: holder-vcs-add-profiles\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - /opt/vcs_holder_configure.sh\n        volumeMounts:\n        - name: script\n          mountPath: /opt\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "826",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "kind: Job\napiVersion: batch/v1\nmetadata:\n  name: holder-vcs-add-profiles\nspec:\n  template:\n    spec:\n      volumes:\n      - name: script\n        configMap:\n          name: holder-vcs-add-profiles-script\n      restartPolicy: Never\n      initContainers:\n      - name: wait\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - -c\n        - sleep 5\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: healthcheck-ready\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - 'while [[ \"$(wget -T 5 -S --spider http://${HOLDER_VCS_SERVICE_HOST}/healthcheck\n          2>&1 | grep ''200 OK'')\" == \"\" ]];\n\n          do echo \"waiting for endpoint\";\n\n          sleep 5;\n\n          done;\n\n          '\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      containers:\n      - name: holder-vcs-add-profiles\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - /opt/vcs_holder_configure.sh\n        volumeMounts:\n        - name: script\n          mountPath: /opt\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "827",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "kind: Job\napiVersion: batch/v1\nmetadata:\n  name: holder-vcs-add-profiles\nspec:\n  template:\n    spec:\n      volumes:\n      - name: script\n        configMap:\n          name: holder-vcs-add-profiles-script\n      restartPolicy: Never\n      initContainers:\n      - name: wait\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - -c\n        - sleep 5\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      - name: healthcheck-ready\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - 'while [[ \"$(wget -T 5 -S --spider http://${HOLDER_VCS_SERVICE_HOST}/healthcheck\n          2>&1 | grep ''200 OK'')\" == \"\" ]];\n\n          do echo \"waiting for endpoint\";\n\n          sleep 5;\n\n          done;\n\n          '\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n      containers:\n      - name: holder-vcs-add-profiles\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - /opt/vcs_holder_configure.sh\n        volumeMounts:\n        - name: script\n          mountPath: /opt\n        securityContext:\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          privileged: false\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "828",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "kind: Job\napiVersion: batch/v1\nmetadata:\n  name: holder-vcs-add-profiles\nspec:\n  template:\n    spec:\n      volumes:\n      - name: script\n        configMap:\n          name: holder-vcs-add-profiles-script\n      restartPolicy: Never\n      initContainers:\n      - name: wait\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - -c\n        - sleep 5\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: healthcheck-ready\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - 'while [[ \"$(wget -T 5 -S --spider http://${HOLDER_VCS_SERVICE_HOST}/healthcheck\n          2>&1 | grep ''200 OK'')\" == \"\" ]];\n\n          do echo \"waiting for endpoint\";\n\n          sleep 5;\n\n          done;\n\n          '\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: holder-vcs-add-profiles\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - /opt/vcs_holder_configure.sh\n        volumeMounts:\n        - name: script\n          mountPath: /opt\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "829",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "kind: Job\napiVersion: batch/v1\nmetadata:\n  name: holder-vcs-add-profiles\nspec:\n  template:\n    spec:\n      volumes:\n      - name: script\n        configMap:\n          name: holder-vcs-add-profiles-script\n      restartPolicy: Never\n      initContainers:\n      - name: wait\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - -c\n        - sleep 5\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: healthcheck-ready\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - 'while [[ \"$(wget -T 5 -S --spider http://${HOLDER_VCS_SERVICE_HOST}/healthcheck\n          2>&1 | grep ''200 OK'')\" == \"\" ]];\n\n          do echo \"waiting for endpoint\";\n\n          sleep 5;\n\n          done;\n\n          '\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: holder-vcs-add-profiles\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - /opt/vcs_holder_configure.sh\n        volumeMounts:\n        - name: script\n          mountPath: /opt\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "830",
    "policy_id": "read_only_root_fs",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "kind: Job\napiVersion: batch/v1\nmetadata:\n  name: holder-vcs-add-profiles\nspec:\n  template:\n    spec:\n      volumes:\n      - name: script\n        configMap:\n          name: holder-vcs-add-profiles-script\n      restartPolicy: Never\n      initContainers:\n      - name: wait\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - -c\n        - sleep 5\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: healthcheck-ready\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - 'while [[ \"$(wget -T 5 -S --spider http://${HOLDER_VCS_SERVICE_HOST}/healthcheck\n          2>&1 | grep ''200 OK'')\" == \"\" ]];\n\n          do echo \"waiting for endpoint\";\n\n          sleep 5;\n\n          done;\n\n          '\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: holder-vcs-add-profiles\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - /opt/vcs_holder_configure.sh\n        volumeMounts:\n        - name: script\n          mountPath: /opt\n        securityContext:\n          readOnlyRootFilesystem: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "831",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "kind: Job\napiVersion: batch/v1\nmetadata:\n  name: holder-vcs-add-profiles\nspec:\n  template:\n    spec:\n      volumes:\n      - name: script\n        configMap:\n          name: holder-vcs-add-profiles-script\n      restartPolicy: Never\n      initContainers:\n      - name: wait\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - -c\n        - sleep 5\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: healthcheck-ready\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - 'while [[ \"$(wget -T 5 -S --spider http://${HOLDER_VCS_SERVICE_HOST}/healthcheck\n          2>&1 | grep ''200 OK'')\" == \"\" ]];\n\n          do echo \"waiting for endpoint\";\n\n          sleep 5;\n\n          done;\n\n          '\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: holder-vcs-add-profiles\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - /opt/vcs_holder_configure.sh\n        volumeMounts:\n        - name: script\n          mountPath: /opt\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "832",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "kind: Job\napiVersion: batch/v1\nmetadata:\n  name: holder-vcs-add-profiles\nspec:\n  template:\n    spec:\n      volumes:\n      - name: script\n        configMap:\n          name: holder-vcs-add-profiles-script\n      restartPolicy: Never\n      initContainers:\n      - name: wait\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - -c\n        - sleep 5\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: healthcheck-ready\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - 'while [[ \"$(wget -T 5 -S --spider http://${HOLDER_VCS_SERVICE_HOST}/healthcheck\n          2>&1 | grep ''200 OK'')\" == \"\" ]];\n\n          do echo \"waiting for endpoint\";\n\n          sleep 5;\n\n          done;\n\n          '\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: holder-vcs-add-profiles\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - /opt/vcs_holder_configure.sh\n        volumeMounts:\n        - name: script\n          mountPath: /opt\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "833",
    "policy_id": "run_as_non_root",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "kind: Job\napiVersion: batch/v1\nmetadata:\n  name: holder-vcs-add-profiles\nspec:\n  template:\n    spec:\n      volumes:\n      - name: script\n        configMap:\n          name: holder-vcs-add-profiles-script\n      restartPolicy: Never\n      initContainers:\n      - name: wait\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - -c\n        - sleep 5\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: healthcheck-ready\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - 'while [[ \"$(wget -T 5 -S --spider http://${HOLDER_VCS_SERVICE_HOST}/healthcheck\n          2>&1 | grep ''200 OK'')\" == \"\" ]];\n\n          do echo \"waiting for endpoint\";\n\n          sleep 5;\n\n          done;\n\n          '\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: holder-vcs-add-profiles\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - /opt/vcs_holder_configure.sh\n        volumeMounts:\n        - name: script\n          mountPath: /opt\n        securityContext:\n          runAsNonRoot: true\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "834",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "kind: Job\napiVersion: batch/v1\nmetadata:\n  name: holder-vcs-add-profiles\nspec:\n  template:\n    spec:\n      volumes:\n      - name: script\n        configMap:\n          name: holder-vcs-add-profiles-script\n      restartPolicy: Never\n      initContainers:\n      - name: wait\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - -c\n        - sleep 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: healthcheck-ready\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - 'while [[ \"$(wget -T 5 -S --spider http://${HOLDER_VCS_SERVICE_HOST}/healthcheck\n          2>&1 | grep ''200 OK'')\" == \"\" ]];\n\n          do echo \"waiting for endpoint\";\n\n          sleep 5;\n\n          done;\n\n          '\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: holder-vcs-add-profiles\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - /opt/vcs_holder_configure.sh\n        volumeMounts:\n        - name: script\n          mountPath: /opt\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "835",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "kind: Job\napiVersion: batch/v1\nmetadata:\n  name: holder-vcs-add-profiles\nspec:\n  template:\n    spec:\n      volumes:\n      - name: script\n        configMap:\n          name: holder-vcs-add-profiles-script\n      restartPolicy: Never\n      initContainers:\n      - name: wait\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - -c\n        - sleep 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: healthcheck-ready\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - 'while [[ \"$(wget -T 5 -S --spider http://${HOLDER_VCS_SERVICE_HOST}/healthcheck\n          2>&1 | grep ''200 OK'')\" == \"\" ]];\n\n          do echo \"waiting for endpoint\";\n\n          sleep 5;\n\n          done;\n\n          '\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: holder-vcs-add-profiles\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - /opt/vcs_holder_configure.sh\n        volumeMounts:\n        - name: script\n          mountPath: /opt\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "836",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "kind: Job\napiVersion: batch/v1\nmetadata:\n  name: holder-vcs-add-profiles\nspec:\n  template:\n    spec:\n      volumes:\n      - name: script\n        configMap:\n          name: holder-vcs-add-profiles-script\n      restartPolicy: Never\n      initContainers:\n      - name: wait\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - -c\n        - sleep 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: healthcheck-ready\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - 'while [[ \"$(wget -T 5 -S --spider http://${HOLDER_VCS_SERVICE_HOST}/healthcheck\n          2>&1 | grep ''200 OK'')\" == \"\" ]];\n\n          do echo \"waiting for endpoint\";\n\n          sleep 5;\n\n          done;\n\n          '\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: holder-vcs-add-profiles\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - /opt/vcs_holder_configure.sh\n        volumeMounts:\n        - name: script\n          mountPath: /opt\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "837",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "kind: Job\napiVersion: batch/v1\nmetadata:\n  name: holder-vcs-add-profiles\nspec:\n  template:\n    spec:\n      volumes:\n      - name: script\n        configMap:\n          name: holder-vcs-add-profiles-script\n      restartPolicy: Never\n      initContainers:\n      - name: wait\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - -c\n        - sleep 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: healthcheck-ready\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - 'while [[ \"$(wget -T 5 -S --spider http://${HOLDER_VCS_SERVICE_HOST}/healthcheck\n          2>&1 | grep ''200 OK'')\" == \"\" ]];\n\n          do echo \"waiting for endpoint\";\n\n          sleep 5;\n\n          done;\n\n          '\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: holder-vcs-add-profiles\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - /opt/vcs_holder_configure.sh\n        volumeMounts:\n        - name: script\n          mountPath: /opt\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "838",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "kind: Job\napiVersion: batch/v1\nmetadata:\n  name: holder-vcs-add-profiles\nspec:\n  template:\n    spec:\n      volumes:\n      - name: script\n        configMap:\n          name: holder-vcs-add-profiles-script\n      restartPolicy: Never\n      initContainers:\n      - name: wait\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - -c\n        - sleep 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: healthcheck-ready\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - 'while [[ \"$(wget -T 5 -S --spider http://${HOLDER_VCS_SERVICE_HOST}/healthcheck\n          2>&1 | grep ''200 OK'')\" == \"\" ]];\n\n          do echo \"waiting for endpoint\";\n\n          sleep 5;\n\n          done;\n\n          '\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: holder-vcs-add-profiles\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - /opt/vcs_holder_configure.sh\n        volumeMounts:\n        - name: script\n          mountPath: /opt\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "839",
    "policy_id": "set_requests_limits",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "kind: Job\napiVersion: batch/v1\nmetadata:\n  name: holder-vcs-add-profiles\nspec:\n  template:\n    spec:\n      volumes:\n      - name: script\n        configMap:\n          name: holder-vcs-add-profiles-script\n      restartPolicy: Never\n      initContainers:\n      - name: wait\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - -c\n        - sleep 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      - name: healthcheck-ready\n        image: busybox:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - -c\n        - 'while [[ \"$(wget -T 5 -S --spider http://${HOLDER_VCS_SERVICE_HOST}/healthcheck\n          2>&1 | grep ''200 OK'')\" == \"\" ]];\n\n          do echo \"waiting for endpoint\";\n\n          sleep 5;\n\n          done;\n\n          '\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n      containers:\n      - name: holder-vcs-add-profiles\n        image: alpine:stable\n        imagePullPolicy: IfNotPresent\n        command:\n        - /bin/sh\n        args:\n        - /opt/vcs_holder_configure.sh\n        volumeMounts:\n        - name: script\n          mountPath: /opt\n        resources:\n          requests:\n            cpu: 100m\n            memory: 128Mi\n          limits:\n            cpu: 500m\n            memory: 256Mi\n        securityContext:\n          privileged: false\n          capabilities:\n            drop:\n            - NET_RAW\n            - NET_ADMIN\n            - SYS_ADMIN\n            - SYS_MODULE\n            - SYS_PTRACE\n            - SYS_CHROOT\n          allowPrivilegeEscalation: false\n",
    "errors": []
  },
  {
    "id": "840",
    "policy_id": "no_latest_tag",
    "accepted": true,
    "ok_schema": true,
    "ok_policy": true,
    "ok_safety": true,
    "ok_rescan": true,
    "patched_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: image-demo-654\nspec:\n  containers:\n  - name: nginx\n    image: nginx:stable\n    securityContext:\n      capabilities:\n        drop:\n        - NET_RAW\n        - NET_ADMIN\n        - SYS_ADMIN\n        - SYS_MODULE\n        - SYS_PTRACE\n        - SYS_CHROOT\n      privileged: false\n      allowPrivilegeEscalation: false\n",
    "errors": []
  }
]